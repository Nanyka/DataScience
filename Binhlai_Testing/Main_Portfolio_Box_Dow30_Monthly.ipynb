{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb9q2_QZgdNk"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch\n",
    "## BinhLai_Dataset_Monthly\n",
    "Network with 128 neutrons and 2 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Check Additional Packages](#1.1)\n",
    "    * [2.2. Import Packages](#1.2)\n",
    "    * [2.3. Create Folders & Relevant Configurations¶](#1.3)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess fundamental data](#3)        \n",
    "    * [4.1. Import the financial data](#3.1)\n",
    "    * [4.2. Specify items needed to calculate financial ratios](#3.2)\n",
    "    * [4.3. Turn the final_ratios to daily basis](#3.3)\n",
    "    * [4.4. Merge stock price data and ratios into one dataframe](#3.4)\n",
    "    * [4.5. Finish data preparation](#3.5)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. Set up the training environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Train DRL Agent](#5)  \n",
    "* [7.Backtest Our Strategy](#6)  \n",
    "    * [7.1. BackTest with DJIA](#6.1)\n",
    "    * [7.2. BackTest with Buy&Hold Strategy](#6.2)\n",
    "* [8.Save & load model](#7)\n",
    "    * [8.1. Save model](#7.1)\n",
    "    * [8.2. Load model](#7.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If continuing the previous training, jump to [**this point**](#8.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "<a id='1.1'></a>\n",
    "## 2.1. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "import math\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "# from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Create Folders & Relevant Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TEST_END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "TRAIN_START_DATE = '2000-01-01'\n",
    "TRAIN_END_DATE = '2021-01-01'\n",
    "TEST_START_DATE = '2021-01-01'\n",
    "TEST_END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Load price data from csv file\n",
    "tic_dir = './' + DATA_SAVE_DIR + '/sp500_price_monthly.csv'\n",
    "df = pd.read_csv(tic_dir,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is available locally, we can skip downloading steps and jump directly to part [**4.5.Finish data preparation**](#3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Price Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "0a5b0405-7c4f-4afd-c3e1-1dabd55c81fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download data from YFinance\n",
    "# tic_dir = './' + DATA_SAVE_DIR + '/sp500_ticker.csv'\n",
    "# tic_list = pd.read_csv(tic_dir,index_col=0)\n",
    "# SP_500_TICKER = np.array(tic_list.tic).tolist()\n",
    "# df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "#                      end_date = TEST_END_DATE,\n",
    "#                      ticker_list = SP_500_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GiRuFOTOtj1Y",
    "outputId": "402874c0-b13f-437b-a67f-a83f88de66eb"
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DSw4ZEzVtj1Z",
    "outputId": "94617d16-432c-40eb-f758-16d2fdab09e0"
   },
   "outputs": [],
   "source": [
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "73944c23-5a4e-49f8-b9e5-da382b4fc7f5"
   },
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "87cca0b1-8d3c-4a61-e061-ea0d9989daa1"
   },
   "outputs": [],
   "source": [
    "# df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2vryMsdNL9H",
    "outputId": "6691ba9b-e613-412b-dba5-dee592bb0ff2"
   },
   "outputs": [],
   "source": [
    "# len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcNyXa7RNPrF",
    "outputId": "edb04575-9b82-4d5e-f13a-55c884214725"
   },
   "outputs": [],
   "source": [
    "# df.tic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "<a id='3'></a>\n",
    "# Part 4: Preprocess fundamental data\n",
    "- Import finanical data downloaded from Alpha Vantage\n",
    "- Preprocess the dataset and calculate financial ratios\n",
    "- Turn yearly ratio into daily basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "## 4.1 Import the financial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define configurations of the collecting data & download data via Alpha Vantage API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# api_key = 'GZWRUSYXT18ZTR6C'\n",
    "# features_cols = ['fiscalDateEnding','totalRevenue','costOfRevenue','sellingGeneralAndAdministrative','researchAndDevelopment','depreciation','interestExpense','totalCurrentLiabilities','incomeTaxExpense','netIncome','commonStockSharesOutstanding','cashAndCashEquivalentsAtCarryingValue','cashAndShortTermInvestments','operatingCashflow','totalLiabilities','inventory','currentNetReceivables','propertyPlantEquipment','capitalExpenditures','longTermInvestments','totalShareholderEquity','longTermDebt','retainedEarnings','dividendPayoutCommonStock','paymentsForRepurchaseOfCommonStock','treasuryStock','currentLongTermDebt']\n",
    "# price_cols = ['open','high','low','close','volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download fundamental data from financial reports by ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_fundamental(ticket):\n",
    "#     # Download income statement\n",
    "#     url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_is = r.json()\n",
    "\n",
    "#     # Download balance sheet\n",
    "#     url = f'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_bs = r.json()\n",
    "\n",
    "#     # Download cash flow\n",
    "#     url = f'https://www.alphavantage.co/query?function=CASH_FLOW&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_cf = r.json()\n",
    "\n",
    "#     df_is = pd.json_normalize(data_is['annualReports'])\n",
    "#     df_bs = pd.json_normalize(data_bs['annualReports'])\n",
    "#     df_cf = pd.json_normalize(data_cf['annualReports'])\n",
    "\n",
    "#     merged_df = df_is.merge(df_bs).merge(df_cf)\n",
    "#     merged_df['tic'] = ticket\n",
    "#     merged_df = merged_df[['tic']+features_cols]\n",
    "#     merged_df['fiscalDateEnding'] = pd.to_datetime(merged_df.fiscalDateEnding,format='mixed')\n",
    "\n",
    "#     return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download stock price by ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_price(ticket):\n",
    "#     url = f'https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_monthly_price = r.json()\n",
    "\n",
    "#     price_monthly = pd.DataFrame.from_dict(data_monthly_price['Monthly Time Series'], orient='index')\n",
    "#     price_monthly.columns = price_cols\n",
    "#     price_monthly['fiscalDateEnding'] = pd.to_datetime(price_monthly.index,format='mixed')\n",
    "#     price_monthly.reset_index(inplace=True,drop=True)\n",
    "#     price_monthly = price_monthly[['fiscalDateEnding','open','high','low','close','volume']]\n",
    "#     return price_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to merge monthly stock price into yearly fundamental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_price_to_df(merged_df,price_monthly):\n",
    "#     merged_df['year'] = merged_df.fiscalDateEnding.dt.year\n",
    "#     merged_df['month'] = merged_df.fiscalDateEnding.dt.month\n",
    "#     price_monthly['year'] = price_monthly.fiscalDateEnding.dt.year\n",
    "#     price_monthly['month'] = price_monthly.fiscalDateEnding.dt.month\n",
    "#     merged_final = pd.merge(merged_df,price_monthly,how=\"left\",on=['year','month'])\n",
    "#     merged_final.drop(columns=['year','month','fiscalDateEnding_y'],inplace=True)\n",
    "#     merged_final = df_final.rename(columns={'fiscalDateEnding_x': 'date'})\n",
    "#     merged_final['tic'] = ticket\n",
    "\n",
    "#     merged_columns = [merged_final.columns[-1]]\n",
    "#     for i in range(0,len(merged_final.columns)-1):\n",
    "#         merged_columns.append(merged_final.columns[i])\n",
    "#     merged_final = merged_final[merged_columns]\n",
    "    \n",
    "#     return merged_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_tics = SP_500_TICKER[453:]\n",
    "# print(download_tics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data = pd.DataFrame()\n",
    "\n",
    "# for ticket in download_tics:\n",
    "#     df_fund = collect_fundamental(ticket)\n",
    "#     fund_data = pd.concat([fund_data, df_fund], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data.to_csv('sp500_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dropped tickers which are not available data to download from Alpha Vantage\n",
    "\n",
    "# tics_1 = pd.DataFrame()\n",
    "# tics_2 = pd.DataFrame()\n",
    "# tics_1['tic'] = df.tic.unique()\n",
    "# tics_2['tic'] = fund_data.tic.unique()\n",
    "\n",
    "# merged_df = tics_1.merge(tics_2, how='outer', indicator=True)\n",
    "# unique_in_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "# unique_in_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check reach download limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol=IBM&apikey=GZWRUSYXT18ZTR6C'\n",
    "# r = requests.get(url)\n",
    "# data_is = r.json()\n",
    "# data_is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data = pd.read_csv('./' + DATA_SAVE_DIR + '/sp500_fundamental.csv',index_col=0)\n",
    "# # fund_data = fund_data.rename(columns={'fiscalDateEnding_x':'date'})\n",
    "# fund_data['date'] = pd.to_datetime(fund_data.date,format='mixed')\n",
    "# fund_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTIL TOOL: merge yearly fundamental data to daily stock price\n",
    "\n",
    "# start_date = df.iloc[0].date\n",
    "# end_date = df.iloc[-1].date\n",
    "# date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# date_range = pd.DataFrame(date_range)\n",
    "# date_range.columns = ['date']\n",
    "\n",
    "# fund_data = fund_data.rename(columns={'fiscalDateEnding':'date'})\n",
    "# fund_data['date'] = pd.to_datetime(fund_data.date,format='mixed')\n",
    "\n",
    "# fund_data_with_price = pd.DataFrame()\n",
    "# for ticket in fund_data.tic.unique():\n",
    "#     price_by_ticket = df[df.tic == ticket]\n",
    "#     price_by_ticket['date'] = pd.to_datetime(price_by_ticket['date'],format='mixed')\n",
    "#     price_by_ticket = pd.merge(date_range,price_by_ticket,how='left')\n",
    "#     price_by_ticket.bfill(inplace=True)\n",
    "#     price_by_ticket = pd.merge(fund_data.loc[fund_data.tic==ticket],price_by_ticket,how='left',on=['date'])\n",
    "#     price_by_ticket.drop(columns=['tic_y','day'],inplace=True,axis=0)\n",
    "#     price_by_ticket = price_by_ticket.rename(columns={'tic_x':'tic'})\n",
    "#     fund_data_with_price = pd.concat([fund_data_with_price, price_by_ticket], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning ####\n",
    "Refine the data before computing fundamental ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(fund_data.info(),'\\n')\n",
    "# print(fund_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company with zero totalRevenue might cause problems for computing ratios while it is the denominator in some formulars.<br>\n",
    "Deleting all tickers containing this issue is a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_revenue_tics = fund_data[fund_data.totalRevenue == 0].tic.unique()\n",
    "# fund_data = fund_data[~fund_data.tic.isin(zero_revenue_tics)]\n",
    "# fund_data[fund_data.totalRevenue == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While removing zero revenue data was neccessary, other columns with zero values might indicate some potential issues that require further investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_nan = fund_data.eq(0).any()\n",
    "# column_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data = fund_data.fillna(0)\n",
    "# for i in fund_data.columns:\n",
    "#     print(i,'\\n',fund_data[i].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Compute fundamental ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define support functions before computing fundamental ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to count positive values within a window\n",
    "# def count_positives(window):\n",
    "#   return window[window > 0].count()\n",
    "\n",
    "# def count_positives_window(data,k):\n",
    "#     df = pd.DataFrame(data, columns=['values'])\n",
    "\n",
    "#     # Create a new column with the adjusted positive count (using a shifted window)\n",
    "#     df['positive_count'] = df['values'].rolling(window=k, min_periods=1).apply(count_positives)\n",
    "\n",
    "#     # Set positive_count of the first k rows to positive_count of row k\n",
    "#     df.loc[:k-1,'positive_count'] = df.loc[k-1].positive_count\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to min value within a window\n",
    "# def get_min(window):\n",
    "#   return window.min()\n",
    "\n",
    "# def min_in_window(data,k):\n",
    "#     df = pd.DataFrame(data, columns=['values'])\n",
    "\n",
    "#     # Create a new column with the min in the window (using a shifted window)\n",
    "#     df['min'] = df['values'].rolling(window=k, min_periods=1).apply(get_min)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, data and supporting functions are ready for computing fundamental ratios required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_fund_ratios(df_final):\n",
    "#     pos_count_window = 10  # number of years to look back for count_positive_profit\n",
    "#     min_ebit_window = 4  # number of years to look back for min_ebit\n",
    "    \n",
    "#     gross_income = df_final.totalRevenue - df_final.costOfRevenue\n",
    "#     ebit = gross_income - df_final.sellingGeneralAndAdministrative\n",
    "#     profit = ebit - df_final.interestExpense - df_final.incomeTaxExpense\n",
    "#     market_equity = df_final.commonStockSharesOutstanding * df_final.close\n",
    "#     market_asset = df_final.totalLiabilities + market_equity\n",
    "    \n",
    "#     # Gross profit margin\n",
    "#     gross_profit_margin = (gross_income/df_final.totalRevenue).to_frame('gross_profit_margin')\n",
    "    \n",
    "#     # SGA Expense / Gross Profit\n",
    "#     sga_ratio = (df_final.sellingGeneralAndAdministrative/gross_income).to_frame('sga_ratio')\n",
    "    \n",
    "#     # Depreciation / Gross Profit\n",
    "#     dep_ratio = (df_final.depreciation/gross_income).to_frame('dep_ratio')\n",
    "    \n",
    "#     # EBIT / Bond interest\n",
    "#     ebit_on_int = (ebit/df_final.interestExpense).to_frame('ebit_on_int')\n",
    "    \n",
    "#     # Profit margin\n",
    "#     profit_margin = (profit/df_final.totalRevenue).to_frame('profit_margin')\n",
    "    \n",
    "#     # Amount of positive profit within a window\n",
    "#     count_positive_profit = count_positives_window(profit,pos_count_window)\n",
    "#     count_positive_profit = count_positive_profit['positive_count'].to_frame('count_positive_profit')\n",
    "    \n",
    "#     # Cash And Short Term Investments / Total Liabilities\n",
    "#     csti_on_liabilities = (df_final.cashAndShortTermInvestments/df_final.totalLiabilities).to_frame('csti_on_liabilities')\n",
    "    \n",
    "#     # Inventory / EBIT\n",
    "#     inventory_on_ebit = (df_final.inventory / ebit).to_frame('inventory_on_ebit')\n",
    "    \n",
    "#     # Receivable / Revenue\n",
    "#     receivable_on_rev = (df_final.currentNetReceivables / df_final.totalRevenue).to_frame('receivable_on_rev')\n",
    "    \n",
    "#     # ROA\n",
    "#     roa = (profit / market_asset).to_frame('roa')\n",
    "    \n",
    "#     # ROE\n",
    "#     roe = (profit / market_equity).to_frame('roe')\n",
    "    \n",
    "#     # Long-term debt / minEBIT\n",
    "#     min_ebit = min_in_window(ebit,min_ebit_window)['min']\n",
    "#     debt_on_min_ebit = (df_final.longTermDebt / min_ebit).to_frame('debt_on_min_ebit')\n",
    "    \n",
    "#     # Total Liabilities / Total Equity\n",
    "#     liabilities_on_equity = (df_final.totalLiabilities / market_equity).to_frame('liabilities_on_equity')\n",
    "    \n",
    "#     # Capital Expenditures / EBIT\n",
    "#     capital_cost_on_ebit = (df_final.capitalExpenditures / ebit).to_frame('capital_cost_on_ebit')\n",
    "    \n",
    "#     # EPS / MP\n",
    "#     eps = profit / df_final.commonStockSharesOutstanding\n",
    "#     eps_on_mp = (eps / df_final.close).to_frame('eps_on_mp')\n",
    "    \n",
    "#     # Cash and Stock Dividend & Repurchase Common / MP\n",
    "#     dividend_on_mp = ((df_final.dividendPayoutCommonStock + df_final.paymentsForRepurchaseOfCommonStock) / df_final.close).to_frame('dividend_on_mp')\n",
    "    \n",
    "#     # MP / BV\n",
    "#     mp_on_bv = (df_final.close / (df_final.cashAndShortTermInvestments + df_final.currentNetReceivables*0.8 +df_final.inventory*0.5 + df_final.propertyPlantEquipment*0.2 + df_final.longTermInvestments - df_final.totalLiabilities)).to_frame('mp_on_bv')\n",
    "\n",
    "#     # Create a dataframe that merges all the ratios\n",
    "#     ratios = pd.concat([df_final.date,df_final.tic,gross_profit_margin,sga_ratio,dep_ratio,\n",
    "#                     ebit_on_int,profit_margin,count_positive_profit,csti_on_liabilities,\n",
    "#                     inventory_on_ebit,receivable_on_rev,roa,roe,debt_on_min_ebit,\n",
    "#                    liabilities_on_equity,capital_cost_on_ebit,eps_on_mp,dividend_on_mp,mp_on_bv], axis=1)\n",
    "\n",
    "#     return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios = compute_fund_ratios(fund_data)\n",
    "# ratios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check columns with inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_list = ratios.columns.drop(['date','tic'])\n",
    "# check_ratios = ratios[ratio_list]\n",
    "# inf_cols = check_ratios.columns[~np.isfinite(check_ratios).all()]\n",
    "# inf_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check rows with inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_inf = ratios[((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]\n",
    "# print(len(ratios[((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]))\n",
    "# ratio_inf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ebit_on_int** has infinity values for companies without banking support. We need to address these cases separately: <br>\n",
    " * Replace positive inf with maximum value in ebit_on_int\n",
    " * Replace negative inf with minimum value in ebit_on_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_finite = ratios[~((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]\n",
    "# ratios['ebit_on_int'] = ratios.ebit_on_int.replace(np.inf,ratio_finite.ebit_on_int.max())\n",
    "# ratios['ebit_on_int'] = ratios.ebit_on_int.replace(-np.inf,ratio_finite.ebit_on_int.min())\n",
    "# print(len(ratios[((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While data processing greatly reduces the number of inf values, some still remain.<br>\n",
    "Since the remain inf values represent a small portion of the data, we can safely remove the corresponding rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios = ratios[~((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]\n",
    "# ratios.reset_index(inplace=True,drop=True)\n",
    "# check_ratios = ratios[ratio_list]\n",
    "# inf_cols = check_ratios.columns[~np.isfinite(check_ratios).all()]\n",
    "# inf_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "## 4.3 Turn the final_ratios to monthly basis¶\n",
    "After our initial inspection, we’ll want to dig deeper to investigate the following:\n",
    "- The data type of each variable.\n",
    "- How discrete/categorical data is coded (and whether we need to make any changes).\n",
    "- How the data are scaled.\n",
    "- Whether there is missing data and how it is coded.\n",
    "- Whether there are outliers.\n",
    "- The distributions of continuous features.\n",
    "- The relationships between pairs of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types\n",
    "It is important to check the data type for each feature. <br>\n",
    "The **date** should be in datetime type <br>\n",
    "The **ratios** should be read in as float64 — and categorical variables should be stored as object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ratios['date'] = pd.to_datetime(ratios['date'],format='mixed')\n",
    "# ratios.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is no missing values from all ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn the final_ratios to monthly basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UTIL TOOL: Get monthly price for each company\n",
    "\n",
    "# def get_end_month_price (df):\n",
    "#     # Set date as index\n",
    "#     df.set_index('date', inplace=True)\n",
    "#     # Resample by month and get the last day of each month\n",
    "#     last_day_of_month = df.resample('M').last()\n",
    "#     df = df.reset_index()\n",
    "#     return last_day_of_month\n",
    "\n",
    "# df['date'] = pd.to_datetime(df.date,format='mixed')\n",
    "# monthly_price = pd.DataFrame()\n",
    "# for ticket in fund_data.tic.unique():\n",
    "#     price_by_tic = get_end_month_price(df[df.tic == ticket])\n",
    "#     monthly_price = pd.concat([monthly_price, price_by_tic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = df.iloc[0].date\n",
    "# end_date = df.iloc[-1].date\n",
    "# date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# date_range = pd.DataFrame(date_range)\n",
    "# date_range.columns = ['date']\n",
    "# date_range.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate missing data in the middle of years for each ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# daily_ratios = pd.DataFrame()\n",
    "# for ticket in ratios.tic.unique():\n",
    "#     # Interpolate data for each ticket\n",
    "#     one_tic_ratios = pd.merge(date_range,ratios[ratios.tic == ticket],how=\"left\",on=['date'])\n",
    "#     one_tic_ratios['tic'] = ticket\n",
    "#     one_tic_ratios = one_tic_ratios.interpolate('linear')\n",
    "#     daily_ratios = pd.concat([daily_ratios, one_tic_ratios], ignore_index=True)\n",
    "\n",
    "#     # Check data by drawing it out\n",
    "#     # %matplotlib inline\n",
    "#     # plt.figure(figsize=(16, 4)) \n",
    "#     # plt.plot(one_tic_ratios.date, one_tic_ratios.gross_profit_margin, color = 'red')\n",
    "#     # plt.title(f'Gross profit margin of {ticket}')\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_ratios.dropna(subset='gross_profit_margin',inplace=True)\n",
    "# daily_ratios.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "## 4.4 Merge stock price data and ratios into one dataframe\n",
    "- Merge the price dataframe preprocessed in Part 3 and the ratio dataframe created in this part\n",
    "- Since the prices are daily and ratios are quartely, we have NAs in the ratio columns after merging the two dataframes. We deal with this by backfilling the ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_date = pd.DataFrame(df)[['date','tic','close']]\n",
    "# df_date.columns = ['date','tic','close']\n",
    "# df_date['date'] = pd.to_datetime(df_date.date)\n",
    "# final_ratios = pd.merge(df_date,daily_ratios,how=\"left\",on=['date','tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_ratios.dropna(subset=['gross_profit_margin'],inplace=True,how='any')\n",
    "# final_ratios.reset_index(drop=True,inplace=True)\n",
    "# final_ratios.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_ratios.to_csv('./' + DATA_SAVE_DIR + '/sp500_ready_data_monthly.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.5'></a>\n",
    "## 4.5 Finish data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>gross_profit_margin</th>\n",
       "      <th>sga_ratio</th>\n",
       "      <th>dep_ratio</th>\n",
       "      <th>ebit_on_int</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>count_positive_profit</th>\n",
       "      <th>csti_on_liabilities</th>\n",
       "      <th>inventory_on_ebit</th>\n",
       "      <th>receivable_on_rev</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>debt_on_min_ebit</th>\n",
       "      <th>liabilities_on_equity</th>\n",
       "      <th>capital_cost_on_ebit</th>\n",
       "      <th>eps_on_mp</th>\n",
       "      <th>dividend_on_mp</th>\n",
       "      <th>mp_on_bv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>WYNN</td>\n",
       "      <td>73.214867</td>\n",
       "      <td>0.211086</td>\n",
       "      <td>0.442929</td>\n",
       "      <td>0.447057</td>\n",
       "      <td>2.207989</td>\n",
       "      <td>0.059447</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.293089</td>\n",
       "      <td>0.176490</td>\n",
       "      <td>0.044797</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.027270</td>\n",
       "      <td>6.640253</td>\n",
       "      <td>0.470693</td>\n",
       "      <td>0.576794</td>\n",
       "      <td>0.027270</td>\n",
       "      <td>1.628273e+07</td>\n",
       "      <td>-3.950014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>WYNN</td>\n",
       "      <td>82.021240</td>\n",
       "      <td>0.213774</td>\n",
       "      <td>0.431861</td>\n",
       "      <td>0.435689</td>\n",
       "      <td>2.336475</td>\n",
       "      <td>0.065084</td>\n",
       "      <td>7.915068</td>\n",
       "      <td>0.293346</td>\n",
       "      <td>0.168655</td>\n",
       "      <td>0.044943</td>\n",
       "      <td>0.020557</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>6.528927</td>\n",
       "      <td>0.468225</td>\n",
       "      <td>0.546087</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>1.594436e+07</td>\n",
       "      <td>-3.974793e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>WYNN</td>\n",
       "      <td>86.674721</td>\n",
       "      <td>0.216202</td>\n",
       "      <td>0.421864</td>\n",
       "      <td>0.425421</td>\n",
       "      <td>2.452528</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>7.838356</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.161577</td>\n",
       "      <td>0.045075</td>\n",
       "      <td>0.022376</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>6.428374</td>\n",
       "      <td>0.465995</td>\n",
       "      <td>0.518353</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>1.563873e+07</td>\n",
       "      <td>-3.997174e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>WYNN</td>\n",
       "      <td>89.657188</td>\n",
       "      <td>0.218889</td>\n",
       "      <td>0.410796</td>\n",
       "      <td>0.414053</td>\n",
       "      <td>2.581014</td>\n",
       "      <td>0.075813</td>\n",
       "      <td>7.753425</td>\n",
       "      <td>0.293836</td>\n",
       "      <td>0.153742</td>\n",
       "      <td>0.045221</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>0.035569</td>\n",
       "      <td>6.317048</td>\n",
       "      <td>0.463527</td>\n",
       "      <td>0.487647</td>\n",
       "      <td>0.035569</td>\n",
       "      <td>1.530035e+07</td>\n",
       "      <td>-4.021954e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-30</td>\n",
       "      <td>WYNN</td>\n",
       "      <td>104.108864</td>\n",
       "      <td>0.221490</td>\n",
       "      <td>0.400084</td>\n",
       "      <td>0.403052</td>\n",
       "      <td>2.705356</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>7.671233</td>\n",
       "      <td>0.294084</td>\n",
       "      <td>0.146159</td>\n",
       "      <td>0.045362</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.038335</td>\n",
       "      <td>6.209312</td>\n",
       "      <td>0.461139</td>\n",
       "      <td>0.457931</td>\n",
       "      <td>0.038335</td>\n",
       "      <td>1.497289e+07</td>\n",
       "      <td>-4.045934e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77024</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>DLR</td>\n",
       "      <td>136.375320</td>\n",
       "      <td>0.585775</td>\n",
       "      <td>0.141156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.425107</td>\n",
       "      <td>0.411360</td>\n",
       "      <td>1.084932</td>\n",
       "      <td>0.064895</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035026</td>\n",
       "      <td>0.055106</td>\n",
       "      <td>-3.871747</td>\n",
       "      <td>0.571512</td>\n",
       "      <td>1.265520</td>\n",
       "      <td>0.055106</td>\n",
       "      <td>1.163776e+07</td>\n",
       "      <td>-6.910170e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77025</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>DLR</td>\n",
       "      <td>133.439255</td>\n",
       "      <td>0.586954</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.318181</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>-3.660527</td>\n",
       "      <td>0.553281</td>\n",
       "      <td>1.274745</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>1.134100e+07</td>\n",
       "      <td>-7.065183e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77026</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>DLR</td>\n",
       "      <td>139.269424</td>\n",
       "      <td>0.586954</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.318181</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>-3.660527</td>\n",
       "      <td>0.553281</td>\n",
       "      <td>1.274745</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>1.134100e+07</td>\n",
       "      <td>-7.065183e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77027</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>DLR</td>\n",
       "      <td>145.565582</td>\n",
       "      <td>0.586954</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.318181</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>-3.660527</td>\n",
       "      <td>0.553281</td>\n",
       "      <td>1.274745</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>1.134100e+07</td>\n",
       "      <td>-7.065183e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77028</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>DLR</td>\n",
       "      <td>142.210007</td>\n",
       "      <td>0.586954</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.318181</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>-3.660527</td>\n",
       "      <td>0.553281</td>\n",
       "      <td>1.274745</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>1.134100e+07</td>\n",
       "      <td>-7.065183e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77029 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic       close  gross_profit_margin  sga_ratio  dep_ratio  \\\n",
       "0     2010-12-31  WYNN   73.214867             0.211086   0.442929   0.447057   \n",
       "1     2011-01-31  WYNN   82.021240             0.213774   0.431861   0.435689   \n",
       "2     2011-02-28  WYNN   86.674721             0.216202   0.421864   0.425421   \n",
       "3     2011-03-31  WYNN   89.657188             0.218889   0.410796   0.414053   \n",
       "4     2011-04-30  WYNN  104.108864             0.221490   0.400084   0.403052   \n",
       "...          ...   ...         ...                  ...        ...        ...   \n",
       "77024 2023-11-30   DLR  136.375320             0.585775   0.141156   0.000000   \n",
       "77025 2023-12-31   DLR  133.439255             0.586954   0.139685   0.000000   \n",
       "77026 2024-01-31   DLR  139.269424             0.586954   0.139685   0.000000   \n",
       "77027 2024-02-29   DLR  145.565582             0.586954   0.139685   0.000000   \n",
       "77028 2024-03-31   DLR  142.210007             0.586954   0.139685   0.000000   \n",
       "\n",
       "       ebit_on_int  profit_margin  count_positive_profit  csti_on_liabilities  \\\n",
       "0         2.207989       0.059447               8.000000             0.293089   \n",
       "1         2.336475       0.065084               7.915068             0.293346   \n",
       "2         2.452528       0.070176               7.838356             0.293578   \n",
       "3         2.581014       0.075813               7.753425             0.293836   \n",
       "4         2.705356       0.081269               7.671233             0.294084   \n",
       "...            ...            ...                    ...                  ...   \n",
       "77024     6.425107       0.411360               1.084932             0.064895   \n",
       "77025     6.318181       0.411244               1.000000             0.070316   \n",
       "77026     6.318181       0.411244               1.000000             0.070316   \n",
       "77027     6.318181       0.411244               1.000000             0.070316   \n",
       "77028     6.318181       0.411244               1.000000             0.070316   \n",
       "\n",
       "       inventory_on_ebit  receivable_on_rev       roa       roe  \\\n",
       "0               0.176490           0.044797  0.018542  0.027270   \n",
       "1               0.168655           0.044943  0.020557  0.030128   \n",
       "2               0.161577           0.045075  0.022376  0.032710   \n",
       "3               0.153742           0.045221  0.024391  0.035569   \n",
       "4               0.146159           0.045362  0.026341  0.038335   \n",
       "...                  ...                ...       ...       ...   \n",
       "77024           0.064176           0.000000  0.035026  0.055106   \n",
       "77025           0.000000           0.000000  0.034707  0.053909   \n",
       "77026           0.000000           0.000000  0.034707  0.053909   \n",
       "77027           0.000000           0.000000  0.034707  0.053909   \n",
       "77028           0.000000           0.000000  0.034707  0.053909   \n",
       "\n",
       "       debt_on_min_ebit  liabilities_on_equity  capital_cost_on_ebit  \\\n",
       "0              6.640253               0.470693              0.576794   \n",
       "1              6.528927               0.468225              0.546087   \n",
       "2              6.428374               0.465995              0.518353   \n",
       "3              6.317048               0.463527              0.487647   \n",
       "4              6.209312               0.461139              0.457931   \n",
       "...                 ...                    ...                   ...   \n",
       "77024         -3.871747               0.571512              1.265520   \n",
       "77025         -3.660527               0.553281              1.274745   \n",
       "77026         -3.660527               0.553281              1.274745   \n",
       "77027         -3.660527               0.553281              1.274745   \n",
       "77028         -3.660527               0.553281              1.274745   \n",
       "\n",
       "       eps_on_mp  dividend_on_mp      mp_on_bv  \n",
       "0       0.027270    1.628273e+07 -3.950014e-08  \n",
       "1       0.030128    1.594436e+07 -3.974793e-08  \n",
       "2       0.032710    1.563873e+07 -3.997174e-08  \n",
       "3       0.035569    1.530035e+07 -4.021954e-08  \n",
       "4       0.038335    1.497289e+07 -4.045934e-08  \n",
       "...          ...             ...           ...  \n",
       "77024   0.055106    1.163776e+07 -6.910170e-09  \n",
       "77025   0.053909    1.134100e+07 -7.065183e-09  \n",
       "77026   0.053909    1.134100e+07 -7.065183e-09  \n",
       "77027   0.053909    1.134100e+07 -7.065183e-09  \n",
       "77028   0.053909    1.134100e+07 -7.065183e-09  \n",
       "\n",
       "[77029 rows x 20 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the data is available in the data storage, load processed_full from readied data\n",
    "processed_full = pd.read_csv('./' + DATA_SAVE_DIR + '/sp500_ready_data_monthly.csv',index_col=0)\n",
    "processed_full['date'] = pd.to_datetime(processed_full.date,format='mixed')\n",
    "processed_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 77029 entries, 0 to 77028\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   date                   77029 non-null  datetime64[ns]\n",
      " 1   tic                    77029 non-null  object        \n",
      " 2   close                  77029 non-null  float64       \n",
      " 3   gross_profit_margin    77029 non-null  float64       \n",
      " 4   sga_ratio              77029 non-null  float64       \n",
      " 5   dep_ratio              77029 non-null  float64       \n",
      " 6   ebit_on_int            77029 non-null  float64       \n",
      " 7   profit_margin          77029 non-null  float64       \n",
      " 8   count_positive_profit  77029 non-null  float64       \n",
      " 9   csti_on_liabilities    77029 non-null  float64       \n",
      " 10  inventory_on_ebit      77029 non-null  float64       \n",
      " 11  receivable_on_rev      77029 non-null  float64       \n",
      " 12  roa                    77029 non-null  float64       \n",
      " 13  roe                    77029 non-null  float64       \n",
      " 14  debt_on_min_ebit       77029 non-null  float64       \n",
      " 15  liabilities_on_equity  77029 non-null  float64       \n",
      " 16  capital_cost_on_ebit   77029 non-null  float64       \n",
      " 17  eps_on_mp              77029 non-null  float64       \n",
      " 18  dividend_on_mp         77029 non-null  float64       \n",
      " 19  mp_on_bv               77029 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(18), object(1)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "processed_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WBA', 'AAPL', 'MSFT', 'V', 'UNH', 'JNJ', 'JPM', 'WMT', 'PG', 'HD',\n",
       "       'CVX', 'MRK', 'KO', 'CSCO', 'MCD', 'CRM', 'NKE', 'DIS', 'AMGN',\n",
       "       'CAT', 'VZ', 'INTC', 'BA', 'IBM', 'HON', 'AXP', 'GS', 'MMM', 'DOW',\n",
       "       'TRV'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full = processed_full[processed_full.tic.isin(DOW_30_TICKER)]\n",
    "processed_full.tic.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset **TRAIN_START_DATE** and **TEST_END_DATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_START_DATE:  2009-09-30 \n",
      "\n",
      "TRAIN_END_DATE:  2021-01-01 \n",
      "\n",
      "TEST_START_DATE:  2021-01-01 \n",
      "\n",
      "TEST_END_DATE:  2024-03-31 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = processed_full.date.min().strftime(\"%Y-%m-%d\")\n",
    "TEST_END_DATE = processed_full.date.max().strftime(\"%Y-%m-%d\")\n",
    "print('TRAIN_START_DATE: ',TRAIN_START_DATE,'\\n')\n",
    "print('TRAIN_END_DATE: ',TRAIN_END_DATE,'\\n')\n",
    "print('TEST_START_DATE: ',TEST_START_DATE,'\\n')\n",
    "print('TEST_END_DATE: ',TEST_END_DATE,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1 Training & Trade Data Split\n",
    "- Training data period: 2009-01-01 to 2020-01-01\n",
    "- Trade data period: 2020-01-01 to 2023-12-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3655\n",
      "1140\n"
     ]
    }
   ],
   "source": [
    "train_data = data_split(processed_full, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "trade_data = data_split(processed_full, TEST_START_DATE, TEST_END_DATE)\n",
    "# Check the length of the two datasets\n",
    "print(len(train_data))\n",
    "print(len(trade_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>gross_profit_margin</th>\n",
       "      <th>sga_ratio</th>\n",
       "      <th>dep_ratio</th>\n",
       "      <th>ebit_on_int</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>count_positive_profit</th>\n",
       "      <th>csti_on_liabilities</th>\n",
       "      <th>inventory_on_ebit</th>\n",
       "      <th>receivable_on_rev</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>debt_on_min_ebit</th>\n",
       "      <th>liabilities_on_equity</th>\n",
       "      <th>capital_cost_on_ebit</th>\n",
       "      <th>eps_on_mp</th>\n",
       "      <th>dividend_on_mp</th>\n",
       "      <th>mp_on_bv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-09-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>5.604187</td>\n",
       "      <td>0.304696</td>\n",
       "      <td>0.317372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.374233</td>\n",
       "      <td>0.111106</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.479352</td>\n",
       "      <td>0.050986</td>\n",
       "      <td>0.078336</td>\n",
       "      <td>0.228046</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.145352</td>\n",
       "      <td>0.128194</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.618375e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-09-30</td>\n",
       "      <td>V</td>\n",
       "      <td>15.578794</td>\n",
       "      <td>0.732890</td>\n",
       "      <td>0.247976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.121739</td>\n",
       "      <td>0.296050</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.670885</td>\n",
       "      <td>0.639013</td>\n",
       "      <td>0.064245</td>\n",
       "      <td>0.091882</td>\n",
       "      <td>0.155239</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.689547</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.155239</td>\n",
       "      <td>1.902586e+08</td>\n",
       "      <td>-1.542455e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-10-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>5.699428</td>\n",
       "      <td>0.304017</td>\n",
       "      <td>0.314630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.630120</td>\n",
       "      <td>0.113588</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.433146</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.963965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.174256</td>\n",
       "      <td>0.129614</td>\n",
       "      <td>0.963965</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.647365e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-10-31</td>\n",
       "      <td>V</td>\n",
       "      <td>17.077837</td>\n",
       "      <td>0.735809</td>\n",
       "      <td>0.245074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.047435</td>\n",
       "      <td>0.303752</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.673774</td>\n",
       "      <td>0.632417</td>\n",
       "      <td>0.063802</td>\n",
       "      <td>0.095074</td>\n",
       "      <td>0.158929</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>0.676396</td>\n",
       "      <td>0.077720</td>\n",
       "      <td>0.158929</td>\n",
       "      <td>1.809975e+08</td>\n",
       "      <td>-1.856696e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-11-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>6.044419</td>\n",
       "      <td>0.303359</td>\n",
       "      <td>0.311976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.716462</td>\n",
       "      <td>0.115990</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.388430</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>0.079362</td>\n",
       "      <td>0.233329</td>\n",
       "      <td>0.981998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.202228</td>\n",
       "      <td>0.130989</td>\n",
       "      <td>0.981998</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.675419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>UNH</td>\n",
       "      <td>335.059784</td>\n",
       "      <td>0.707009</td>\n",
       "      <td>0.229394</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>84.243536</td>\n",
       "      <td>0.519019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.156063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098794</td>\n",
       "      <td>0.300780</td>\n",
       "      <td>0.421057</td>\n",
       "      <td>0.400580</td>\n",
       "      <td>0.399884</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.421057</td>\n",
       "      <td>2.636544e+07</td>\n",
       "      <td>-7.671028e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>V</td>\n",
       "      <td>213.664169</td>\n",
       "      <td>0.697420</td>\n",
       "      <td>0.133718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.193962</td>\n",
       "      <td>0.441171</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.441947</td>\n",
       "      <td>0.269140</td>\n",
       "      <td>0.080325</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>3.067416</td>\n",
       "      <td>0.115467</td>\n",
       "      <td>0.054096</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>5.456423e+07</td>\n",
       "      <td>-9.743528e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>VZ</td>\n",
       "      <td>48.816624</td>\n",
       "      <td>0.618534</td>\n",
       "      <td>0.397880</td>\n",
       "      <td>0.179892</td>\n",
       "      <td>11.250294</td>\n",
       "      <td>0.295529</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.078657</td>\n",
       "      <td>0.037589</td>\n",
       "      <td>0.186426</td>\n",
       "      <td>0.078316</td>\n",
       "      <td>0.187464</td>\n",
       "      <td>2.972570</td>\n",
       "      <td>1.393680</td>\n",
       "      <td>0.425241</td>\n",
       "      <td>0.187464</td>\n",
       "      <td>2.096007e+08</td>\n",
       "      <td>-2.217831e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>WBA</td>\n",
       "      <td>33.866371</td>\n",
       "      <td>-0.009526</td>\n",
       "      <td>-1.021455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.212650</td>\n",
       "      <td>-0.202215</td>\n",
       "      <td>6.334247</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>-0.305243</td>\n",
       "      <td>0.048514</td>\n",
       "      <td>-0.293656</td>\n",
       "      <td>-0.918168</td>\n",
       "      <td>-0.310980</td>\n",
       "      <td>2.088399</td>\n",
       "      <td>-0.052435</td>\n",
       "      <td>-0.918168</td>\n",
       "      <td>8.263157e+07</td>\n",
       "      <td>-8.529535e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>WMT</td>\n",
       "      <td>45.710587</td>\n",
       "      <td>0.248178</td>\n",
       "      <td>0.837881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.754111</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>4.084699</td>\n",
       "      <td>0.176538</td>\n",
       "      <td>2.007618</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.109269</td>\n",
       "      <td>2.188798</td>\n",
       "      <td>1.392779</td>\n",
       "      <td>0.460734</td>\n",
       "      <td>0.109269</td>\n",
       "      <td>2.090669e+08</td>\n",
       "      <td>-4.641799e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3655 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   tic       close  gross_profit_margin  sga_ratio  dep_ratio  \\\n",
       "0    2009-09-30  AAPL    5.604187             0.304696   0.317372   0.000000   \n",
       "1    2009-09-30     V   15.578794             0.732890   0.247976   0.000000   \n",
       "2    2009-10-31  AAPL    5.699428             0.304017   0.314630   0.000000   \n",
       "3    2009-10-31     V   17.077837             0.735809   0.245074   0.000000   \n",
       "4    2009-11-30  AAPL    6.044419             0.303359   0.311976   0.000000   \n",
       "...         ...   ...         ...                  ...        ...        ...   \n",
       "3650 2020-12-31   UNH  335.059784             0.707009   0.229394   0.005501   \n",
       "3651 2020-12-31     V  213.664169             0.697420   0.133718   0.000000   \n",
       "3652 2020-12-31    VZ   48.816624             0.618534   0.397880   0.179892   \n",
       "3653 2020-12-31   WBA   33.866371            -0.009526  -1.021455   0.000000   \n",
       "3654 2020-12-31   WMT   45.710587             0.248178   0.837881   0.000000   \n",
       "\n",
       "      ebit_on_int  profit_margin  count_positive_profit  csti_on_liabilities  \\\n",
       "0       27.374233       0.111106              10.000000             1.479352   \n",
       "1       33.121739       0.296050              10.000000             0.670885   \n",
       "2       32.630120       0.113588              10.000000             1.433146   \n",
       "3       36.047435       0.303752              10.000000             0.673774   \n",
       "4       37.716462       0.115990              10.000000             1.388430   \n",
       "...           ...            ...                    ...                  ...   \n",
       "3650    84.243536       0.519019              10.000000             0.156063   \n",
       "3651    26.193962       0.441171               9.000000             0.441947   \n",
       "3652    11.250294       0.295529              10.000000             0.078657   \n",
       "3653   -39.212650      -0.202215               6.334247             0.012180   \n",
       "3654     9.754111       0.024076               4.084699             0.176538   \n",
       "\n",
       "      inventory_on_ebit  receivable_on_rev       roa       roe  \\\n",
       "0              0.050986           0.078336  0.228046  0.945331   \n",
       "1              0.639013           0.064245  0.091882  0.155239   \n",
       "2              0.053108           0.078857  0.230731  0.963965   \n",
       "3              0.632417           0.063802  0.095074  0.158929   \n",
       "4              0.055161           0.079362  0.233329  0.981998   \n",
       "...                 ...                ...       ...       ...   \n",
       "3650           0.000000           0.098794  0.300780  0.421057   \n",
       "3651           0.269140           0.080325  0.022702  0.025326   \n",
       "3652           0.037589           0.186426  0.078316  0.187464   \n",
       "3653          -0.305243           0.048514 -0.293656 -0.918168   \n",
       "3654           2.007618           0.011682  0.045633  0.109269   \n",
       "\n",
       "      debt_on_min_ebit  liabilities_on_equity  capital_cost_on_ebit  \\\n",
       "0             0.000000               3.145352              0.128194   \n",
       "1             0.014702               0.689547              0.080336   \n",
       "2             0.000000               3.174256              0.129614   \n",
       "3             0.014221               0.676396              0.077720   \n",
       "4             0.000000               3.202228              0.130989   \n",
       "...                ...                    ...                   ...   \n",
       "3650          0.400580               0.399884              0.014640   \n",
       "3651          3.067416               0.115467              0.054096   \n",
       "3652          2.972570               1.393680              0.425241   \n",
       "3653         -0.310980               2.088399             -0.052435   \n",
       "3654          2.188798               1.392779              0.460734   \n",
       "\n",
       "      eps_on_mp  dividend_on_mp      mp_on_bv  \n",
       "0      0.945331    0.000000e+00  2.618375e-10  \n",
       "1      0.155239    1.902586e+08 -1.542455e-08  \n",
       "2      0.963965    0.000000e+00  2.647365e-10  \n",
       "3      0.158929    1.809975e+08 -1.856696e-08  \n",
       "4      0.981998    0.000000e+00  2.675419e-10  \n",
       "...         ...             ...           ...  \n",
       "3650   0.421057    2.636544e+07 -7.671028e-09  \n",
       "3651   0.025326    5.456423e+07 -9.743528e-09  \n",
       "3652   0.187464    2.096007e+08 -2.217831e-10  \n",
       "3653  -0.918168    8.263157e+07 -8.529535e-10  \n",
       "3654   0.109269    2.090669e+08 -4.641799e-10  \n",
       "\n",
       "[3655 rows x 20 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reset_index(drop=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>gross_profit_margin</th>\n",
       "      <th>sga_ratio</th>\n",
       "      <th>dep_ratio</th>\n",
       "      <th>ebit_on_int</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>count_positive_profit</th>\n",
       "      <th>csti_on_liabilities</th>\n",
       "      <th>inventory_on_ebit</th>\n",
       "      <th>receivable_on_rev</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>debt_on_min_ebit</th>\n",
       "      <th>liabilities_on_equity</th>\n",
       "      <th>capital_cost_on_ebit</th>\n",
       "      <th>eps_on_mp</th>\n",
       "      <th>dividend_on_mp</th>\n",
       "      <th>mp_on_bv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>129.504669</td>\n",
       "      <td>0.319523</td>\n",
       "      <td>0.218454</td>\n",
       "      <td>0.103238</td>\n",
       "      <td>27.902059</td>\n",
       "      <td>0.203952</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.306527</td>\n",
       "      <td>0.064123</td>\n",
       "      <td>0.139187</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>0.030204</td>\n",
       "      <td>14.161230</td>\n",
       "      <td>0.131329</td>\n",
       "      <td>0.113005</td>\n",
       "      <td>0.030204</td>\n",
       "      <td>7.477079e+08</td>\n",
       "      <td>-3.792017e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>217.708099</td>\n",
       "      <td>0.711596</td>\n",
       "      <td>0.302525</td>\n",
       "      <td>0.033894</td>\n",
       "      <td>11.155836</td>\n",
       "      <td>0.416334</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.203956</td>\n",
       "      <td>0.299618</td>\n",
       "      <td>0.201385</td>\n",
       "      <td>0.068308</td>\n",
       "      <td>0.099096</td>\n",
       "      <td>25.551601</td>\n",
       "      <td>0.448228</td>\n",
       "      <td>0.047456</td>\n",
       "      <td>0.099096</td>\n",
       "      <td>3.560891e+07</td>\n",
       "      <td>-5.854302e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>111.826149</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>1.697894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.105818</td>\n",
       "      <td>-0.202210</td>\n",
       "      <td>5.084932</td>\n",
       "      <td>0.187780</td>\n",
       "      <td>-0.719761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.029549</td>\n",
       "      <td>-0.082446</td>\n",
       "      <td>-12.795540</td>\n",
       "      <td>1.768630</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>-0.082446</td>\n",
       "      <td>2.463522e+07</td>\n",
       "      <td>-1.551313e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>194.190002</td>\n",
       "      <td>-0.085335</td>\n",
       "      <td>-0.658330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.249637</td>\n",
       "      <td>-0.165574</td>\n",
       "      <td>6.084932</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>-1.805860</td>\n",
       "      <td>0.034362</td>\n",
       "      <td>-0.024994</td>\n",
       "      <td>-0.044602</td>\n",
       "      <td>-9.837667</td>\n",
       "      <td>0.782739</td>\n",
       "      <td>-0.186545</td>\n",
       "      <td>-0.044602</td>\n",
       "      <td>4.960369e+06</td>\n",
       "      <td>-1.598125e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>171.592255</td>\n",
       "      <td>0.303381</td>\n",
       "      <td>0.364843</td>\n",
       "      <td>0.164570</td>\n",
       "      <td>16.041624</td>\n",
       "      <td>0.155662</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.147812</td>\n",
       "      <td>1.418429</td>\n",
       "      <td>0.396750</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>0.070558</td>\n",
       "      <td>3.278032</td>\n",
       "      <td>0.674961</td>\n",
       "      <td>0.261999</td>\n",
       "      <td>0.070558</td>\n",
       "      <td>2.032006e+07</td>\n",
       "      <td>-9.165359e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>UNH</td>\n",
       "      <td>491.661804</td>\n",
       "      <td>0.737986</td>\n",
       "      <td>0.199189</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>67.659889</td>\n",
       "      <td>0.566194</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.169496</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.104865</td>\n",
       "      <td>0.313486</td>\n",
       "      <td>0.423878</td>\n",
       "      <td>16.703334</td>\n",
       "      <td>0.352142</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.423878</td>\n",
       "      <td>2.747652e+07</td>\n",
       "      <td>-8.568411e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>V</td>\n",
       "      <td>282.640015</td>\n",
       "      <td>0.704715</td>\n",
       "      <td>0.118495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.854037</td>\n",
       "      <td>0.523667</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.314608</td>\n",
       "      <td>0.240010</td>\n",
       "      <td>0.078065</td>\n",
       "      <td>0.035065</td>\n",
       "      <td>0.039327</td>\n",
       "      <td>13.643292</td>\n",
       "      <td>0.121541</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>0.039327</td>\n",
       "      <td>6.881727e+07</td>\n",
       "      <td>-8.084724e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>VZ</td>\n",
       "      <td>40.020000</td>\n",
       "      <td>0.567685</td>\n",
       "      <td>0.430544</td>\n",
       "      <td>0.196397</td>\n",
       "      <td>7.840333</td>\n",
       "      <td>0.245525</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.047495</td>\n",
       "      <td>0.194038</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.204009</td>\n",
       "      <td>74.999502</td>\n",
       "      <td>2.030192</td>\n",
       "      <td>0.567144</td>\n",
       "      <td>0.204009</td>\n",
       "      <td>2.883466e+08</td>\n",
       "      <td>-1.361466e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>WBA</td>\n",
       "      <td>21.260000</td>\n",
       "      <td>-0.066540</td>\n",
       "      <td>-3.659463</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-75.089655</td>\n",
       "      <td>-0.300945</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.010845</td>\n",
       "      <td>-0.189589</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>-0.473656</td>\n",
       "      <td>-2.002519</td>\n",
       "      <td>-0.208762</td>\n",
       "      <td>3.227792</td>\n",
       "      <td>-0.048609</td>\n",
       "      <td>-2.002519</td>\n",
       "      <td>7.399533e+07</td>\n",
       "      <td>-4.587726e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>WMT</td>\n",
       "      <td>58.411064</td>\n",
       "      <td>0.243754</td>\n",
       "      <td>0.829020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.449516</td>\n",
       "      <td>0.029082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108676</td>\n",
       "      <td>2.032134</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>-6.715134</td>\n",
       "      <td>0.126712</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>1.624698e+08</td>\n",
       "      <td>-5.866425e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   tic       close  gross_profit_margin  sga_ratio  dep_ratio  \\\n",
       "0    2021-01-31  AAPL  129.504669             0.319523   0.218454   0.103238   \n",
       "1    2021-01-31  AMGN  217.708099             0.711596   0.302525   0.033894   \n",
       "2    2021-01-31   AXP  111.826149             0.176514   1.697894   0.000000   \n",
       "3    2021-01-31    BA  194.190002            -0.085335  -0.658330   0.000000   \n",
       "4    2021-01-31   CAT  171.592255             0.303381   0.364843   0.164570   \n",
       "...         ...   ...         ...                  ...        ...        ...   \n",
       "1135 2024-02-29   UNH  491.661804             0.737986   0.199189   0.004011   \n",
       "1136 2024-02-29     V  282.640015             0.704715   0.118495   0.000000   \n",
       "1137 2024-02-29    VZ   40.020000             0.567685   0.430544   0.196397   \n",
       "1138 2024-02-29   WBA   21.260000            -0.066540  -3.659463  -0.000000   \n",
       "1139 2024-02-29   WMT   58.411064             0.243754   0.829020   0.000000   \n",
       "\n",
       "      ebit_on_int  profit_margin  count_positive_profit  csti_on_liabilities  \\\n",
       "0       27.902059       0.203952              10.000000             0.306527   \n",
       "1       11.155836       0.416334               7.000000             0.203956   \n",
       "2       -2.105818      -0.202210               5.084932             0.187780   \n",
       "3       -4.249637      -0.165574               6.084932             0.146597   \n",
       "4       16.041624       0.155662              10.000000             0.147812   \n",
       "...           ...            ...                    ...                  ...   \n",
       "1135    67.659889       0.566194              10.000000             0.169496   \n",
       "1136   -30.854037       0.523667               8.000000             0.314608   \n",
       "1137     7.840333       0.245525              10.000000             0.006308   \n",
       "1138   -75.089655      -0.300945               9.000000             0.010845   \n",
       "1139    10.449516       0.029082               1.000000             0.108676   \n",
       "\n",
       "      inventory_on_ebit  receivable_on_rev       roa       roe  \\\n",
       "0              0.064123           0.139187  0.026718  0.030204   \n",
       "1              0.299618           0.201385  0.068308  0.099096   \n",
       "2             -0.719761           0.000000 -0.029549 -0.082446   \n",
       "3             -1.805860           0.034362 -0.024994 -0.044602   \n",
       "4              1.418429           0.396750  0.042134  0.070558   \n",
       "...                 ...                ...       ...       ...   \n",
       "1135           0.012749           0.104865  0.313486  0.423878   \n",
       "1136           0.240010           0.078065  0.035065  0.039327   \n",
       "1137           0.047495           0.194038  0.067325  0.204009   \n",
       "1138          -0.189589           0.038307 -0.473656 -2.002519   \n",
       "1139           2.032134           0.013571  0.012578  0.014171   \n",
       "\n",
       "      debt_on_min_ebit  liabilities_on_equity  capital_cost_on_ebit  \\\n",
       "0            14.161230               0.131329              0.113005   \n",
       "1            25.551601               0.448228              0.047456   \n",
       "2           -12.795540               1.768630              0.001715   \n",
       "3            -9.837667               0.782739             -0.186545   \n",
       "4             3.278032               0.674961              0.261999   \n",
       "...                ...                    ...                   ...   \n",
       "1135         16.703334               0.352142              0.015417   \n",
       "1136         13.643292               0.121541              0.053296   \n",
       "1137         74.999502               2.030192              0.567144   \n",
       "1138         -0.208762               3.227792             -0.048609   \n",
       "1139         -6.715134               0.126712              0.762846   \n",
       "\n",
       "      eps_on_mp  dividend_on_mp      mp_on_bv  \n",
       "0      0.030204    7.477079e+08 -3.792017e-09  \n",
       "1      0.099096    3.560891e+07 -5.854302e-09  \n",
       "2     -0.082446    2.463522e+07 -1.551313e-09  \n",
       "3     -0.044602    4.960369e+06 -1.598125e-09  \n",
       "4      0.070558    2.032006e+07 -9.165359e-09  \n",
       "...         ...             ...           ...  \n",
       "1135   0.423878    2.747652e+07 -8.568411e-09  \n",
       "1136   0.039327    6.881727e+07 -8.084724e-09  \n",
       "1137   0.204009    2.883466e+08 -1.361466e-10  \n",
       "1138  -2.002519    7.399533e+07 -4.587726e-10  \n",
       "1139   0.014171    1.624698e+08 -5.866425e-10  \n",
       "\n",
       "[1140 rows x 20 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_data = trade_data.reset_index(drop=True)\n",
    "trade_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2 Set up the training environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from gym.spaces import Box\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# from stable_baselines3.common import logger\n",
    "\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        # stock_dim,\n",
    "        hmax,\n",
    "        initial_amount,\n",
    "        buy_cost_pct,\n",
    "        sell_cost_pct,\n",
    "        reward_scaling,\n",
    "        state_space,\n",
    "        action_space,\n",
    "        tech_indicator_list,\n",
    "        stop_loss,\n",
    "        punishment_rate,\n",
    "        make_plots=False,\n",
    "        print_verbosity=10,\n",
    "        row=0,\n",
    "        initial=True,\n",
    "        previous_state=[],\n",
    "        model_name=\"\",\n",
    "        mode=\"\",\n",
    "        iteration=\"\",\n",
    "    ):\n",
    "        # self.row = row\n",
    "        self.df = df\n",
    "        # self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.buy_cost_pct = buy_cost_pct\n",
    "        self.sell_cost_pct = sell_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.punishment_rate = punishment_rate\n",
    "        self.stop_loss = stop_loss # the game stops when the asset loses more than stop_loss percent\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
    "        )\n",
    "        # self.data = self.df.loc[self.row, :]\n",
    "        self.terminal = False\n",
    "        self.make_plots = make_plots\n",
    "        self.print_verbosity = print_verbosity\n",
    "        # self.turbulence_threshold = turbulence_threshold\n",
    "        # self.risk_indicator_col = risk_indicator_col\n",
    "        self.initial = initial\n",
    "        self.previous_state = previous_state\n",
    "        self.model_name = model_name\n",
    "        self.mode = mode\n",
    "        self.iteration = iteration\n",
    "        self.portfolio_columns = ['tic','price','buy_price','amount','weight']\n",
    "        self.row = 0\n",
    "        \n",
    "        # initalize state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.episode = 0\n",
    "        \n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        # self.reset()\n",
    "        self._seed()\n",
    "\n",
    "    def _buy_stock(self, action):\n",
    "        def _do_buy():\n",
    "            if self.data.close > 0: # Buy only if the price is > 0 (no missing data in this particular date)\n",
    "                buy_amount = (self.portfolio.loc[0].price * action)\n",
    "                buy_num_shares = math.floor(buy_amount/self.data.close)\n",
    "                if buy_num_shares > 0:\n",
    "                    if self.portfolio[self.portfolio.tic == self.data.tic].empty:\n",
    "                        selected_index = len(self.portfolio)\n",
    "                        selected_row = [self.data.tic,0,self.data.close,0,0]\n",
    "                    else:\n",
    "                        selected_index = self.portfolio[self.portfolio.tic == self.data.tic].index[0]\n",
    "                        selected_row = self.portfolio.loc[selected_index]\n",
    "                        selected_row[2] = (buy_num_shares*self.data.close + selected_row[2]*selected_row[3]) \\\n",
    "                                    /(buy_num_shares + selected_row[3])\n",
    "                    selected_row[1] = self.data.close\n",
    "                    selected_row[3] += buy_num_shares\n",
    "                    self.portfolio.loc[selected_index] = selected_row\n",
    "    \n",
    "                    # Update remain capital\n",
    "                    capital_row = self.portfolio.loc[0]\n",
    "                    capital_change = buy_num_shares * self.data.close * (1 + self.buy_cost_pct)\n",
    "                    capital_row[1] -= capital_change\n",
    "                    capital_row[2] -= capital_change\n",
    "                    self.portfolio.loc[0] = capital_row\n",
    "                    \n",
    "                    self._compute_weight()\n",
    "                    self.cost += selected_row[1] * buy_num_shares * self.buy_cost_pct\n",
    "                    self.trades += 1\n",
    "                else:\n",
    "                    # Punish a certain amount of money if buying without avaiable capital\n",
    "                    self.reward += -10 * self.initial_amount * self.punishment_rate * self.reward_scaling\n",
    "                    # print(f'Set punishment for unavailable buying: {self.reward}')\n",
    "                    \n",
    "            else:\n",
    "                buy_num_shares = 0\n",
    "\n",
    "            return buy_num_shares\n",
    "\n",
    "        buy_num_shares = _do_buy()\n",
    "        return buy_num_shares\n",
    "    \n",
    "    def _sell_stock(self, action):\n",
    "        def _do_sell_normal():\n",
    "            # TODO: Punish a certain amount of money if selling without avaiable stock in the inventory\n",
    "            if self.data.close > 0: # Sell only if the price is > 0 (no missing data in this particular date)\n",
    "                # perform sell action based on the sign of the action\n",
    "                selected_row = self.portfolio[self.portfolio.tic == self.data.tic]\n",
    "                if (selected_row.empty) | (selected_row.amount.any() == False):             \n",
    "                    sell_num_shares = 0\n",
    "                    \n",
    "                    # Punish a certain amount of money if selling without avaiable stock in the inventory\n",
    "                    self.reward += -10 * self.initial_amount * self.punishment_rate * self.reward_scaling\n",
    "                \n",
    "                else:\n",
    "                    sell_num_shares = math.floor(abs(action) * selected_row.amount) \n",
    "                    sell_amount = self.data.close * sell_num_shares * (1 - self.sell_cost_pct)\n",
    "\n",
    "                    # Update reward only when closing a deal\n",
    "                    buy_amount = selected_row.buy_price * sell_num_shares\n",
    "                    self.reward += (sell_amount - buy_amount).values[0].item() * self.reward_scaling\n",
    "                    \n",
    "                    # update stock row in the portfolio\n",
    "                    selected_index = selected_row.index[0]\n",
    "                    selected_row = self.portfolio.loc[selected_index]\n",
    "                    selected_row[1] = self.data.close\n",
    "                    selected_row[3] -= sell_num_shares\n",
    "\n",
    "                    # Update remain capital\n",
    "                    capital_row = self.portfolio.loc[0]\n",
    "                    capital_row[1] += sell_amount\n",
    "                    capital_row[2] += sell_amount\n",
    "\n",
    "                    # Update changes to portfolio\n",
    "                    self.portfolio.loc[selected_index] = selected_row\n",
    "                    self.portfolio.loc[0] = capital_row\n",
    "                    self._compute_weight()\n",
    "                    self.cost += selected_row[1] * sell_num_shares * self.sell_cost_pct\n",
    "                    self.trades += 1\n",
    "            else:\n",
    "                sell_num_shares = 0\n",
    "\n",
    "            return sell_num_shares\n",
    "\n",
    "        sell_num_shares = _do_sell_normal()\n",
    "        return sell_num_shares\n",
    "\n",
    "    def _compute_weight(self):\n",
    "        nav = sum(self.portfolio.price*self.portfolio.amount)\n",
    "        self.portfolio['weight'] = self.portfolio.apply(lambda x: x.price * x.amount / nav, axis=1)\n",
    "    \n",
    "    # def _make_plot(self):\n",
    "    #     plt.plot(self.asset_memory, \"r\")\n",
    "    #     plt.savefig(\"results/account_value_trade_{}.png\".format(self.episode))\n",
    "    #     plt.close()\n",
    "\n",
    "    def step(self, actions):\n",
    "\n",
    "        current_total_asset = sum(self.portfolio.price * self.portfolio.amount)\n",
    "        self.terminal = (self.row >= len(self.df.index.unique()) - 1) | (current_total_asset < self.initial_amount*(1-self.stop_loss))\n",
    "        # print(f'Action of step {self.row} is {actions[0]}')\n",
    "        \n",
    "        # --> IN CASE THE STEP IS THE TERMINATED STEP\n",
    "        if self.terminal: \n",
    "            print(f\"Episode: {self.episode}\")\n",
    "            # if self.make_plots:\n",
    "            #     self._make_plot()\n",
    "                \n",
    "            # Summary the training performance after an episode\n",
    "            end_total_asset = sum(self.portfolio.price*self.portfolio.amount)\n",
    "            tot_reward = end_total_asset - self.initial_amount\n",
    "\n",
    "            # Summary total_value\n",
    "            # df_total_value = pd.DataFrame(self.asset_memory)\n",
    "            # df_total_value.columns = [\"account_value\"]\n",
    "            # df_total_value[\"date\"] = self.date_memory\n",
    "            # df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
    "            # if df_total_value[\"daily_return\"].std() != 0:\n",
    "            #     sharpe = ((252 ** 0.5)* df_total_value[\"daily_return\"].mean()/ df_total_value[\"daily_return\"].std())\n",
    "\n",
    "            # Take tot_reward into account\n",
    "            # self.reward = tot_reward * self.reward_scaling\n",
    "            # self.rewards_memory.append(self.reward)\n",
    "            \n",
    "            # Summary rewards\n",
    "            # df_rewards = pd.DataFrame(self.rewards_memory)\n",
    "            # df_rewards.columns = [\"account_rewards\"]\n",
    "            # df_rewards[\"date\"] = self.date_memory[:-1]\n",
    "\n",
    "            # Print out training results after a certain amount of episodes\n",
    "            if self.episode % self.print_verbosity == 0:\n",
    "                print(f\"row: {self.row}, episode: {self.episode}\")\n",
    "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
    "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
    "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
    "                print(f\"total_cost: {self.cost:0.2f}\")\n",
    "                print(f\"total_trades: {self.trades}\")\n",
    "                # if df_total_value[\"daily_return\"].std() != 0:\n",
    "                #     print(f\"Sharpe: {sharpe:0.3f}\")\n",
    "                print(\"=================================\")\n",
    "\n",
    "            # if (self.model_name != \"\") and (self.mode != \"\"):\n",
    "                # df_actions = self.save_action_memory()\n",
    "                # df_actions.to_csv(\n",
    "                #     \"results/actions_{}_{}_{}.csv\".format(\n",
    "                #         self.mode, self.model_name, self.iteration\n",
    "                #     )\n",
    "                # )\n",
    "                # df_total_value.to_csv(\n",
    "                #     \"results/account_value_{}_{}_{}.csv\".format(\n",
    "                #         self.mode, self.model_name, self.iteration\n",
    "                #     ),\n",
    "                #     index=False,\n",
    "                # )\n",
    "                # df_rewards.to_csv(\n",
    "                #     \"results/account_rewards_{}_{}_{}.csv\".format(\n",
    "                #         self.mode, self.model_name, self.iteration\n",
    "                #     ),\n",
    "                #     index=False,\n",
    "                # )\n",
    "                # plt.plot(self.asset_memory, \"r\")\n",
    "                # plt.savefig(\n",
    "                #     \"results/account_value_{}_{}_{}.png\".format(\n",
    "                #         self.mode, self.model_name, self.iteration\n",
    "                #     ),\n",
    "                #     index=False,\n",
    "                # )\n",
    "                # plt.close()\n",
    "            \n",
    "            truncated = False  # we do not limit the number of steps here\n",
    "            # Optionally we can pass additional info, we are not using that for now\n",
    "            info = {}\n",
    "\n",
    "\n",
    "            return (\n",
    "                np.array(self.state).astype(np.float32),\n",
    "                self.reward,\n",
    "                self.terminal,\n",
    "                truncated,\n",
    "                info,\n",
    "            )\n",
    "\n",
    "        # --> IN A NORMAL STEP\n",
    "        else: \n",
    "\n",
    "            # begin_total_asset = sum(self.portfolio.price * self.portfolio.amount)\n",
    "\n",
    "            # Set a punishment at each step to push the agent decide an action\n",
    "            self.reward += -1 * self.initial_amount * self.punishment_rate * self.reward_scaling\n",
    "            \n",
    "            # update previous_portfolio\n",
    "            self.previous_port = self.portfolio.copy()\n",
    "        \n",
    "            if actions[0] > 0:\n",
    "                self._buy_stock(actions[0])\n",
    "            else:\n",
    "                sell_number_share = self._sell_stock(actions[0])\n",
    "\n",
    "            # actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n",
    "            # actions = actions.astype(int)  # convert into integer because we can't by fraction of shares\n",
    "            # print(type(actions))\n",
    "            self.actions_memory.append(actions)\n",
    "\n",
    "            # Update selected row in the dataset based on state: s -> s+1\n",
    "            self.row += 1\n",
    "            self.data = self.df.loc[self.row]\n",
    "            self.state = self._update_state()\n",
    "    \n",
    "            end_total_asset = sum(self.portfolio.price * self.portfolio.amount)\n",
    "            # print(f'Begin asset: {begin_total_asset}, End asset: {end_total_asset}')\n",
    "\n",
    "            # Update asset memory\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            self.date_memory.append(self._get_date())\n",
    "\n",
    "            # Update reward\n",
    "            # if self.reward == 0:\n",
    "            #     self.reward = end_total_asset - self.initial_amount\n",
    "\n",
    "            if (self.row >= len(self.df.index.unique()) - 1):\n",
    "                self.reward += (end_total_asset - self.initial_amount)  * self.reward_scaling\n",
    "            \n",
    "            self.rewards_memory.append(self.reward)\n",
    "            # self.reward = self.reward * self.reward_scaling\n",
    "\n",
    "        truncated = False  # we do not limit the number of steps here\n",
    "        # Optionally we can pass additional info, we are not using that for now\n",
    "        info = {}\n",
    "        \n",
    "        # return self.state, self.reward, self.terminal, {}\n",
    "    \n",
    "        return (\n",
    "            np.array(self.state).astype(np.float32),\n",
    "            self.reward,\n",
    "            self.terminal,\n",
    "            truncated,\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # initiate state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # Reset asset_memory\n",
    "        if self.initial:\n",
    "            self.asset_memory = [self.initial_amount]\n",
    "        else:\n",
    "            previous_total_asset = sum(self.previous_port.price * self.previous_port.amount)\n",
    "            self.asset_memory = [previous_total_asset]\n",
    "\n",
    "        # Reset support variables\n",
    "        # self.row = 0\n",
    "        # self.data = self.df.loc[self.row, :]\n",
    "        # self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        self.episode += 1\n",
    "\n",
    "        return np.array(self.state).astype(np.float32), {}\n",
    "        # return self.state\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return self.state\n",
    "\n",
    "    def _initiate_state(self):\n",
    "        \n",
    "        # Reset portfolio & previous_portfolio\n",
    "        if self.initial:\n",
    "            self.portfolio = pd.DataFrame([['cap',self.initial_amount,self.initial_amount,1,1]])\n",
    "            self.portfolio.columns = self.portfolio_columns\n",
    "            self.previous_port = self.portfolio.copy()\n",
    "        else:\n",
    "            self.portfolio = self.previous_port.copy()\n",
    "\n",
    "        # Reset data\n",
    "        self.reward = 0\n",
    "        self.row = 0\n",
    "        self.data = self.df.loc[self.row]\n",
    "        \n",
    "         # Reset state\n",
    "        state = self._update_state()\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def _update_state(self):\n",
    "\n",
    "        # if the stock appear in the portfolio already\n",
    "        if self.portfolio[self.portfolio.tic == self.data.tic].empty:\n",
    "            state = ([self.portfolio.loc[0].price] + [self.data['close']] + [0] + [0] + [0] + sum([[self.data[tech]] for tech in self.tech_indicator_list], []))\n",
    "            \n",
    "        else:\n",
    "            # Update stock's prices in portfolio before updating state\n",
    "            selected_index = self.portfolio[self.portfolio.tic == self.data.tic].index[0]\n",
    "            selected_row = self.portfolio.loc[selected_index]\n",
    "            selected_row['price'] = self.data.close\n",
    "            self.portfolio.loc[selected_index] = selected_row\n",
    "            self._compute_weight()\n",
    "            selected_row = self.portfolio.loc[selected_index]\n",
    "            # print(\"Update portfolio at \",self.data.tic,\" price: \", self.data.close,\"; with weight: \", selected_row.weight)\n",
    "            \n",
    "            state = (\n",
    "                    [self.portfolio.iloc[0].price]\n",
    "                    + [(selected_row.buy_price/selected_row.price-1)]\n",
    "                    + [self.data.close]\n",
    "                    + [selected_row.amount]\n",
    "                    + [selected_row.weight]\n",
    "                    + sum([[self.data[tech]] for tech in self.tech_indicator_list], [])\n",
    "                )\n",
    "    \n",
    "        return state\n",
    "\n",
    "    def _get_date(self):\n",
    "        # return self.data.date\n",
    "        return self.row\n",
    "\n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        asset_list = self.asset_memory\n",
    "        # print(len(date_list))\n",
    "        # print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame(\n",
    "            {\"date\": date_list, \"account_value\": asset_list}\n",
    "        )\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        \n",
    "        date_list = self.date_memory[:-1]\n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3 Initialize Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State's space include current capital amount, the return of the current stock, the weight of this stock in the portfolio, and the indicators decided in ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Dimension: 1, State Space: 22\n"
     ]
    }
   ],
   "source": [
    "ratio_list = train_data.columns.drop(['date','tic','close'])\n",
    "\n",
    "action_dimension = 1 # k float in range (-1,1) to decide sell (k<0) or buy (k>0) decisions\n",
    "state_space = 1 + 4*action_dimension + len(ratio_list)\n",
    "print(f\"Action Dimension: {action_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "# Parameters for the environment\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.01,\n",
    "    \"state_space\": state_space, \n",
    "    \"tech_indicator_list\": ratio_list, \n",
    "    \"action_space\": action_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"stop_loss\": 0.3,\n",
    "    \"print_verbosity\":4,\n",
    "    \"punishment_rate\": 0.0001\n",
    "}\n",
    "\n",
    "#Establish the training environment using StockTradingEnv() class\n",
    "e_train_gym = StockTradingEnv(df = train_data, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# If the environment don't follow the interface, an error will be thrown\n",
    "check_env(e_train_gym, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN, DDPG\n",
    "\n",
    "# Instantiate the env\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.00000000e+06, 5.60418749e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 3.04696411e-01, 3.17371696e-01, 0.00000000e+00,\n",
      "       2.73742332e+01, 1.11105934e-01, 1.00000000e+01, 1.47935188e+00,\n",
      "       5.09861037e-02, 7.83358589e-02, 2.28045985e-01, 9.45330918e-01,\n",
      "       0.00000000e+00, 3.14535213e+00, 1.28193632e-01, 9.45330918e-01,\n",
      "       0.00000000e+00, 2.61837552e-10], dtype=float32), {})\n"
     ]
    }
   ],
   "source": [
    "# Get samples from train_data\n",
    "test_env_data = train_data\n",
    "# test_env_data = trade_data.iloc[:20]\n",
    "# test_env_data.close = [10,100,15,90,20,80,25,85,18,92,10,100,15,90,20,80,25,85,18,92]\n",
    "\n",
    "# Parameters for the environment\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"tech_indicator_list\": ratio_list, \n",
    "    \"action_space\": action_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"stop_loss\": 0.3,\n",
    "    \"print_verbosity\":4,\n",
    "    \"punishment_rate\": 0.0001\n",
    "}\n",
    "\n",
    "#Establish the training environment using StockTradingEnv() class\n",
    "test_train_gym = StockTradingEnv(df = test_env_data, **env_kwargs)\n",
    "\n",
    "# test reset state\n",
    "print(test_train_gym.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, action: [-0.14593355], terminated: False, reward: -0.11, Trade: 0\n",
      "Step 2, action: [0.0939177], terminated: False, reward: -0.12, Trade: 1\n",
      "Step 3, action: [-0.39592525], terminated: False, reward: -0.23, Trade: 1\n",
      "Step 4, action: [0.205413], terminated: False, reward: -0.24000000000000002, Trade: 2\n",
      "Step 5, action: [-0.72977334], terminated: False, reward: -0.35, Trade: 2\n",
      "Step 6, action: [0.348484], terminated: False, reward: -0.36, Trade: 3\n",
      "Step 7, action: [-0.23503968], terminated: False, reward: -0.47, Trade: 3\n",
      "Step 8, action: [-0.4293368], terminated: False, reward: -0.58, Trade: 3\n",
      "Step 9, action: [-0.43366036], terminated: False, reward: -0.69, Trade: 3\n",
      "Step 10, action: [-0.2547125], terminated: False, reward: -0.7999999999999999, Trade: 3\n",
      "Step 11, action: [0.09664915], terminated: False, reward: -0.8099999999999999, Trade: 4\n",
      "Step 12, action: [0.59045976], terminated: False, reward: -0.82, Trade: 5\n",
      "Step 13, action: [0.80234593], terminated: False, reward: -0.83, Trade: 6\n",
      "Step 14, action: [0.16716237], terminated: False, reward: -0.84, Trade: 7\n",
      "Step 15, action: [-0.6643205], terminated: False, reward: -0.95, Trade: 7\n",
      "Step 16, action: [-0.9029513], terminated: False, reward: -1.06, Trade: 7\n",
      "Step 17, action: [-0.2804583], terminated: False, reward: -1.1700000000000002, Trade: 7\n",
      "Step 18, action: [-0.20664354], terminated: False, reward: -1.2800000000000002, Trade: 7\n",
      "Step 19, action: [0.5414753], terminated: False, reward: -1.2900000000000003, Trade: 8\n",
      "Step 20, action: [-0.95703256], terminated: False, reward: -1.4000000000000004, Trade: 8\n",
      "Step 21, action: [-0.7485694], terminated: False, reward: -1.5100000000000005, Trade: 8\n",
      "Step 22, action: [0.58273786], terminated: False, reward: -1.5200000000000005, Trade: 9\n",
      "Step 23, action: [0.06752374], terminated: False, reward: -1.5300000000000005, Trade: 10\n",
      "Step 24, action: [-0.84344214], terminated: False, reward: 4.666675956631085, Trade: 11\n",
      "Step 25, action: [-0.60991454], terminated: False, reward: 4.556675956631086, Trade: 11\n",
      "Step 26, action: [-0.63540846], terminated: False, reward: 4.446675956631086, Trade: 11\n",
      "Step 27, action: [0.55723816], terminated: False, reward: 4.4366759566310865, Trade: 12\n",
      "Step 28, action: [-0.7974116], terminated: False, reward: 4.326675956631087, Trade: 12\n",
      "Step 29, action: [0.31971073], terminated: False, reward: 4.316675956631087, Trade: 13\n",
      "Step 30, action: [0.22477455], terminated: False, reward: 4.3066759566310875, Trade: 14\n",
      "Step 31, action: [-0.07155754], terminated: False, reward: 4.196675956631088, Trade: 14\n",
      "Step 32, action: [-0.8474332], terminated: False, reward: 2.827234874590684, Trade: 15\n",
      "Step 33, action: [0.2746916], terminated: False, reward: 2.8172348745906843, Trade: 16\n",
      "Step 34, action: [0.0242358], terminated: False, reward: 2.8072348745906845, Trade: 17\n",
      "Step 35, action: [-0.3624053], terminated: False, reward: 2.7941006210029617, Trade: 18\n",
      "Step 36, action: [0.5354944], terminated: False, reward: 2.784100621002962, Trade: 19\n",
      "Step 37, action: [-0.9549477], terminated: False, reward: 2.674100621002962, Trade: 19\n",
      "Step 38, action: [-0.96327573], terminated: False, reward: 2.564100621002962, Trade: 19\n",
      "Step 39, action: [-0.45260254], terminated: False, reward: 2.4541006210029623, Trade: 19\n",
      "Step 40, action: [0.5066865], terminated: False, reward: 2.4441006210029625, Trade: 20\n",
      "Step 41, action: [0.08709334], terminated: False, reward: 2.4341006210029628, Trade: 21\n",
      "Step 42, action: [0.9558344], terminated: False, reward: 2.424100621002963, Trade: 22\n",
      "Step 43, action: [-0.6654848], terminated: False, reward: 2.4218037547172577, Trade: 23\n",
      "Step 44, action: [0.7088551], terminated: False, reward: 2.411803754717258, Trade: 24\n",
      "Step 45, action: [-0.2536752], terminated: False, reward: 2.5449356298384935, Trade: 25\n",
      "Step 46, action: [0.32319698], terminated: False, reward: 2.5349356298384937, Trade: 26\n",
      "Step 47, action: [-0.05185593], terminated: False, reward: 2.424935629838494, Trade: 26\n",
      "Step 48, action: [-0.01415553], terminated: False, reward: 2.314935629838494, Trade: 26\n",
      "Step 49, action: [0.27198622], terminated: False, reward: 2.304935629838494, Trade: 27\n",
      "Step 50, action: [-0.06726775], terminated: False, reward: 2.1949356298384943, Trade: 27\n",
      "Step 51, action: [0.18973838], terminated: False, reward: 2.1849356298384945, Trade: 28\n",
      "Step 52, action: [-0.82856935], terminated: False, reward: 2.462831324597383, Trade: 29\n",
      "Step 53, action: [-0.2498238], terminated: False, reward: 2.3528313245973833, Trade: 29\n",
      "Step 54, action: [0.00361906], terminated: False, reward: 2.3428313245973835, Trade: 30\n",
      "Step 55, action: [0.33606476], terminated: False, reward: 2.3328313245973837, Trade: 31\n",
      "Step 56, action: [0.37948623], terminated: False, reward: 2.322831324597384, Trade: 32\n",
      "Step 57, action: [0.7528807], terminated: False, reward: 2.312831324597384, Trade: 33\n",
      "Step 58, action: [-0.12848273], terminated: False, reward: 2.3692775634584686, Trade: 34\n",
      "Step 59, action: [0.2535578], terminated: False, reward: 2.359277563458469, Trade: 35\n",
      "Step 60, action: [0.1081442], terminated: False, reward: 2.349277563458469, Trade: 36\n",
      "Step 61, action: [0.39283758], terminated: False, reward: 2.3392775634584693, Trade: 37\n",
      "Step 62, action: [0.8097594], terminated: False, reward: 2.3292775634584695, Trade: 38\n",
      "Step 63, action: [0.14966953], terminated: False, reward: 2.3192775634584697, Trade: 39\n",
      "Step 64, action: [-0.14427692], terminated: False, reward: 2.286407290164021, Trade: 40\n",
      "Step 65, action: [0.24074182], terminated: False, reward: 2.276407290164021, Trade: 41\n",
      "Step 66, action: [-0.22449927], terminated: False, reward: 2.270120636562696, Trade: 42\n",
      "Step 67, action: [-0.2629122], terminated: False, reward: 2.442580909071193, Trade: 43\n",
      "Step 68, action: [-0.41350102], terminated: False, reward: 2.42680112073072, Trade: 44\n",
      "Step 69, action: [-0.3867421], terminated: False, reward: 2.31680112073072, Trade: 44\n",
      "Step 70, action: [0.3438151], terminated: False, reward: 2.30680112073072, Trade: 45\n",
      "Step 71, action: [-0.6010684], terminated: False, reward: 2.6953350680436947, Trade: 46\n",
      "Step 72, action: [-0.37130523], terminated: False, reward: 2.585335068043695, Trade: 46\n",
      "Step 73, action: [0.62822837], terminated: False, reward: 2.575335068043695, Trade: 47\n",
      "Step 74, action: [-0.84373677], terminated: False, reward: 2.738657512616914, Trade: 48\n",
      "Step 75, action: [0.14528519], terminated: False, reward: 2.7286575126169144, Trade: 49\n",
      "Step 76, action: [0.8213315], terminated: False, reward: 2.7186575126169146, Trade: 50\n",
      "Step 77, action: [-0.45969892], terminated: False, reward: 3.4910018869005537, Trade: 51\n",
      "Step 78, action: [-0.41615656], terminated: False, reward: 3.5547033626755447, Trade: 52\n",
      "Step 79, action: [-0.5437859], terminated: False, reward: 3.7442676274343594, Trade: 53\n",
      "Step 80, action: [0.14856856], terminated: False, reward: 3.7342676274343596, Trade: 54\n",
      "Step 81, action: [0.23722032], terminated: False, reward: 3.72426762743436, Trade: 55\n",
      "Step 82, action: [-0.39738512], terminated: False, reward: 3.7191917806741825, Trade: 56\n",
      "Step 83, action: [0.75690866], terminated: False, reward: 3.7091917806741828, Trade: 57\n",
      "Step 84, action: [-0.41990227], terminated: False, reward: 3.935004758511354, Trade: 58\n",
      "Step 85, action: [-0.5342252], terminated: False, reward: 3.936123133616391, Trade: 59\n",
      "Step 86, action: [0.192664], terminated: False, reward: 3.9261231336163913, Trade: 60\n",
      "Step 87, action: [-0.78981584], terminated: False, reward: 3.9383211604983956, Trade: 61\n",
      "Step 88, action: [-0.3353324], terminated: False, reward: 3.9275044344038523, Trade: 62\n",
      "Step 89, action: [0.45765728], terminated: False, reward: 3.9175044344038525, Trade: 63\n",
      "Step 90, action: [-0.8021494], terminated: False, reward: 3.9274868071750206, Trade: 64\n",
      "Step 91, action: [0.45027915], terminated: False, reward: 3.917486807175021, Trade: 65\n",
      "Step 92, action: [0.47582048], terminated: False, reward: 3.907486807175021, Trade: 66\n",
      "Step 93, action: [-0.15312438], terminated: False, reward: 3.861076258518504, Trade: 67\n",
      "Step 94, action: [0.6046139], terminated: False, reward: 3.8510762585185043, Trade: 68\n",
      "Step 95, action: [0.32306612], terminated: False, reward: 3.8410762585185045, Trade: 69\n",
      "Step 96, action: [-0.26792723], terminated: False, reward: 3.845460396109138, Trade: 70\n",
      "Step 97, action: [-0.20934351], terminated: False, reward: 3.8744115190099104, Trade: 71\n",
      "Step 98, action: [0.99177766], terminated: False, reward: 3.8644115190099106, Trade: 72\n",
      "Step 99, action: [0.91932774], terminated: False, reward: 3.7544115190099108, Trade: 72\n",
      "Step 100, action: [0.9745947], terminated: False, reward: 3.744411519009911, Trade: 73\n",
      "Step 101, action: [-0.7384991], terminated: False, reward: 3.910082055720894, Trade: 74\n",
      "Step 102, action: [0.71627945], terminated: False, reward: 3.9000820557208944, Trade: 75\n",
      "Step 103, action: [0.03691007], terminated: False, reward: 3.8900820557208946, Trade: 76\n",
      "Step 104, action: [-0.68664485], terminated: False, reward: 3.881274345674508, Trade: 77\n",
      "Step 105, action: [0.65525025], terminated: False, reward: 3.8712743456745082, Trade: 78\n",
      "Step 106, action: [-0.8420533], terminated: False, reward: 4.369404352165695, Trade: 79\n",
      "Step 107, action: [0.9269789], terminated: False, reward: 4.359404352165695, Trade: 80\n",
      "Step 108, action: [0.73801774], terminated: False, reward: 4.3494043521656955, Trade: 81\n",
      "Step 109, action: [-0.7688237], terminated: False, reward: 4.3394169336729, Trade: 82\n",
      "Step 110, action: [-0.65467364], terminated: False, reward: 4.3153537508253095, Trade: 83\n",
      "Step 111, action: [0.45886952], terminated: False, reward: 4.30535375082531, Trade: 84\n",
      "Step 112, action: [-0.542377], terminated: False, reward: 4.295180243456841, Trade: 85\n",
      "Step 113, action: [0.7961306], terminated: False, reward: 4.285180243456841, Trade: 86\n",
      "Step 114, action: [-0.9078697], terminated: False, reward: 4.3433793729332075, Trade: 87\n",
      "Step 115, action: [-0.08472101], terminated: False, reward: 4.237702477937513, Trade: 88\n",
      "Step 116, action: [-0.63236094], terminated: False, reward: 4.085653075392347, Trade: 89\n",
      "Step 117, action: [0.19897357], terminated: False, reward: 4.0756530753923474, Trade: 90\n",
      "Step 118, action: [-0.8758349], terminated: False, reward: 4.081775791710636, Trade: 91\n",
      "Step 119, action: [-0.32460457], terminated: False, reward: 4.123879319097111, Trade: 92\n",
      "Step 120, action: [-0.75875825], terminated: False, reward: 3.8942596556195475, Trade: 93\n",
      "Step 121, action: [-0.33361822], terminated: False, reward: 3.450473092052945, Trade: 94\n",
      "Step 122, action: [-0.81417215], terminated: False, reward: 3.5848107237161955, Trade: 95\n",
      "Step 123, action: [-0.18983427], terminated: False, reward: 3.579489329817277, Trade: 96\n",
      "Step 124, action: [0.34530723], terminated: False, reward: 3.5694893298172774, Trade: 97\n",
      "Step 125, action: [-0.0833839], terminated: False, reward: 3.5527222973653725, Trade: 98\n",
      "Step 126, action: [-0.7643341], terminated: False, reward: 3.541235822210496, Trade: 99\n",
      "Step 127, action: [-0.33982244], terminated: False, reward: 3.338828551651446, Trade: 100\n",
      "Step 128, action: [-0.06364981], terminated: False, reward: 3.332402031174569, Trade: 101\n",
      "Step 129, action: [0.24029085], terminated: False, reward: 3.322402031174569, Trade: 102\n",
      "Step 130, action: [0.00835253], terminated: False, reward: 3.312402031174569, Trade: 103\n",
      "Step 131, action: [-0.6377496], terminated: False, reward: 3.2024020311745693, Trade: 103\n",
      "Step 132, action: [-0.85653514], terminated: False, reward: 3.191952544463393, Trade: 104\n",
      "Step 133, action: [0.59789395], terminated: False, reward: 3.1819525444633934, Trade: 105\n",
      "Step 134, action: [-0.4327148], terminated: False, reward: 2.82594883661419, Trade: 106\n",
      "Step 135, action: [0.7928032], terminated: False, reward: 2.81594883661419, Trade: 107\n",
      "Step 136, action: [-0.44943056], terminated: False, reward: 2.7416105130578665, Trade: 108\n",
      "Step 137, action: [-0.688227], terminated: False, reward: 2.73378154814073, Trade: 109\n",
      "Step 138, action: [0.46755293], terminated: False, reward: 2.7237815481407304, Trade: 110\n",
      "Step 139, action: [0.620994], terminated: False, reward: 2.7137815481407306, Trade: 111\n",
      "Step 140, action: [0.88803524], terminated: False, reward: 2.703781548140731, Trade: 112\n",
      "Step 141, action: [0.9665611], terminated: False, reward: 2.693781548140731, Trade: 113\n",
      "Step 142, action: [-0.53924865], terminated: False, reward: 2.7387201438781887, Trade: 114\n",
      "Step 143, action: [0.81084734], terminated: False, reward: 2.728720143878189, Trade: 115\n",
      "Step 144, action: [0.12412304], terminated: False, reward: 2.618720143878189, Trade: 115\n",
      "Step 145, action: [0.6464487], terminated: False, reward: 2.6087201438781893, Trade: 116\n",
      "Step 146, action: [-0.9315668], terminated: False, reward: 2.5939907643976947, Trade: 117\n",
      "Step 147, action: [0.79959893], terminated: False, reward: 2.583990764397695, Trade: 118\n",
      "Step 148, action: [0.16772898], terminated: False, reward: 2.573990764397695, Trade: 119\n",
      "Step 149, action: [0.9824174], terminated: False, reward: 2.5639907643976954, Trade: 120\n",
      "Step 150, action: [0.19279867], terminated: False, reward: 2.4539907643976955, Trade: 120\n",
      "Step 151, action: [-0.37802497], terminated: False, reward: 2.461038535789547, Trade: 121\n",
      "Step 152, action: [0.5532604], terminated: False, reward: 2.451038535789547, Trade: 122\n",
      "Step 153, action: [0.33613396], terminated: False, reward: 2.441038535789547, Trade: 123\n",
      "Step 154, action: [-0.59417975], terminated: False, reward: 2.3310385357895473, Trade: 123\n",
      "Step 155, action: [0.843689], terminated: False, reward: 2.3210385357895476, Trade: 124\n",
      "Step 156, action: [0.3139647], terminated: False, reward: 2.3110385357895478, Trade: 125\n",
      "Step 157, action: [-0.11467475], terminated: False, reward: 2.301038535789548, Trade: 126\n",
      "Step 158, action: [0.89139503], terminated: False, reward: 2.291038535789548, Trade: 127\n",
      "Step 159, action: [-0.37929624], terminated: False, reward: 2.075948182171688, Trade: 128\n",
      "Step 160, action: [-0.12208146], terminated: False, reward: 2.07766873632032, Trade: 129\n",
      "Step 161, action: [0.08661311], terminated: False, reward: 2.06766873632032, Trade: 130\n",
      "Step 162, action: [0.96799356], terminated: False, reward: 2.0576687363203203, Trade: 131\n",
      "Step 163, action: [-0.72044146], terminated: False, reward: 1.6337269942478012, Trade: 132\n",
      "Step 164, action: [-0.25736606], terminated: False, reward: 1.6432664974087634, Trade: 133\n",
      "Step 165, action: [0.9419521], terminated: False, reward: 1.6332664974087634, Trade: 134\n",
      "Step 166, action: [0.24417531], terminated: False, reward: 1.6232664974087634, Trade: 135\n",
      "Step 167, action: [-0.99299204], terminated: False, reward: 1.7143987269154466, Trade: 136\n",
      "Step 168, action: [-0.02779984], terminated: False, reward: 1.6043987269154465, Trade: 136\n",
      "Step 169, action: [0.47156703], terminated: False, reward: 1.5943987269154465, Trade: 137\n",
      "Step 170, action: [0.8602672], terminated: False, reward: 1.5843987269154465, Trade: 138\n",
      "Step 171, action: [0.39797315], terminated: False, reward: 1.5743987269154465, Trade: 139\n",
      "Step 172, action: [-0.9486835], terminated: False, reward: 1.565712922879249, Trade: 140\n",
      "Step 173, action: [-0.18442465], terminated: False, reward: 1.6992385276790245, Trade: 141\n",
      "Step 174, action: [-0.00767388], terminated: False, reward: 1.6876493410859692, Trade: 142\n",
      "Step 175, action: [-0.9329139], terminated: False, reward: 1.6814185090977212, Trade: 143\n",
      "Step 176, action: [0.608574], terminated: False, reward: 1.6714185090977212, Trade: 144\n",
      "Step 177, action: [-0.31503984], terminated: False, reward: 1.6780079430970811, Trade: 145\n",
      "Step 178, action: [0.5032215], terminated: False, reward: 1.6680079430970811, Trade: 146\n",
      "Step 179, action: [-0.7144419], terminated: False, reward: 1.3806183780856478, Trade: 147\n",
      "Step 180, action: [-0.95246375], terminated: False, reward: 1.2706183780856477, Trade: 147\n",
      "Step 181, action: [-0.3904359], terminated: False, reward: 1.2629165487073288, Trade: 148\n",
      "Step 182, action: [-0.6461398], terminated: False, reward: 1.2529165487073288, Trade: 149\n",
      "Step 183, action: [0.78540325], terminated: False, reward: 1.2429165487073288, Trade: 150\n",
      "Step 184, action: [-0.974646], terminated: False, reward: 1.548826870055589, Trade: 151\n",
      "Step 185, action: [-0.88999414], terminated: False, reward: 1.3132578259844665, Trade: 152\n",
      "Step 186, action: [0.50240034], terminated: False, reward: 1.3032578259844665, Trade: 153\n",
      "Step 187, action: [-0.13467588], terminated: False, reward: 1.2856456723219716, Trade: 154\n",
      "Step 188, action: [-0.3064686], terminated: False, reward: 1.243887692923106, Trade: 155\n",
      "Step 189, action: [0.81080437], terminated: False, reward: 1.233887692923106, Trade: 156\n",
      "Step 190, action: [0.19439581], terminated: False, reward: 1.223887692923106, Trade: 157\n",
      "Step 191, action: [-0.13618305], terminated: False, reward: 0.8836935535242845, Trade: 158\n",
      "Step 192, action: [0.9503973], terminated: False, reward: 0.8736935535242845, Trade: 159\n",
      "Step 193, action: [-0.17041288], terminated: False, reward: 0.8636935535242845, Trade: 160\n",
      "Step 194, action: [-0.1627166], terminated: False, reward: 0.7536935535242845, Trade: 160\n",
      "Step 195, action: [-0.9116645], terminated: False, reward: 0.7337599392556041, Trade: 161\n",
      "Step 196, action: [-0.46723458], terminated: False, reward: 0.11849098681438053, Trade: 162\n",
      "Step 197, action: [-0.16907792], terminated: False, reward: 0.10537959281468927, Trade: 163\n",
      "Step 198, action: [0.88797796], terminated: False, reward: 0.09537959281468927, Trade: 164\n",
      "Step 199, action: [0.09429632], terminated: False, reward: 0.08537959281468928, Trade: 165\n",
      "Step 200, action: [0.03919336], terminated: False, reward: 0.07537959281468928, Trade: 166\n",
      "Step 201, action: [-0.45447206], terminated: False, reward: 0.06537959281468929, Trade: 167\n",
      "Step 202, action: [0.35114518], terminated: False, reward: 0.05537959281468929, Trade: 168\n",
      "Step 203, action: [-0.62057734], terminated: False, reward: 0.07974353989819868, Trade: 169\n",
      "Step 204, action: [0.69764394], terminated: False, reward: 0.06974353989819869, Trade: 170\n",
      "Step 205, action: [0.38594967], terminated: False, reward: 0.05974353989819869, Trade: 171\n",
      "Step 206, action: [-0.76250416], terminated: False, reward: -0.05025646010180132, Trade: 171\n",
      "Step 207, action: [0.20683183], terminated: False, reward: -0.06025646010180132, Trade: 172\n",
      "Step 208, action: [-0.20875585], terminated: False, reward: -0.07025646010180132, Trade: 173\n",
      "Step 209, action: [-0.5841677], terminated: False, reward: -0.1420993335423194, Trade: 174\n",
      "Step 210, action: [-0.190592], terminated: False, reward: -0.14925549777059602, Trade: 175\n",
      "Step 211, action: [-0.49820843], terminated: False, reward: -0.18037436367953083, Trade: 176\n",
      "Step 212, action: [-0.5862318], terminated: False, reward: 0.3351758006713874, Trade: 177\n",
      "Step 213, action: [-0.00544232], terminated: False, reward: 0.3248365410741795, Trade: 178\n",
      "Step 214, action: [0.1024235], terminated: False, reward: 0.31483654107417947, Trade: 179\n",
      "Step 215, action: [0.04401059], terminated: False, reward: 0.30483654107417946, Trade: 180\n",
      "Step 216, action: [0.47518128], terminated: False, reward: 0.29483654107417945, Trade: 181\n",
      "Step 217, action: [0.0239422], terminated: False, reward: 0.28483654107417944, Trade: 182\n",
      "Step 218, action: [-0.17304187], terminated: False, reward: 0.42927601649515557, Trade: 183\n",
      "Step 219, action: [-0.01736346], terminated: False, reward: 0.41927601649515556, Trade: 184\n",
      "Step 220, action: [0.30070135], terminated: False, reward: 0.40927601649515555, Trade: 185\n",
      "Step 221, action: [0.20422621], terminated: False, reward: 0.39927601649515554, Trade: 186\n",
      "Step 222, action: [0.8474142], terminated: False, reward: 0.38927601649515553, Trade: 187\n",
      "Step 223, action: [-0.19178925], terminated: False, reward: 0.38358917856914826, Trade: 188\n",
      "Step 224, action: [-0.2779205], terminated: False, reward: 0.5905848256441729, Trade: 189\n",
      "Step 225, action: [0.53112864], terminated: False, reward: 0.5805848256441729, Trade: 190\n",
      "Step 226, action: [0.12688015], terminated: False, reward: 0.5705848256441729, Trade: 191\n",
      "Step 227, action: [0.5264041], terminated: False, reward: 0.5605848256441729, Trade: 192\n",
      "Step 228, action: [0.311188], terminated: False, reward: 0.5505848256441729, Trade: 193\n",
      "Step 229, action: [0.02820021], terminated: False, reward: 0.5405848256441729, Trade: 194\n",
      "Step 230, action: [0.21729226], terminated: False, reward: 0.5305848256441729, Trade: 195\n",
      "Step 231, action: [-0.5115246], terminated: False, reward: 0.5250739310755995, Trade: 196\n",
      "Step 232, action: [0.7052164], terminated: False, reward: 0.5150739310755995, Trade: 197\n",
      "Step 233, action: [0.8744023], terminated: False, reward: 0.5050739310755995, Trade: 198\n",
      "Step 234, action: [0.10980061], terminated: False, reward: 0.4950739310755995, Trade: 199\n",
      "Step 235, action: [-0.80870914], terminated: False, reward: 0.5316530237283674, Trade: 200\n",
      "Step 236, action: [0.5821726], terminated: False, reward: 0.5216530237283674, Trade: 201\n",
      "Step 237, action: [0.990236], terminated: False, reward: 0.5116530237283674, Trade: 202\n",
      "Step 238, action: [-0.25004694], terminated: False, reward: 0.7106493651682144, Trade: 203\n",
      "Step 239, action: [-0.6185677], terminated: False, reward: 0.7000942008043868, Trade: 204\n",
      "Step 240, action: [-0.9798182], terminated: False, reward: 0.9606943061179565, Trade: 205\n",
      "Step 241, action: [-0.48828775], terminated: False, reward: 1.2039512391347644, Trade: 206\n",
      "Step 242, action: [-0.3014647], terminated: False, reward: 1.181572963275555, Trade: 207\n",
      "Step 243, action: [-0.33354446], terminated: False, reward: 1.6318588189187442, Trade: 208\n",
      "Step 244, action: [-0.55219615], terminated: False, reward: 2.0399282399542122, Trade: 209\n",
      "Step 245, action: [0.00859873], terminated: False, reward: 2.0299282399542125, Trade: 210\n",
      "Step 246, action: [0.18568704], terminated: False, reward: 2.0199282399542127, Trade: 211\n",
      "Step 247, action: [-0.7655715], terminated: False, reward: 2.044393309147088, Trade: 212\n",
      "Step 248, action: [-0.30444437], terminated: False, reward: 2.1333010820426543, Trade: 213\n",
      "Step 249, action: [-0.9480316], terminated: False, reward: 2.1347547944464065, Trade: 214\n",
      "Step 250, action: [-0.27897364], terminated: False, reward: 2.3850863951303993, Trade: 215\n",
      "Step 251, action: [-0.43671823], terminated: False, reward: 3.6111399530329407, Trade: 216\n",
      "Step 252, action: [0.3795365], terminated: False, reward: 3.601139953032941, Trade: 217\n",
      "Step 253, action: [0.9083756], terminated: False, reward: 3.591139953032941, Trade: 218\n",
      "Step 254, action: [-0.05994495], terminated: False, reward: 3.6495544205033963, Trade: 219\n",
      "Step 255, action: [0.76622796], terminated: False, reward: 3.6395544205033965, Trade: 220\n",
      "Step 256, action: [0.7564187], terminated: False, reward: 3.6295544205033967, Trade: 221\n",
      "Step 257, action: [0.6432037], terminated: False, reward: 3.619554420503397, Trade: 222\n",
      "Step 258, action: [-0.6133735], terminated: False, reward: 3.6512360909639074, Trade: 223\n",
      "Step 259, action: [-0.88311243], terminated: False, reward: 3.6566519768068897, Trade: 224\n",
      "Step 260, action: [-0.07416549], terminated: False, reward: 3.64665197680689, Trade: 225\n",
      "Step 261, action: [0.79692936], terminated: False, reward: 3.63665197680689, Trade: 226\n",
      "Step 262, action: [0.558613], terminated: False, reward: 3.6266519768068903, Trade: 227\n",
      "Step 263, action: [0.29613322], terminated: False, reward: 3.6166519768068905, Trade: 228\n",
      "Step 264, action: [0.384874], terminated: False, reward: 3.6066519768068908, Trade: 229\n",
      "Step 265, action: [-0.04598656], terminated: False, reward: 3.596830246176965, Trade: 230\n",
      "Step 266, action: [0.9069567], terminated: False, reward: 3.586830246176965, Trade: 231\n",
      "Step 267, action: [-0.16366006], terminated: False, reward: 3.566435647662698, Trade: 232\n",
      "Step 268, action: [-0.8161591], terminated: False, reward: 3.6467173238135446, Trade: 233\n",
      "Step 269, action: [-0.10431216], terminated: False, reward: 3.5675885817321693, Trade: 234\n",
      "Step 270, action: [-0.66624755], terminated: False, reward: 3.8827901264911016, Trade: 235\n",
      "Step 271, action: [-0.73486125], terminated: False, reward: 3.9007354767198987, Trade: 236\n",
      "Step 272, action: [0.51775986], terminated: False, reward: 3.890735476719899, Trade: 237\n",
      "Step 273, action: [0.97619253], terminated: False, reward: 3.880735476719899, Trade: 238\n",
      "Step 274, action: [0.24898319], terminated: False, reward: 3.8707354767198994, Trade: 239\n",
      "Step 275, action: [-0.6190794], terminated: False, reward: 3.8609631169876932, Trade: 240\n",
      "Step 276, action: [0.9814125], terminated: False, reward: 3.8509631169876934, Trade: 241\n",
      "Step 277, action: [0.88294655], terminated: False, reward: 3.7409631169876936, Trade: 241\n",
      "Step 278, action: [-0.43211418], terminated: False, reward: 4.026139182935605, Trade: 242\n",
      "Step 279, action: [-0.19350225], terminated: False, reward: 3.9908205211295926, Trade: 243\n",
      "Step 280, action: [0.86451346], terminated: False, reward: 3.980820521129593, Trade: 244\n",
      "Step 281, action: [-0.38350248], terminated: False, reward: 3.9922923568831505, Trade: 245\n",
      "Step 282, action: [-0.75195], terminated: False, reward: 4.097947637072093, Trade: 246\n",
      "Step 283, action: [0.84951836], terminated: False, reward: 4.0879476370720935, Trade: 247\n",
      "Step 284, action: [0.81653684], terminated: False, reward: 4.077947637072094, Trade: 248\n",
      "Step 285, action: [0.67488265], terminated: False, reward: 4.067947637072094, Trade: 249\n",
      "Step 286, action: [-0.04647281], terminated: False, reward: 4.057947637072094, Trade: 250\n",
      "Step 287, action: [-0.47233042], terminated: False, reward: 4.050554094420831, Trade: 251\n",
      "Step 288, action: [-0.42965946], terminated: False, reward: 4.069040665258361, Trade: 252\n",
      "Step 289, action: [-0.13318738], terminated: False, reward: 4.056883937303513, Trade: 253\n",
      "Step 290, action: [0.801198], terminated: False, reward: 4.046883937303513, Trade: 254\n",
      "Step 291, action: [-0.14392222], terminated: False, reward: 4.037373269786692, Trade: 255\n",
      "Step 292, action: [0.7771971], terminated: False, reward: 4.027373269786692, Trade: 256\n",
      "Step 293, action: [-0.8051428], terminated: False, reward: 4.0833896849577345, Trade: 257\n",
      "Step 294, action: [-0.3317403], terminated: False, reward: 4.078641707364613, Trade: 258\n",
      "Step 295, action: [-0.03440858], terminated: False, reward: 4.059574060553697, Trade: 259\n",
      "Step 296, action: [-0.37664795], terminated: False, reward: 4.139120225081311, Trade: 260\n",
      "Step 297, action: [-0.82566047], terminated: False, reward: 4.135104155421463, Trade: 261\n",
      "Step 298, action: [0.6121537], terminated: False, reward: 4.125104155421464, Trade: 262\n",
      "Step 299, action: [-0.65349525], terminated: False, reward: 4.3946394558411885, Trade: 263\n",
      "Step 300, action: [-0.61588496], terminated: False, reward: 4.672609912779448, Trade: 264\n",
      "Step 301, action: [-0.5878175], terminated: False, reward: 4.663041760168746, Trade: 265\n",
      "Step 302, action: [-0.50596225], terminated: False, reward: 5.267232193921958, Trade: 266\n",
      "Step 303, action: [0.6211359], terminated: False, reward: 5.257232193921959, Trade: 267\n",
      "Step 304, action: [-0.9760099], terminated: False, reward: 5.571207210797163, Trade: 268\n",
      "Step 305, action: [-0.19155052], terminated: False, reward: 5.461207210797164, Trade: 268\n",
      "Step 306, action: [0.625996], terminated: False, reward: 5.451207210797164, Trade: 269\n",
      "Step 307, action: [-0.31790802], terminated: False, reward: 6.13385705717761, Trade: 270\n",
      "Step 308, action: [0.9518503], terminated: False, reward: 6.12385705717761, Trade: 271\n",
      "Step 309, action: [0.29020524], terminated: False, reward: 6.1138570571776105, Trade: 272\n",
      "Step 310, action: [0.8812734], terminated: False, reward: 6.103857057177611, Trade: 273\n",
      "Step 311, action: [0.2713089], terminated: False, reward: 6.093857057177611, Trade: 274\n",
      "Step 312, action: [0.89130867], terminated: False, reward: 6.083857057177611, Trade: 275\n",
      "Step 313, action: [-0.2832171], terminated: False, reward: 6.073857057177611, Trade: 276\n",
      "Step 314, action: [0.43985543], terminated: False, reward: 5.963857057177612, Trade: 276\n",
      "Step 315, action: [0.87131214], terminated: False, reward: 5.953857057177612, Trade: 277\n",
      "Step 316, action: [-0.8332509], terminated: False, reward: 5.908969224018404, Trade: 278\n",
      "Step 317, action: [0.89938575], terminated: False, reward: 5.898969224018404, Trade: 279\n",
      "Step 318, action: [0.727539], terminated: False, reward: 5.888969224018404, Trade: 280\n",
      "Step 319, action: [0.93303114], terminated: False, reward: 5.878969224018404, Trade: 281\n",
      "Step 320, action: [0.79540116], terminated: False, reward: 5.768969224018405, Trade: 281\n",
      "Step 321, action: [-0.96153426], terminated: False, reward: 5.775296307656279, Trade: 282\n",
      "Step 322, action: [-0.02912346], terminated: False, reward: 5.783795998770653, Trade: 283\n",
      "Step 323, action: [0.6215467], terminated: False, reward: 5.7737959987706535, Trade: 284\n",
      "Step 324, action: [0.42604122], terminated: False, reward: 5.763795998770654, Trade: 285\n",
      "Step 325, action: [0.09492581], terminated: False, reward: 5.753795998770654, Trade: 286\n",
      "Step 326, action: [0.33483347], terminated: False, reward: 5.743795998770654, Trade: 287\n",
      "Step 327, action: [-0.6278815], terminated: False, reward: 5.810860916570096, Trade: 288\n",
      "Step 328, action: [-0.09753136], terminated: False, reward: 5.800860916570096, Trade: 289\n",
      "Step 329, action: [0.22057572], terminated: False, reward: 5.790860916570097, Trade: 290\n",
      "Step 330, action: [0.8233445], terminated: False, reward: 5.780860916570097, Trade: 291\n",
      "Step 331, action: [0.35016915], terminated: False, reward: 5.770860916570097, Trade: 292\n",
      "Step 332, action: [-0.5192511], terminated: False, reward: 5.660860916570098, Trade: 292\n",
      "Step 333, action: [-0.78263044], terminated: False, reward: 8.18270893517085, Trade: 293\n",
      "Step 334, action: [-0.83960253], terminated: False, reward: 8.92796233037371, Trade: 294\n",
      "Step 335, action: [0.3068972], terminated: False, reward: 8.91796233037371, Trade: 295\n",
      "Step 336, action: [-0.9795453], terminated: False, reward: 9.060047549629507, Trade: 296\n",
      "Step 337, action: [0.5511804], terminated: False, reward: 9.050047549629507, Trade: 297\n",
      "Step 338, action: [-0.8070229], terminated: False, reward: 9.164039254865772, Trade: 298\n",
      "Step 339, action: [-0.36823064], terminated: False, reward: 9.15211827261212, Trade: 299\n",
      "Step 340, action: [0.6087153], terminated: False, reward: 9.14211827261212, Trade: 300\n",
      "Step 341, action: [0.57666034], terminated: False, reward: 9.13211827261212, Trade: 301\n",
      "Step 342, action: [-0.23871717], terminated: False, reward: 9.149444201003362, Trade: 302\n",
      "Step 343, action: [-0.69663256], terminated: False, reward: 9.134052184409907, Trade: 303\n",
      "Step 344, action: [-0.80194545], terminated: False, reward: 10.087731653098025, Trade: 304\n",
      "Step 345, action: [0.5208922], terminated: False, reward: 10.077731653098025, Trade: 305\n",
      "Step 346, action: [-0.9825298], terminated: False, reward: 10.107473544949588, Trade: 306\n",
      "Step 347, action: [-0.5007605], terminated: False, reward: 10.08416980450784, Trade: 307\n",
      "Step 348, action: [0.5083626], terminated: False, reward: 10.07416980450784, Trade: 308\n",
      "Step 349, action: [-0.25671867], terminated: False, reward: 10.379432863994195, Trade: 309\n",
      "Step 350, action: [-0.0658052], terminated: False, reward: 10.383406314123453, Trade: 310\n",
      "Step 351, action: [0.19534715], terminated: False, reward: 10.373406314123454, Trade: 311\n",
      "Step 352, action: [-0.971913], terminated: False, reward: 9.155707740078821, Trade: 312\n",
      "Step 353, action: [-0.7621373], terminated: False, reward: 9.407425513882202, Trade: 313\n",
      "Step 354, action: [-0.48625192], terminated: False, reward: 9.42093806925394, Trade: 314\n",
      "Step 355, action: [-0.6790901], terminated: False, reward: 9.41154680009146, Trade: 315\n",
      "Step 356, action: [0.01506258], terminated: False, reward: 9.40154680009146, Trade: 316\n",
      "Step 357, action: [0.44454193], terminated: False, reward: 9.39154680009146, Trade: 317\n",
      "Step 358, action: [0.8747551], terminated: False, reward: 9.38154680009146, Trade: 318\n",
      "Step 359, action: [0.853806], terminated: False, reward: 9.37154680009146, Trade: 319\n",
      "Step 360, action: [-0.4829484], terminated: False, reward: 9.804231003315994, Trade: 320\n",
      "Step 361, action: [-0.29361033], terminated: False, reward: 9.846629017143831, Trade: 321\n",
      "Step 362, action: [0.19759297], terminated: False, reward: 9.836629017143832, Trade: 322\n",
      "Step 363, action: [-0.9523989], terminated: False, reward: 9.832497445553372, Trade: 323\n",
      "Step 364, action: [0.76404303], terminated: False, reward: 9.822497445553372, Trade: 324\n",
      "Step 365, action: [-0.6633627], terminated: False, reward: 9.824681748145048, Trade: 325\n",
      "Step 366, action: [-0.18270762], terminated: False, reward: 9.816203627280865, Trade: 326\n",
      "Step 367, action: [0.20486926], terminated: False, reward: 9.806203627280865, Trade: 327\n",
      "Step 368, action: [0.531059], terminated: False, reward: 9.796203627280866, Trade: 328\n",
      "Step 369, action: [-0.13959756], terminated: False, reward: 9.800785921672631, Trade: 329\n",
      "Step 370, action: [-0.4878706], terminated: False, reward: 9.790341810603216, Trade: 330\n",
      "Step 371, action: [0.73296744], terminated: False, reward: 9.780341810603217, Trade: 331\n",
      "Step 372, action: [0.04960829], terminated: False, reward: 9.770341810603217, Trade: 332\n",
      "Step 373, action: [-0.9578086], terminated: False, reward: 9.760886026286963, Trade: 333\n",
      "Step 374, action: [-0.44079107], terminated: False, reward: 9.75058859796875, Trade: 334\n",
      "Step 375, action: [-0.85673875], terminated: False, reward: 9.803050085436945, Trade: 335\n",
      "Step 376, action: [-0.3483093], terminated: False, reward: 10.214251386428568, Trade: 336\n",
      "Step 377, action: [-0.70423377], terminated: False, reward: 10.412768218855357, Trade: 337\n",
      "Step 378, action: [-0.7019406], terminated: False, reward: 10.413945451771474, Trade: 338\n",
      "Step 379, action: [0.8649905], terminated: False, reward: 10.403945451771474, Trade: 339\n",
      "Step 380, action: [0.09393352], terminated: False, reward: 10.393945451771474, Trade: 340\n",
      "Step 381, action: [0.34330824], terminated: False, reward: 10.383945451771474, Trade: 341\n",
      "Step 382, action: [0.48048106], terminated: False, reward: 10.373945451771474, Trade: 342\n",
      "Step 383, action: [0.52876204], terminated: False, reward: 10.363945451771475, Trade: 343\n",
      "Step 384, action: [-0.02082734], terminated: False, reward: 10.436442214868118, Trade: 344\n",
      "Step 385, action: [-0.43278906], terminated: False, reward: 10.226855377382362, Trade: 345\n",
      "Step 386, action: [0.59064615], terminated: False, reward: 10.216855377382362, Trade: 346\n",
      "Step 387, action: [0.54324675], terminated: False, reward: 10.206855377382363, Trade: 347\n",
      "Step 388, action: [-0.9655086], terminated: False, reward: 10.382795183783013, Trade: 348\n",
      "Step 389, action: [-0.18299598], terminated: False, reward: 10.441230127826207, Trade: 349\n",
      "Step 390, action: [-0.32824293], terminated: False, reward: 10.431230127826208, Trade: 350\n",
      "Step 391, action: [-0.12439152], terminated: False, reward: 10.403895114292878, Trade: 351\n",
      "Step 392, action: [-0.6743902], terminated: False, reward: 10.394990435699413, Trade: 352\n",
      "Step 393, action: [-0.3891822], terminated: False, reward: 10.380197511379471, Trade: 353\n",
      "Step 394, action: [-0.04645837], terminated: False, reward: 10.361439397370303, Trade: 354\n",
      "Step 395, action: [0.2844732], terminated: False, reward: 10.351439397370303, Trade: 355\n",
      "Step 396, action: [0.31912133], terminated: False, reward: 10.341439397370303, Trade: 356\n",
      "Step 397, action: [-0.15737097], terminated: False, reward: 10.331396851348375, Trade: 357\n",
      "Step 398, action: [-0.3217343], terminated: False, reward: 10.431341932296023, Trade: 358\n",
      "Step 399, action: [0.31455204], terminated: False, reward: 10.421341932296023, Trade: 359\n",
      "Step 400, action: [-0.9347828], terminated: False, reward: 10.411341932296024, Trade: 360\n",
      "Step 401, action: [0.7594001], terminated: False, reward: 10.401341932296024, Trade: 361\n",
      "Step 402, action: [0.8748064], terminated: False, reward: 10.391341932296024, Trade: 362\n",
      "Step 403, action: [0.9990036], terminated: False, reward: 10.381341932296024, Trade: 363\n",
      "Step 404, action: [0.35871646], terminated: False, reward: 10.271341932296025, Trade: 363\n",
      "Step 405, action: [0.7630708], terminated: False, reward: 10.161341932296025, Trade: 363\n",
      "Step 406, action: [-0.5411367], terminated: False, reward: 10.198254973713217, Trade: 364\n",
      "Step 407, action: [-0.43303937], terminated: False, reward: 10.232639605141781, Trade: 365\n",
      "Step 408, action: [0.212845], terminated: False, reward: 10.222639605141781, Trade: 366\n",
      "Step 409, action: [-0.65078956], terminated: False, reward: 10.213298605051905, Trade: 367\n",
      "Step 410, action: [-0.61475414], terminated: False, reward: 10.820593347978429, Trade: 368\n",
      "Step 411, action: [-0.8256574], terminated: False, reward: 15.081220003145393, Trade: 369\n",
      "Step 412, action: [0.5045048], terminated: False, reward: 15.071220003145394, Trade: 370\n",
      "Step 413, action: [-0.17648605], terminated: False, reward: 15.115947040169235, Trade: 371\n",
      "Step 414, action: [-0.70742214], terminated: False, reward: 15.40188316506832, Trade: 372\n",
      "Step 415, action: [-0.9716371], terminated: False, reward: 15.399184055551013, Trade: 373\n",
      "Step 416, action: [-0.85443246], terminated: False, reward: 16.09650924275831, Trade: 374\n",
      "Step 417, action: [0.47151738], terminated: False, reward: 16.086509242758307, Trade: 375\n",
      "Step 418, action: [-0.27419496], terminated: False, reward: 16.566465046171665, Trade: 376\n",
      "Step 419, action: [-0.35199958], terminated: False, reward: 16.5568368135318, Trade: 377\n",
      "Step 420, action: [0.64788955], terminated: False, reward: 16.546836813531797, Trade: 378\n",
      "Step 421, action: [0.52043915], terminated: False, reward: 16.536836813531796, Trade: 379\n",
      "Step 422, action: [-0.4143317], terminated: False, reward: 16.797257790386922, Trade: 380\n",
      "Step 423, action: [0.92109], terminated: False, reward: 16.78725779038692, Trade: 381\n",
      "Step 424, action: [-0.2467684], terminated: False, reward: 16.777377454014754, Trade: 382\n",
      "Step 425, action: [-0.49696195], terminated: False, reward: 16.879190752711597, Trade: 383\n",
      "Step 426, action: [-0.37801456], terminated: False, reward: 16.8905217219298, Trade: 384\n",
      "Step 427, action: [-0.46515897], terminated: False, reward: 16.8805217219298, Trade: 385\n",
      "Step 428, action: [-0.13344006], terminated: False, reward: 16.896540141934498, Trade: 386\n",
      "Step 429, action: [0.26723894], terminated: False, reward: 16.886540141934496, Trade: 387\n",
      "Step 430, action: [0.14742522], terminated: False, reward: 16.876540141934495, Trade: 388\n",
      "Step 431, action: [0.45141596], terminated: False, reward: 16.866540141934493, Trade: 389\n",
      "Step 432, action: [-0.8268851], terminated: False, reward: 16.904721160932908, Trade: 390\n",
      "Step 433, action: [-0.5313295], terminated: False, reward: 16.845547108407164, Trade: 391\n",
      "Step 434, action: [-0.8371985], terminated: False, reward: 16.877525878810683, Trade: 392\n",
      "Step 435, action: [-0.10916431], terminated: False, reward: 16.855027582482265, Trade: 393\n",
      "Step 436, action: [-0.19882238], terminated: False, reward: 16.844643454016968, Trade: 394\n",
      "Step 437, action: [-0.8462047], terminated: False, reward: 17.138273892419175, Trade: 395\n",
      "Step 438, action: [-0.607409], terminated: False, reward: 17.659954766618895, Trade: 396\n",
      "Step 439, action: [0.6659675], terminated: False, reward: 17.649954766618894, Trade: 397\n",
      "Step 440, action: [0.71576416], terminated: False, reward: 17.639954766618892, Trade: 398\n",
      "Step 441, action: [0.563514], terminated: False, reward: 17.62995476661889, Trade: 399\n",
      "Step 442, action: [0.43326843], terminated: False, reward: 17.61995476661889, Trade: 400\n",
      "Step 443, action: [-0.5517731], terminated: False, reward: 17.748542366923186, Trade: 401\n",
      "Step 444, action: [0.66049093], terminated: False, reward: 17.738542366923184, Trade: 402\n",
      "Step 445, action: [0.6931831], terminated: False, reward: 17.728542366923183, Trade: 403\n",
      "Step 446, action: [0.7762748], terminated: False, reward: 17.71854236692318, Trade: 404\n",
      "Step 447, action: [-0.37283912], terminated: False, reward: 17.85288115854578, Trade: 405\n",
      "Step 448, action: [0.24083985], terminated: False, reward: 17.84288115854578, Trade: 406\n",
      "Step 449, action: [-0.1670907], terminated: False, reward: 17.883595157017602, Trade: 407\n",
      "Step 450, action: [0.820152], terminated: False, reward: 17.8735951570176, Trade: 408\n",
      "Step 451, action: [0.58457386], terminated: False, reward: 17.8635951570176, Trade: 409\n",
      "Step 452, action: [-0.3252826], terminated: False, reward: 17.88636747423515, Trade: 410\n",
      "Step 453, action: [-0.7879137], terminated: False, reward: 17.93392057028574, Trade: 411\n",
      "Step 454, action: [0.04830793], terminated: False, reward: 17.923920570285738, Trade: 412\n",
      "Step 455, action: [-0.51416856], terminated: False, reward: 17.951807084086102, Trade: 413\n",
      "Step 456, action: [0.26547298], terminated: False, reward: 17.9418070840861, Trade: 414\n",
      "Step 457, action: [-0.78121674], terminated: False, reward: 18.556970368772397, Trade: 415\n",
      "Step 458, action: [-0.23310693], terminated: False, reward: 18.565779414625197, Trade: 416\n",
      "Step 459, action: [-0.1728379], terminated: False, reward: 18.557055487837165, Trade: 417\n",
      "Step 460, action: [-0.14708017], terminated: False, reward: 18.52569852946552, Trade: 418\n",
      "Step 461, action: [-0.5737339], terminated: False, reward: 18.5198670993914, Trade: 419\n",
      "Step 462, action: [0.8024209], terminated: False, reward: 18.5098670993914, Trade: 420\n",
      "Step 463, action: [-0.216679], terminated: False, reward: 18.499631943971348, Trade: 421\n",
      "Step 464, action: [0.80360425], terminated: False, reward: 18.489631943971347, Trade: 422\n",
      "Step 465, action: [0.6151354], terminated: False, reward: 18.479631943971345, Trade: 423\n",
      "Step 466, action: [0.3993361], terminated: False, reward: 18.469631943971343, Trade: 424\n",
      "Step 467, action: [-0.9574516], terminated: False, reward: 18.741164786901166, Trade: 425\n",
      "Step 468, action: [-0.14762399], terminated: False, reward: 18.72923968725618, Trade: 426\n",
      "Step 469, action: [0.91751546], terminated: False, reward: 18.719239687256177, Trade: 427\n",
      "Step 470, action: [-0.63975865], terminated: False, reward: 18.80882325230184, Trade: 428\n",
      "Step 471, action: [-0.30072647], terminated: False, reward: 18.70832848067396, Trade: 429\n",
      "Step 472, action: [-0.205098], terminated: False, reward: 18.93491804577233, Trade: 430\n",
      "Step 473, action: [0.84867555], terminated: False, reward: 18.92491804577233, Trade: 431\n",
      "Step 474, action: [-0.03932351], terminated: False, reward: 18.95187528771598, Trade: 432\n",
      "Step 475, action: [-0.9817774], terminated: False, reward: 18.876979232066137, Trade: 433\n",
      "Step 476, action: [-0.49821326], terminated: False, reward: 18.90400354607929, Trade: 434\n",
      "Step 477, action: [-0.8923063], terminated: False, reward: 19.852444986835685, Trade: 435\n",
      "Step 478, action: [-0.14963567], terminated: False, reward: 19.84578074676169, Trade: 436\n",
      "Step 479, action: [-0.9596164], terminated: False, reward: 19.90480850747983, Trade: 437\n",
      "Step 480, action: [0.7954999], terminated: False, reward: 19.89480850747983, Trade: 438\n",
      "Step 481, action: [0.8576585], terminated: False, reward: 19.88480850747983, Trade: 439\n",
      "Step 482, action: [0.382504], terminated: False, reward: 19.874808507479827, Trade: 440\n",
      "Step 483, action: [-0.6766155], terminated: False, reward: 19.86200647410658, Trade: 441\n",
      "Step 484, action: [0.4343599], terminated: False, reward: 19.852006474106577, Trade: 442\n",
      "Step 485, action: [0.9408372], terminated: False, reward: 19.842006474106576, Trade: 443\n",
      "Step 486, action: [-0.01964554], terminated: False, reward: 19.832006474106574, Trade: 444\n",
      "Step 487, action: [-0.3187118], terminated: False, reward: 19.792257844024107, Trade: 445\n",
      "Step 488, action: [-0.38874707], terminated: False, reward: 19.783370633408804, Trade: 446\n",
      "Step 489, action: [0.10388391], terminated: False, reward: 19.773370633408803, Trade: 447\n",
      "Step 490, action: [0.80049], terminated: False, reward: 19.7633706334088, Trade: 448\n",
      "Step 491, action: [-0.1202416], terminated: False, reward: 19.73639553471667, Trade: 449\n",
      "Step 492, action: [-0.03970711], terminated: False, reward: 19.745201163968286, Trade: 450\n",
      "Step 493, action: [-0.5300738], terminated: False, reward: 19.604241959342804, Trade: 451\n",
      "Step 494, action: [0.8090715], terminated: False, reward: 19.594241959342803, Trade: 452\n",
      "Step 495, action: [-0.82808834], terminated: False, reward: 19.569328961325713, Trade: 453\n",
      "Step 496, action: [0.71009284], terminated: False, reward: 19.55932896132571, Trade: 454\n",
      "Step 497, action: [-0.73035747], terminated: False, reward: 19.59942289758629, Trade: 455\n",
      "Step 498, action: [0.93284184], terminated: False, reward: 19.58942289758629, Trade: 456\n",
      "Step 499, action: [0.54613125], terminated: False, reward: 19.579422897586287, Trade: 457\n",
      "Step 500, action: [0.64903986], terminated: False, reward: 19.569422897586286, Trade: 458\n",
      "Step 501, action: [-0.6240982], terminated: False, reward: 20.136300810049338, Trade: 459\n",
      "Step 502, action: [-0.33351317], terminated: False, reward: 20.12394988417497, Trade: 460\n",
      "Step 503, action: [0.46625137], terminated: False, reward: 20.113949884174968, Trade: 461\n",
      "Step 504, action: [0.508814], terminated: False, reward: 20.103949884174966, Trade: 462\n",
      "Step 505, action: [0.88190025], terminated: False, reward: 20.093949884174965, Trade: 463\n",
      "Step 506, action: [-0.31385988], terminated: False, reward: 20.08462216063882, Trade: 464\n",
      "Step 507, action: [0.3971701], terminated: False, reward: 20.074622160638818, Trade: 465\n",
      "Step 508, action: [0.34011632], terminated: False, reward: 20.064622160638816, Trade: 466\n",
      "Step 509, action: [-0.6192929], terminated: False, reward: 20.04497804578274, Trade: 467\n",
      "Step 510, action: [-0.3038279], terminated: False, reward: 20.032534701815127, Trade: 468\n",
      "Step 511, action: [0.60290813], terminated: False, reward: 20.022534701815125, Trade: 469\n",
      "Step 512, action: [0.4536139], terminated: False, reward: 20.012534701815124, Trade: 470\n",
      "Step 513, action: [0.43988258], terminated: False, reward: 20.002534701815122, Trade: 471\n",
      "Step 514, action: [0.7975108], terminated: False, reward: 19.99253470181512, Trade: 472\n",
      "Step 515, action: [-0.4561951], terminated: False, reward: 19.983384766287937, Trade: 473\n",
      "Step 516, action: [0.16212808], terminated: False, reward: 19.873384766287934, Trade: 473\n",
      "Step 517, action: [-0.37030655], terminated: False, reward: 19.85634278166883, Trade: 474\n",
      "Step 518, action: [0.5648022], terminated: False, reward: 19.846342781668827, Trade: 475\n",
      "Step 519, action: [0.6803988], terminated: False, reward: 19.836342781668826, Trade: 476\n",
      "Step 520, action: [-0.8224206], terminated: False, reward: 18.90231077408595, Trade: 477\n",
      "Step 521, action: [-0.59176105], terminated: False, reward: 19.04670468695031, Trade: 478\n",
      "Step 522, action: [0.3363669], terminated: False, reward: 19.03670468695031, Trade: 479\n",
      "Step 523, action: [-0.36705366], terminated: False, reward: 19.136338891420447, Trade: 480\n",
      "Step 524, action: [-0.8092369], terminated: False, reward: 19.14646812396201, Trade: 481\n",
      "Step 525, action: [-0.77238965], terminated: False, reward: 17.86626398356647, Trade: 482\n",
      "Step 526, action: [0.4615798], terminated: False, reward: 17.856263983566468, Trade: 483\n",
      "Step 527, action: [-0.24339384], terminated: False, reward: 17.906184740952128, Trade: 484\n",
      "Step 528, action: [0.6266094], terminated: False, reward: 17.896184740952126, Trade: 485\n",
      "Step 529, action: [-0.45653668], terminated: False, reward: 17.886522902714923, Trade: 486\n",
      "Step 530, action: [0.3120237], terminated: False, reward: 17.87652290271492, Trade: 487\n",
      "Step 531, action: [0.14342849], terminated: False, reward: 17.86652290271492, Trade: 488\n",
      "Step 532, action: [0.7249152], terminated: False, reward: 17.856522902714918, Trade: 489\n",
      "Step 533, action: [-0.01849314], terminated: False, reward: 17.846522902714916, Trade: 490\n",
      "Step 534, action: [0.08630508], terminated: False, reward: 17.836522902714915, Trade: 491\n",
      "Step 535, action: [-0.48202592], terminated: False, reward: 17.776208122140183, Trade: 492\n",
      "Step 536, action: [0.5090659], terminated: False, reward: 17.76620812214018, Trade: 493\n",
      "Step 537, action: [0.78820395], terminated: False, reward: 17.75620812214018, Trade: 494\n",
      "Step 538, action: [-0.703018], terminated: False, reward: 17.489705986366616, Trade: 495\n",
      "Step 539, action: [0.33629635], terminated: False, reward: 17.479705986366614, Trade: 496\n",
      "Step 540, action: [-0.01189038], terminated: False, reward: 17.469705986366613, Trade: 497\n",
      "Step 541, action: [0.5983338], terminated: False, reward: 17.45970598636661, Trade: 498\n",
      "Step 542, action: [-0.6449436], terminated: False, reward: 17.45017885196934, Trade: 499\n",
      "Step 543, action: [0.01660191], terminated: False, reward: 17.44017885196934, Trade: 500\n",
      "Step 544, action: [-0.16341828], terminated: False, reward: 17.427624195587384, Trade: 501\n",
      "Step 545, action: [-0.6525543], terminated: False, reward: 17.17810461069464, Trade: 502\n",
      "Step 546, action: [0.19094616], terminated: False, reward: 17.168104610694638, Trade: 503\n",
      "Step 547, action: [0.24344693], terminated: False, reward: 17.158104610694636, Trade: 504\n",
      "Step 548, action: [0.00657084], terminated: False, reward: 17.148104610694634, Trade: 505\n",
      "Step 549, action: [0.3245375], terminated: False, reward: 17.138104610694633, Trade: 506\n",
      "Step 550, action: [0.8514548], terminated: False, reward: 17.12810461069463, Trade: 507\n",
      "Step 551, action: [-0.8946879], terminated: False, reward: 17.122105109217287, Trade: 508\n",
      "Step 552, action: [-0.71929324], terminated: False, reward: 16.59071691495314, Trade: 509\n",
      "Step 553, action: [0.80252296], terminated: False, reward: 16.58071691495314, Trade: 510\n",
      "Step 554, action: [0.24726883], terminated: False, reward: 16.570716914953138, Trade: 511\n",
      "Step 555, action: [-0.3745617], terminated: False, reward: 16.586751360772162, Trade: 512\n",
      "Step 556, action: [0.408755], terminated: False, reward: 16.57675136077216, Trade: 513\n",
      "Step 557, action: [0.02246117], terminated: False, reward: 16.56675136077216, Trade: 514\n",
      "Step 558, action: [0.32206506], terminated: False, reward: 16.556751360772157, Trade: 515\n",
      "Step 559, action: [0.15619126], terminated: False, reward: 16.546751360772156, Trade: 516\n",
      "Step 560, action: [0.26340503], terminated: False, reward: 16.536751360772154, Trade: 517\n",
      "Step 561, action: [0.99393094], terminated: False, reward: 16.526751360772153, Trade: 518\n",
      "Step 562, action: [0.34674513], terminated: False, reward: 16.51675136077215, Trade: 519\n",
      "Step 563, action: [0.7890167], terminated: False, reward: 16.406751360772148, Trade: 519\n",
      "Step 564, action: [0.29862884], terminated: False, reward: 16.296751360772145, Trade: 519\n",
      "Step 565, action: [0.7569089], terminated: False, reward: 16.186751360772142, Trade: 519\n",
      "Step 566, action: [0.37581855], terminated: False, reward: 16.07675136077214, Trade: 519\n",
      "Step 567, action: [-0.29310513], terminated: False, reward: 16.068079788956428, Trade: 520\n",
      "Step 568, action: [0.6007573], terminated: False, reward: 16.058079788956427, Trade: 521\n",
      "Step 569, action: [0.56615394], terminated: False, reward: 16.048079788956425, Trade: 522\n",
      "Step 570, action: [-0.4603598], terminated: False, reward: 15.209165365571968, Trade: 523\n",
      "Step 571, action: [-0.5418521], terminated: False, reward: 15.20186958903203, Trade: 524\n",
      "Step 572, action: [0.24201246], terminated: False, reward: 15.19186958903203, Trade: 525\n",
      "Step 573, action: [-0.14789595], terminated: False, reward: 15.26219502788763, Trade: 526\n",
      "Step 574, action: [0.09380079], terminated: False, reward: 15.25219502788763, Trade: 527\n",
      "Step 575, action: [-0.05777539], terminated: False, reward: 15.24279491190668, Trade: 528\n",
      "Step 576, action: [-0.15834934], terminated: False, reward: 15.182502563682378, Trade: 529\n",
      "Step 577, action: [-0.8228343], terminated: False, reward: 15.242330654158526, Trade: 530\n",
      "Step 578, action: [-0.96050876], terminated: False, reward: 15.232330654158526, Trade: 531\n",
      "Step 579, action: [-0.38205525], terminated: False, reward: 15.16896768625481, Trade: 532\n",
      "Step 580, action: [0.93650657], terminated: False, reward: 15.15896768625481, Trade: 533\n",
      "Step 581, action: [-0.44567603], terminated: False, reward: 15.237947155390815, Trade: 534\n",
      "Step 582, action: [-0.30029967], terminated: False, reward: 15.53118690420519, Trade: 535\n",
      "Step 583, action: [0.98976797], terminated: False, reward: 15.52118690420519, Trade: 536\n",
      "Step 584, action: [-0.76660204], terminated: False, reward: 15.918398442018182, Trade: 537\n",
      "Step 585, action: [-0.41823006], terminated: False, reward: 15.908494506494408, Trade: 538\n",
      "Step 586, action: [-0.18662846], terminated: False, reward: 15.967401032619748, Trade: 539\n",
      "Step 587, action: [0.6053104], terminated: False, reward: 15.957401032619748, Trade: 540\n",
      "Step 588, action: [-0.46186996], terminated: False, reward: 16.82165004184072, Trade: 541\n",
      "Step 589, action: [-0.593786], terminated: False, reward: 16.78322135936016, Trade: 542\n",
      "Step 590, action: [0.99412054], terminated: False, reward: 16.773221359360157, Trade: 543\n",
      "Step 591, action: [-0.9941723], terminated: False, reward: 16.829437370278974, Trade: 544\n",
      "Step 592, action: [-0.8256512], terminated: False, reward: 16.840045899419195, Trade: 545\n",
      "Step 593, action: [0.1494878], terminated: False, reward: 16.830045899419193, Trade: 546\n",
      "Step 594, action: [0.02650893], terminated: False, reward: 16.820045899419192, Trade: 547\n",
      "Step 595, action: [-0.7592612], terminated: False, reward: 17.04546593336317, Trade: 548\n",
      "Step 596, action: [0.84466535], terminated: False, reward: 17.03546593336317, Trade: 549\n",
      "Step 597, action: [-0.4347614], terminated: False, reward: 16.384382134773343, Trade: 550\n",
      "Step 598, action: [0.30458584], terminated: False, reward: 16.37438213477334, Trade: 551\n",
      "Step 599, action: [0.5496478], terminated: False, reward: 16.36438213477334, Trade: 552\n",
      "Step 600, action: [0.55243963], terminated: False, reward: 16.35438213477334, Trade: 553\n",
      "Step 601, action: [0.82832986], terminated: False, reward: 16.344382134773337, Trade: 554\n",
      "Step 602, action: [-0.9491404], terminated: False, reward: 16.40055300271481, Trade: 555\n",
      "Step 603, action: [0.47773087], terminated: False, reward: 16.390553002714807, Trade: 556\n",
      "Step 604, action: [0.14395848], terminated: False, reward: 16.380553002714805, Trade: 557\n",
      "Step 605, action: [-0.7569802], terminated: False, reward: 16.370553002714804, Trade: 558\n",
      "Step 606, action: [0.5124546], terminated: False, reward: 16.360553002714802, Trade: 559\n",
      "Step 607, action: [0.3695908], terminated: False, reward: 16.3505530027148, Trade: 560\n",
      "Step 608, action: [0.7215395], terminated: False, reward: 16.3405530027148, Trade: 561\n",
      "Step 609, action: [-0.85210997], terminated: False, reward: 16.924077614785393, Trade: 562\n",
      "Step 610, action: [-0.5308718], terminated: False, reward: 16.971811448625733, Trade: 563\n",
      "Step 611, action: [-0.33582857], terminated: False, reward: 16.98415719012824, Trade: 564\n",
      "Step 612, action: [0.5166824], terminated: False, reward: 16.97415719012824, Trade: 565\n",
      "Step 613, action: [-0.03009423], terminated: False, reward: 16.977993464389108, Trade: 566\n",
      "Step 614, action: [0.01749531], terminated: False, reward: 16.967993464389107, Trade: 567\n",
      "Step 615, action: [-0.9600063], terminated: False, reward: 18.47916446038795, Trade: 568\n",
      "Step 616, action: [-0.3247943], terminated: False, reward: 18.48426735220404, Trade: 569\n",
      "Step 617, action: [-0.949952], terminated: False, reward: 20.60937388290238, Trade: 570\n",
      "Step 618, action: [-0.90675116], terminated: False, reward: 20.599489244521443, Trade: 571\n",
      "Step 619, action: [0.7560846], terminated: False, reward: 20.58948924452144, Trade: 572\n",
      "Step 620, action: [0.17544633], terminated: False, reward: 20.57948924452144, Trade: 573\n",
      "Step 621, action: [-0.18985774], terminated: False, reward: 20.562785295612795, Trade: 574\n",
      "Step 622, action: [0.7139673], terminated: False, reward: 20.552785295612793, Trade: 575\n",
      "Step 623, action: [-0.33949834], terminated: False, reward: 20.584782332823497, Trade: 576\n",
      "Step 624, action: [0.51160175], terminated: False, reward: 20.574782332823496, Trade: 577\n",
      "Step 625, action: [-0.07779618], terminated: False, reward: 20.569979788918424, Trade: 578\n",
      "Step 626, action: [0.52368474], terminated: False, reward: 20.559979788918422, Trade: 579\n",
      "Step 627, action: [-0.42275482], terminated: False, reward: 20.74518312163629, Trade: 580\n",
      "Step 628, action: [0.90990263], terminated: False, reward: 20.73518312163629, Trade: 581\n",
      "Step 629, action: [0.28846174], terminated: False, reward: 20.725183121636288, Trade: 582\n",
      "Step 630, action: [0.65519816], terminated: False, reward: 20.715183121636287, Trade: 583\n",
      "Step 631, action: [0.46472815], terminated: False, reward: 20.705183121636285, Trade: 584\n",
      "Step 632, action: [0.08622699], terminated: False, reward: 20.595183121636282, Trade: 584\n",
      "Step 633, action: [0.36454362], terminated: False, reward: 20.58518312163628, Trade: 585\n",
      "Step 634, action: [-0.42590052], terminated: False, reward: 22.67368933979635, Trade: 586\n",
      "Step 635, action: [0.27543154], terminated: False, reward: 22.66368933979635, Trade: 587\n",
      "Step 636, action: [-0.6287864], terminated: False, reward: 22.721691638458804, Trade: 588\n",
      "Step 637, action: [-0.70642984], terminated: False, reward: 22.837527946499126, Trade: 589\n",
      "Step 638, action: [-0.43185115], terminated: False, reward: 22.872867863941508, Trade: 590\n",
      "Step 639, action: [-0.21773282], terminated: False, reward: 22.94516179840357, Trade: 591\n",
      "Step 640, action: [-0.67369276], terminated: False, reward: 23.367612609327935, Trade: 592\n",
      "Step 641, action: [0.4345035], terminated: False, reward: 23.357612609327933, Trade: 593\n",
      "Step 642, action: [-0.65219545], terminated: False, reward: 23.3971774321443, Trade: 594\n",
      "Step 643, action: [-0.20025222], terminated: False, reward: 23.413501158022488, Trade: 595\n",
      "Step 644, action: [0.6218547], terminated: False, reward: 23.403501158022486, Trade: 596\n",
      "Step 645, action: [0.3170451], terminated: False, reward: 23.393501158022485, Trade: 597\n",
      "Step 646, action: [0.9132845], terminated: False, reward: 23.383501158022483, Trade: 598\n",
      "Step 647, action: [-0.746995], terminated: False, reward: 24.232850812854767, Trade: 599\n",
      "Step 648, action: [-0.96518147], terminated: False, reward: 24.211509157907177, Trade: 600\n",
      "Step 649, action: [0.51847976], terminated: False, reward: 24.201509157907175, Trade: 601\n",
      "Step 650, action: [-0.32425407], terminated: False, reward: 24.193203279101457, Trade: 602\n",
      "Step 651, action: [-0.18864301], terminated: False, reward: 24.169241609340297, Trade: 603\n",
      "Step 652, action: [-0.5628484], terminated: False, reward: 24.220493335829723, Trade: 604\n",
      "Step 653, action: [0.51593167], terminated: False, reward: 24.21049333582972, Trade: 605\n",
      "Step 654, action: [0.22889003], terminated: False, reward: 24.20049333582972, Trade: 606\n",
      "Step 655, action: [-0.73411953], terminated: False, reward: 24.67837113843276, Trade: 607\n",
      "Step 656, action: [-0.8511588], terminated: False, reward: 24.674897777365814, Trade: 608\n",
      "Step 657, action: [0.7286946], terminated: False, reward: 24.664897777365812, Trade: 609\n",
      "Step 658, action: [-0.8538596], terminated: False, reward: 24.66468055392924, Trade: 610\n",
      "Step 659, action: [0.1324732], terminated: False, reward: 24.65468055392924, Trade: 611\n",
      "Step 660, action: [-0.14973207], terminated: False, reward: 24.647936855219626, Trade: 612\n",
      "Step 661, action: [-0.7266331], terminated: False, reward: 26.92824727336569, Trade: 613\n",
      "Step 662, action: [0.7342792], terminated: False, reward: 26.91824727336569, Trade: 614\n",
      "Step 663, action: [0.34663716], terminated: False, reward: 26.90824727336569, Trade: 615\n",
      "Step 664, action: [0.23295127], terminated: False, reward: 26.898247273365687, Trade: 616\n",
      "Step 665, action: [0.6033913], terminated: False, reward: 26.888247273365685, Trade: 617\n",
      "Step 666, action: [0.5092636], terminated: False, reward: 26.878247273365684, Trade: 618\n",
      "Step 667, action: [0.69340986], terminated: False, reward: 26.868247273365682, Trade: 619\n",
      "Step 668, action: [-0.20496903], terminated: False, reward: 26.805185343051534, Trade: 620\n",
      "Step 669, action: [0.593608], terminated: False, reward: 26.795185343051532, Trade: 621\n",
      "Step 670, action: [0.3801316], terminated: False, reward: 26.78518534305153, Trade: 622\n",
      "Step 671, action: [-0.3487298], terminated: False, reward: 26.85345275368968, Trade: 623\n",
      "Step 672, action: [0.2555179], terminated: False, reward: 26.84345275368968, Trade: 624\n",
      "Step 673, action: [-0.08509424], terminated: False, reward: 26.909179852723152, Trade: 625\n",
      "Step 674, action: [0.2029062], terminated: False, reward: 26.89917985272315, Trade: 626\n",
      "Step 675, action: [-0.6635576], terminated: False, reward: 26.88961050166651, Trade: 627\n",
      "Step 676, action: [0.37467477], terminated: False, reward: 26.87961050166651, Trade: 628\n",
      "Step 677, action: [-0.8013825], terminated: False, reward: 26.959377925166557, Trade: 629\n",
      "Step 678, action: [-0.8523515], terminated: False, reward: 27.01421611625221, Trade: 630\n",
      "Step 679, action: [-0.25899327], terminated: False, reward: 27.023197128015855, Trade: 631\n",
      "Step 680, action: [-0.4617753], terminated: False, reward: 27.21485943976459, Trade: 632\n",
      "Step 681, action: [-0.6911818], terminated: False, reward: 27.47743902206881, Trade: 633\n",
      "Step 682, action: [0.6983012], terminated: False, reward: 27.46743902206881, Trade: 634\n",
      "Step 683, action: [0.33330053], terminated: False, reward: 27.457439022068808, Trade: 635\n",
      "Step 684, action: [-0.8120826], terminated: False, reward: 28.340801461224572, Trade: 636\n",
      "Step 685, action: [0.47021592], terminated: False, reward: 28.33080146122457, Trade: 637\n",
      "Step 686, action: [-0.21820632], terminated: False, reward: 28.321765577105978, Trade: 638\n",
      "Step 687, action: [0.03308709], terminated: False, reward: 28.311765577105977, Trade: 639\n",
      "Step 688, action: [0.29496908], terminated: False, reward: 28.301765577105975, Trade: 640\n",
      "Step 689, action: [-0.12580732], terminated: False, reward: 28.67811131919815, Trade: 641\n",
      "Step 690, action: [0.96911055], terminated: False, reward: 28.668111319198147, Trade: 642\n",
      "Step 691, action: [-0.9338753], terminated: False, reward: 28.78010273140083, Trade: 643\n",
      "Step 692, action: [0.13253209], terminated: False, reward: 28.77010273140083, Trade: 644\n",
      "Step 693, action: [0.56243056], terminated: False, reward: 28.760102731400828, Trade: 645\n",
      "Step 694, action: [-0.2355711], terminated: False, reward: 28.85932482736528, Trade: 646\n",
      "Step 695, action: [0.08215991], terminated: False, reward: 28.84932482736528, Trade: 647\n",
      "Step 696, action: [-0.8233301], terminated: False, reward: 28.80367448261019, Trade: 648\n",
      "Step 697, action: [-0.61764973], terminated: False, reward: 29.026356264047966, Trade: 649\n",
      "Step 698, action: [-0.24018879], terminated: False, reward: 29.050613823919115, Trade: 650\n",
      "Step 699, action: [0.16950658], terminated: False, reward: 29.040613823919113, Trade: 651\n",
      "Step 700, action: [0.00086795], terminated: False, reward: 28.93061382391911, Trade: 651\n",
      "Step 701, action: [-0.3414904], terminated: False, reward: 28.979132740284022, Trade: 652\n",
      "Step 702, action: [0.01506999], terminated: False, reward: 28.96913274028402, Trade: 653\n",
      "Step 703, action: [-0.19930665], terminated: False, reward: 29.255146614621786, Trade: 654\n",
      "Step 704, action: [-0.69403076], terminated: False, reward: 29.25639435981566, Trade: 655\n",
      "Step 705, action: [0.35643587], terminated: False, reward: 29.246394359815657, Trade: 656\n",
      "Step 706, action: [-0.18154784], terminated: False, reward: 29.24911236845398, Trade: 657\n",
      "Step 707, action: [0.05107899], terminated: False, reward: 29.239112368453977, Trade: 658\n",
      "Step 708, action: [0.29582363], terminated: False, reward: 29.229112368453976, Trade: 659\n",
      "Step 709, action: [0.97044015], terminated: False, reward: 29.219112368453974, Trade: 660\n",
      "Step 710, action: [-0.786103], terminated: False, reward: 29.2222175399532, Trade: 661\n",
      "Step 711, action: [-0.00049024], terminated: False, reward: 29.212217539953198, Trade: 662\n",
      "Step 712, action: [0.8941102], terminated: False, reward: 29.202217539953196, Trade: 663\n",
      "Step 713, action: [-0.93692636], terminated: False, reward: 29.192638717475397, Trade: 664\n",
      "Step 714, action: [0.5001444], terminated: False, reward: 29.182638717475395, Trade: 665\n",
      "Step 715, action: [0.4303936], terminated: False, reward: 29.172638717475394, Trade: 666\n",
      "Step 716, action: [-0.8450767], terminated: False, reward: 31.732845734060735, Trade: 667\n",
      "Step 717, action: [-0.6063918], terminated: False, reward: 31.851221715632317, Trade: 668\n",
      "Step 718, action: [0.23258701], terminated: False, reward: 31.841221715632315, Trade: 669\n",
      "Step 719, action: [0.90174896], terminated: False, reward: 31.831221715632314, Trade: 670\n",
      "Step 720, action: [0.2890606], terminated: False, reward: 31.821221715632312, Trade: 671\n",
      "Step 721, action: [0.52788043], terminated: False, reward: 31.81122171563231, Trade: 672\n",
      "Step 722, action: [-0.57538915], terminated: False, reward: 31.778723689797264, Trade: 673\n",
      "Step 723, action: [0.9190281], terminated: False, reward: 31.768723689797262, Trade: 674\n",
      "Step 724, action: [-0.98274684], terminated: False, reward: 31.88649367996098, Trade: 675\n",
      "Step 725, action: [0.3954746], terminated: False, reward: 31.87649367996098, Trade: 676\n",
      "Step 726, action: [-0.3995404], terminated: False, reward: 32.05016128241652, Trade: 677\n",
      "Step 727, action: [0.34128195], terminated: False, reward: 32.04016128241652, Trade: 678\n",
      "Step 728, action: [-0.21694292], terminated: False, reward: 32.04241282164078, Trade: 679\n",
      "Step 729, action: [0.14644621], terminated: False, reward: 32.03241282164078, Trade: 680\n",
      "Step 730, action: [0.269811], terminated: False, reward: 32.022412821640785, Trade: 681\n",
      "Step 731, action: [0.32260758], terminated: False, reward: 32.01241282164079, Trade: 682\n",
      "Step 732, action: [0.5071564], terminated: False, reward: 32.00241282164079, Trade: 683\n",
      "Step 733, action: [0.7856406], terminated: False, reward: 31.992412821640787, Trade: 684\n",
      "Step 734, action: [0.24921687], terminated: False, reward: 31.982412821640786, Trade: 685\n",
      "Step 735, action: [0.8417261], terminated: False, reward: 31.972412821640784, Trade: 686\n",
      "Step 736, action: [-0.00672163], terminated: False, reward: 31.967718950178085, Trade: 687\n",
      "Step 737, action: [-0.99962264], terminated: False, reward: 31.957763896105146, Trade: 688\n",
      "Step 738, action: [0.35479727], terminated: False, reward: 31.947763896105144, Trade: 689\n",
      "Step 739, action: [-0.7464008], terminated: False, reward: 32.406545863241156, Trade: 690\n",
      "Step 740, action: [-0.872505], terminated: False, reward: 32.396474945905354, Trade: 691\n",
      "Step 741, action: [0.61098516], terminated: False, reward: 32.386474945905356, Trade: 692\n",
      "Step 742, action: [0.5727475], terminated: False, reward: 32.37647494590536, Trade: 693\n",
      "Step 743, action: [-0.4390043], terminated: False, reward: 32.56187858474676, Trade: 694\n",
      "Step 744, action: [0.6622342], terminated: False, reward: 32.55187858474676, Trade: 695\n",
      "Step 745, action: [-0.7798261], terminated: False, reward: 32.338287515541076, Trade: 696\n",
      "Step 746, action: [-0.33426672], terminated: False, reward: 32.917224242544584, Trade: 697\n",
      "Step 747, action: [0.01291426], terminated: False, reward: 32.907224242544586, Trade: 698\n",
      "Step 748, action: [-0.06918269], terminated: False, reward: 32.92946122769708, Trade: 699\n",
      "Step 749, action: [0.31889105], terminated: False, reward: 32.919461227697084, Trade: 700\n",
      "Step 750, action: [0.43768063], terminated: False, reward: 32.909461227697086, Trade: 701\n",
      "Step 751, action: [-0.23285724], terminated: False, reward: 32.899868248933146, Trade: 702\n",
      "Step 752, action: [-0.46522725], terminated: False, reward: 32.99212339354892, Trade: 703\n",
      "Step 753, action: [-0.23969561], terminated: False, reward: 33.0099921682085, Trade: 704\n",
      "Step 754, action: [0.2537363], terminated: False, reward: 32.9999921682085, Trade: 705\n",
      "Step 755, action: [-0.3668556], terminated: False, reward: 32.93160997255728, Trade: 706\n",
      "Step 756, action: [0.9032029], terminated: False, reward: 32.921609972557285, Trade: 707\n",
      "Step 757, action: [0.84314466], terminated: False, reward: 32.91160997255729, Trade: 708\n",
      "Step 758, action: [0.68492115], terminated: False, reward: 32.90160997255729, Trade: 709\n",
      "Step 759, action: [-0.9750663], terminated: False, reward: 32.1422025265075, Trade: 710\n",
      "Step 760, action: [-0.93981576], terminated: False, reward: 32.17415849164924, Trade: 711\n",
      "Step 761, action: [-0.5226171], terminated: False, reward: 32.17208302692086, Trade: 712\n",
      "Step 762, action: [0.8777693], terminated: False, reward: 32.16208302692086, Trade: 713\n",
      "Step 763, action: [0.50662446], terminated: False, reward: 32.15208302692086, Trade: 714\n",
      "Step 764, action: [-0.43635997], terminated: False, reward: 32.142083026920865, Trade: 715\n",
      "Step 765, action: [0.8788431], terminated: False, reward: 32.13208302692087, Trade: 716\n",
      "Step 766, action: [0.47869596], terminated: False, reward: 32.12208302692087, Trade: 717\n",
      "Step 767, action: [0.45474765], terminated: False, reward: 32.11208302692087, Trade: 718\n",
      "Step 768, action: [-0.28264767], terminated: False, reward: 32.04793236412178, Trade: 719\n",
      "Step 769, action: [-0.39136103], terminated: False, reward: 32.33180527104106, Trade: 720\n",
      "Step 770, action: [-0.5525109], terminated: False, reward: 32.373170153362025, Trade: 721\n",
      "Step 771, action: [0.73953635], terminated: False, reward: 32.36317015336203, Trade: 722\n",
      "Step 772, action: [0.16593574], terminated: False, reward: 32.35317015336203, Trade: 723\n",
      "Step 773, action: [0.87440604], terminated: False, reward: 32.34317015336203, Trade: 724\n",
      "Step 774, action: [-0.2382994], terminated: False, reward: 32.566437894588766, Trade: 725\n",
      "Step 775, action: [0.19069384], terminated: False, reward: 32.55643789458877, Trade: 726\n",
      "Step 776, action: [0.7434964], terminated: False, reward: 32.54643789458877, Trade: 727\n",
      "Step 777, action: [0.12239068], terminated: False, reward: 32.53643789458877, Trade: 728\n",
      "Step 778, action: [0.9447212], terminated: False, reward: 32.526437894588774, Trade: 729\n",
      "Step 779, action: [-0.8117702], terminated: False, reward: 32.71332400568509, Trade: 730\n",
      "Step 780, action: [0.57723355], terminated: False, reward: 32.70332400568509, Trade: 731\n",
      "Step 781, action: [-0.772661], terminated: False, reward: 33.33405141140405, Trade: 732\n",
      "Step 782, action: [-0.97217876], terminated: False, reward: 33.20376884224901, Trade: 733\n",
      "Step 783, action: [0.12517734], terminated: False, reward: 33.193768842249014, Trade: 734\n",
      "Step 784, action: [0.15191326], terminated: False, reward: 33.183768842249016, Trade: 735\n",
      "Step 785, action: [-0.2390816], terminated: False, reward: 33.175649910082385, Trade: 736\n",
      "Step 786, action: [-0.06818046], terminated: False, reward: 33.16564991008239, Trade: 737\n",
      "Step 787, action: [-0.26360595], terminated: False, reward: 33.15683931321618, Trade: 738\n",
      "Step 788, action: [0.01910415], terminated: False, reward: 33.146839313216184, Trade: 739\n",
      "Step 789, action: [-0.9332599], terminated: False, reward: 33.22366632080603, Trade: 740\n",
      "Step 790, action: [0.8136853], terminated: False, reward: 33.213666320806034, Trade: 741\n",
      "Step 791, action: [-0.94550425], terminated: False, reward: 33.203666320806036, Trade: 742\n",
      "Step 792, action: [-0.11475576], terminated: False, reward: 33.195442998644516, Trade: 743\n",
      "Step 793, action: [0.73666674], terminated: False, reward: 33.18544299864452, Trade: 744\n",
      "Step 794, action: [-0.08677509], terminated: False, reward: 33.17544299864452, Trade: 745\n",
      "Step 795, action: [-0.6690639], terminated: False, reward: 33.221977688856654, Trade: 746\n",
      "Step 796, action: [-0.58029383], terminated: False, reward: 33.87194426344846, Trade: 747\n",
      "Step 797, action: [-0.44417852], terminated: False, reward: 33.89703463153439, Trade: 748\n",
      "Step 798, action: [-0.90866154], terminated: False, reward: 32.24753844496546, Trade: 749\n",
      "Step 799, action: [0.40465948], terminated: False, reward: 32.23753844496546, Trade: 750\n",
      "Step 800, action: [0.39028922], terminated: False, reward: 32.22753844496546, Trade: 751\n",
      "Step 801, action: [0.29250917], terminated: False, reward: 32.21753844496546, Trade: 752\n",
      "Step 802, action: [-0.59285545], terminated: False, reward: 32.49406386819907, Trade: 753\n",
      "Step 803, action: [0.7560569], terminated: False, reward: 32.48406386819907, Trade: 754\n",
      "Step 804, action: [0.7756788], terminated: False, reward: 32.474063868199075, Trade: 755\n",
      "Step 805, action: [0.17814861], terminated: False, reward: 32.46406386819908, Trade: 756\n",
      "Step 806, action: [0.2876241], terminated: False, reward: 32.45406386819908, Trade: 757\n",
      "Step 807, action: [0.334906], terminated: False, reward: 32.44406386819908, Trade: 758\n",
      "Step 808, action: [0.2886122], terminated: False, reward: 32.43406386819908, Trade: 759\n",
      "Step 809, action: [-0.5910127], terminated: False, reward: 32.42193015131003, Trade: 760\n",
      "Step 810, action: [-0.10128991], terminated: False, reward: 32.31262527007837, Trade: 761\n",
      "Step 811, action: [0.34363326], terminated: False, reward: 32.30262527007837, Trade: 762\n",
      "Step 812, action: [-0.7619529], terminated: False, reward: 32.308786753051955, Trade: 763\n",
      "Step 813, action: [0.4662188], terminated: False, reward: 32.29878675305196, Trade: 764\n",
      "Step 814, action: [-0.50151765], terminated: False, reward: 32.29038494918179, Trade: 765\n",
      "Step 815, action: [0.6556722], terminated: False, reward: 32.280384949181794, Trade: 766\n",
      "Step 816, action: [-0.74511653], terminated: False, reward: 32.2757467901152, Trade: 767\n",
      "Step 817, action: [0.58994657], terminated: False, reward: 32.2657467901152, Trade: 768\n",
      "Step 818, action: [-0.27460998], terminated: False, reward: 32.255746790115204, Trade: 769\n",
      "Step 819, action: [0.37155208], terminated: False, reward: 32.245746790115206, Trade: 770\n",
      "Step 820, action: [-0.583309], terminated: False, reward: 32.47601684719039, Trade: 771\n",
      "Step 821, action: [-0.9992853], terminated: False, reward: 32.465730329390176, Trade: 772\n",
      "Step 822, action: [0.09484533], terminated: False, reward: 32.45573032939018, Trade: 773\n",
      "Step 823, action: [0.9178452], terminated: False, reward: 32.44573032939018, Trade: 774\n",
      "Step 824, action: [-0.25173393], terminated: False, reward: 32.44264666426083, Trade: 775\n",
      "Step 825, action: [0.52118933], terminated: False, reward: 32.43264666426083, Trade: 776\n",
      "Step 826, action: [0.3340687], terminated: False, reward: 32.42264666426083, Trade: 777\n",
      "Step 827, action: [0.26692095], terminated: False, reward: 32.41264666426083, Trade: 778\n",
      "Step 828, action: [0.51297057], terminated: False, reward: 32.402646664260836, Trade: 779\n",
      "Step 829, action: [-0.9402661], terminated: False, reward: 32.62259671591476, Trade: 780\n",
      "Step 830, action: [-0.3776301], terminated: False, reward: 33.26818925808852, Trade: 781\n",
      "Step 831, action: [0.20424971], terminated: False, reward: 33.25818925808852, Trade: 782\n",
      "Step 832, action: [-0.6244972], terminated: False, reward: 33.28998366730417, Trade: 783\n",
      "Step 833, action: [-0.15631415], terminated: False, reward: 33.2990634284137, Trade: 784\n",
      "Step 834, action: [-0.50628585], terminated: False, reward: 33.37444810225209, Trade: 785\n",
      "Step 835, action: [-0.2623658], terminated: False, reward: 33.34555458991819, Trade: 786\n",
      "Step 836, action: [0.52441365], terminated: False, reward: 33.33555458991819, Trade: 787\n",
      "Step 837, action: [-0.28348494], terminated: False, reward: 33.427198034891674, Trade: 788\n",
      "Step 838, action: [0.4436523], terminated: False, reward: 33.417198034891676, Trade: 789\n",
      "Step 839, action: [-0.11044376], terminated: False, reward: 33.40776446759851, Trade: 790\n",
      "Step 840, action: [0.5021586], terminated: False, reward: 33.39776446759851, Trade: 791\n",
      "Step 841, action: [-0.7950148], terminated: False, reward: 33.39047854959413, Trade: 792\n",
      "Step 842, action: [0.4402826], terminated: False, reward: 33.38047854959413, Trade: 793\n",
      "Step 843, action: [0.28995496], terminated: False, reward: 33.37047854959413, Trade: 794\n",
      "Step 844, action: [0.8533722], terminated: False, reward: 33.360478549594134, Trade: 795\n",
      "Step 845, action: [-0.43476847], terminated: False, reward: 33.350478549594136, Trade: 796\n",
      "Step 846, action: [-0.6564142], terminated: False, reward: 33.42044047921239, Trade: 797\n",
      "Step 847, action: [-0.25710535], terminated: False, reward: 33.40647216890546, Trade: 798\n",
      "Step 848, action: [0.4725184], terminated: False, reward: 33.39647216890546, Trade: 799\n",
      "Step 849, action: [-0.7280626], terminated: False, reward: 33.44905744220651, Trade: 800\n",
      "Step 850, action: [0.64081144], terminated: False, reward: 33.43905744220651, Trade: 801\n",
      "Step 851, action: [-0.68116695], terminated: False, reward: 33.45489387639969, Trade: 802\n",
      "Step 852, action: [0.9014487], terminated: False, reward: 33.44489387639969, Trade: 803\n",
      "Step 853, action: [-0.37043554], terminated: False, reward: 33.69042738137241, Trade: 804\n",
      "Step 854, action: [0.5275474], terminated: False, reward: 33.68042738137241, Trade: 805\n",
      "Step 855, action: [0.9019027], terminated: False, reward: 33.67042738137241, Trade: 806\n",
      "Step 856, action: [0.3744956], terminated: False, reward: 33.660427381372415, Trade: 807\n",
      "Step 857, action: [0.63247913], terminated: False, reward: 33.65042738137242, Trade: 808\n",
      "Step 858, action: [-0.5980268], terminated: False, reward: 35.01641731711088, Trade: 809\n",
      "Step 859, action: [0.58177495], terminated: False, reward: 35.00641731711088, Trade: 810\n",
      "Step 860, action: [-0.6360553], terminated: False, reward: 35.06594219986446, Trade: 811\n",
      "Step 861, action: [0.4455209], terminated: False, reward: 35.05594219986446, Trade: 812\n",
      "Step 862, action: [0.9102445], terminated: False, reward: 35.04594219986446, Trade: 813\n",
      "Step 863, action: [-0.36606622], terminated: False, reward: 35.048719754597954, Trade: 814\n",
      "Step 864, action: [0.5858094], terminated: False, reward: 35.038719754597956, Trade: 815\n",
      "Step 865, action: [0.80906636], terminated: False, reward: 35.02871975459796, Trade: 816\n",
      "Step 866, action: [0.43115708], terminated: False, reward: 35.01871975459796, Trade: 817\n",
      "Step 867, action: [0.1002575], terminated: False, reward: 35.00871975459796, Trade: 818\n",
      "Step 868, action: [0.8788769], terminated: False, reward: 34.998719754597964, Trade: 819\n",
      "Step 869, action: [-0.7424599], terminated: False, reward: 35.134640626198006, Trade: 820\n",
      "Step 870, action: [-0.18097451], terminated: False, reward: 35.12947121265007, Trade: 821\n",
      "Step 871, action: [0.34273353], terminated: False, reward: 35.11947121265007, Trade: 822\n",
      "Step 872, action: [0.31104636], terminated: False, reward: 35.10947121265007, Trade: 823\n",
      "Step 873, action: [0.5475345], terminated: False, reward: 35.09947121265007, Trade: 824\n",
      "Step 874, action: [0.48957357], terminated: False, reward: 35.089471212650075, Trade: 825\n",
      "Step 875, action: [0.2886789], terminated: False, reward: 35.07947121265008, Trade: 826\n",
      "Step 876, action: [-0.8805746], terminated: False, reward: 35.08933354823767, Trade: 827\n",
      "Step 877, action: [-0.22722873], terminated: False, reward: 35.28215130360119, Trade: 828\n",
      "Step 878, action: [0.31787083], terminated: False, reward: 35.27215130360119, Trade: 829\n",
      "Step 879, action: [-0.832179], terminated: False, reward: 35.15769291985648, Trade: 830\n",
      "Step 880, action: [-0.24424353], terminated: False, reward: 35.29535689280476, Trade: 831\n",
      "Step 881, action: [-0.91588014], terminated: False, reward: 37.800894926347844, Trade: 832\n",
      "Step 882, action: [0.37458172], terminated: False, reward: 37.790894926347846, Trade: 833\n",
      "Step 883, action: [0.35923976], terminated: False, reward: 37.78089492634785, Trade: 834\n",
      "Step 884, action: [0.15098931], terminated: False, reward: 37.77089492634785, Trade: 835\n",
      "Step 885, action: [0.94212115], terminated: False, reward: 37.76089492634785, Trade: 836\n",
      "Step 886, action: [0.9979902], terminated: False, reward: 37.750894926347854, Trade: 837\n",
      "Step 887, action: [-0.22356239], terminated: False, reward: 37.75056723422684, Trade: 838\n",
      "Step 888, action: [0.26900592], terminated: False, reward: 37.740567234226845, Trade: 839\n",
      "Step 889, action: [-0.7564605], terminated: False, reward: 37.651122164836714, Trade: 840\n",
      "Step 890, action: [-0.26363617], terminated: False, reward: 37.63987648385551, Trade: 841\n",
      "Step 891, action: [0.23869485], terminated: False, reward: 37.62987648385551, Trade: 842\n",
      "Step 892, action: [-0.5939096], terminated: False, reward: 37.09316985274098, Trade: 843\n",
      "Step 893, action: [-0.86363906], terminated: False, reward: 37.085353102906666, Trade: 844\n",
      "Step 894, action: [-0.07443955], terminated: False, reward: 37.104215981460804, Trade: 845\n",
      "Step 895, action: [-0.7932101], terminated: False, reward: 37.096073517724975, Trade: 846\n",
      "Step 896, action: [0.47095552], terminated: False, reward: 37.08607351772498, Trade: 847\n",
      "Step 897, action: [-0.83953995], terminated: False, reward: 37.07657817435277, Trade: 848\n",
      "Step 898, action: [-0.79951656], terminated: False, reward: 31.882499875095792, Trade: 849\n",
      "Step 899, action: [-0.4813931], terminated: False, reward: 31.879497895219114, Trade: 850\n",
      "Step 900, action: [0.56538767], terminated: False, reward: 31.869497895219112, Trade: 851\n",
      "Step 901, action: [-0.6680415], terminated: False, reward: 31.849190154596464, Trade: 852\n",
      "Step 902, action: [0.05140837], terminated: False, reward: 31.839190154596462, Trade: 853\n",
      "Step 903, action: [-0.08349134], terminated: False, reward: 31.82919015459646, Trade: 854\n",
      "Step 904, action: [0.08185461], terminated: False, reward: 31.81919015459646, Trade: 855\n",
      "Step 905, action: [0.0033676], terminated: False, reward: 31.809190154596457, Trade: 856\n",
      "Step 906, action: [0.05867116], terminated: False, reward: 31.799190154596456, Trade: 857\n",
      "Step 907, action: [-0.9427834], terminated: False, reward: 32.24518481881738, Trade: 858\n",
      "Step 908, action: [-0.57161134], terminated: False, reward: 32.40803439734571, Trade: 859\n",
      "Step 909, action: [0.02362585], terminated: False, reward: 32.39803439734571, Trade: 860\n",
      "Step 910, action: [0.95715374], terminated: False, reward: 32.38803439734571, Trade: 861\n",
      "Step 911, action: [-0.59390414], terminated: False, reward: 33.0112623730185, Trade: 862\n",
      "Step 912, action: [-0.5583983], terminated: False, reward: 33.701121890695894, Trade: 863\n",
      "Step 913, action: [0.30776408], terminated: False, reward: 33.6911218906959, Trade: 864\n",
      "Step 914, action: [-0.0122728], terminated: False, reward: 33.6811218906959, Trade: 865\n",
      "Step 915, action: [-0.94319373], terminated: False, reward: 33.67204342794883, Trade: 866\n",
      "Step 916, action: [-0.04607117], terminated: False, reward: 33.66592372017321, Trade: 867\n",
      "Step 917, action: [0.10046719], terminated: False, reward: 33.65592372017321, Trade: 868\n",
      "Step 918, action: [0.794457], terminated: False, reward: 33.645923720173215, Trade: 869\n",
      "Step 919, action: [-0.12513049], terminated: False, reward: 33.684372056107044, Trade: 870\n",
      "Step 920, action: [-0.89138114], terminated: False, reward: 33.67403625146277, Trade: 871\n",
      "Step 921, action: [0.8772909], terminated: False, reward: 33.664036251462775, Trade: 872\n",
      "Step 922, action: [-0.73152906], terminated: False, reward: 33.6549346195481, Trade: 873\n",
      "Step 923, action: [0.21318573], terminated: False, reward: 33.6449346195481, Trade: 874\n",
      "Step 924, action: [-0.3153544], terminated: False, reward: 33.63473439198723, Trade: 875\n",
      "Step 925, action: [-0.8923307], terminated: False, reward: 31.99898036043527, Trade: 876\n",
      "Step 926, action: [-0.20105866], terminated: False, reward: 31.990111445493405, Trade: 877\n",
      "Step 927, action: [0.86068225], terminated: False, reward: 31.980111445493403, Trade: 878\n",
      "Step 928, action: [0.9019244], terminated: False, reward: 31.9701114454934, Trade: 879\n",
      "Step 929, action: [0.8736105], terminated: False, reward: 31.9601114454934, Trade: 880\n",
      "Step 930, action: [-0.87351376], terminated: False, reward: 31.951900606716947, Trade: 881\n",
      "Step 931, action: [0.89931995], terminated: False, reward: 31.941900606716946, Trade: 882\n",
      "Step 932, action: [-0.4995917], terminated: False, reward: 31.892924113728533, Trade: 883\n",
      "Step 933, action: [0.20899491], terminated: False, reward: 31.88292411372853, Trade: 884\n",
      "Step 934, action: [0.8808412], terminated: False, reward: 31.87292411372853, Trade: 885\n",
      "Step 935, action: [0.36414796], terminated: False, reward: 31.86292411372853, Trade: 886\n",
      "Step 936, action: [0.6463445], terminated: False, reward: 31.852924113728527, Trade: 887\n",
      "Step 937, action: [0.55894107], terminated: False, reward: 31.842924113728525, Trade: 888\n",
      "Step 938, action: [-0.71970123], terminated: False, reward: 32.1053928686653, Trade: 889\n",
      "Step 939, action: [-0.01559777], terminated: False, reward: 32.09998925677526, Trade: 890\n",
      "Step 940, action: [0.47032347], terminated: False, reward: 32.08998925677526, Trade: 891\n",
      "Step 941, action: [-0.440649], terminated: False, reward: 32.095248836348716, Trade: 892\n",
      "Step 942, action: [0.43395552], terminated: False, reward: 32.08524883634872, Trade: 893\n",
      "Step 943, action: [-0.28339985], terminated: False, reward: 32.10686054972477, Trade: 894\n",
      "Step 944, action: [-0.31475878], terminated: False, reward: 32.166891167825895, Trade: 895\n",
      "Step 945, action: [-0.7046795], terminated: False, reward: 33.73947498135283, Trade: 896\n",
      "Step 946, action: [-0.12638573], terminated: False, reward: 33.804625064564355, Trade: 897\n",
      "Step 947, action: [-0.240381], terminated: False, reward: 33.79462506456436, Trade: 898\n",
      "Step 948, action: [0.9413326], terminated: False, reward: 33.78462506456436, Trade: 899\n",
      "Step 949, action: [0.7912329], terminated: False, reward: 33.77462506456436, Trade: 900\n",
      "Step 950, action: [-0.9312058], terminated: False, reward: 34.15783222723527, Trade: 901\n",
      "Step 951, action: [0.23799506], terminated: False, reward: 34.14783222723527, Trade: 902\n",
      "Step 952, action: [0.5972396], terminated: False, reward: 34.13783222723527, Trade: 903\n",
      "Step 953, action: [0.72823054], terminated: False, reward: 34.127832227235274, Trade: 904\n",
      "Step 954, action: [0.8866019], terminated: False, reward: 34.117832227235276, Trade: 905\n",
      "Step 955, action: [-0.6531811], terminated: False, reward: 34.11006041930003, Trade: 906\n",
      "Step 956, action: [-0.05432116], terminated: False, reward: 34.10011974985797, Trade: 907\n",
      "Step 957, action: [-0.50522757], terminated: False, reward: 34.8898710629481, Trade: 908\n",
      "Step 958, action: [-0.5406571], terminated: False, reward: 34.85426693140916, Trade: 909\n",
      "Step 959, action: [-0.6712662], terminated: False, reward: 34.85153635128824, Trade: 910\n",
      "Step 960, action: [0.36850312], terminated: False, reward: 34.84153635128824, Trade: 911\n",
      "Step 961, action: [0.4509385], terminated: False, reward: 34.83153635128824, Trade: 912\n",
      "Step 962, action: [-0.91451955], terminated: False, reward: 34.786763715096406, Trade: 913\n",
      "Step 963, action: [0.41163456], terminated: False, reward: 34.77676371509641, Trade: 914\n",
      "Step 964, action: [0.44911104], terminated: False, reward: 34.76676371509641, Trade: 915\n",
      "Step 965, action: [-0.44940034], terminated: False, reward: 34.822361398943464, Trade: 916\n",
      "Step 966, action: [0.88023764], terminated: False, reward: 34.812361398943466, Trade: 917\n",
      "Step 967, action: [-0.2412521], terminated: False, reward: 35.361091833660865, Trade: 918\n",
      "Step 968, action: [-0.89344037], terminated: False, reward: 35.42378669966487, Trade: 919\n",
      "Step 969, action: [-0.00048666], terminated: False, reward: 35.41378980928304, Trade: 920\n",
      "Step 970, action: [0.17439352], terminated: False, reward: 35.40378980928304, Trade: 921\n",
      "Step 971, action: [-0.03722686], terminated: False, reward: 35.39378980928304, Trade: 922\n",
      "Step 972, action: [0.30524418], terminated: False, reward: 35.383789809283044, Trade: 923\n",
      "Step 973, action: [-0.47040188], terminated: False, reward: 35.39880247323064, Trade: 924\n",
      "Step 974, action: [-0.30316514], terminated: False, reward: 35.51515504241701, Trade: 925\n",
      "Step 975, action: [-0.39463398], terminated: False, reward: 35.82509961693639, Trade: 926\n",
      "Step 976, action: [-0.3397436], terminated: False, reward: 36.086515869878134, Trade: 927\n",
      "Step 977, action: [-0.25047794], terminated: False, reward: 36.076515869878136, Trade: 928\n",
      "Step 978, action: [-0.7920851], terminated: False, reward: 39.61726152278249, Trade: 929\n",
      "Step 979, action: [-0.64514405], terminated: False, reward: 39.65162537345322, Trade: 930\n",
      "Step 980, action: [0.7303404], terminated: False, reward: 39.64162537345322, Trade: 931\n",
      "Step 981, action: [0.32092097], terminated: False, reward: 39.631625373453225, Trade: 932\n",
      "Step 982, action: [-0.2736294], terminated: False, reward: 39.59997116198519, Trade: 933\n",
      "Step 983, action: [-0.51451343], terminated: False, reward: 39.61490393021196, Trade: 934\n",
      "Step 984, action: [-0.36067733], terminated: False, reward: 40.24954622125646, Trade: 935\n",
      "Step 985, action: [0.7376175], terminated: False, reward: 40.23954622125646, Trade: 936\n",
      "Step 986, action: [0.8121755], terminated: False, reward: 40.22954622125646, Trade: 937\n",
      "Step 987, action: [0.7472895], terminated: False, reward: 40.219546221256465, Trade: 938\n",
      "Step 988, action: [-0.9579234], terminated: False, reward: 40.89813318929419, Trade: 939\n",
      "Step 989, action: [-0.12121546], terminated: False, reward: 40.887990150809884, Trade: 940\n",
      "Step 990, action: [0.8308152], terminated: False, reward: 40.877990150809886, Trade: 941\n",
      "Step 991, action: [0.90627205], terminated: False, reward: 40.86799015080989, Trade: 942\n",
      "Step 992, action: [0.60736644], terminated: False, reward: 40.85799015080989, Trade: 943\n",
      "Step 993, action: [-0.9541755], terminated: False, reward: 41.55584001825076, Trade: 944\n",
      "Step 994, action: [0.16599843], terminated: False, reward: 41.545840018250765, Trade: 945\n",
      "Step 995, action: [-0.24871264], terminated: False, reward: 41.5385761481185, Trade: 946\n",
      "Step 996, action: [0.8748484], terminated: False, reward: 41.5285761481185, Trade: 947\n",
      "Step 997, action: [0.81363344], terminated: False, reward: 41.518576148118505, Trade: 948\n",
      "Step 998, action: [0.9753191], terminated: False, reward: 41.50857614811851, Trade: 949\n",
      "Step 999, action: [0.95017356], terminated: False, reward: 41.49857614811851, Trade: 950\n",
      "Step 1000, action: [-0.00313265], terminated: False, reward: 41.48857614811851, Trade: 951\n",
      "Step 1001, action: [-0.55422777], terminated: False, reward: 41.569901038868416, Trade: 952\n",
      "Step 1002, action: [0.998636], terminated: False, reward: 41.55990103886842, Trade: 953\n",
      "Step 1003, action: [0.17279832], terminated: False, reward: 41.44990103886842, Trade: 953\n",
      "Step 1004, action: [0.5287964], terminated: False, reward: 41.33990103886842, Trade: 953\n",
      "Step 1005, action: [0.9816979], terminated: False, reward: 41.22990103886842, Trade: 953\n",
      "Step 1006, action: [0.04254707], terminated: False, reward: 41.11990103886842, Trade: 953\n",
      "Step 1007, action: [-0.06593149], terminated: False, reward: 41.16667883068218, Trade: 954\n",
      "Step 1008, action: [0.8485227], terminated: False, reward: 41.15667883068218, Trade: 955\n",
      "Step 1009, action: [-0.44138864], terminated: False, reward: 41.12565987033012, Trade: 956\n",
      "Step 1010, action: [0.70259887], terminated: False, reward: 41.11565987033012, Trade: 957\n",
      "Step 1011, action: [-0.01308578], terminated: False, reward: 41.124799552593075, Trade: 958\n",
      "Step 1012, action: [0.62486935], terminated: False, reward: 41.11479955259308, Trade: 959\n",
      "Step 1013, action: [0.6834164], terminated: False, reward: 41.10479955259308, Trade: 960\n",
      "Step 1014, action: [-0.94562584], terminated: False, reward: 41.866547619655975, Trade: 961\n",
      "Step 1015, action: [-0.96917397], terminated: False, reward: 41.87986818731551, Trade: 962\n",
      "Step 1016, action: [0.7645199], terminated: False, reward: 41.86986818731551, Trade: 963\n",
      "Step 1017, action: [-0.9471219], terminated: False, reward: 42.29015544109393, Trade: 964\n",
      "Step 1018, action: [-0.823717], terminated: False, reward: 42.54489443326676, Trade: 965\n",
      "Step 1019, action: [-0.45797157], terminated: False, reward: 42.59868119502903, Trade: 966\n",
      "Step 1020, action: [-0.307294], terminated: False, reward: 42.5892708901336, Trade: 967\n",
      "Step 1021, action: [-0.9999411], terminated: False, reward: 45.26636903390891, Trade: 968\n",
      "Step 1022, action: [0.74067295], terminated: False, reward: 45.25636903390891, Trade: 969\n",
      "Step 1023, action: [-0.37192369], terminated: False, reward: 45.391641687064705, Trade: 970\n",
      "Step 1024, action: [0.28648683], terminated: False, reward: 45.38164168706471, Trade: 971\n",
      "Step 1025, action: [0.77874345], terminated: False, reward: 45.37164168706471, Trade: 972\n",
      "Step 1026, action: [0.99142843], terminated: False, reward: 45.36164168706471, Trade: 973\n",
      "Step 1027, action: [-0.20194012], terminated: False, reward: 45.381355702782955, Trade: 974\n",
      "Step 1028, action: [0.6518801], terminated: False, reward: 45.37135570278296, Trade: 975\n",
      "Step 1029, action: [0.41039026], terminated: False, reward: 45.36135570278296, Trade: 976\n",
      "Step 1030, action: [0.3206221], terminated: False, reward: 45.35135570278296, Trade: 977\n",
      "Step 1031, action: [0.14344053], terminated: False, reward: 45.24135570278296, Trade: 977\n",
      "Step 1032, action: [0.7954952], terminated: False, reward: 45.23135570278296, Trade: 978\n",
      "Step 1033, action: [0.26938316], terminated: False, reward: 45.121355702782964, Trade: 978\n",
      "Step 1034, action: [0.22215874], terminated: False, reward: 45.011355702782964, Trade: 978\n",
      "Step 1035, action: [0.41069958], terminated: False, reward: 44.901355702782965, Trade: 978\n",
      "Step 1036, action: [0.8523131], terminated: False, reward: 44.89135570278297, Trade: 979\n",
      "Step 1037, action: [0.8409507], terminated: False, reward: 44.78135570278297, Trade: 979\n",
      "Step 1038, action: [0.04274828], terminated: False, reward: 44.67135570278297, Trade: 979\n",
      "Step 1039, action: [0.5309465], terminated: False, reward: 44.56135570278297, Trade: 979\n",
      "Step 1040, action: [0.05744367], terminated: False, reward: 44.45135570278297, Trade: 979\n",
      "Step 1041, action: [-0.17594299], terminated: False, reward: 44.450746205044936, Trade: 980\n",
      "Step 1042, action: [0.38740006], terminated: False, reward: 44.44074620504494, Trade: 981\n",
      "Step 1043, action: [-0.17480296], terminated: False, reward: 44.45974659242187, Trade: 982\n",
      "Step 1044, action: [-0.08886654], terminated: False, reward: 44.457274616658566, Trade: 983\n",
      "Step 1045, action: [0.6327485], terminated: False, reward: 44.44727461665857, Trade: 984\n",
      "Step 1046, action: [0.48912975], terminated: False, reward: 44.43727461665857, Trade: 985\n",
      "Step 1047, action: [-0.0194675], terminated: False, reward: 44.42796195919151, Trade: 986\n",
      "Step 1048, action: [0.4165834], terminated: False, reward: 44.41796195919151, Trade: 987\n",
      "Step 1049, action: [-0.8582205], terminated: False, reward: 45.910889450457915, Trade: 988\n",
      "Step 1050, action: [0.06145973], terminated: False, reward: 45.90088945045792, Trade: 989\n",
      "Step 1051, action: [-0.512772], terminated: False, reward: 44.16196010838645, Trade: 990\n",
      "Step 1052, action: [0.38844708], terminated: False, reward: 44.151960108386454, Trade: 991\n",
      "Step 1053, action: [0.90781504], terminated: False, reward: 44.141960108386456, Trade: 992\n",
      "Step 1054, action: [0.42032292], terminated: False, reward: 44.13196010838646, Trade: 993\n",
      "Step 1055, action: [-0.04254185], terminated: False, reward: 44.122095083031674, Trade: 994\n",
      "Step 1056, action: [0.22289562], terminated: False, reward: 44.112095083031676, Trade: 995\n",
      "Step 1057, action: [0.79596126], terminated: False, reward: 44.10209508303168, Trade: 996\n",
      "Step 1058, action: [0.41292274], terminated: False, reward: 44.09209508303168, Trade: 997\n",
      "Step 1059, action: [0.1908056], terminated: False, reward: 44.08209508303168, Trade: 998\n",
      "Step 1060, action: [0.32088298], terminated: False, reward: 44.072095083031684, Trade: 999\n",
      "Step 1061, action: [-0.88930434], terminated: False, reward: 45.80559225391366, Trade: 1000\n",
      "Step 1062, action: [0.31346288], terminated: False, reward: 45.79559225391366, Trade: 1001\n",
      "Step 1063, action: [-0.03005215], terminated: False, reward: 45.79264421646292, Trade: 1002\n",
      "Step 1064, action: [-0.05481819], terminated: False, reward: 45.79560870150762, Trade: 1003\n",
      "Step 1065, action: [0.7959445], terminated: False, reward: 45.78560870150762, Trade: 1004\n",
      "Step 1066, action: [-0.46156058], terminated: False, reward: 46.45279059101404, Trade: 1005\n",
      "Step 1067, action: [0.75590205], terminated: False, reward: 46.442790591014045, Trade: 1006\n",
      "Step 1068, action: [0.5178099], terminated: False, reward: 46.43279059101405, Trade: 1007\n",
      "Step 1069, action: [0.19472986], terminated: False, reward: 46.42279059101405, Trade: 1008\n",
      "Step 1070, action: [0.6655872], terminated: False, reward: 46.41279059101405, Trade: 1009\n",
      "Step 1071, action: [0.11820131], terminated: False, reward: 46.40279059101405, Trade: 1010\n",
      "Step 1072, action: [0.85636026], terminated: False, reward: 46.392790591014055, Trade: 1011\n",
      "Step 1073, action: [-0.51310223], terminated: False, reward: 46.434641756623584, Trade: 1012\n",
      "Step 1074, action: [-0.9555545], terminated: False, reward: 46.50603690874362, Trade: 1013\n",
      "Step 1075, action: [-0.88817096], terminated: False, reward: 46.4958559625701, Trade: 1014\n",
      "Step 1076, action: [-0.8821322], terminated: False, reward: 47.15448828468924, Trade: 1015\n",
      "Step 1077, action: [-0.740145], terminated: False, reward: 48.424106240974396, Trade: 1016\n",
      "Step 1078, action: [0.7520588], terminated: False, reward: 48.4141062409744, Trade: 1017\n",
      "Step 1079, action: [-0.2161295], terminated: False, reward: 48.2885975590206, Trade: 1018\n",
      "Step 1080, action: [0.89286953], terminated: False, reward: 48.278597559020604, Trade: 1019\n",
      "Step 1081, action: [0.5381825], terminated: False, reward: 48.268597559020606, Trade: 1020\n",
      "Step 1082, action: [-0.6915513], terminated: False, reward: 48.269033309022774, Trade: 1021\n",
      "Step 1083, action: [-0.30121058], terminated: False, reward: 48.39000594881483, Trade: 1022\n",
      "Step 1084, action: [-0.11887657], terminated: False, reward: 48.54531466564748, Trade: 1023\n",
      "Step 1085, action: [0.5085965], terminated: False, reward: 48.53531466564748, Trade: 1024\n",
      "Step 1086, action: [-0.06882852], terminated: False, reward: 48.627781992766195, Trade: 1025\n",
      "Step 1087, action: [0.24725054], terminated: False, reward: 48.6177819927662, Trade: 1026\n",
      "Step 1088, action: [0.01142934], terminated: False, reward: 48.6077819927662, Trade: 1027\n",
      "Step 1089, action: [0.8551707], terminated: False, reward: 48.5977819927662, Trade: 1028\n",
      "Step 1090, action: [0.260534], terminated: False, reward: 48.5877819927662, Trade: 1029\n",
      "Step 1091, action: [-0.66722375], terminated: False, reward: 48.72198113971555, Trade: 1030\n",
      "Step 1092, action: [-0.30511826], terminated: False, reward: 49.92637292978185, Trade: 1031\n",
      "Step 1093, action: [-0.6403099], terminated: False, reward: 50.196737857851836, Trade: 1032\n",
      "Step 1094, action: [0.47133476], terminated: False, reward: 50.18673785785184, Trade: 1033\n",
      "Step 1095, action: [-0.19046275], terminated: False, reward: 50.2000377034561, Trade: 1034\n",
      "Step 1096, action: [0.48456568], terminated: False, reward: 50.1900377034561, Trade: 1035\n",
      "Step 1097, action: [-0.9637268], terminated: False, reward: 51.45780392316705, Trade: 1036\n",
      "Step 1098, action: [-0.84339017], terminated: False, reward: 51.543330063940495, Trade: 1037\n",
      "Step 1099, action: [0.05087875], terminated: False, reward: 51.5333300639405, Trade: 1038\n",
      "Step 1100, action: [0.04247853], terminated: False, reward: 51.5233300639405, Trade: 1039\n",
      "Step 1101, action: [-0.03884052], terminated: False, reward: 51.5133300639405, Trade: 1040\n",
      "Step 1102, action: [0.404426], terminated: False, reward: 51.5033300639405, Trade: 1041\n",
      "Step 1103, action: [0.7370892], terminated: False, reward: 51.493330063940505, Trade: 1042\n",
      "Step 1104, action: [-0.54141587], terminated: False, reward: 51.65299068102211, Trade: 1043\n",
      "Step 1105, action: [0.8073024], terminated: False, reward: 51.64299068102211, Trade: 1044\n",
      "Step 1106, action: [0.37994254], terminated: False, reward: 51.632990681022115, Trade: 1045\n",
      "Step 1107, action: [0.3086558], terminated: False, reward: 51.62299068102212, Trade: 1046\n",
      "Step 1108, action: [-0.41596752], terminated: False, reward: 51.76960072438554, Trade: 1047\n",
      "Step 1109, action: [0.8852778], terminated: False, reward: 51.75960072438554, Trade: 1048\n",
      "Step 1110, action: [0.66242814], terminated: False, reward: 51.749600724385544, Trade: 1049\n",
      "Step 1111, action: [0.94046664], terminated: False, reward: 51.73960072438555, Trade: 1050\n",
      "Step 1112, action: [0.8275963], terminated: False, reward: 51.62960072438555, Trade: 1050\n",
      "Step 1113, action: [0.9208472], terminated: False, reward: 51.51960072438555, Trade: 1050\n",
      "Step 1114, action: [0.622018], terminated: False, reward: 51.40960072438555, Trade: 1050\n",
      "Step 1115, action: [-0.12493676], terminated: False, reward: 51.45520317180965, Trade: 1051\n",
      "Step 1116, action: [-0.9890702], terminated: False, reward: 50.781775104847725, Trade: 1052\n",
      "Step 1117, action: [0.00549637], terminated: False, reward: 50.77177510484773, Trade: 1053\n",
      "Step 1118, action: [0.45566943], terminated: False, reward: 50.76177510484773, Trade: 1054\n",
      "Step 1119, action: [0.6330012], terminated: False, reward: 50.75177510484773, Trade: 1055\n",
      "Step 1120, action: [-0.8667578], terminated: False, reward: 50.896891922225926, Trade: 1056\n",
      "Step 1121, action: [0.3555135], terminated: False, reward: 50.88689192222593, Trade: 1057\n",
      "Step 1122, action: [0.36844862], terminated: False, reward: 50.87689192222593, Trade: 1058\n",
      "Step 1123, action: [0.24305819], terminated: False, reward: 50.86689192222593, Trade: 1059\n",
      "Step 1124, action: [-0.35300696], terminated: False, reward: 50.87291480220415, Trade: 1060\n",
      "Step 1125, action: [0.7063379], terminated: False, reward: 50.86291480220415, Trade: 1061\n",
      "Step 1126, action: [-0.89944607], terminated: False, reward: 50.92112821847045, Trade: 1062\n",
      "Step 1127, action: [0.8600557], terminated: False, reward: 50.91112821847045, Trade: 1063\n",
      "Step 1128, action: [0.07068734], terminated: False, reward: 50.901128218470454, Trade: 1064\n",
      "Step 1129, action: [-0.26782897], terminated: False, reward: 50.917684161053636, Trade: 1065\n",
      "Step 1130, action: [0.1578913], terminated: False, reward: 50.90768416105364, Trade: 1066\n",
      "Step 1131, action: [0.9847626], terminated: False, reward: 50.89768416105364, Trade: 1067\n",
      "Step 1132, action: [0.699815], terminated: False, reward: 50.88768416105364, Trade: 1068\n",
      "Step 1133, action: [0.1301948], terminated: False, reward: 50.77768416105364, Trade: 1068\n",
      "Step 1134, action: [0.00357152], terminated: False, reward: 50.66768416105364, Trade: 1068\n",
      "Step 1135, action: [-0.7550706], terminated: False, reward: 50.85075161296514, Trade: 1069\n",
      "Step 1136, action: [-0.01650453], terminated: False, reward: 50.84087849820384, Trade: 1070\n",
      "Step 1137, action: [-0.45676622], terminated: False, reward: 51.031050339878306, Trade: 1071\n",
      "Step 1138, action: [-0.18227965], terminated: False, reward: 51.30806955108108, Trade: 1072\n",
      "Step 1139, action: [0.15080076], terminated: False, reward: 51.298069551081085, Trade: 1073\n",
      "Step 1140, action: [-0.06801092], terminated: False, reward: 51.38891627297704, Trade: 1074\n",
      "Step 1141, action: [0.9277048], terminated: False, reward: 51.378916272977044, Trade: 1075\n",
      "Step 1142, action: [-0.08897818], terminated: False, reward: 51.41411540409973, Trade: 1076\n",
      "Step 1143, action: [-0.1511234], terminated: False, reward: 51.40378344360292, Trade: 1077\n",
      "Step 1144, action: [-0.32886937], terminated: False, reward: 51.457895246947274, Trade: 1078\n",
      "Step 1145, action: [0.9126152], terminated: False, reward: 51.447895246947276, Trade: 1079\n",
      "Step 1146, action: [-0.5087213], terminated: False, reward: 53.23531155431715, Trade: 1080\n",
      "Step 1147, action: [0.08453807], terminated: False, reward: 53.22531155431715, Trade: 1081\n",
      "Step 1148, action: [0.66336703], terminated: False, reward: 53.215311554317154, Trade: 1082\n",
      "Step 1149, action: [0.08967923], terminated: False, reward: 53.205311554317156, Trade: 1083\n",
      "Step 1150, action: [0.76708895], terminated: False, reward: 53.19531155431716, Trade: 1084\n",
      "Step 1151, action: [0.08875193], terminated: False, reward: 53.18531155431716, Trade: 1085\n",
      "Step 1152, action: [-0.29226622], terminated: False, reward: 53.17718605273163, Trade: 1086\n",
      "Step 1153, action: [-0.8880594], terminated: False, reward: 53.18429580284083, Trade: 1087\n",
      "Step 1154, action: [0.5288568], terminated: False, reward: 53.17429580284083, Trade: 1088\n",
      "Step 1155, action: [-0.6930077], terminated: False, reward: 53.173402484970325, Trade: 1089\n",
      "Step 1156, action: [-0.6511493], terminated: False, reward: 53.14985182693528, Trade: 1090\n",
      "Step 1157, action: [0.33958375], terminated: False, reward: 53.139851826935285, Trade: 1091\n",
      "Step 1158, action: [0.7755364], terminated: False, reward: 53.12985182693529, Trade: 1092\n",
      "Step 1159, action: [-0.5029223], terminated: False, reward: 53.76379789609505, Trade: 1093\n",
      "Step 1160, action: [0.0170405], terminated: False, reward: 53.75379789609505, Trade: 1094\n",
      "Step 1161, action: [0.7009329], terminated: False, reward: 53.74379789609505, Trade: 1095\n",
      "Step 1162, action: [-0.00650435], terminated: False, reward: 53.733797896095055, Trade: 1096\n",
      "Step 1163, action: [-0.6754481], terminated: False, reward: 53.72600299460393, Trade: 1097\n",
      "Step 1164, action: [0.9843019], terminated: False, reward: 53.71600299460393, Trade: 1098\n",
      "Step 1165, action: [-0.922697], terminated: False, reward: 54.52811251647509, Trade: 1099\n",
      "Step 1166, action: [0.4769108], terminated: False, reward: 54.51811251647509, Trade: 1100\n",
      "Step 1167, action: [-0.57589155], terminated: False, reward: 55.08626497704042, Trade: 1101\n",
      "Step 1168, action: [-0.99458605], terminated: False, reward: 54.921313436041906, Trade: 1102\n",
      "Step 1169, action: [-0.32854995], terminated: False, reward: 55.035102291969146, Trade: 1103\n",
      "Step 1170, action: [0.24544065], terminated: False, reward: 55.02510229196915, Trade: 1104\n",
      "Step 1171, action: [0.14190543], terminated: False, reward: 55.01510229196915, Trade: 1105\n",
      "Step 1172, action: [-0.7932449], terminated: False, reward: 55.08254956384992, Trade: 1106\n",
      "Step 1173, action: [0.95900697], terminated: False, reward: 55.072549563849925, Trade: 1107\n",
      "Step 1174, action: [0.2803639], terminated: False, reward: 55.06254956384993, Trade: 1108\n",
      "Step 1175, action: [-0.8059283], terminated: False, reward: 54.50803688258288, Trade: 1109\n",
      "Step 1176, action: [0.6442939], terminated: False, reward: 54.49803688258288, Trade: 1110\n",
      "Step 1177, action: [0.48870513], terminated: False, reward: 54.48803688258288, Trade: 1111\n",
      "Step 1178, action: [0.27163178], terminated: False, reward: 54.478036882582884, Trade: 1112\n",
      "Step 1179, action: [0.51262474], terminated: False, reward: 54.46803688258289, Trade: 1113\n",
      "Step 1180, action: [-0.22701782], terminated: False, reward: 54.45833409907737, Trade: 1114\n",
      "Step 1181, action: [-0.7764792], terminated: False, reward: 54.43613881858433, Trade: 1115\n",
      "Step 1182, action: [0.5534666], terminated: False, reward: 54.426138818584334, Trade: 1116\n",
      "Step 1183, action: [-0.96989137], terminated: False, reward: 54.396596529179824, Trade: 1117\n",
      "Step 1184, action: [0.64065593], terminated: False, reward: 54.386596529179826, Trade: 1118\n",
      "Step 1185, action: [0.32624856], terminated: False, reward: 54.37659652917983, Trade: 1119\n",
      "Step 1186, action: [-0.95064896], terminated: False, reward: 54.6857460100244, Trade: 1120\n",
      "Step 1187, action: [0.47038192], terminated: False, reward: 54.675746010024405, Trade: 1121\n",
      "Step 1188, action: [-0.30558524], terminated: False, reward: 55.838623001504736, Trade: 1122\n",
      "Step 1189, action: [-0.74863976], terminated: False, reward: 55.90783840664041, Trade: 1123\n",
      "Step 1190, action: [0.522079], terminated: False, reward: 55.89783840664041, Trade: 1124\n",
      "Step 1191, action: [-0.07371105], terminated: False, reward: 55.955065514846844, Trade: 1125\n",
      "Step 1192, action: [0.98965764], terminated: False, reward: 55.945065514846846, Trade: 1126\n",
      "Step 1193, action: [-0.5164875], terminated: False, reward: 55.93260152606968, Trade: 1127\n",
      "Step 1194, action: [-0.87111765], terminated: False, reward: 56.37058636474743, Trade: 1128\n",
      "Step 1195, action: [0.8829124], terminated: False, reward: 56.360586364747434, Trade: 1129\n",
      "Step 1196, action: [-0.0881827], terminated: False, reward: 56.378781872039674, Trade: 1130\n",
      "Step 1197, action: [0.29222655], terminated: False, reward: 56.368781872039676, Trade: 1131\n",
      "Step 1198, action: [-0.6765115], terminated: False, reward: 56.4689790331077, Trade: 1132\n",
      "Step 1199, action: [-0.6036792], terminated: False, reward: 56.47444588359061, Trade: 1133\n",
      "Step 1200, action: [-0.84415674], terminated: False, reward: 57.49069853056687, Trade: 1134\n",
      "Step 1201, action: [0.6120502], terminated: False, reward: 57.48069853056687, Trade: 1135\n",
      "Step 1202, action: [0.09419762], terminated: False, reward: 57.47069853056687, Trade: 1136\n",
      "Step 1203, action: [-0.03631957], terminated: False, reward: 57.495202950686014, Trade: 1137\n",
      "Step 1204, action: [-0.00938862], terminated: False, reward: 57.48695656823625, Trade: 1138\n",
      "Step 1205, action: [0.68811584], terminated: False, reward: 57.476956568236254, Trade: 1139\n",
      "Step 1206, action: [-0.59605783], terminated: False, reward: 57.67096719275876, Trade: 1140\n",
      "Step 1207, action: [0.8621082], terminated: False, reward: 57.66096719275876, Trade: 1141\n",
      "Step 1208, action: [-0.71305555], terminated: False, reward: 57.68553361858636, Trade: 1142\n",
      "Step 1209, action: [0.1404516], terminated: False, reward: 57.675533618586364, Trade: 1143\n",
      "Step 1210, action: [0.7844558], terminated: False, reward: 57.665533618586366, Trade: 1144\n",
      "Step 1211, action: [-0.61403316], terminated: False, reward: 57.53187830930848, Trade: 1145\n",
      "Step 1212, action: [-0.23424073], terminated: False, reward: 57.53939624031165, Trade: 1146\n",
      "Step 1213, action: [-0.03844289], terminated: False, reward: 57.532439219459, Trade: 1147\n",
      "Step 1214, action: [0.42252454], terminated: False, reward: 57.522439219459, Trade: 1148\n",
      "Step 1215, action: [-0.1116657], terminated: False, reward: 58.13373366206229, Trade: 1149\n",
      "Step 1216, action: [-0.90077543], terminated: False, reward: 58.15827112615675, Trade: 1150\n",
      "Step 1217, action: [-0.2802444], terminated: False, reward: 58.168709576116484, Trade: 1151\n",
      "Step 1218, action: [0.5321437], terminated: False, reward: 58.158709576116486, Trade: 1152\n",
      "Step 1219, action: [-0.85319465], terminated: False, reward: 57.906155048278016, Trade: 1153\n",
      "Step 1220, action: [-0.16280468], terminated: False, reward: 57.89161145522793, Trade: 1154\n",
      "Step 1221, action: [-0.93529433], terminated: False, reward: 57.94766478205321, Trade: 1155\n",
      "Step 1222, action: [0.39636508], terminated: False, reward: 57.93766478205321, Trade: 1156\n",
      "Step 1223, action: [0.61041516], terminated: False, reward: 57.92766478205321, Trade: 1157\n",
      "Step 1224, action: [0.10177384], terminated: False, reward: 57.917664782053215, Trade: 1158\n",
      "Step 1225, action: [0.5695785], terminated: False, reward: 57.90766478205322, Trade: 1159\n",
      "Step 1226, action: [-0.70844144], terminated: False, reward: 57.936816712852526, Trade: 1160\n",
      "Step 1227, action: [0.1392472], terminated: False, reward: 57.92681671285253, Trade: 1161\n",
      "Step 1228, action: [0.0215839], terminated: False, reward: 57.91681671285253, Trade: 1162\n",
      "Step 1229, action: [-0.0550245], terminated: False, reward: 57.9055240222822, Trade: 1163\n",
      "Step 1230, action: [-0.15523905], terminated: False, reward: 58.16746800279536, Trade: 1164\n",
      "Step 1231, action: [-0.670899], terminated: False, reward: 57.93128716585337, Trade: 1165\n",
      "Step 1232, action: [0.87737674], terminated: False, reward: 57.92128716585337, Trade: 1166\n",
      "Step 1233, action: [-0.69828427], terminated: False, reward: 58.03857100750873, Trade: 1167\n",
      "Step 1234, action: [-0.71482444], terminated: False, reward: 58.221510349428044, Trade: 1168\n",
      "Step 1235, action: [0.58329713], terminated: False, reward: 58.211510349428046, Trade: 1169\n",
      "Step 1236, action: [0.08402628], terminated: False, reward: 58.20151034942805, Trade: 1170\n",
      "Step 1237, action: [0.3003687], terminated: False, reward: 58.19151034942805, Trade: 1171\n",
      "Step 1238, action: [0.16655464], terminated: False, reward: 58.18151034942805, Trade: 1172\n",
      "Step 1239, action: [0.21678272], terminated: False, reward: 58.171510349428054, Trade: 1173\n",
      "Step 1240, action: [0.49237382], terminated: False, reward: 58.161510349428056, Trade: 1174\n",
      "Step 1241, action: [-0.17034715], terminated: False, reward: 58.577952788366275, Trade: 1175\n",
      "Step 1242, action: [-0.47071216], terminated: False, reward: 61.64339298410673, Trade: 1176\n",
      "Step 1243, action: [0.04876912], terminated: False, reward: 61.633392984106735, Trade: 1177\n",
      "Step 1244, action: [0.28582597], terminated: False, reward: 61.62339298410674, Trade: 1178\n",
      "Step 1245, action: [0.6281106], terminated: False, reward: 61.61339298410674, Trade: 1179\n",
      "Step 1246, action: [-0.9108272], terminated: False, reward: 61.479391870641116, Trade: 1180\n",
      "Step 1247, action: [-0.34283602], terminated: False, reward: 61.47810698205082, Trade: 1181\n",
      "Step 1248, action: [-0.4543844], terminated: False, reward: 61.46810698205082, Trade: 1182\n",
      "Step 1249, action: [-0.4425594], terminated: False, reward: 61.65407450160402, Trade: 1183\n",
      "Step 1250, action: [-0.23585404], terminated: False, reward: 61.771788966035, Trade: 1184\n",
      "Step 1251, action: [0.48939914], terminated: False, reward: 61.761788966035, Trade: 1185\n",
      "Step 1252, action: [0.10506385], terminated: False, reward: 61.751788966035, Trade: 1186\n",
      "Step 1253, action: [-0.0276217], terminated: False, reward: 61.741788966035, Trade: 1187\n",
      "Step 1254, action: [0.5035315], terminated: False, reward: 61.731788966035005, Trade: 1188\n",
      "Step 1255, action: [-0.8319006], terminated: False, reward: 62.52817303578097, Trade: 1189\n",
      "Step 1256, action: [0.28188542], terminated: False, reward: 62.518173035780976, Trade: 1190\n",
      "Step 1257, action: [-0.02837229], terminated: False, reward: 62.575956703147305, Trade: 1191\n",
      "Step 1258, action: [0.6260768], terminated: False, reward: 62.56595670314731, Trade: 1192\n",
      "Step 1259, action: [0.27842066], terminated: False, reward: 62.55595670314731, Trade: 1193\n",
      "Step 1260, action: [0.34666222], terminated: False, reward: 62.54595670314731, Trade: 1194\n",
      "Step 1261, action: [-0.26606786], terminated: False, reward: 62.56866785965338, Trade: 1195\n",
      "Step 1262, action: [-0.05790908], terminated: False, reward: 62.56825931669112, Trade: 1196\n",
      "Step 1263, action: [0.7466519], terminated: False, reward: 62.55825931669112, Trade: 1197\n",
      "Step 1264, action: [-0.81575847], terminated: False, reward: 62.609743420433986, Trade: 1198\n",
      "Step 1265, action: [-0.97200876], terminated: False, reward: 62.7300342109757, Trade: 1199\n",
      "Step 1266, action: [-0.91965955], terminated: False, reward: 63.095734767043254, Trade: 1200\n",
      "Step 1267, action: [0.8065939], terminated: False, reward: 63.085734767043256, Trade: 1201\n",
      "Step 1268, action: [-0.02284623], terminated: False, reward: 63.12296514952598, Trade: 1202\n",
      "Step 1269, action: [0.40329698], terminated: False, reward: 63.112965149525984, Trade: 1203\n",
      "Step 1270, action: [0.03307629], terminated: False, reward: 63.102965149525986, Trade: 1204\n",
      "Step 1271, action: [0.66004777], terminated: False, reward: 63.09296514952599, Trade: 1205\n",
      "Step 1272, action: [-0.8960893], terminated: False, reward: 64.91447397617019, Trade: 1206\n",
      "Step 1273, action: [-0.72583395], terminated: False, reward: 64.90118246511507, Trade: 1207\n",
      "Step 1274, action: [0.32381198], terminated: False, reward: 64.89118246511507, Trade: 1208\n",
      "Step 1275, action: [-0.63856864], terminated: False, reward: 64.885721053226, Trade: 1209\n",
      "Step 1276, action: [-0.05599384], terminated: False, reward: 64.8975832660543, Trade: 1210\n",
      "Step 1277, action: [-0.04379807], terminated: False, reward: 64.91362581960173, Trade: 1211\n",
      "Step 1278, action: [0.4729729], terminated: False, reward: 64.90362581960173, Trade: 1212\n",
      "Step 1279, action: [0.04768426], terminated: False, reward: 64.89362581960172, Trade: 1213\n",
      "Step 1280, action: [0.6369977], terminated: False, reward: 64.88362581960172, Trade: 1214\n",
      "Step 1281, action: [0.532677], terminated: False, reward: 64.87362581960171, Trade: 1215\n",
      "Step 1282, action: [0.6111353], terminated: False, reward: 64.86362581960171, Trade: 1216\n",
      "Step 1283, action: [0.45497173], terminated: False, reward: 64.8536258196017, Trade: 1217\n",
      "Step 1284, action: [0.6427164], terminated: False, reward: 64.8436258196017, Trade: 1218\n",
      "Step 1285, action: [-0.44006622], terminated: False, reward: 64.99071622476218, Trade: 1219\n",
      "Step 1286, action: [0.63553965], terminated: False, reward: 64.98071622476218, Trade: 1220\n",
      "Step 1287, action: [0.34960705], terminated: False, reward: 64.97071622476217, Trade: 1221\n",
      "Step 1288, action: [0.3823813], terminated: False, reward: 64.96071622476217, Trade: 1222\n",
      "Step 1289, action: [0.67625743], terminated: False, reward: 64.95071622476216, Trade: 1223\n",
      "Step 1290, action: [-0.1574895], terminated: False, reward: 64.96943775731557, Trade: 1224\n",
      "Step 1291, action: [0.98676944], terminated: False, reward: 64.95943775731557, Trade: 1225\n",
      "Step 1292, action: [0.68949634], terminated: False, reward: 64.94943775731556, Trade: 1226\n",
      "Step 1293, action: [0.6736192], terminated: False, reward: 64.93943775731556, Trade: 1227\n",
      "Step 1294, action: [0.778092], terminated: False, reward: 64.92943775731555, Trade: 1228\n",
      "Step 1295, action: [-0.70423603], terminated: False, reward: 67.11571238846638, Trade: 1229\n",
      "Step 1296, action: [-0.44598252], terminated: False, reward: 68.56984501339349, Trade: 1230\n",
      "Step 1297, action: [-0.1637282], terminated: False, reward: 68.54872723088474, Trade: 1231\n",
      "Step 1298, action: [-0.12105164], terminated: False, reward: 68.77416602815879, Trade: 1232\n",
      "Step 1299, action: [0.6422924], terminated: False, reward: 68.76416602815878, Trade: 1233\n",
      "Step 1300, action: [0.49577603], terminated: False, reward: 68.75416602815878, Trade: 1234\n",
      "Step 1301, action: [0.7170498], terminated: False, reward: 68.74416602815877, Trade: 1235\n",
      "Step 1302, action: [-0.10023892], terminated: False, reward: 68.73416602815877, Trade: 1236\n",
      "Step 1303, action: [0.4859778], terminated: False, reward: 68.72416602815876, Trade: 1237\n",
      "Step 1304, action: [0.7268853], terminated: False, reward: 68.71416602815876, Trade: 1238\n",
      "Step 1305, action: [-0.308439], terminated: False, reward: 68.50855770381722, Trade: 1239\n",
      "Step 1306, action: [0.2617579], terminated: False, reward: 68.49855770381721, Trade: 1240\n",
      "Step 1307, action: [-0.12883839], terminated: False, reward: 68.46775829221042, Trade: 1241\n",
      "Step 1308, action: [0.30209014], terminated: False, reward: 68.45775829221041, Trade: 1242\n",
      "Step 1309, action: [0.27998656], terminated: False, reward: 68.44775829221041, Trade: 1243\n",
      "Step 1310, action: [-0.272272], terminated: False, reward: 68.3641766256789, Trade: 1244\n",
      "Step 1311, action: [-0.7428896], terminated: False, reward: 69.64688045914171, Trade: 1245\n",
      "Step 1312, action: [-0.38257113], terminated: False, reward: 69.85346438207657, Trade: 1246\n",
      "Step 1313, action: [-0.7851045], terminated: False, reward: 71.23491003116258, Trade: 1247\n",
      "Step 1314, action: [-0.95632607], terminated: False, reward: 71.1371598228499, Trade: 1248\n",
      "Step 1315, action: [-0.40893358], terminated: False, reward: 71.12613353897056, Trade: 1249\n",
      "Step 1316, action: [0.368235], terminated: False, reward: 71.11613353897056, Trade: 1250\n",
      "Step 1317, action: [-0.84145284], terminated: False, reward: 71.10307033040111, Trade: 1251\n",
      "Step 1318, action: [0.5125826], terminated: False, reward: 71.0930703304011, Trade: 1252\n",
      "Step 1319, action: [0.07347092], terminated: False, reward: 71.0830703304011, Trade: 1253\n",
      "Step 1320, action: [-0.80425245], terminated: False, reward: 71.0799127298083, Trade: 1254\n",
      "Step 1321, action: [-0.8730878], terminated: False, reward: 70.77618381517884, Trade: 1255\n",
      "Step 1322, action: [0.78215146], terminated: False, reward: 70.76618381517883, Trade: 1256\n",
      "Step 1323, action: [0.3918073], terminated: False, reward: 70.75618381517883, Trade: 1257\n",
      "Step 1324, action: [-0.23925394], terminated: False, reward: 70.7392183691933, Trade: 1258\n",
      "Step 1325, action: [0.65387905], terminated: False, reward: 70.72921836919329, Trade: 1259\n",
      "Step 1326, action: [0.2786296], terminated: False, reward: 70.71921836919329, Trade: 1260\n",
      "Step 1327, action: [0.9846646], terminated: False, reward: 70.70921836919328, Trade: 1261\n",
      "Step 1328, action: [0.15870693], terminated: False, reward: 70.59921836919328, Trade: 1261\n",
      "Step 1329, action: [0.71172893], terminated: False, reward: 70.48921836919328, Trade: 1261\n",
      "Step 1330, action: [0.73217505], terminated: False, reward: 70.47921836919328, Trade: 1262\n",
      "Step 1331, action: [0.55588704], terminated: False, reward: 70.36921836919328, Trade: 1262\n",
      "Step 1332, action: [-0.04736733], terminated: False, reward: 70.3671417940886, Trade: 1263\n",
      "Step 1333, action: [-0.90348613], terminated: False, reward: 70.56857585606448, Trade: 1264\n",
      "Step 1334, action: [0.62377787], terminated: False, reward: 70.55857585606448, Trade: 1265\n",
      "Step 1335, action: [0.3255216], terminated: False, reward: 70.54857585606447, Trade: 1266\n",
      "Step 1336, action: [0.41163835], terminated: False, reward: 70.53857585606447, Trade: 1267\n",
      "Step 1337, action: [-0.18200928], terminated: False, reward: 70.51749206045443, Trade: 1268\n",
      "Step 1338, action: [-0.43783557], terminated: False, reward: 70.79423863693768, Trade: 1269\n",
      "Step 1339, action: [-0.5298059], terminated: False, reward: 71.13419917859555, Trade: 1270\n",
      "Step 1340, action: [-0.50098896], terminated: False, reward: 71.36378484407005, Trade: 1271\n",
      "Step 1341, action: [-0.7202334], terminated: False, reward: 71.35569540022989, Trade: 1272\n",
      "Step 1342, action: [-0.86590016], terminated: False, reward: 71.36092032191037, Trade: 1273\n",
      "Step 1343, action: [-0.81286114], terminated: False, reward: 71.6249884408033, Trade: 1274\n",
      "Step 1344, action: [-0.46951717], terminated: False, reward: 71.63389674723123, Trade: 1275\n",
      "Step 1345, action: [0.3920397], terminated: False, reward: 71.62389674723123, Trade: 1276\n",
      "Step 1346, action: [-0.16555588], terminated: False, reward: 71.61241722795678, Trade: 1277\n",
      "Step 1347, action: [-0.62231773], terminated: False, reward: 71.60347585137671, Trade: 1278\n",
      "Step 1348, action: [0.6080657], terminated: False, reward: 71.59347585137671, Trade: 1279\n",
      "Step 1349, action: [0.5666919], terminated: False, reward: 71.5834758513767, Trade: 1280\n",
      "Step 1350, action: [0.53075343], terminated: False, reward: 71.5734758513767, Trade: 1281\n",
      "Step 1351, action: [0.25946528], terminated: False, reward: 71.5634758513767, Trade: 1282\n",
      "Step 1352, action: [0.7393711], terminated: False, reward: 71.55347585137669, Trade: 1283\n",
      "Step 1353, action: [0.56903934], terminated: False, reward: 71.54347585137668, Trade: 1284\n",
      "Step 1354, action: [0.97808146], terminated: False, reward: 71.53347585137668, Trade: 1285\n",
      "Step 1355, action: [0.8569863], terminated: False, reward: 71.42347585137668, Trade: 1285\n",
      "Step 1356, action: [0.76975876], terminated: False, reward: 71.31347585137668, Trade: 1285\n",
      "Step 1357, action: [0.9404474], terminated: False, reward: 71.20347585137668, Trade: 1285\n",
      "Step 1358, action: [-0.55776113], terminated: False, reward: 71.58053084835885, Trade: 1286\n",
      "Step 1359, action: [-0.9358051], terminated: False, reward: 72.1435842273239, Trade: 1287\n",
      "Step 1360, action: [-0.9346375], terminated: False, reward: 72.1750975264414, Trade: 1288\n",
      "Step 1361, action: [-0.95664954], terminated: False, reward: 72.72331385928045, Trade: 1289\n",
      "Step 1362, action: [0.38383144], terminated: False, reward: 72.71331385928045, Trade: 1290\n",
      "Step 1363, action: [0.88357383], terminated: False, reward: 72.70331385928044, Trade: 1291\n",
      "Step 1364, action: [-0.97764844], terminated: False, reward: 72.82089754940634, Trade: 1292\n",
      "Step 1365, action: [0.18825033], terminated: False, reward: 72.81089754940633, Trade: 1293\n",
      "Step 1366, action: [-0.5789694], terminated: False, reward: 72.98502423197513, Trade: 1294\n",
      "Step 1367, action: [-0.75157475], terminated: False, reward: 73.28445968855112, Trade: 1295\n",
      "Step 1368, action: [-0.69927573], terminated: False, reward: 73.27396966488841, Trade: 1296\n",
      "Step 1369, action: [-0.3034912], terminated: False, reward: 73.26540222754902, Trade: 1297\n",
      "Step 1370, action: [0.1136065], terminated: False, reward: 73.25540222754901, Trade: 1298\n",
      "Step 1371, action: [0.4577918], terminated: False, reward: 73.24540222754901, Trade: 1299\n",
      "Step 1372, action: [0.5089365], terminated: False, reward: 73.235402227549, Trade: 1300\n",
      "Step 1373, action: [-0.97980917], terminated: False, reward: 73.21779805596138, Trade: 1301\n",
      "Step 1374, action: [0.09123849], terminated: False, reward: 73.20779805596138, Trade: 1302\n",
      "Step 1375, action: [-0.43539122], terminated: False, reward: 73.61550143259974, Trade: 1303\n",
      "Step 1376, action: [-0.98733413], terminated: False, reward: 72.28946479869626, Trade: 1304\n",
      "Step 1377, action: [-0.35478243], terminated: False, reward: 73.00174660989411, Trade: 1305\n",
      "Step 1378, action: [-0.22931135], terminated: False, reward: 72.98863271693925, Trade: 1306\n",
      "Step 1379, action: [-0.99588454], terminated: False, reward: 76.86402808837111, Trade: 1307\n",
      "Step 1380, action: [-0.66408545], terminated: False, reward: 75.00578694563606, Trade: 1308\n",
      "Step 1381, action: [-0.8611903], terminated: False, reward: 75.32027857480358, Trade: 1309\n",
      "Step 1382, action: [-0.49632362], terminated: False, reward: 75.63219569333948, Trade: 1310\n",
      "Step 1383, action: [0.43625832], terminated: False, reward: 75.62219569333948, Trade: 1311\n",
      "Step 1384, action: [0.26063922], terminated: False, reward: 75.61219569333947, Trade: 1312\n",
      "Step 1385, action: [-0.61771137], terminated: False, reward: 75.79429622152473, Trade: 1313\n",
      "Step 1386, action: [-0.59549946], terminated: False, reward: 75.81742477722392, Trade: 1314\n",
      "Step 1387, action: [-0.36344397], terminated: False, reward: 75.80879787526575, Trade: 1315\n",
      "Step 1388, action: [-0.9800515], terminated: False, reward: 75.8350118877219, Trade: 1316\n",
      "Step 1389, action: [-0.3618482], terminated: False, reward: 75.78021873670815, Trade: 1317\n",
      "Step 1390, action: [0.09730976], terminated: False, reward: 75.77021873670815, Trade: 1318\n",
      "Step 1391, action: [0.6681559], terminated: False, reward: 75.76021873670814, Trade: 1319\n",
      "Step 1392, action: [0.510683], terminated: False, reward: 75.75021873670813, Trade: 1320\n",
      "Step 1393, action: [-0.8831564], terminated: False, reward: 75.88359405804891, Trade: 1321\n",
      "Step 1394, action: [-0.91435415], terminated: False, reward: 75.95871044735705, Trade: 1322\n",
      "Step 1395, action: [-0.88623786], terminated: False, reward: 75.94843304963513, Trade: 1323\n",
      "Step 1396, action: [0.72907865], terminated: False, reward: 75.93843304963512, Trade: 1324\n",
      "Step 1397, action: [0.17533837], terminated: False, reward: 75.92843304963512, Trade: 1325\n",
      "Step 1398, action: [0.01428354], terminated: False, reward: 75.91843304963511, Trade: 1326\n",
      "Step 1399, action: [-0.39357015], terminated: False, reward: 75.11777722318028, Trade: 1327\n",
      "Step 1400, action: [0.09834263], terminated: False, reward: 75.10777722318028, Trade: 1328\n",
      "Step 1401, action: [-0.5620966], terminated: False, reward: 75.10574534125061, Trade: 1329\n",
      "Step 1402, action: [-0.42006797], terminated: False, reward: 75.52789657204764, Trade: 1330\n",
      "Step 1403, action: [0.5301147], terminated: False, reward: 75.51789657204763, Trade: 1331\n",
      "Step 1404, action: [0.30781433], terminated: False, reward: 75.50789657204763, Trade: 1332\n",
      "Step 1405, action: [-0.2016432], terminated: False, reward: 75.50411810375564, Trade: 1333\n",
      "Step 1406, action: [-0.44473547], terminated: False, reward: 75.49943245216637, Trade: 1334\n",
      "Step 1407, action: [0.07434096], terminated: False, reward: 75.48943245216637, Trade: 1335\n",
      "Step 1408, action: [0.14149754], terminated: False, reward: 75.47943245216636, Trade: 1336\n",
      "Step 1409, action: [-0.7737726], terminated: False, reward: 75.65686965611548, Trade: 1337\n",
      "Step 1410, action: [-0.9932244], terminated: False, reward: 75.73166257090483, Trade: 1338\n",
      "Step 1411, action: [0.67317903], terminated: False, reward: 75.72166257090483, Trade: 1339\n",
      "Step 1412, action: [0.57333386], terminated: False, reward: 75.71166257090482, Trade: 1340\n",
      "Step 1413, action: [-0.13693786], terminated: False, reward: 75.70220721286987, Trade: 1341\n",
      "Step 1414, action: [-0.7003381], terminated: False, reward: 75.69456226422778, Trade: 1342\n",
      "Step 1415, action: [0.15571678], terminated: False, reward: 75.68456226422778, Trade: 1343\n",
      "Step 1416, action: [0.31225142], terminated: False, reward: 75.67456226422777, Trade: 1344\n",
      "Step 1417, action: [-0.7468372], terminated: False, reward: 76.46925498260268, Trade: 1345\n",
      "Step 1418, action: [0.87757766], terminated: False, reward: 76.45925498260267, Trade: 1346\n",
      "Step 1419, action: [-0.36489567], terminated: False, reward: 76.73496405198733, Trade: 1347\n",
      "Step 1420, action: [-0.13111062], terminated: False, reward: 76.72702251306633, Trade: 1348\n",
      "Step 1421, action: [-0.3335234], terminated: False, reward: 76.71981895512609, Trade: 1349\n",
      "Step 1422, action: [0.8065547], terminated: False, reward: 76.70981895512608, Trade: 1350\n",
      "Step 1423, action: [-0.21950868], terminated: False, reward: 76.67337621848674, Trade: 1351\n",
      "Step 1424, action: [0.89628696], terminated: False, reward: 76.66337621848673, Trade: 1352\n",
      "Step 1425, action: [0.96804726], terminated: False, reward: 76.65337621848673, Trade: 1353\n",
      "Step 1426, action: [0.9659311], terminated: False, reward: 76.64337621848672, Trade: 1354\n",
      "Step 1427, action: [-0.33871177], terminated: False, reward: 76.65952971426412, Trade: 1355\n",
      "Step 1428, action: [0.45830584], terminated: False, reward: 76.64952971426412, Trade: 1356\n",
      "Step 1429, action: [0.50914353], terminated: False, reward: 76.63952971426411, Trade: 1357\n",
      "Step 1430, action: [-0.7844783], terminated: False, reward: 76.73964120588828, Trade: 1358\n",
      "Step 1431, action: [0.48969764], terminated: False, reward: 76.72964120588827, Trade: 1359\n",
      "Step 1432, action: [0.33670515], terminated: False, reward: 76.71964120588827, Trade: 1360\n",
      "Step 1433, action: [-0.16281633], terminated: False, reward: 76.71146123144996, Trade: 1361\n",
      "Step 1434, action: [0.45537835], terminated: False, reward: 76.70146123144995, Trade: 1362\n",
      "Step 1435, action: [0.4839219], terminated: False, reward: 76.69146123144995, Trade: 1363\n",
      "Step 1436, action: [0.9032133], terminated: False, reward: 76.68146123144994, Trade: 1364\n",
      "Step 1437, action: [-0.9530627], terminated: False, reward: 76.6827570216107, Trade: 1365\n",
      "Step 1438, action: [-0.4401411], terminated: False, reward: 77.14360926936034, Trade: 1366\n",
      "Step 1439, action: [0.22051324], terminated: False, reward: 77.13360926936033, Trade: 1367\n",
      "Step 1440, action: [-0.00714892], terminated: False, reward: 77.12360926936033, Trade: 1368\n",
      "Step 1441, action: [0.87795025], terminated: False, reward: 77.11360926936032, Trade: 1369\n",
      "Step 1442, action: [0.23764852], terminated: False, reward: 77.10360926936032, Trade: 1370\n",
      "Step 1443, action: [0.51652855], terminated: False, reward: 77.09360926936031, Trade: 1371\n",
      "Step 1444, action: [0.51658154], terminated: False, reward: 77.08360926936031, Trade: 1372\n",
      "Step 1445, action: [-0.14108697], terminated: False, reward: 77.05765009094452, Trade: 1373\n",
      "Step 1446, action: [-0.3812564], terminated: False, reward: 77.24887925893182, Trade: 1374\n",
      "Step 1447, action: [0.10807487], terminated: False, reward: 77.23887925893182, Trade: 1375\n",
      "Step 1448, action: [-0.24367908], terminated: False, reward: 77.23012732649669, Trade: 1376\n",
      "Step 1449, action: [0.27405745], terminated: False, reward: 77.22012732649668, Trade: 1377\n",
      "Step 1450, action: [-0.16578971], terminated: False, reward: 77.1751159947026, Trade: 1378\n",
      "Step 1451, action: [-0.43439162], terminated: False, reward: 77.45527032672815, Trade: 1379\n",
      "Step 1452, action: [0.79214305], terminated: False, reward: 77.44527032672815, Trade: 1380\n",
      "Step 1453, action: [0.681], terminated: False, reward: 77.43527032672814, Trade: 1381\n",
      "Step 1454, action: [-0.25957295], terminated: False, reward: 77.43429876151042, Trade: 1382\n",
      "Step 1455, action: [-0.13946973], terminated: False, reward: 77.42356126201992, Trade: 1383\n",
      "Step 1456, action: [0.53598124], terminated: False, reward: 77.41356126201991, Trade: 1384\n",
      "Step 1457, action: [0.10623618], terminated: False, reward: 77.4035612620199, Trade: 1385\n",
      "Step 1458, action: [-0.59335756], terminated: False, reward: 78.05802037904286, Trade: 1386\n",
      "Step 1459, action: [0.98399335], terminated: False, reward: 78.04802037904285, Trade: 1387\n",
      "Step 1460, action: [-0.19324473], terminated: False, reward: 78.03928464302084, Trade: 1388\n",
      "Step 1461, action: [0.43321684], terminated: False, reward: 78.02928464302083, Trade: 1389\n",
      "Step 1462, action: [-0.99329966], terminated: False, reward: 78.19005933748389, Trade: 1390\n",
      "Step 1463, action: [0.17565921], terminated: False, reward: 78.18005933748388, Trade: 1391\n",
      "Step 1464, action: [-0.4113843], terminated: False, reward: 78.17005933748388, Trade: 1392\n",
      "Step 1465, action: [0.8483296], terminated: False, reward: 78.16005933748387, Trade: 1393\n",
      "Step 1466, action: [0.930006], terminated: False, reward: 78.15005933748387, Trade: 1394\n",
      "Step 1467, action: [0.04320673], terminated: False, reward: 78.04005933748387, Trade: 1394\n",
      "Step 1468, action: [0.00252653], terminated: False, reward: 77.93005933748387, Trade: 1394\n",
      "Step 1469, action: [0.2321632], terminated: False, reward: 77.82005933748387, Trade: 1394\n",
      "Step 1470, action: [-0.5202372], terminated: False, reward: 78.04393194565856, Trade: 1395\n",
      "Step 1471, action: [-0.08371533], terminated: False, reward: 78.0389332000123, Trade: 1396\n",
      "Step 1472, action: [0.7143504], terminated: False, reward: 78.02893320001229, Trade: 1397\n",
      "Step 1473, action: [0.679414], terminated: False, reward: 78.01893320001228, Trade: 1398\n",
      "Step 1474, action: [-0.25604305], terminated: False, reward: 78.00763825763751, Trade: 1399\n",
      "Step 1475, action: [0.52802753], terminated: False, reward: 77.9976382576375, Trade: 1400\n",
      "Step 1476, action: [0.15112987], terminated: False, reward: 77.9876382576375, Trade: 1401\n",
      "Step 1477, action: [-0.53381836], terminated: False, reward: 77.8678375591962, Trade: 1402\n",
      "Step 1478, action: [0.06004258], terminated: False, reward: 77.8578375591962, Trade: 1403\n",
      "Step 1479, action: [-0.94914496], terminated: False, reward: 77.794843666723, Trade: 1404\n",
      "Step 1480, action: [-0.64236444], terminated: False, reward: 77.42190129102077, Trade: 1405\n",
      "Step 1481, action: [-0.44938043], terminated: False, reward: 77.43441981167582, Trade: 1406\n",
      "Step 1482, action: [-0.5232707], terminated: False, reward: 77.41912832322055, Trade: 1407\n",
      "Step 1483, action: [0.5124705], terminated: False, reward: 77.40912832322054, Trade: 1408\n",
      "Step 1484, action: [-0.68568414], terminated: False, reward: 77.62594256073758, Trade: 1409\n",
      "Step 1485, action: [0.81536037], terminated: False, reward: 77.61594256073758, Trade: 1410\n",
      "Step 1486, action: [-0.9942251], terminated: False, reward: 78.06646166238386, Trade: 1411\n",
      "Step 1487, action: [0.38676006], terminated: False, reward: 78.05646166238385, Trade: 1412\n",
      "Step 1488, action: [-0.24041192], terminated: False, reward: 78.05375138703437, Trade: 1413\n",
      "Step 1489, action: [0.4974362], terminated: False, reward: 78.04375138703436, Trade: 1414\n",
      "Step 1490, action: [-0.7701849], terminated: False, reward: 78.14722233132294, Trade: 1415\n",
      "Step 1491, action: [0.10429096], terminated: False, reward: 78.13722233132293, Trade: 1416\n",
      "Step 1492, action: [0.6530219], terminated: False, reward: 78.12722233132293, Trade: 1417\n",
      "Step 1493, action: [-0.19941728], terminated: False, reward: 78.21938367064313, Trade: 1418\n",
      "Step 1494, action: [0.03011318], terminated: False, reward: 78.20938367064312, Trade: 1419\n",
      "Step 1495, action: [0.4724541], terminated: False, reward: 78.19938367064312, Trade: 1420\n",
      "Step 1496, action: [0.32881555], terminated: False, reward: 78.18938367064311, Trade: 1421\n",
      "Step 1497, action: [-0.28109545], terminated: False, reward: 78.30261749202785, Trade: 1422\n",
      "Step 1498, action: [-0.6107544], terminated: False, reward: 78.52955803258777, Trade: 1423\n",
      "Step 1499, action: [-0.15330085], terminated: False, reward: 78.1486390591853, Trade: 1424\n",
      "Step 1500, action: [0.8370244], terminated: False, reward: 78.1386390591853, Trade: 1425\n",
      "Step 1501, action: [0.7570924], terminated: False, reward: 78.12863905918529, Trade: 1426\n",
      "Step 1502, action: [0.06292775], terminated: False, reward: 78.11863905918528, Trade: 1427\n",
      "Step 1503, action: [-0.3590881], terminated: False, reward: 78.1641063726077, Trade: 1428\n",
      "Step 1504, action: [0.2289698], terminated: False, reward: 78.1541063726077, Trade: 1429\n",
      "Step 1505, action: [0.00783115], terminated: False, reward: 78.1441063726077, Trade: 1430\n",
      "Step 1506, action: [0.95947427], terminated: False, reward: 78.13410637260769, Trade: 1431\n",
      "Step 1507, action: [0.8467189], terminated: False, reward: 78.12410637260768, Trade: 1432\n",
      "Step 1508, action: [-0.24843428], terminated: False, reward: 78.11985826520343, Trade: 1433\n",
      "Step 1509, action: [-0.3835107], terminated: False, reward: 78.10961999906492, Trade: 1434\n",
      "Step 1510, action: [0.4552426], terminated: False, reward: 78.09961999906491, Trade: 1435\n",
      "Step 1511, action: [0.5768657], terminated: False, reward: 78.08961999906491, Trade: 1436\n",
      "Step 1512, action: [0.54227704], terminated: False, reward: 78.0796199990649, Trade: 1437\n",
      "Step 1513, action: [-0.86866117], terminated: False, reward: 78.07234515957563, Trade: 1438\n",
      "Step 1514, action: [0.52442324], terminated: False, reward: 78.06234515957563, Trade: 1439\n",
      "Step 1515, action: [0.07715068], terminated: False, reward: 77.95234515957563, Trade: 1439\n",
      "Step 1516, action: [-0.5121798], terminated: False, reward: 77.97785203860343, Trade: 1440\n",
      "Step 1517, action: [-0.7766196], terminated: False, reward: 77.9604844041403, Trade: 1441\n",
      "Step 1518, action: [0.9272925], terminated: False, reward: 77.9504844041403, Trade: 1442\n",
      "Step 1519, action: [-0.5843826], terminated: False, reward: 80.5586195639307, Trade: 1443\n",
      "Step 1520, action: [0.36441606], terminated: False, reward: 80.5486195639307, Trade: 1444\n",
      "Step 1521, action: [-0.34405744], terminated: False, reward: 80.54262835748126, Trade: 1445\n",
      "Step 1522, action: [0.96731627], terminated: False, reward: 80.53262835748126, Trade: 1446\n",
      "Step 1523, action: [-0.6869287], terminated: False, reward: 80.58331925224248, Trade: 1447\n",
      "Step 1524, action: [0.6403544], terminated: False, reward: 80.57331925224247, Trade: 1448\n",
      "Step 1525, action: [0.68096495], terminated: False, reward: 80.56331925224247, Trade: 1449\n",
      "Step 1526, action: [0.6706842], terminated: False, reward: 80.55331925224246, Trade: 1450\n",
      "Step 1527, action: [-0.15480419], terminated: False, reward: 80.56339203207285, Trade: 1451\n",
      "Step 1528, action: [-0.5268523], terminated: False, reward: 80.5662583837832, Trade: 1452\n",
      "Step 1529, action: [0.03440533], terminated: False, reward: 80.55625838378319, Trade: 1453\n",
      "Step 1530, action: [-0.96561855], terminated: False, reward: 81.2767944973677, Trade: 1454\n",
      "Step 1531, action: [-0.63388515], terminated: False, reward: 81.29443743379072, Trade: 1455\n",
      "Step 1532, action: [-0.6853392], terminated: False, reward: 81.56164905973503, Trade: 1456\n",
      "Step 1533, action: [0.13187672], terminated: False, reward: 81.55164905973503, Trade: 1457\n",
      "Step 1534, action: [-0.54048145], terminated: False, reward: 81.47585831641982, Trade: 1458\n",
      "Step 1535, action: [0.16065337], terminated: False, reward: 81.46585831641981, Trade: 1459\n",
      "Step 1536, action: [0.03944017], terminated: False, reward: 81.4558583164198, Trade: 1460\n",
      "Step 1537, action: [0.24047212], terminated: False, reward: 81.4458583164198, Trade: 1461\n",
      "Step 1538, action: [-0.3115149], terminated: False, reward: 81.5008771857096, Trade: 1462\n",
      "Step 1539, action: [0.3436551], terminated: False, reward: 81.49087718570959, Trade: 1463\n",
      "Step 1540, action: [0.0448574], terminated: False, reward: 81.48087718570959, Trade: 1464\n",
      "Step 1541, action: [-0.15044478], terminated: False, reward: 81.42505479070913, Trade: 1465\n",
      "Step 1542, action: [-0.5064097], terminated: False, reward: 81.70051978126048, Trade: 1466\n",
      "Step 1543, action: [-0.60251564], terminated: False, reward: 81.67009276240127, Trade: 1467\n",
      "Step 1544, action: [-0.49999848], terminated: False, reward: 81.65935519036445, Trade: 1468\n",
      "Step 1545, action: [0.18996905], terminated: False, reward: 81.64935519036445, Trade: 1469\n",
      "Step 1546, action: [0.17883405], terminated: False, reward: 81.63935519036444, Trade: 1470\n",
      "Step 1547, action: [-0.50891304], terminated: False, reward: 82.0171613377646, Trade: 1471\n",
      "Step 1548, action: [0.34985605], terminated: False, reward: 82.0071613377646, Trade: 1472\n",
      "Step 1549, action: [0.42348903], terminated: False, reward: 81.9971613377646, Trade: 1473\n",
      "Step 1550, action: [-0.2657768], terminated: False, reward: 81.99639381261791, Trade: 1474\n",
      "Step 1551, action: [-0.28420967], terminated: False, reward: 82.11630554318452, Trade: 1475\n",
      "Step 1552, action: [-0.62339914], terminated: False, reward: 82.20987386384056, Trade: 1476\n",
      "Step 1553, action: [0.19279273], terminated: False, reward: 82.19987386384055, Trade: 1477\n",
      "Step 1554, action: [-0.7278493], terminated: False, reward: 83.16108302322317, Trade: 1478\n",
      "Step 1555, action: [0.774415], terminated: False, reward: 83.15108302322317, Trade: 1479\n",
      "Step 1556, action: [0.68266034], terminated: False, reward: 83.14108302322316, Trade: 1480\n",
      "Step 1557, action: [-0.5803692], terminated: False, reward: 83.15054971773453, Trade: 1481\n",
      "Step 1558, action: [-0.6834105], terminated: False, reward: 83.18284245413003, Trade: 1482\n",
      "Step 1559, action: [-0.9020172], terminated: False, reward: 83.38006601075716, Trade: 1483\n",
      "Step 1560, action: [-0.6521258], terminated: False, reward: 83.71261349697411, Trade: 1484\n",
      "Step 1561, action: [-0.12565315], terminated: False, reward: 83.74286454859185, Trade: 1485\n",
      "Step 1562, action: [0.27961186], terminated: False, reward: 83.73286454859185, Trade: 1486\n",
      "Step 1563, action: [0.6197592], terminated: False, reward: 83.72286454859184, Trade: 1487\n",
      "Step 1564, action: [0.25744277], terminated: False, reward: 83.71286454859184, Trade: 1488\n",
      "Step 1565, action: [-0.09574723], terminated: False, reward: 83.71770373398668, Trade: 1489\n",
      "Step 1566, action: [0.2685746], terminated: False, reward: 83.70770373398668, Trade: 1490\n",
      "Step 1567, action: [0.4683483], terminated: False, reward: 83.69770373398667, Trade: 1491\n",
      "Step 1568, action: [0.73200876], terminated: False, reward: 83.68770373398667, Trade: 1492\n",
      "Step 1569, action: [-0.5538112], terminated: False, reward: 83.70751342636876, Trade: 1493\n",
      "Step 1570, action: [0.9555389], terminated: False, reward: 83.69751342636876, Trade: 1494\n",
      "Step 1571, action: [-0.65002614], terminated: False, reward: 83.68363081747108, Trade: 1495\n",
      "Step 1572, action: [0.6839446], terminated: False, reward: 83.67363081747108, Trade: 1496\n",
      "Step 1573, action: [-0.90401536], terminated: False, reward: 86.51175603521934, Trade: 1497\n",
      "Step 1574, action: [-0.12311608], terminated: False, reward: 86.5912308601213, Trade: 1498\n",
      "Step 1575, action: [-0.85832405], terminated: False, reward: 86.51271362413362, Trade: 1499\n",
      "Step 1576, action: [-0.09204065], terminated: False, reward: 86.95330809561516, Trade: 1500\n",
      "Step 1577, action: [-0.4077914], terminated: False, reward: 86.95659270427063, Trade: 1501\n",
      "Step 1578, action: [-0.27464423], terminated: False, reward: 87.02928119727936, Trade: 1502\n",
      "Step 1579, action: [0.4676281], terminated: False, reward: 87.01928119727935, Trade: 1503\n",
      "Step 1580, action: [-0.25920844], terminated: False, reward: 86.88113067585033, Trade: 1504\n",
      "Step 1581, action: [0.23184398], terminated: False, reward: 86.87113067585032, Trade: 1505\n",
      "Step 1582, action: [0.3745955], terminated: False, reward: 86.86113067585032, Trade: 1506\n",
      "Step 1583, action: [-0.28287634], terminated: False, reward: 86.89537087116274, Trade: 1507\n",
      "Step 1584, action: [-0.28495803], terminated: False, reward: 86.89039772537835, Trade: 1508\n",
      "Step 1585, action: [0.6810548], terminated: False, reward: 86.88039772537834, Trade: 1509\n",
      "Step 1586, action: [-0.47502348], terminated: False, reward: 86.8842053266275, Trade: 1510\n",
      "Step 1587, action: [-0.6901385], terminated: False, reward: 87.04824953899464, Trade: 1511\n",
      "Step 1588, action: [0.51223207], terminated: False, reward: 87.03824953899463, Trade: 1512\n",
      "Step 1589, action: [0.8300248], terminated: False, reward: 87.02824953899463, Trade: 1513\n",
      "Step 1590, action: [-0.66097087], terminated: False, reward: 87.39602045899994, Trade: 1514\n",
      "Step 1591, action: [-0.3277659], terminated: False, reward: 88.26289634224847, Trade: 1515\n",
      "Step 1592, action: [0.91641825], terminated: False, reward: 88.25289634224846, Trade: 1516\n",
      "Step 1593, action: [0.4693198], terminated: False, reward: 88.24289634224846, Trade: 1517\n",
      "Step 1594, action: [0.83582115], terminated: False, reward: 88.23289634224845, Trade: 1518\n",
      "Step 1595, action: [0.2573303], terminated: False, reward: 88.22289634224845, Trade: 1519\n",
      "Step 1596, action: [-0.31601158], terminated: False, reward: 88.21619479151879, Trade: 1520\n",
      "Step 1597, action: [0.38529533], terminated: False, reward: 88.20619479151878, Trade: 1521\n",
      "Step 1598, action: [0.0761935], terminated: False, reward: 88.19619479151878, Trade: 1522\n",
      "Step 1599, action: [0.5455172], terminated: False, reward: 88.18619479151877, Trade: 1523\n",
      "Step 1600, action: [-0.8937328], terminated: False, reward: 88.54041716762931, Trade: 1524\n",
      "Step 1601, action: [-0.0070495], terminated: False, reward: 88.53482445111133, Trade: 1525\n",
      "Step 1602, action: [0.7103808], terminated: False, reward: 88.52482445111133, Trade: 1526\n",
      "Step 1603, action: [0.7737194], terminated: False, reward: 88.51482445111132, Trade: 1527\n",
      "Step 1604, action: [0.33463475], terminated: False, reward: 88.50482445111132, Trade: 1528\n",
      "Step 1605, action: [-0.37437513], terminated: False, reward: 88.6294605699033, Trade: 1529\n",
      "Step 1606, action: [0.3091733], terminated: False, reward: 88.6194605699033, Trade: 1530\n",
      "Step 1607, action: [-0.15909706], terminated: False, reward: 88.40496378819161, Trade: 1531\n",
      "Step 1608, action: [-0.53661704], terminated: False, reward: 88.83811183031857, Trade: 1532\n",
      "Step 1609, action: [0.78377867], terminated: False, reward: 88.82811183031856, Trade: 1533\n",
      "Step 1610, action: [0.14147106], terminated: False, reward: 88.81811183031856, Trade: 1534\n",
      "Step 1611, action: [0.9518391], terminated: False, reward: 88.80811183031855, Trade: 1535\n",
      "Step 1612, action: [0.42130774], terminated: False, reward: 88.79811183031855, Trade: 1536\n",
      "Step 1613, action: [0.7090526], terminated: False, reward: 88.78811183031854, Trade: 1537\n",
      "Step 1614, action: [0.8053994], terminated: False, reward: 88.77811183031854, Trade: 1538\n",
      "Step 1615, action: [-0.18086682], terminated: False, reward: 88.87235010051818, Trade: 1539\n",
      "Step 1616, action: [0.47750124], terminated: False, reward: 88.86235010051817, Trade: 1540\n",
      "Step 1617, action: [-0.93275654], terminated: False, reward: 89.014185319331, Trade: 1541\n",
      "Step 1618, action: [0.9355261], terminated: False, reward: 89.004185319331, Trade: 1542\n",
      "Step 1619, action: [0.4919319], terminated: False, reward: 88.994185319331, Trade: 1543\n",
      "Step 1620, action: [-0.71882826], terminated: False, reward: 87.93806391285, Trade: 1544\n",
      "Step 1621, action: [-0.58430195], terminated: False, reward: 88.00886831199534, Trade: 1545\n",
      "Step 1622, action: [-0.73690623], terminated: False, reward: 87.13601310615694, Trade: 1546\n",
      "Step 1623, action: [0.11678214], terminated: False, reward: 87.12601310615693, Trade: 1547\n",
      "Step 1624, action: [-0.00031365], terminated: False, reward: 87.11601310615693, Trade: 1548\n",
      "Step 1625, action: [-0.13387792], terminated: False, reward: 87.10601310615692, Trade: 1549\n",
      "Step 1626, action: [-0.3266884], terminated: False, reward: 86.96206888607637, Trade: 1550\n",
      "Step 1627, action: [-0.6529431], terminated: False, reward: 86.97956586448929, Trade: 1551\n",
      "Step 1628, action: [0.14376053], terminated: False, reward: 86.96956586448928, Trade: 1552\n",
      "Step 1629, action: [-0.85045636], terminated: False, reward: 86.8573839651024, Trade: 1553\n",
      "Step 1630, action: [0.39114356], terminated: False, reward: 86.8473839651024, Trade: 1554\n",
      "Step 1631, action: [-0.4809076], terminated: False, reward: 86.83408811919254, Trade: 1555\n",
      "Step 1632, action: [-0.63167727], terminated: False, reward: 86.78532355489975, Trade: 1556\n",
      "Step 1633, action: [0.5323292], terminated: False, reward: 86.77532355489974, Trade: 1557\n",
      "Step 1634, action: [-0.26013422], terminated: False, reward: 86.40289593708061, Trade: 1558\n",
      "Step 1635, action: [0.05322509], terminated: False, reward: 86.39289593708061, Trade: 1559\n",
      "Step 1636, action: [-0.47240952], terminated: False, reward: 87.0073407841539, Trade: 1560\n",
      "Step 1637, action: [-0.70303255], terminated: False, reward: 86.73769310604064, Trade: 1561\n",
      "Step 1638, action: [-0.60188115], terminated: False, reward: 86.685853469568, Trade: 1562\n",
      "Step 1639, action: [0.7924967], terminated: False, reward: 86.675853469568, Trade: 1563\n",
      "Step 1640, action: [-0.1796184], terminated: False, reward: 86.66777529789508, Trade: 1564\n",
      "Step 1641, action: [-0.46956417], terminated: False, reward: 86.71825301853283, Trade: 1565\n",
      "Step 1642, action: [-0.30309305], terminated: False, reward: 86.80987041134786, Trade: 1566\n",
      "Step 1643, action: [0.6467761], terminated: False, reward: 86.79987041134785, Trade: 1567\n",
      "Step 1644, action: [-0.23282787], terminated: False, reward: 86.79235665470875, Trade: 1568\n",
      "Step 1645, action: [0.20385209], terminated: False, reward: 86.78235665470875, Trade: 1569\n",
      "Step 1646, action: [-0.45282006], terminated: False, reward: 86.80424319099141, Trade: 1570\n",
      "Step 1647, action: [-0.2305543], terminated: False, reward: 86.71374416897595, Trade: 1571\n",
      "Step 1648, action: [-0.75542414], terminated: False, reward: 86.76524405558521, Trade: 1572\n",
      "Step 1649, action: [0.03519747], terminated: False, reward: 86.75524405558521, Trade: 1573\n",
      "Step 1650, action: [0.44972318], terminated: False, reward: 86.7452440555852, Trade: 1574\n",
      "Step 1651, action: [0.91406393], terminated: False, reward: 86.7352440555852, Trade: 1575\n",
      "Step 1652, action: [-0.272002], terminated: False, reward: 86.72466389041381, Trade: 1576\n",
      "Step 1653, action: [-0.40163642], terminated: False, reward: 86.75911829803725, Trade: 1577\n",
      "Step 1654, action: [0.59712034], terminated: False, reward: 86.74911829803725, Trade: 1578\n",
      "Step 1655, action: [-0.1487668], terminated: False, reward: 86.908775982477, Trade: 1579\n",
      "Step 1656, action: [-0.7572472], terminated: False, reward: 86.9003081825649, Trade: 1580\n",
      "Step 1657, action: [-0.23212652], terminated: False, reward: 87.08141599927758, Trade: 1581\n",
      "Step 1658, action: [-0.3323381], terminated: False, reward: 87.07199489408553, Trade: 1582\n",
      "Step 1659, action: [-0.9050093], terminated: False, reward: 87.12612603351006, Trade: 1583\n",
      "Step 1660, action: [0.21296343], terminated: False, reward: 87.11612603351006, Trade: 1584\n",
      "Step 1661, action: [0.80258036], terminated: False, reward: 87.10612603351005, Trade: 1585\n",
      "Step 1662, action: [0.77542233], terminated: False, reward: 87.09612603351005, Trade: 1586\n",
      "Step 1663, action: [-0.07625233], terminated: False, reward: 87.1000850154684, Trade: 1587\n",
      "Step 1664, action: [0.19088298], terminated: False, reward: 87.09008501546839, Trade: 1588\n",
      "Step 1665, action: [0.46191964], terminated: False, reward: 87.08008501546838, Trade: 1589\n",
      "Step 1666, action: [-0.12556231], terminated: False, reward: 87.03841902890217, Trade: 1590\n",
      "Step 1667, action: [0.38911465], terminated: False, reward: 87.02841902890216, Trade: 1591\n",
      "Step 1668, action: [-0.21728435], terminated: False, reward: 87.03777410813017, Trade: 1592\n",
      "Step 1669, action: [-0.37707183], terminated: False, reward: 87.19949322748495, Trade: 1593\n",
      "Step 1670, action: [0.19418746], terminated: False, reward: 87.18949322748495, Trade: 1594\n",
      "Step 1671, action: [0.7605847], terminated: False, reward: 87.17949322748494, Trade: 1595\n",
      "Step 1672, action: [-0.32007465], terminated: False, reward: 88.42823854122219, Trade: 1596\n",
      "Step 1673, action: [0.10718301], terminated: False, reward: 88.41823854122218, Trade: 1597\n",
      "Step 1674, action: [0.74294084], terminated: False, reward: 88.40823854122218, Trade: 1598\n",
      "Step 1675, action: [0.5487761], terminated: False, reward: 88.39823854122217, Trade: 1599\n",
      "Step 1676, action: [0.85153246], terminated: False, reward: 88.38823854122217, Trade: 1600\n",
      "Step 1677, action: [0.14835803], terminated: False, reward: 88.37823854122216, Trade: 1601\n",
      "Step 1678, action: [-0.94314694], terminated: False, reward: 88.25737272176221, Trade: 1602\n",
      "Step 1679, action: [0.91702914], terminated: False, reward: 88.2473727217622, Trade: 1603\n",
      "Step 1680, action: [-0.35135832], terminated: False, reward: 88.25223384800869, Trade: 1604\n",
      "Step 1681, action: [0.15996219], terminated: False, reward: 88.24223384800868, Trade: 1605\n",
      "Step 1682, action: [0.67674005], terminated: False, reward: 88.23223384800868, Trade: 1606\n",
      "Step 1683, action: [0.82980657], terminated: False, reward: 88.22223384800867, Trade: 1607\n",
      "Step 1684, action: [-0.75386024], terminated: False, reward: 87.3270803116758, Trade: 1608\n",
      "Step 1685, action: [0.11861368], terminated: False, reward: 87.3170803116758, Trade: 1609\n",
      "Step 1686, action: [0.75423753], terminated: False, reward: 87.30708031167579, Trade: 1610\n",
      "Step 1687, action: [0.03323171], terminated: False, reward: 87.29708031167578, Trade: 1611\n",
      "Step 1688, action: [0.2612959], terminated: False, reward: 87.28708031167578, Trade: 1612\n",
      "Step 1689, action: [0.09590423], terminated: False, reward: 87.27708031167577, Trade: 1613\n",
      "Step 1690, action: [-0.4511337], terminated: False, reward: 87.27038562309203, Trade: 1614\n",
      "Step 1691, action: [0.87846696], terminated: False, reward: 87.26038562309202, Trade: 1615\n",
      "Step 1692, action: [0.44498488], terminated: False, reward: 87.25038562309201, Trade: 1616\n",
      "Step 1693, action: [-0.5625006], terminated: False, reward: 86.51604276710674, Trade: 1617\n",
      "Step 1694, action: [-0.9359192], terminated: False, reward: 86.54077431922967, Trade: 1618\n",
      "Step 1695, action: [-0.16072482], terminated: False, reward: 86.54220735256925, Trade: 1619\n",
      "Step 1696, action: [0.19711263], terminated: False, reward: 86.53220735256924, Trade: 1620\n",
      "Step 1697, action: [-0.7336896], terminated: False, reward: 86.68865052902514, Trade: 1621\n",
      "Step 1698, action: [-0.20717946], terminated: False, reward: 86.67153779655779, Trade: 1622\n",
      "Step 1699, action: [0.86992043], terminated: False, reward: 86.66153779655778, Trade: 1623\n",
      "Step 1700, action: [0.6594188], terminated: False, reward: 86.65153779655778, Trade: 1624\n",
      "Step 1701, action: [-0.03128073], terminated: False, reward: 86.6255290719585, Trade: 1625\n",
      "Step 1702, action: [0.344083], terminated: False, reward: 86.61552907195849, Trade: 1626\n",
      "Step 1703, action: [-0.64682096], terminated: False, reward: 86.51317089102476, Trade: 1627\n",
      "Step 1704, action: [0.5426291], terminated: False, reward: 86.50317089102475, Trade: 1628\n",
      "Step 1705, action: [-0.6559176], terminated: False, reward: 86.5013235187169, Trade: 1629\n",
      "Step 1706, action: [0.68148994], terminated: False, reward: 86.4913235187169, Trade: 1630\n",
      "Step 1707, action: [0.24131425], terminated: False, reward: 86.48132351871689, Trade: 1631\n",
      "Step 1708, action: [0.94459474], terminated: False, reward: 86.47132351871689, Trade: 1632\n",
      "Step 1709, action: [-0.32492658], terminated: False, reward: 86.70993675510292, Trade: 1633\n",
      "Step 1710, action: [-0.86396027], terminated: False, reward: 86.72298412440392, Trade: 1634\n",
      "Step 1711, action: [0.7201391], terminated: False, reward: 86.71298412440392, Trade: 1635\n",
      "Step 1712, action: [0.45958], terminated: False, reward: 86.70298412440391, Trade: 1636\n",
      "Step 1713, action: [-0.97756773], terminated: False, reward: 87.40552853818507, Trade: 1637\n",
      "Step 1714, action: [-0.96193486], terminated: False, reward: 86.10158805780179, Trade: 1638\n",
      "Step 1715, action: [0.38547975], terminated: False, reward: 86.09158805780179, Trade: 1639\n",
      "Step 1716, action: [0.99928665], terminated: False, reward: 86.08158805780178, Trade: 1640\n",
      "Step 1717, action: [0.63089097], terminated: False, reward: 85.97158805780178, Trade: 1640\n",
      "Step 1718, action: [0.1701045], terminated: False, reward: 85.86158805780178, Trade: 1640\n",
      "Step 1719, action: [0.25789583], terminated: False, reward: 85.75158805780178, Trade: 1640\n",
      "Step 1720, action: [-0.09644913], terminated: False, reward: 85.66217322167861, Trade: 1641\n",
      "Step 1721, action: [-0.8891446], terminated: False, reward: 85.6468728966229, Trade: 1642\n",
      "Step 1722, action: [0.02796436], terminated: False, reward: 85.63687289662289, Trade: 1643\n",
      "Step 1723, action: [0.6819763], terminated: False, reward: 85.62687289662288, Trade: 1644\n",
      "Step 1724, action: [-0.44018596], terminated: False, reward: 85.72235493920611, Trade: 1645\n",
      "Step 1725, action: [-0.14939041], terminated: False, reward: 85.69191428950265, Trade: 1646\n",
      "Step 1726, action: [-0.31476784], terminated: False, reward: 87.04794067394413, Trade: 1647\n",
      "Step 1727, action: [0.08650036], terminated: False, reward: 87.03794067394412, Trade: 1648\n",
      "Step 1728, action: [-0.58222526], terminated: False, reward: 86.88269460088624, Trade: 1649\n",
      "Step 1729, action: [-0.5096573], terminated: False, reward: 86.84842209644087, Trade: 1650\n",
      "Step 1730, action: [0.9130241], terminated: False, reward: 86.83842209644087, Trade: 1651\n",
      "Step 1731, action: [0.41794977], terminated: False, reward: 86.82842209644086, Trade: 1652\n",
      "Step 1732, action: [0.18004945], terminated: False, reward: 86.81842209644086, Trade: 1653\n",
      "Step 1733, action: [-0.9467316], terminated: False, reward: 86.69160420271568, Trade: 1654\n",
      "Step 1734, action: [0.9117536], terminated: False, reward: 86.68160420271568, Trade: 1655\n",
      "Step 1735, action: [-0.94177395], terminated: False, reward: 86.67057658134526, Trade: 1656\n",
      "Step 1736, action: [0.69737786], terminated: False, reward: 86.66057658134525, Trade: 1657\n",
      "Step 1737, action: [-0.19215272], terminated: False, reward: 86.65123159662069, Trade: 1658\n",
      "Step 1738, action: [0.9852871], terminated: False, reward: 86.64123159662068, Trade: 1659\n",
      "Step 1739, action: [-0.91905767], terminated: False, reward: 86.64162290934117, Trade: 1660\n",
      "Step 1740, action: [0.76036924], terminated: False, reward: 86.63162290934116, Trade: 1661\n",
      "Step 1741, action: [-0.61094105], terminated: False, reward: 86.59546812150096, Trade: 1662\n",
      "Step 1742, action: [0.7975309], terminated: False, reward: 86.58546812150095, Trade: 1663\n",
      "Step 1743, action: [0.42965797], terminated: False, reward: 86.57546812150095, Trade: 1664\n",
      "Step 1744, action: [-0.43613335], terminated: False, reward: 86.79161265102499, Trade: 1665\n",
      "Step 1745, action: [-0.7286286], terminated: False, reward: 87.85345403577558, Trade: 1666\n",
      "Step 1746, action: [-0.38747132], terminated: False, reward: 87.88060222712959, Trade: 1667\n",
      "Step 1747, action: [-0.65123683], terminated: False, reward: 87.28774722272206, Trade: 1668\n",
      "Step 1748, action: [-0.02496093], terminated: False, reward: 87.27774722272206, Trade: 1669\n",
      "Step 1749, action: [0.49197632], terminated: False, reward: 87.26774722272205, Trade: 1670\n",
      "Step 1750, action: [0.61560667], terminated: False, reward: 87.25774722272205, Trade: 1671\n",
      "Step 1751, action: [0.5878509], terminated: False, reward: 87.24774722272204, Trade: 1672\n",
      "Step 1752, action: [0.78120303], terminated: False, reward: 87.23774722272204, Trade: 1673\n",
      "Step 1753, action: [0.8363219], terminated: False, reward: 87.22774722272203, Trade: 1674\n",
      "Step 1754, action: [-0.5122271], terminated: False, reward: 87.1215681182707, Trade: 1675\n",
      "Step 1755, action: [-0.21600014], terminated: False, reward: 87.072243164881, Trade: 1676\n",
      "Step 1756, action: [-0.76141316], terminated: False, reward: 87.03743589571327, Trade: 1677\n",
      "Step 1757, action: [-0.9038936], terminated: False, reward: 86.8608041737097, Trade: 1678\n",
      "Step 1758, action: [-0.4725216], terminated: False, reward: 87.11796365010717, Trade: 1679\n",
      "Step 1759, action: [0.31292802], terminated: False, reward: 87.10796365010717, Trade: 1680\n",
      "Step 1760, action: [0.43331233], terminated: False, reward: 87.09796365010716, Trade: 1681\n",
      "Step 1761, action: [0.07651734], terminated: False, reward: 87.08796365010716, Trade: 1682\n",
      "Step 1762, action: [-0.7209667], terminated: False, reward: 87.07811419514186, Trade: 1683\n",
      "Step 1763, action: [-0.7114346], terminated: False, reward: 87.48753541681285, Trade: 1684\n",
      "Step 1764, action: [0.61779904], terminated: False, reward: 87.47753541681284, Trade: 1685\n",
      "Step 1765, action: [0.2463243], terminated: False, reward: 87.46753541681284, Trade: 1686\n",
      "Step 1766, action: [0.6771535], terminated: False, reward: 87.45753541681283, Trade: 1687\n",
      "Step 1767, action: [-0.74532175], terminated: False, reward: 87.52603913159832, Trade: 1688\n",
      "Step 1768, action: [0.4927945], terminated: False, reward: 87.51603913159832, Trade: 1689\n",
      "Step 1769, action: [0.8212521], terminated: False, reward: 87.50603913159831, Trade: 1690\n",
      "Step 1770, action: [-0.12320918], terminated: False, reward: 87.47056297560685, Trade: 1691\n",
      "Step 1771, action: [0.9324896], terminated: False, reward: 87.46056297560685, Trade: 1692\n",
      "Step 1772, action: [0.10684854], terminated: False, reward: 87.45056297560684, Trade: 1693\n",
      "Step 1773, action: [0.53167313], terminated: False, reward: 87.44056297560684, Trade: 1694\n",
      "Step 1774, action: [-0.17412403], terminated: False, reward: 87.37541913076622, Trade: 1695\n",
      "Step 1775, action: [-0.37802443], terminated: False, reward: 87.36541913076621, Trade: 1696\n",
      "Step 1776, action: [-0.7248639], terminated: False, reward: 87.55167841182056, Trade: 1697\n",
      "Step 1777, action: [-0.9772659], terminated: False, reward: 87.76636139888866, Trade: 1698\n",
      "Step 1778, action: [0.30483305], terminated: False, reward: 87.75636139888866, Trade: 1699\n",
      "Step 1779, action: [0.8343837], terminated: False, reward: 87.74636139888865, Trade: 1700\n",
      "Step 1780, action: [-0.27927855], terminated: False, reward: 88.07466744003455, Trade: 1701\n",
      "Step 1781, action: [0.9840041], terminated: False, reward: 88.06466744003454, Trade: 1702\n",
      "Step 1782, action: [-0.85969543], terminated: False, reward: 87.88120990028958, Trade: 1703\n",
      "Step 1783, action: [0.20993564], terminated: False, reward: 87.87120990028957, Trade: 1704\n",
      "Step 1784, action: [-0.8668778], terminated: False, reward: 87.75126656139787, Trade: 1705\n",
      "Step 1785, action: [0.97268474], terminated: False, reward: 87.74126656139786, Trade: 1706\n",
      "Step 1786, action: [-0.650438], terminated: False, reward: 87.95683260373903, Trade: 1707\n",
      "Step 1787, action: [0.7130261], terminated: False, reward: 87.94683260373903, Trade: 1708\n",
      "Step 1788, action: [-0.40481895], terminated: False, reward: 87.98763863887193, Trade: 1709\n",
      "Step 1789, action: [0.5224439], terminated: False, reward: 87.97763863887192, Trade: 1710\n",
      "Step 1790, action: [-0.43389857], terminated: False, reward: 88.0745222724341, Trade: 1711\n",
      "Step 1791, action: [-0.7681341], terminated: False, reward: 88.02663162306659, Trade: 1712\n",
      "Step 1792, action: [0.264127], terminated: False, reward: 88.01663162306659, Trade: 1713\n",
      "Step 1793, action: [0.07620174], terminated: False, reward: 88.00663162306658, Trade: 1714\n",
      "Step 1794, action: [0.45175007], terminated: False, reward: 87.99663162306658, Trade: 1715\n",
      "Step 1795, action: [-0.56364447], terminated: False, reward: 88.02345874479818, Trade: 1716\n",
      "Step 1796, action: [0.23528187], terminated: False, reward: 88.01345874479817, Trade: 1717\n",
      "Step 1797, action: [-0.9930935], terminated: False, reward: 87.33220474023396, Trade: 1718\n",
      "Step 1798, action: [-0.41883546], terminated: False, reward: 87.44495098184755, Trade: 1719\n",
      "Step 1799, action: [0.12954275], terminated: False, reward: 87.43495098184755, Trade: 1720\n",
      "Step 1800, action: [0.59425735], terminated: False, reward: 87.42495098184754, Trade: 1721\n",
      "Step 1801, action: [0.36528704], terminated: False, reward: 87.41495098184754, Trade: 1722\n",
      "Step 1802, action: [-0.1490088], terminated: False, reward: 87.40495098184753, Trade: 1723\n",
      "Step 1803, action: [-0.9670044], terminated: False, reward: 87.45340020484078, Trade: 1724\n",
      "Step 1804, action: [0.99085826], terminated: False, reward: 87.44340020484077, Trade: 1725\n",
      "Step 1805, action: [-0.0055646], terminated: False, reward: 87.43337082324477, Trade: 1726\n",
      "Step 1806, action: [0.1920577], terminated: False, reward: 87.42337082324477, Trade: 1727\n",
      "Step 1807, action: [0.5954997], terminated: False, reward: 87.41337082324476, Trade: 1728\n",
      "Step 1808, action: [-0.10203001], terminated: False, reward: 87.2666983195059, Trade: 1729\n",
      "Step 1809, action: [-0.00443891], terminated: False, reward: 87.2566983195059, Trade: 1730\n",
      "Step 1810, action: [-0.78079], terminated: False, reward: 87.19838065022493, Trade: 1731\n",
      "Step 1811, action: [0.10445373], terminated: False, reward: 87.18838065022493, Trade: 1732\n",
      "Step 1812, action: [-0.25053012], terminated: False, reward: 87.20398620044664, Trade: 1733\n",
      "Step 1813, action: [0.19110201], terminated: False, reward: 87.19398620044663, Trade: 1734\n",
      "Step 1814, action: [0.4676931], terminated: False, reward: 87.18398620044663, Trade: 1735\n",
      "Step 1815, action: [-0.81126726], terminated: False, reward: 86.8869665485508, Trade: 1736\n",
      "Step 1816, action: [-0.53657454], terminated: False, reward: 86.8689933374737, Trade: 1737\n",
      "Step 1817, action: [-0.8544214], terminated: False, reward: 86.91451784537226, Trade: 1738\n",
      "Step 1818, action: [0.57563204], terminated: False, reward: 86.90451784537225, Trade: 1739\n",
      "Step 1819, action: [-0.05269545], terminated: False, reward: 86.82467632096842, Trade: 1740\n",
      "Step 1820, action: [-0.17635116], terminated: False, reward: 86.79038794507099, Trade: 1741\n",
      "Step 1821, action: [0.0278984], terminated: False, reward: 86.78038794507098, Trade: 1742\n",
      "Step 1822, action: [0.8166859], terminated: False, reward: 86.77038794507098, Trade: 1743\n",
      "Step 1823, action: [0.54864645], terminated: False, reward: 86.76038794507097, Trade: 1744\n",
      "Step 1824, action: [-0.2011145], terminated: False, reward: 86.74768538551749, Trade: 1745\n",
      "Step 1825, action: [-0.7582542], terminated: False, reward: 86.5289106704127, Trade: 1746\n",
      "Step 1826, action: [-0.72334963], terminated: False, reward: 86.4649726872939, Trade: 1747\n",
      "Step 1827, action: [0.06899095], terminated: False, reward: 86.45497268729389, Trade: 1748\n",
      "Step 1828, action: [0.77501976], terminated: False, reward: 86.44497268729388, Trade: 1749\n",
      "Step 1829, action: [0.8290632], terminated: False, reward: 86.43497268729388, Trade: 1750\n",
      "Step 1830, action: [-0.7033881], terminated: False, reward: 86.42332501818584, Trade: 1751\n",
      "Step 1831, action: [0.87234944], terminated: False, reward: 86.41332501818583, Trade: 1752\n",
      "Step 1832, action: [0.48407888], terminated: False, reward: 86.40332501818583, Trade: 1753\n",
      "Step 1833, action: [-0.34672955], terminated: False, reward: 86.29332501818583, Trade: 1753\n",
      "Step 1834, action: [-0.9138568], terminated: False, reward: 84.86789587579261, Trade: 1754\n",
      "Step 1835, action: [0.37176988], terminated: False, reward: 84.85789587579261, Trade: 1755\n",
      "Step 1836, action: [-0.9265187], terminated: False, reward: 82.8111712689817, Trade: 1756\n",
      "Step 1837, action: [0.78411096], terminated: False, reward: 82.80117126898169, Trade: 1757\n",
      "Step 1838, action: [-0.7944765], terminated: False, reward: 82.78103387528989, Trade: 1758\n",
      "Step 1839, action: [-0.7062515], terminated: False, reward: 82.7152210063776, Trade: 1759\n",
      "Step 1840, action: [0.31262463], terminated: False, reward: 82.7052210063776, Trade: 1760\n",
      "Step 1841, action: [0.5350573], terminated: False, reward: 82.6952210063776, Trade: 1761\n",
      "Step 1842, action: [-0.06533783], terminated: False, reward: 82.56096508042066, Trade: 1762\n",
      "Step 1843, action: [-0.05866717], terminated: False, reward: 82.54392994042789, Trade: 1763\n",
      "Step 1844, action: [-0.69864905], terminated: False, reward: 82.52605990026048, Trade: 1764\n",
      "Step 1845, action: [-0.07905119], terminated: False, reward: 82.51605911807609, Trade: 1765\n",
      "Step 1846, action: [0.1624031], terminated: False, reward: 82.50605911807608, Trade: 1766\n",
      "Step 1847, action: [0.00183906], terminated: False, reward: 82.49605911807608, Trade: 1767\n",
      "Step 1848, action: [-0.21492535], terminated: False, reward: 82.45695264701283, Trade: 1768\n",
      "Step 1849, action: [-0.24669439], terminated: False, reward: 82.34153262263078, Trade: 1769\n",
      "Step 1850, action: [-0.27297592], terminated: False, reward: 82.366011510515, Trade: 1770\n",
      "Step 1851, action: [0.19000134], terminated: False, reward: 82.35601151051499, Trade: 1771\n",
      "Step 1852, action: [-0.10516333], terminated: False, reward: 82.34508327537706, Trade: 1772\n",
      "Step 1853, action: [-0.91409063], terminated: False, reward: 82.19624665460903, Trade: 1773\n",
      "Step 1854, action: [0.9219382], terminated: False, reward: 82.18624665460902, Trade: 1774\n",
      "Step 1855, action: [0.00054517], terminated: False, reward: 82.07624665460902, Trade: 1774\n",
      "Step 1856, action: [-0.67639846], terminated: False, reward: 81.63290701242727, Trade: 1775\n",
      "Step 1857, action: [0.97295636], terminated: False, reward: 81.62290701242726, Trade: 1776\n",
      "Step 1858, action: [-0.66125774], terminated: False, reward: 81.61270340679762, Trade: 1777\n",
      "Step 1859, action: [-0.21927038], terminated: False, reward: 81.44032722319356, Trade: 1778\n",
      "Step 1860, action: [0.2394293], terminated: False, reward: 81.43032722319356, Trade: 1779\n",
      "Step 1861, action: [0.43200874], terminated: False, reward: 81.42032722319355, Trade: 1780\n",
      "Step 1862, action: [0.69505495], terminated: False, reward: 81.41032722319355, Trade: 1781\n",
      "Step 1863, action: [-0.36287373], terminated: False, reward: 81.79305876062523, Trade: 1782\n",
      "Step 1864, action: [-0.2486565], terminated: False, reward: 81.76961894478761, Trade: 1783\n",
      "Step 1865, action: [-0.24517052], terminated: False, reward: 81.71958273752863, Trade: 1784\n",
      "Step 1866, action: [0.22452295], terminated: False, reward: 81.70958273752862, Trade: 1785\n",
      "Step 1867, action: [0.21772505], terminated: False, reward: 81.69958273752862, Trade: 1786\n",
      "Step 1868, action: [0.3405272], terminated: False, reward: 81.68958273752861, Trade: 1787\n",
      "Step 1869, action: [0.3051223], terminated: False, reward: 81.6795827375286, Trade: 1788\n",
      "Step 1870, action: [-0.636729], terminated: False, reward: 81.61583142516628, Trade: 1789\n",
      "Step 1871, action: [-0.9137643], terminated: False, reward: 81.54286111193534, Trade: 1790\n",
      "Step 1872, action: [-0.89976895], terminated: False, reward: 81.55514716979083, Trade: 1791\n",
      "Step 1873, action: [-0.32118815], terminated: False, reward: 81.55063088880105, Trade: 1792\n",
      "Step 1874, action: [-0.71895224], terminated: False, reward: 81.1228766481368, Trade: 1793\n",
      "Step 1875, action: [0.05356206], terminated: False, reward: 81.11287664813679, Trade: 1794\n",
      "Step 1876, action: [0.7826299], terminated: False, reward: 81.10287664813679, Trade: 1795\n",
      "Step 1877, action: [0.56239396], terminated: False, reward: 81.09287664813678, Trade: 1796\n",
      "Step 1878, action: [-0.87849075], terminated: False, reward: 81.34068540942033, Trade: 1797\n",
      "Step 1879, action: [0.05899991], terminated: False, reward: 81.33068540942033, Trade: 1798\n",
      "Step 1880, action: [-0.2971819], terminated: False, reward: 81.3213286508022, Trade: 1799\n",
      "Step 1881, action: [-0.09538647], terminated: False, reward: 81.31105540742348, Trade: 1800\n",
      "Step 1882, action: [-0.6373674], terminated: False, reward: 82.14943632266646, Trade: 1801\n",
      "Step 1883, action: [-0.17143977], terminated: False, reward: 82.64204155596406, Trade: 1802\n",
      "Step 1884, action: [-0.75254905], terminated: False, reward: 82.708510856782, Trade: 1803\n",
      "Step 1885, action: [-0.54089165], terminated: False, reward: 83.4804792278465, Trade: 1804\n",
      "Step 1886, action: [-0.05462471], terminated: False, reward: 83.4704792278465, Trade: 1805\n",
      "Step 1887, action: [-0.48818678], terminated: False, reward: 83.6077805218541, Trade: 1806\n",
      "Step 1888, action: [0.50602186], terminated: False, reward: 83.59778052185409, Trade: 1807\n",
      "Step 1889, action: [0.7975918], terminated: False, reward: 83.58778052185409, Trade: 1808\n",
      "Step 1890, action: [-0.53138703], terminated: False, reward: 83.38820675925282, Trade: 1809\n",
      "Step 1891, action: [0.9717333], terminated: False, reward: 83.37820675925282, Trade: 1810\n",
      "Step 1892, action: [0.5473303], terminated: False, reward: 83.36820675925281, Trade: 1811\n",
      "Step 1893, action: [0.49839178], terminated: False, reward: 83.35820675925281, Trade: 1812\n",
      "Step 1894, action: [0.43806818], terminated: False, reward: 83.24820675925281, Trade: 1812\n",
      "Step 1895, action: [-0.8248054], terminated: False, reward: 83.21946650374561, Trade: 1813\n",
      "Step 1896, action: [-0.77621174], terminated: False, reward: 84.14214823227614, Trade: 1814\n",
      "Step 1897, action: [-0.6544992], terminated: False, reward: 84.16045726754149, Trade: 1815\n",
      "Step 1898, action: [-0.5226078], terminated: False, reward: 84.17616321554843, Trade: 1816\n",
      "Step 1899, action: [0.2271888], terminated: False, reward: 84.16616321554842, Trade: 1817\n",
      "Step 1900, action: [-0.26654738], terminated: False, reward: 84.15758746298414, Trade: 1818\n",
      "Step 1901, action: [0.8051328], terminated: False, reward: 84.14758746298413, Trade: 1819\n",
      "Step 1902, action: [0.7540671], terminated: False, reward: 84.13758746298413, Trade: 1820\n",
      "Step 1903, action: [0.42175102], terminated: False, reward: 84.12758746298412, Trade: 1821\n",
      "Step 1904, action: [-0.02444235], terminated: False, reward: 84.12325334490824, Trade: 1822\n",
      "Step 1905, action: [-0.3700282], terminated: False, reward: 84.12988840558843, Trade: 1823\n",
      "Step 1906, action: [0.46148485], terminated: False, reward: 84.11988840558843, Trade: 1824\n",
      "Step 1907, action: [0.16542457], terminated: False, reward: 84.10988840558842, Trade: 1825\n",
      "Step 1908, action: [0.18110633], terminated: False, reward: 84.09988840558842, Trade: 1826\n",
      "Step 1909, action: [0.84409475], terminated: False, reward: 84.08988840558841, Trade: 1827\n",
      "Step 1910, action: [-0.03286207], terminated: False, reward: 84.09929980789917, Trade: 1828\n",
      "Step 1911, action: [0.80884546], terminated: False, reward: 84.08929980789917, Trade: 1829\n",
      "Step 1912, action: [-0.8575973], terminated: False, reward: 84.08097976953295, Trade: 1830\n",
      "Step 1913, action: [-0.55083597], terminated: False, reward: 84.48341863010442, Trade: 1831\n",
      "Step 1914, action: [0.64677984], terminated: False, reward: 84.47341863010442, Trade: 1832\n",
      "Step 1915, action: [0.6314314], terminated: False, reward: 84.46341863010441, Trade: 1833\n",
      "Step 1916, action: [0.0949193], terminated: False, reward: 84.45341863010441, Trade: 1834\n",
      "Step 1917, action: [-0.9857109], terminated: False, reward: 84.40820080883879, Trade: 1835\n",
      "Step 1918, action: [-0.7950836], terminated: False, reward: 84.28307630075642, Trade: 1836\n",
      "Step 1919, action: [-0.42686492], terminated: False, reward: 83.69999613288532, Trade: 1837\n",
      "Step 1920, action: [-0.23021238], terminated: False, reward: 83.68519990105693, Trade: 1838\n",
      "Step 1921, action: [-0.30917752], terminated: False, reward: 83.47393866337522, Trade: 1839\n",
      "Step 1922, action: [0.8095207], terminated: False, reward: 83.46393866337522, Trade: 1840\n",
      "Step 1923, action: [0.75223446], terminated: False, reward: 83.45393866337521, Trade: 1841\n",
      "Step 1924, action: [-0.68177897], terminated: False, reward: 83.60099364859374, Trade: 1842\n",
      "Step 1925, action: [-0.7005573], terminated: False, reward: 83.59611292982122, Trade: 1843\n",
      "Step 1926, action: [-0.45935693], terminated: False, reward: 83.58140994733907, Trade: 1844\n",
      "Step 1927, action: [0.6041155], terminated: False, reward: 83.57140994733906, Trade: 1845\n",
      "Step 1928, action: [-0.47549298], terminated: False, reward: 83.56274873116013, Trade: 1846\n",
      "Step 1929, action: [-0.36944777], terminated: False, reward: 83.53935167068258, Trade: 1847\n",
      "Step 1930, action: [0.25141993], terminated: False, reward: 83.52935167068257, Trade: 1848\n",
      "Step 1931, action: [-0.09942403], terminated: False, reward: 83.67904738500931, Trade: 1849\n",
      "Step 1932, action: [0.7114528], terminated: False, reward: 83.6690473850093, Trade: 1850\n",
      "Step 1933, action: [-0.99036336], terminated: False, reward: 83.65487997620963, Trade: 1851\n",
      "Step 1934, action: [-0.7667057], terminated: False, reward: 83.68702658914897, Trade: 1852\n",
      "Step 1935, action: [-0.865033], terminated: False, reward: 93.51419862819562, Trade: 1853\n",
      "Step 1936, action: [0.43915972], terminated: False, reward: 93.50419862819561, Trade: 1854\n",
      "Step 1937, action: [0.8301064], terminated: False, reward: 93.4941986281956, Trade: 1855\n",
      "Step 1938, action: [-0.40937564], terminated: False, reward: 93.74851613982366, Trade: 1856\n",
      "Step 1939, action: [-0.12654555], terminated: False, reward: 93.9443350804238, Trade: 1857\n",
      "Step 1940, action: [-0.835703], terminated: False, reward: 93.94291133695954, Trade: 1858\n",
      "Step 1941, action: [-0.32989472], terminated: False, reward: 94.0359039904525, Trade: 1859\n",
      "Step 1942, action: [-0.3963643], terminated: False, reward: 94.076043375993, Trade: 1860\n",
      "Step 1943, action: [0.8025278], terminated: False, reward: 94.06604337599299, Trade: 1861\n",
      "Step 1944, action: [-0.09113007], terminated: False, reward: 94.04075249873284, Trade: 1862\n",
      "Step 1945, action: [-0.77921563], terminated: False, reward: 94.032114533511, Trade: 1863\n",
      "Step 1946, action: [-0.1644687], terminated: False, reward: 94.01874886766504, Trade: 1864\n",
      "Step 1947, action: [-0.85896933], terminated: False, reward: 92.76547676796345, Trade: 1865\n",
      "Step 1948, action: [0.64123905], terminated: False, reward: 92.75547676796344, Trade: 1866\n",
      "Step 1949, action: [0.52741], terminated: False, reward: 92.74547676796344, Trade: 1867\n",
      "Step 1950, action: [0.19633731], terminated: False, reward: 92.73547676796343, Trade: 1868\n",
      "Step 1951, action: [0.39758864], terminated: False, reward: 92.72547676796343, Trade: 1869\n",
      "Step 1952, action: [0.13778393], terminated: False, reward: 92.71547676796342, Trade: 1870\n",
      "Step 1953, action: [0.2737681], terminated: False, reward: 92.70547676796342, Trade: 1871\n",
      "Step 1954, action: [-0.22368446], terminated: False, reward: 92.68395074537459, Trade: 1872\n",
      "Step 1955, action: [0.25985324], terminated: False, reward: 92.67395074537458, Trade: 1873\n",
      "Step 1956, action: [0.37983492], terminated: False, reward: 92.66395074537458, Trade: 1874\n",
      "Step 1957, action: [-0.08572842], terminated: False, reward: 92.6499460839874, Trade: 1875\n",
      "Step 1958, action: [0.8423629], terminated: False, reward: 92.6399460839874, Trade: 1876\n",
      "Step 1959, action: [-0.23622808], terminated: False, reward: 92.6057218843659, Trade: 1877\n",
      "Step 1960, action: [-0.93761325], terminated: False, reward: 93.33997775562726, Trade: 1878\n",
      "Step 1961, action: [-0.8712177], terminated: False, reward: 93.32702417438838, Trade: 1879\n",
      "Step 1962, action: [-0.9254695], terminated: False, reward: 93.32846566271589, Trade: 1880\n",
      "Step 1963, action: [-0.35384646], terminated: False, reward: 93.99492951745489, Trade: 1881\n",
      "Step 1964, action: [-0.32644153], terminated: False, reward: 93.99312131972802, Trade: 1882\n",
      "Step 1965, action: [0.09371144], terminated: False, reward: 93.98312131972801, Trade: 1883\n",
      "Step 1966, action: [-0.2789144], terminated: False, reward: 94.07607369948482, Trade: 1884\n",
      "Step 1967, action: [-0.9078234], terminated: False, reward: 95.24712322957332, Trade: 1885\n",
      "Step 1968, action: [-0.87494344], terminated: False, reward: 95.23956408902747, Trade: 1886\n",
      "Step 1969, action: [0.17977633], terminated: False, reward: 95.22956408902746, Trade: 1887\n",
      "Step 1970, action: [-0.79131955], terminated: False, reward: 95.25147400515326, Trade: 1888\n",
      "Step 1971, action: [-0.6697389], terminated: False, reward: 94.95710921282831, Trade: 1889\n",
      "Step 1972, action: [0.20986937], terminated: False, reward: 94.94710921282831, Trade: 1890\n",
      "Step 1973, action: [-0.4149434], terminated: False, reward: 94.93643330604039, Trade: 1891\n",
      "Step 1974, action: [0.72589314], terminated: False, reward: 94.92643330604038, Trade: 1892\n",
      "Step 1975, action: [0.8872819], terminated: False, reward: 94.91643330604037, Trade: 1893\n",
      "Step 1976, action: [-0.9933873], terminated: False, reward: 94.35347678309984, Trade: 1894\n",
      "Step 1977, action: [0.03744728], terminated: False, reward: 94.34347678309983, Trade: 1895\n",
      "Step 1978, action: [0.8350205], terminated: False, reward: 94.33347678309983, Trade: 1896\n",
      "Step 1979, action: [-0.12846483], terminated: False, reward: 94.33048781782117, Trade: 1897\n",
      "Step 1980, action: [0.5154756], terminated: False, reward: 94.32048781782116, Trade: 1898\n",
      "Step 1981, action: [0.75836945], terminated: False, reward: 94.31048781782115, Trade: 1899\n",
      "Step 1982, action: [-0.3663775], terminated: False, reward: 94.2781822349494, Trade: 1900\n",
      "Step 1983, action: [0.50278497], terminated: False, reward: 94.26818223494939, Trade: 1901\n",
      "Step 1984, action: [0.01191624], terminated: False, reward: 94.1581822349494, Trade: 1901\n",
      "Step 1985, action: [0.02127876], terminated: False, reward: 94.0481822349494, Trade: 1901\n",
      "Step 1986, action: [0.7279391], terminated: False, reward: 94.03818223494939, Trade: 1902\n",
      "Step 1987, action: [-0.73335034], terminated: False, reward: 93.67475204065332, Trade: 1903\n",
      "Step 1988, action: [-0.94679856], terminated: False, reward: 93.72940879202694, Trade: 1904\n",
      "Step 1989, action: [-0.3943347], terminated: False, reward: 93.71940879202694, Trade: 1905\n",
      "Step 1990, action: [0.9377123], terminated: False, reward: 93.70940879202693, Trade: 1906\n",
      "Step 1991, action: [-0.13904594], terminated: False, reward: 93.83571763538419, Trade: 1907\n",
      "Step 1992, action: [-0.9955591], terminated: False, reward: 94.63293001986573, Trade: 1908\n",
      "Step 1993, action: [-0.79608685], terminated: False, reward: 93.49371630148464, Trade: 1909\n",
      "Step 1994, action: [0.06609932], terminated: False, reward: 93.48371630148463, Trade: 1910\n",
      "Step 1995, action: [-0.36053136], terminated: False, reward: 93.51329794472204, Trade: 1911\n",
      "Step 1996, action: [-0.6431548], terminated: False, reward: 93.50329794472204, Trade: 1912\n",
      "Step 1997, action: [0.94149923], terminated: False, reward: 93.49329794472203, Trade: 1913\n",
      "Step 1998, action: [0.57030845], terminated: False, reward: 93.48329794472203, Trade: 1914\n",
      "Step 1999, action: [0.73367465], terminated: False, reward: 93.47329794472202, Trade: 1915\n",
      "Step 2000, action: [0.64775693], terminated: False, reward: 93.46329794472202, Trade: 1916\n",
      "Step 2001, action: [-0.9064382], terminated: False, reward: 93.45182482770532, Trade: 1917\n",
      "Step 2002, action: [0.86790174], terminated: False, reward: 93.44182482770532, Trade: 1918\n",
      "Step 2003, action: [0.2785222], terminated: False, reward: 93.43182482770531, Trade: 1919\n",
      "Step 2004, action: [0.05605878], terminated: False, reward: 93.32182482770531, Trade: 1919\n",
      "Step 2005, action: [-0.02253852], terminated: False, reward: 93.29237466820639, Trade: 1920\n",
      "Step 2006, action: [-0.98617965], terminated: False, reward: 91.37945714890974, Trade: 1921\n",
      "Step 2007, action: [-0.7971133], terminated: False, reward: 91.79924583573512, Trade: 1922\n",
      "Step 2008, action: [-0.41779786], terminated: False, reward: 91.84239513568075, Trade: 1923\n",
      "Step 2009, action: [-0.43763438], terminated: False, reward: 91.89668085198112, Trade: 1924\n",
      "Step 2010, action: [-0.12826931], terminated: False, reward: 91.89194363554813, Trade: 1925\n",
      "Step 2011, action: [0.47084445], terminated: False, reward: 91.88194363554813, Trade: 1926\n",
      "Step 2012, action: [-0.94480765], terminated: False, reward: 91.89052845570396, Trade: 1927\n",
      "Step 2013, action: [0.98120475], terminated: False, reward: 91.88052845570395, Trade: 1928\n",
      "Step 2014, action: [-0.15352066], terminated: False, reward: 91.96378018642592, Trade: 1929\n",
      "Step 2015, action: [-0.82911426], terminated: False, reward: 92.05960736967506, Trade: 1930\n",
      "Step 2016, action: [-0.45488697], terminated: False, reward: 92.05234151706497, Trade: 1931\n",
      "Step 2017, action: [-0.50024784], terminated: False, reward: 92.04234151706497, Trade: 1932\n",
      "Step 2018, action: [0.9212315], terminated: False, reward: 92.03234151706496, Trade: 1933\n",
      "Step 2019, action: [-0.69857526], terminated: False, reward: 92.84070764937611, Trade: 1934\n",
      "Step 2020, action: [-0.04973491], terminated: False, reward: 92.83070764937611, Trade: 1935\n",
      "Step 2021, action: [0.8646713], terminated: False, reward: 92.8207076493761, Trade: 1936\n",
      "Step 2022, action: [0.56697905], terminated: False, reward: 92.8107076493761, Trade: 1937\n",
      "Step 2023, action: [-0.710229], terminated: False, reward: 92.85135951801627, Trade: 1938\n",
      "Step 2024, action: [-0.9708163], terminated: False, reward: 92.84135951801626, Trade: 1939\n",
      "Step 2025, action: [0.09375561], terminated: False, reward: 92.83135951801626, Trade: 1940\n",
      "Step 2026, action: [-0.547338], terminated: False, reward: 92.91123320651808, Trade: 1941\n",
      "Step 2027, action: [0.2870302], terminated: False, reward: 92.90123320651807, Trade: 1942\n",
      "Step 2028, action: [-0.5642769], terminated: False, reward: 95.66873770447661, Trade: 1943\n",
      "Step 2029, action: [-0.7261064], terminated: False, reward: 95.65873770447661, Trade: 1944\n",
      "Step 2030, action: [0.81761056], terminated: False, reward: 95.6487377044766, Trade: 1945\n",
      "Step 2031, action: [-0.4567993], terminated: False, reward: 95.39642244512682, Trade: 1946\n",
      "Step 2032, action: [0.5537756], terminated: False, reward: 95.38642244512681, Trade: 1947\n",
      "Step 2033, action: [-0.7078845], terminated: False, reward: 95.21594970210856, Trade: 1948\n",
      "Step 2034, action: [-0.6879955], terminated: False, reward: 95.20322413430814, Trade: 1949\n",
      "Step 2035, action: [0.08463429], terminated: False, reward: 95.19322413430814, Trade: 1950\n",
      "Step 2036, action: [-0.48272273], terminated: False, reward: 95.23316741462183, Trade: 1951\n",
      "Step 2037, action: [0.9838001], terminated: False, reward: 95.22316741462183, Trade: 1952\n",
      "Step 2038, action: [0.9110453], terminated: False, reward: 95.21316741462182, Trade: 1953\n",
      "Step 2039, action: [0.6677339], terminated: False, reward: 95.10316741462182, Trade: 1953\n",
      "Step 2040, action: [-0.32104406], terminated: False, reward: 95.09316741462182, Trade: 1954\n",
      "Step 2041, action: [0.6918989], terminated: False, reward: 95.08316741462181, Trade: 1955\n",
      "Step 2042, action: [-0.69951135], terminated: False, reward: 95.27733199657267, Trade: 1956\n",
      "Step 2043, action: [0.74036753], terminated: False, reward: 95.26733199657266, Trade: 1957\n",
      "Step 2044, action: [-0.99918735], terminated: False, reward: 95.26131543663226, Trade: 1958\n",
      "Step 2045, action: [0.17068686], terminated: False, reward: 95.25131543663225, Trade: 1959\n",
      "Step 2046, action: [-0.9349303], terminated: False, reward: 95.48029920219402, Trade: 1960\n",
      "Step 2047, action: [-0.31671792], terminated: False, reward: 95.5834760934684, Trade: 1961\n",
      "Step 2048, action: [0.39164674], terminated: False, reward: 95.5734760934684, Trade: 1962\n",
      "Step 2049, action: [-0.9304784], terminated: False, reward: 95.96296342452204, Trade: 1963\n",
      "Step 2050, action: [-0.01943188], terminated: False, reward: 95.95421739274633, Trade: 1964\n",
      "Step 2051, action: [-0.27950695], terminated: False, reward: 95.94703686171144, Trade: 1965\n",
      "Step 2052, action: [-0.21941243], terminated: False, reward: 95.93703686171143, Trade: 1966\n",
      "Step 2053, action: [-0.03386308], terminated: False, reward: 95.97558818859352, Trade: 1967\n",
      "Step 2054, action: [0.5208631], terminated: False, reward: 95.96558818859351, Trade: 1968\n",
      "Step 2055, action: [0.20343547], terminated: False, reward: 95.95558818859351, Trade: 1969\n",
      "Step 2056, action: [0.11444481], terminated: False, reward: 95.9455881885935, Trade: 1970\n",
      "Step 2057, action: [0.8780881], terminated: False, reward: 95.9355881885935, Trade: 1971\n",
      "Step 2058, action: [-0.5162256], terminated: False, reward: 95.88687044895178, Trade: 1972\n",
      "Step 2059, action: [-0.8568395], terminated: False, reward: 95.9646237336402, Trade: 1973\n",
      "Step 2060, action: [-0.4372525], terminated: False, reward: 95.96272828177152, Trade: 1974\n",
      "Step 2061, action: [0.8948088], terminated: False, reward: 95.95272828177151, Trade: 1975\n",
      "Step 2062, action: [0.64147633], terminated: False, reward: 95.94272828177151, Trade: 1976\n",
      "Step 2063, action: [-0.15372404], terminated: False, reward: 95.93425567351906, Trade: 1977\n",
      "Step 2064, action: [0.38672385], terminated: False, reward: 95.92425567351906, Trade: 1978\n",
      "Step 2065, action: [-0.63041216], terminated: False, reward: 96.34657114936859, Trade: 1979\n",
      "Step 2066, action: [0.0775972], terminated: False, reward: 96.33657114936858, Trade: 1980\n",
      "Step 2067, action: [-0.9927781], terminated: False, reward: 95.66580570551913, Trade: 1981\n",
      "Step 2068, action: [-0.78580827], terminated: False, reward: 95.65652835934917, Trade: 1982\n",
      "Step 2069, action: [0.17272827], terminated: False, reward: 95.64652835934916, Trade: 1983\n",
      "Step 2070, action: [0.8108191], terminated: False, reward: 95.63652835934916, Trade: 1984\n",
      "Step 2071, action: [0.02908216], terminated: False, reward: 95.62652835934915, Trade: 1985\n",
      "Step 2072, action: [0.4666692], terminated: False, reward: 95.61652835934915, Trade: 1986\n",
      "Step 2073, action: [-0.53317094], terminated: False, reward: 95.60967090283974, Trade: 1987\n",
      "Step 2074, action: [0.76667196], terminated: False, reward: 95.59967090283973, Trade: 1988\n",
      "Step 2075, action: [-0.46035478], terminated: False, reward: 95.68718313235418, Trade: 1989\n",
      "Step 2076, action: [0.4317633], terminated: False, reward: 95.67718313235417, Trade: 1990\n",
      "Step 2077, action: [0.19960897], terminated: False, reward: 95.66718313235417, Trade: 1991\n",
      "Step 2078, action: [-0.6967461], terminated: False, reward: 95.90249335941914, Trade: 1992\n",
      "Step 2079, action: [-0.30402875], terminated: False, reward: 95.89126032496857, Trade: 1993\n",
      "Step 2080, action: [-0.1509932], terminated: False, reward: 95.88126032496857, Trade: 1994\n",
      "Step 2081, action: [-0.5983687], terminated: False, reward: 97.79404340285554, Trade: 1995\n",
      "Step 2082, action: [-0.35958782], terminated: False, reward: 97.87157900863704, Trade: 1996\n",
      "Step 2083, action: [-0.8759612], terminated: False, reward: 98.09873178914414, Trade: 1997\n",
      "Step 2084, action: [0.34309074], terminated: False, reward: 98.08873178914413, Trade: 1998\n",
      "Step 2085, action: [0.8502897], terminated: False, reward: 98.07873178914413, Trade: 1999\n",
      "Step 2086, action: [-0.18498446], terminated: False, reward: 98.33659476889497, Trade: 2000\n",
      "Step 2087, action: [-0.97179943], terminated: False, reward: 98.30621099498735, Trade: 2001\n",
      "Step 2088, action: [0.0078239], terminated: False, reward: 98.29621099498735, Trade: 2002\n",
      "Step 2089, action: [0.05260425], terminated: False, reward: 98.28621099498734, Trade: 2003\n",
      "Step 2090, action: [0.09394512], terminated: False, reward: 98.27621099498734, Trade: 2004\n",
      "Step 2091, action: [0.2804229], terminated: False, reward: 98.26621099498733, Trade: 2005\n",
      "Step 2092, action: [0.98829937], terminated: False, reward: 98.25621099498733, Trade: 2006\n",
      "Step 2093, action: [0.5113094], terminated: False, reward: 98.24621099498732, Trade: 2007\n",
      "Step 2094, action: [-0.29787165], terminated: False, reward: 98.27441864281236, Trade: 2008\n",
      "Step 2095, action: [-0.7295084], terminated: False, reward: 98.25366625905569, Trade: 2009\n",
      "Step 2096, action: [0.35862136], terminated: False, reward: 98.24366625905569, Trade: 2010\n",
      "Step 2097, action: [0.2462016], terminated: False, reward: 98.23366625905568, Trade: 2011\n",
      "Step 2098, action: [-0.23874387], terminated: False, reward: 98.20137605534647, Trade: 2012\n",
      "Step 2099, action: [0.7741705], terminated: False, reward: 98.19137605534647, Trade: 2013\n",
      "Step 2100, action: [-0.10102364], terminated: False, reward: 98.19733296916843, Trade: 2014\n",
      "Step 2101, action: [-0.2901021], terminated: False, reward: 98.18686143870693, Trade: 2015\n",
      "Step 2102, action: [0.08570366], terminated: False, reward: 98.17686143870692, Trade: 2016\n",
      "Step 2103, action: [0.9766879], terminated: False, reward: 98.16686143870692, Trade: 2017\n",
      "Step 2104, action: [-0.25521436], terminated: False, reward: 98.23133407236745, Trade: 2018\n",
      "Step 2105, action: [-0.01973172], terminated: False, reward: 98.22247830167372, Trade: 2019\n",
      "Step 2106, action: [0.29463968], terminated: False, reward: 98.21247830167371, Trade: 2020\n",
      "Step 2107, action: [0.8178571], terminated: False, reward: 98.20247830167371, Trade: 2021\n",
      "Step 2108, action: [0.3355844], terminated: False, reward: 98.1924783016737, Trade: 2022\n",
      "Step 2109, action: [-0.47517392], terminated: False, reward: 99.25556819132791, Trade: 2023\n",
      "Step 2110, action: [0.2450654], terminated: False, reward: 99.2455681913279, Trade: 2024\n",
      "Step 2111, action: [-0.2573477], terminated: False, reward: 99.22886183238636, Trade: 2025\n",
      "Step 2112, action: [0.71249694], terminated: False, reward: 99.21886183238635, Trade: 2026\n",
      "Step 2113, action: [0.32960245], terminated: False, reward: 99.20886183238635, Trade: 2027\n",
      "Step 2114, action: [-0.09535035], terminated: False, reward: 99.3701708286665, Trade: 2028\n",
      "Step 2115, action: [0.21995445], terminated: False, reward: 99.3601708286665, Trade: 2029\n",
      "Step 2116, action: [-0.9797283], terminated: False, reward: 99.61127169025092, Trade: 2030\n",
      "Step 2117, action: [0.91784084], terminated: False, reward: 99.60127169025091, Trade: 2031\n",
      "Step 2118, action: [0.4470648], terminated: False, reward: 99.5912716902509, Trade: 2032\n",
      "Step 2119, action: [0.05436969], terminated: False, reward: 99.5812716902509, Trade: 2033\n",
      "Step 2120, action: [0.12258731], terminated: False, reward: 99.5712716902509, Trade: 2034\n",
      "Step 2121, action: [-0.91874236], terminated: False, reward: 100.04082601426818, Trade: 2035\n",
      "Step 2122, action: [0.9747446], terminated: False, reward: 100.03082601426817, Trade: 2036\n",
      "Step 2123, action: [-0.80217946], terminated: False, reward: 100.0194088049923, Trade: 2037\n",
      "Step 2124, action: [0.5492707], terminated: False, reward: 100.00940880499229, Trade: 2038\n",
      "Step 2125, action: [0.73458886], terminated: False, reward: 99.99940880499229, Trade: 2039\n",
      "Step 2126, action: [-0.8357366], terminated: False, reward: 100.71885562356888, Trade: 2040\n",
      "Step 2127, action: [0.29524326], terminated: False, reward: 100.70885562356888, Trade: 2041\n",
      "Step 2128, action: [-0.77773863], terminated: False, reward: 100.85982490414409, Trade: 2042\n",
      "Step 2129, action: [-0.35035658], terminated: False, reward: 100.85019571029247, Trade: 2043\n",
      "Step 2130, action: [0.45637015], terminated: False, reward: 100.84019571029246, Trade: 2044\n",
      "Step 2131, action: [-0.67078954], terminated: False, reward: 100.87879191362359, Trade: 2045\n",
      "Step 2132, action: [-0.4493636], terminated: False, reward: 101.00160093267426, Trade: 2046\n",
      "Step 2133, action: [0.8015448], terminated: False, reward: 100.99160093267426, Trade: 2047\n",
      "Step 2134, action: [0.32016692], terminated: False, reward: 100.98160093267425, Trade: 2048\n",
      "Step 2135, action: [-0.4955891], terminated: False, reward: 100.97254963017244, Trade: 2049\n",
      "Step 2136, action: [-0.19549257], terminated: False, reward: 100.96276221346398, Trade: 2050\n",
      "Step 2137, action: [0.7097519], terminated: False, reward: 100.95276221346397, Trade: 2051\n",
      "Step 2138, action: [-0.94015515], terminated: False, reward: 101.61173570147169, Trade: 2052\n",
      "Step 2139, action: [0.59022266], terminated: False, reward: 101.60173570147168, Trade: 2053\n",
      "Step 2140, action: [0.0563985], terminated: False, reward: 101.59173570147168, Trade: 2054\n",
      "Step 2141, action: [0.64103913], terminated: False, reward: 101.58173570147167, Trade: 2055\n",
      "Step 2142, action: [-0.16887483], terminated: False, reward: 101.84410224594147, Trade: 2056\n",
      "Step 2143, action: [-0.75085425], terminated: False, reward: 101.84845412441459, Trade: 2057\n",
      "Step 2144, action: [0.81335866], terminated: False, reward: 101.83845412441458, Trade: 2058\n",
      "Step 2145, action: [0.44428954], terminated: False, reward: 101.82845412441458, Trade: 2059\n",
      "Step 2146, action: [-0.34560016], terminated: False, reward: 101.84106620733219, Trade: 2060\n",
      "Step 2147, action: [0.8135407], terminated: False, reward: 101.83106620733219, Trade: 2061\n",
      "Step 2148, action: [0.90081394], terminated: False, reward: 101.82106620733218, Trade: 2062\n",
      "Step 2149, action: [-0.59854215], terminated: False, reward: 101.84341781509768, Trade: 2063\n",
      "Step 2150, action: [-0.10453156], terminated: False, reward: 101.83537088568414, Trade: 2064\n",
      "Step 2151, action: [-0.8010155], terminated: False, reward: 101.82537088568414, Trade: 2065\n",
      "Step 2152, action: [0.4885409], terminated: False, reward: 101.81537088568413, Trade: 2066\n",
      "Step 2153, action: [-0.67797685], terminated: False, reward: 103.07588424617161, Trade: 2067\n",
      "Step 2154, action: [0.6281452], terminated: False, reward: 103.0658842461716, Trade: 2068\n",
      "Step 2155, action: [-0.03124693], terminated: False, reward: 103.09648242335416, Trade: 2069\n",
      "Step 2156, action: [-0.5659679], terminated: False, reward: 103.10206739981598, Trade: 2070\n",
      "Step 2157, action: [-0.00704318], terminated: False, reward: 103.09206739981597, Trade: 2071\n",
      "Step 2158, action: [0.25798237], terminated: False, reward: 103.08206739981597, Trade: 2072\n",
      "Step 2159, action: [-0.28072125], terminated: False, reward: 103.07699443940058, Trade: 2073\n",
      "Step 2160, action: [-0.47224808], terminated: False, reward: 103.15713506308559, Trade: 2074\n",
      "Step 2161, action: [0.5651679], terminated: False, reward: 103.14713506308559, Trade: 2075\n",
      "Step 2162, action: [-0.33994633], terminated: False, reward: 103.23800808274417, Trade: 2076\n",
      "Step 2163, action: [-0.18471909], terminated: False, reward: 103.2317152135144, Trade: 2077\n",
      "Step 2164, action: [0.0934215], terminated: False, reward: 103.2217152135144, Trade: 2078\n",
      "Step 2165, action: [-0.56786126], terminated: False, reward: 103.88288761027887, Trade: 2079\n",
      "Step 2166, action: [0.7211722], terminated: False, reward: 103.87288761027887, Trade: 2080\n",
      "Step 2167, action: [-0.85330904], terminated: False, reward: 104.08470648059665, Trade: 2081\n",
      "Step 2168, action: [0.12742223], terminated: False, reward: 104.07470648059665, Trade: 2082\n",
      "Step 2169, action: [0.52674097], terminated: False, reward: 104.06470648059664, Trade: 2083\n",
      "Step 2170, action: [0.26016104], terminated: False, reward: 104.05470648059664, Trade: 2084\n",
      "Step 2171, action: [-0.1786362], terminated: False, reward: 104.04778046433222, Trade: 2085\n",
      "Step 2172, action: [-0.90172005], terminated: False, reward: 103.96768402886867, Trade: 2086\n",
      "Step 2173, action: [-0.9482857], terminated: False, reward: 103.2297355710005, Trade: 2087\n",
      "Step 2174, action: [0.88192815], terminated: False, reward: 103.2197355710005, Trade: 2088\n",
      "Step 2175, action: [-0.14077747], terminated: False, reward: 103.33147857352726, Trade: 2089\n",
      "Step 2176, action: [0.87228024], terminated: False, reward: 103.32147857352726, Trade: 2090\n",
      "Step 2177, action: [-0.80166394], terminated: False, reward: 103.32997664749263, Trade: 2091\n",
      "Step 2178, action: [-0.27187833], terminated: False, reward: 103.3548389671159, Trade: 2092\n",
      "Step 2179, action: [0.31328613], terminated: False, reward: 103.34483896711589, Trade: 2093\n",
      "Step 2180, action: [-0.2439513], terminated: False, reward: 103.33028805585249, Trade: 2094\n",
      "Step 2181, action: [0.820087], terminated: False, reward: 103.32028805585249, Trade: 2095\n",
      "Step 2182, action: [-0.67686296], terminated: False, reward: 103.39229608453911, Trade: 2096\n",
      "Step 2183, action: [0.94489384], terminated: False, reward: 103.3822960845391, Trade: 2097\n",
      "Step 2184, action: [-0.9073795], terminated: False, reward: 103.3813081995857, Trade: 2098\n",
      "Step 2185, action: [0.02272083], terminated: False, reward: 103.3713081995857, Trade: 2099\n",
      "Step 2186, action: [0.163673], terminated: False, reward: 103.3613081995857, Trade: 2100\n",
      "Step 2187, action: [0.8966994], terminated: False, reward: 103.35130819958569, Trade: 2101\n",
      "Step 2188, action: [0.39199075], terminated: False, reward: 103.34130819958568, Trade: 2102\n",
      "Step 2189, action: [0.509068], terminated: False, reward: 103.33130819958568, Trade: 2103\n",
      "Step 2190, action: [-0.18904641], terminated: False, reward: 103.35870702728056, Trade: 2104\n",
      "Step 2191, action: [-0.9057384], terminated: False, reward: 103.33107533561028, Trade: 2105\n",
      "Step 2192, action: [-0.6352695], terminated: False, reward: 103.33074870495119, Trade: 2106\n",
      "Step 2193, action: [0.6729259], terminated: False, reward: 103.32074870495119, Trade: 2107\n",
      "Step 2194, action: [0.32271856], terminated: False, reward: 103.31074870495118, Trade: 2108\n",
      "Step 2195, action: [0.78792214], terminated: False, reward: 103.30074870495118, Trade: 2109\n",
      "Step 2196, action: [0.55133975], terminated: False, reward: 103.29074870495117, Trade: 2110\n",
      "Step 2197, action: [0.60706717], terminated: False, reward: 103.28074870495116, Trade: 2111\n",
      "Step 2198, action: [0.27549753], terminated: False, reward: 103.27074870495116, Trade: 2112\n",
      "Step 2199, action: [0.25845182], terminated: False, reward: 103.26074870495115, Trade: 2113\n",
      "Step 2200, action: [0.9988664], terminated: False, reward: 103.15074870495116, Trade: 2113\n",
      "Step 2201, action: [-0.33727315], terminated: False, reward: 103.15438428815364, Trade: 2114\n",
      "Step 2202, action: [0.3646167], terminated: False, reward: 103.14438428815363, Trade: 2115\n",
      "Step 2203, action: [0.5740259], terminated: False, reward: 103.13438428815363, Trade: 2116\n",
      "Step 2204, action: [-0.78642035], terminated: False, reward: 103.06334750981644, Trade: 2117\n",
      "Step 2205, action: [-0.889196], terminated: False, reward: 103.05665248802565, Trade: 2118\n",
      "Step 2206, action: [-0.32211065], terminated: False, reward: 103.09730774239146, Trade: 2119\n",
      "Step 2207, action: [-0.15141927], terminated: False, reward: 103.09734482034796, Trade: 2120\n",
      "Step 2208, action: [0.07646997], terminated: False, reward: 103.08734482034795, Trade: 2121\n",
      "Step 2209, action: [0.03842048], terminated: False, reward: 103.07734482034795, Trade: 2122\n",
      "Step 2210, action: [-0.10993092], terminated: False, reward: 103.05348235828986, Trade: 2123\n",
      "Step 2211, action: [-0.23204036], terminated: False, reward: 103.06501958346189, Trade: 2124\n",
      "Step 2212, action: [0.9146486], terminated: False, reward: 103.05501958346188, Trade: 2125\n",
      "Step 2213, action: [0.015682], terminated: False, reward: 103.04501958346188, Trade: 2126\n",
      "Step 2214, action: [-0.31184366], terminated: False, reward: 102.96090911877967, Trade: 2127\n",
      "Step 2215, action: [0.9749813], terminated: False, reward: 102.95090911877966, Trade: 2128\n",
      "Step 2216, action: [-0.77141416], terminated: False, reward: 102.93969261855558, Trade: 2129\n",
      "Step 2217, action: [-0.5926311], terminated: False, reward: 102.87082665611524, Trade: 2130\n",
      "Step 2218, action: [0.96905637], terminated: False, reward: 102.86082665611524, Trade: 2131\n",
      "Step 2219, action: [0.7532168], terminated: False, reward: 102.85082665611523, Trade: 2132\n",
      "Step 2220, action: [-0.19153596], terminated: False, reward: 102.84105256907776, Trade: 2133\n",
      "Step 2221, action: [0.27121434], terminated: False, reward: 102.83105256907776, Trade: 2134\n",
      "Step 2222, action: [-0.17550412], terminated: False, reward: 102.8853150800704, Trade: 2135\n",
      "Step 2223, action: [-0.40861118], terminated: False, reward: 102.89886435472732, Trade: 2136\n",
      "Step 2224, action: [0.4298885], terminated: False, reward: 102.88886435472732, Trade: 2137\n",
      "Step 2225, action: [0.37800312], terminated: False, reward: 102.87886435472731, Trade: 2138\n",
      "Step 2226, action: [0.18797849], terminated: False, reward: 102.86886435472731, Trade: 2139\n",
      "Step 2227, action: [0.03723553], terminated: False, reward: 102.8588643547273, Trade: 2140\n",
      "Step 2228, action: [-0.49568552], terminated: False, reward: 102.82096098841407, Trade: 2141\n",
      "Step 2229, action: [-0.13369846], terminated: False, reward: 102.82918130925229, Trade: 2142\n",
      "Step 2230, action: [0.8990695], terminated: False, reward: 102.81918130925229, Trade: 2143\n",
      "Step 2231, action: [0.1131272], terminated: False, reward: 102.80918130925228, Trade: 2144\n",
      "Step 2232, action: [-0.9434917], terminated: False, reward: 102.68204062977627, Trade: 2145\n",
      "Step 2233, action: [-0.96845704], terminated: False, reward: 102.67227244186718, Trade: 2146\n",
      "Step 2234, action: [-0.05377899], terminated: False, reward: 102.67766341504573, Trade: 2147\n",
      "Step 2235, action: [0.2681396], terminated: False, reward: 102.66766341504572, Trade: 2148\n",
      "Step 2236, action: [-0.6368732], terminated: False, reward: 102.68618331203861, Trade: 2149\n",
      "Step 2237, action: [0.07478467], terminated: False, reward: 102.6761833120386, Trade: 2150\n",
      "Step 2238, action: [0.17214207], terminated: False, reward: 102.6661833120386, Trade: 2151\n",
      "Step 2239, action: [-0.45194417], terminated: False, reward: 102.70883125917862, Trade: 2152\n",
      "Step 2240, action: [0.5224412], terminated: False, reward: 102.69883125917862, Trade: 2153\n",
      "Step 2241, action: [0.22179383], terminated: False, reward: 102.68883125917861, Trade: 2154\n",
      "Step 2242, action: [-0.37585637], terminated: False, reward: 102.5111130293049, Trade: 2155\n",
      "Step 2243, action: [0.41893908], terminated: False, reward: 102.50111302930489, Trade: 2156\n",
      "Step 2244, action: [-0.03423072], terminated: False, reward: 102.49111302930488, Trade: 2157\n",
      "Step 2245, action: [-0.30260804], terminated: False, reward: 102.5339587200449, Trade: 2158\n",
      "Step 2246, action: [0.86737573], terminated: False, reward: 102.52395872004489, Trade: 2159\n",
      "Step 2247, action: [0.8228966], terminated: False, reward: 102.51395872004488, Trade: 2160\n",
      "Step 2248, action: [0.71382827], terminated: False, reward: 102.50395872004488, Trade: 2161\n",
      "Step 2249, action: [0.17973235], terminated: False, reward: 102.39395872004488, Trade: 2161\n",
      "Step 2250, action: [-0.8909077], terminated: False, reward: 103.45611304312388, Trade: 2162\n",
      "Step 2251, action: [-0.24653308], terminated: False, reward: 103.44397762307933, Trade: 2163\n",
      "Step 2252, action: [-0.7152857], terminated: False, reward: 104.03925595267866, Trade: 2164\n",
      "Step 2253, action: [-0.05020495], terminated: False, reward: 104.20100369933732, Trade: 2165\n",
      "Step 2254, action: [-0.8906158], terminated: False, reward: 104.9940091198056, Trade: 2166\n",
      "Step 2255, action: [-0.72685367], terminated: False, reward: 104.99916663043517, Trade: 2167\n",
      "Step 2256, action: [0.31259218], terminated: False, reward: 104.98916663043516, Trade: 2168\n",
      "Step 2257, action: [-0.86392945], terminated: False, reward: 105.11310658388753, Trade: 2169\n",
      "Step 2258, action: [0.00970176], terminated: False, reward: 105.10310658388752, Trade: 2170\n",
      "Step 2259, action: [-0.2680851], terminated: False, reward: 105.3734950293341, Trade: 2171\n",
      "Step 2260, action: [0.84122914], terminated: False, reward: 105.36349502933409, Trade: 2172\n",
      "Step 2261, action: [-0.4500197], terminated: False, reward: 105.35349502933408, Trade: 2173\n",
      "Step 2262, action: [0.39770216], terminated: False, reward: 105.34349502933408, Trade: 2174\n",
      "Step 2263, action: [0.17786193], terminated: False, reward: 105.33349502933407, Trade: 2175\n",
      "Step 2264, action: [0.48707324], terminated: False, reward: 105.32349502933407, Trade: 2176\n",
      "Step 2265, action: [-0.39049712], terminated: False, reward: 105.5756088717606, Trade: 2177\n",
      "Step 2266, action: [0.16219631], terminated: False, reward: 105.56560887176059, Trade: 2178\n",
      "Step 2267, action: [0.8004711], terminated: False, reward: 105.55560887176058, Trade: 2179\n",
      "Step 2268, action: [0.13107745], terminated: False, reward: 105.54560887176058, Trade: 2180\n",
      "Step 2269, action: [-0.5152874], terminated: False, reward: 105.58928104463773, Trade: 2181\n",
      "Step 2270, action: [0.69267887], terminated: False, reward: 105.57928104463772, Trade: 2182\n",
      "Step 2271, action: [0.23631796], terminated: False, reward: 105.56928104463772, Trade: 2183\n",
      "Step 2272, action: [-0.00498587], terminated: False, reward: 105.55928104463771, Trade: 2184\n",
      "Step 2273, action: [-0.02852797], terminated: False, reward: 105.54951036001134, Trade: 2185\n",
      "Step 2274, action: [-0.24402557], terminated: False, reward: 105.72781592770517, Trade: 2186\n",
      "Step 2275, action: [-0.952049], terminated: False, reward: 105.72724334974038, Trade: 2187\n",
      "Step 2276, action: [0.4715721], terminated: False, reward: 105.71724334974037, Trade: 2188\n",
      "Step 2277, action: [0.6312577], terminated: False, reward: 105.70724334974037, Trade: 2189\n",
      "Step 2278, action: [-0.09623867], terminated: False, reward: 105.71080800252192, Trade: 2190\n",
      "Step 2279, action: [-0.8150577], terminated: False, reward: 105.69912921061977, Trade: 2191\n",
      "Step 2280, action: [0.6588891], terminated: False, reward: 105.68912921061977, Trade: 2192\n",
      "Step 2281, action: [0.7975761], terminated: False, reward: 105.67912921061976, Trade: 2193\n",
      "Step 2282, action: [0.83700097], terminated: False, reward: 105.66912921061976, Trade: 2194\n",
      "Step 2283, action: [0.69754136], terminated: False, reward: 105.65912921061975, Trade: 2195\n",
      "Step 2284, action: [0.568919], terminated: False, reward: 105.54912921061975, Trade: 2195\n",
      "Step 2285, action: [-0.3823142], terminated: False, reward: 105.5485603806228, Trade: 2196\n",
      "Step 2286, action: [-0.59681284], terminated: False, reward: 111.37697314824426, Trade: 2197\n",
      "Step 2287, action: [-0.19976817], terminated: False, reward: 111.5522958917296, Trade: 2198\n",
      "Step 2288, action: [-0.38926983], terminated: False, reward: 113.4489627430745, Trade: 2199\n",
      "Step 2289, action: [-0.32480994], terminated: False, reward: 113.4389627430745, Trade: 2200\n",
      "Step 2290, action: [-0.3436844], terminated: False, reward: 113.47889531288078, Trade: 2201\n",
      "Step 2291, action: [0.19981459], terminated: False, reward: 113.46889531288078, Trade: 2202\n",
      "Step 2292, action: [0.30327672], terminated: False, reward: 113.45889531288077, Trade: 2203\n",
      "Step 2293, action: [0.39302337], terminated: False, reward: 113.44889531288077, Trade: 2204\n",
      "Step 2294, action: [0.04541222], terminated: False, reward: 113.43889531288076, Trade: 2205\n",
      "Step 2295, action: [-0.4630623], terminated: False, reward: 113.7492671491644, Trade: 2206\n",
      "Step 2296, action: [-0.7058398], terminated: False, reward: 113.62028214572902, Trade: 2207\n",
      "Step 2297, action: [0.98621833], terminated: False, reward: 113.61028214572902, Trade: 2208\n",
      "Step 2298, action: [0.47251892], terminated: False, reward: 113.60028214572901, Trade: 2209\n",
      "Step 2299, action: [0.59398323], terminated: False, reward: 113.590282145729, Trade: 2210\n",
      "Step 2300, action: [0.18789186], terminated: False, reward: 113.580282145729, Trade: 2211\n",
      "Step 2301, action: [0.18746926], terminated: False, reward: 113.570282145729, Trade: 2212\n",
      "Step 2302, action: [-0.3093778], terminated: False, reward: 113.88004900135606, Trade: 2213\n",
      "Step 2303, action: [-0.6237345], terminated: False, reward: 113.87129350955594, Trade: 2214\n",
      "Step 2304, action: [-0.25561243], terminated: False, reward: 113.89205284581796, Trade: 2215\n",
      "Step 2305, action: [0.22662361], terminated: False, reward: 113.88205284581795, Trade: 2216\n",
      "Step 2306, action: [-0.19859634], terminated: False, reward: 113.89895530339396, Trade: 2217\n",
      "Step 2307, action: [-0.6005384], terminated: False, reward: 113.89186247436129, Trade: 2218\n",
      "Step 2308, action: [0.40874404], terminated: False, reward: 113.88186247436128, Trade: 2219\n",
      "Step 2309, action: [-0.8840947], terminated: False, reward: 115.61147828286416, Trade: 2220\n",
      "Step 2310, action: [-0.790847], terminated: False, reward: 115.61491152460772, Trade: 2221\n",
      "Step 2311, action: [-0.6694875], terminated: False, reward: 115.61636304538385, Trade: 2222\n",
      "Step 2312, action: [-0.98764634], terminated: False, reward: 119.03019948557142, Trade: 2223\n",
      "Step 2313, action: [0.27374604], terminated: False, reward: 119.02019948557141, Trade: 2224\n",
      "Step 2314, action: [0.4675114], terminated: False, reward: 119.0101994855714, Trade: 2225\n",
      "Step 2315, action: [-0.06527834], terminated: False, reward: 119.04968001757197, Trade: 2226\n",
      "Step 2316, action: [-0.17878324], terminated: False, reward: 119.68796196850984, Trade: 2227\n",
      "Step 2317, action: [-0.53982955], terminated: False, reward: 119.67796196850983, Trade: 2228\n",
      "Step 2318, action: [-0.23369713], terminated: False, reward: 119.70473805867321, Trade: 2229\n",
      "Step 2319, action: [0.3523312], terminated: False, reward: 119.69473805867321, Trade: 2230\n",
      "Step 2320, action: [0.2560884], terminated: False, reward: 119.6847380586732, Trade: 2231\n",
      "Step 2321, action: [-0.80590296], terminated: False, reward: 120.93025680392, Trade: 2232\n",
      "Step 2322, action: [-0.25227526], terminated: False, reward: 121.1441794997301, Trade: 2233\n",
      "Step 2323, action: [0.09306842], terminated: False, reward: 121.1341794997301, Trade: 2234\n",
      "Step 2324, action: [-0.25350198], terminated: False, reward: 121.23447938645258, Trade: 2235\n",
      "Step 2325, action: [0.64580196], terminated: False, reward: 121.22447938645257, Trade: 2236\n",
      "Step 2326, action: [0.1584698], terminated: False, reward: 121.21447938645257, Trade: 2237\n",
      "Step 2327, action: [-0.27277082], terminated: False, reward: 121.47601343511616, Trade: 2238\n",
      "Step 2328, action: [-0.27462748], terminated: False, reward: 121.47641527161741, Trade: 2239\n",
      "Step 2329, action: [-0.89197034], terminated: False, reward: 121.8463370494068, Trade: 2240\n",
      "Step 2330, action: [0.96626353], terminated: False, reward: 121.8363370494068, Trade: 2241\n",
      "Step 2331, action: [0.8659263], terminated: False, reward: 121.82633704940679, Trade: 2242\n",
      "Step 2332, action: [-0.4838474], terminated: False, reward: 121.89705275174377, Trade: 2243\n",
      "Step 2333, action: [0.6243702], terminated: False, reward: 121.88705275174377, Trade: 2244\n",
      "Step 2334, action: [-0.88407093], terminated: False, reward: 121.98665586318293, Trade: 2245\n",
      "Step 2335, action: [0.625575], terminated: False, reward: 121.97665586318293, Trade: 2246\n",
      "Step 2336, action: [0.8104814], terminated: False, reward: 121.96665586318292, Trade: 2247\n",
      "Step 2337, action: [0.03600059], terminated: False, reward: 121.85665586318292, Trade: 2247\n",
      "Step 2338, action: [0.534126], terminated: False, reward: 121.84665586318292, Trade: 2248\n",
      "Step 2339, action: [-0.8137702], terminated: False, reward: 121.84275443030012, Trade: 2249\n",
      "Step 2340, action: [-0.0946108], terminated: False, reward: 121.83424860385303, Trade: 2250\n",
      "Step 2341, action: [0.77151585], terminated: False, reward: 121.82424860385302, Trade: 2251\n",
      "Step 2342, action: [0.41320744], terminated: False, reward: 121.71424860385302, Trade: 2251\n",
      "Step 2343, action: [0.13306625], terminated: False, reward: 121.60424860385302, Trade: 2251\n",
      "Step 2344, action: [0.73607916], terminated: False, reward: 121.59424860385302, Trade: 2252\n",
      "Step 2345, action: [0.2818168], terminated: False, reward: 121.58424860385301, Trade: 2253\n",
      "Step 2346, action: [0.99187595], terminated: False, reward: 121.57424860385301, Trade: 2254\n",
      "Step 2347, action: [-0.9357105], terminated: False, reward: 121.17488242994219, Trade: 2255\n",
      "Step 2348, action: [-0.12331931], terminated: False, reward: 121.30464242487452, Trade: 2256\n",
      "Step 2349, action: [-0.46249005], terminated: False, reward: 121.43944480221917, Trade: 2257\n",
      "Step 2350, action: [-0.34172097], terminated: False, reward: 121.59568776386033, Trade: 2258\n",
      "Step 2351, action: [-0.20484407], terminated: False, reward: 121.6385480803958, Trade: 2259\n",
      "Step 2352, action: [-0.53325164], terminated: False, reward: 121.84893658319825, Trade: 2260\n",
      "Step 2353, action: [0.2602066], terminated: False, reward: 121.83893658319825, Trade: 2261\n",
      "Step 2354, action: [0.25235364], terminated: False, reward: 121.82893658319824, Trade: 2262\n",
      "Step 2355, action: [-0.5654176], terminated: False, reward: 122.28623935129815, Trade: 2263\n",
      "Step 2356, action: [-0.507274], terminated: False, reward: 122.29529260260003, Trade: 2264\n",
      "Step 2357, action: [0.6853038], terminated: False, reward: 122.28529260260002, Trade: 2265\n",
      "Step 2358, action: [0.18215454], terminated: False, reward: 122.27529260260002, Trade: 2266\n",
      "Step 2359, action: [0.20677963], terminated: False, reward: 122.26529260260001, Trade: 2267\n",
      "Step 2360, action: [0.15004209], terminated: False, reward: 122.25529260260001, Trade: 2268\n",
      "Step 2361, action: [0.83554584], terminated: False, reward: 122.2452926026, Trade: 2269\n",
      "Step 2362, action: [0.5542628], terminated: False, reward: 122.2352926026, Trade: 2270\n",
      "Step 2363, action: [0.5047426], terminated: False, reward: 122.22529260259999, Trade: 2271\n",
      "Step 2364, action: [0.28810626], terminated: False, reward: 122.21529260259999, Trade: 2272\n",
      "Step 2365, action: [0.41997525], terminated: False, reward: 122.20529260259998, Trade: 2273\n",
      "Step 2366, action: [0.449413], terminated: False, reward: 122.19529260259998, Trade: 2274\n",
      "Step 2367, action: [0.8474132], terminated: False, reward: 122.18529260259997, Trade: 2275\n",
      "Step 2368, action: [-0.7308859], terminated: False, reward: 122.19249417863094, Trade: 2276\n",
      "Step 2369, action: [0.53640693], terminated: False, reward: 122.18249417863093, Trade: 2277\n",
      "Step 2370, action: [-0.4603536], terminated: False, reward: 125.50443951326486, Trade: 2278\n",
      "Step 2371, action: [0.10560352], terminated: False, reward: 125.49443951326485, Trade: 2279\n",
      "Step 2372, action: [-0.39627185], terminated: False, reward: 127.10628158394566, Trade: 2280\n",
      "Step 2373, action: [0.8837679], terminated: False, reward: 127.09628158394565, Trade: 2281\n",
      "Step 2374, action: [-0.5139889], terminated: False, reward: 127.08371643791325, Trade: 2282\n",
      "Step 2375, action: [-0.22336012], terminated: False, reward: 127.06090825772405, Trade: 2283\n",
      "Step 2376, action: [0.659227], terminated: False, reward: 127.05090825772405, Trade: 2284\n",
      "Step 2377, action: [0.44717443], terminated: False, reward: 127.04090825772404, Trade: 2285\n",
      "Step 2378, action: [-0.8704382], terminated: False, reward: 127.06187655062584, Trade: 2286\n",
      "Step 2379, action: [-0.5783299], terminated: False, reward: 127.18087413770938, Trade: 2287\n",
      "Step 2380, action: [0.43179572], terminated: False, reward: 127.17087413770938, Trade: 2288\n",
      "Step 2381, action: [-0.824812], terminated: False, reward: 127.58132383736375, Trade: 2289\n",
      "Step 2382, action: [0.98050255], terminated: False, reward: 127.57132383736375, Trade: 2290\n",
      "Step 2383, action: [-0.825703], terminated: False, reward: 128.0522359756493, Trade: 2291\n",
      "Step 2384, action: [-0.9599817], terminated: False, reward: 128.06194371672896, Trade: 2292\n",
      "Step 2385, action: [-0.45730326], terminated: False, reward: 127.93739016256418, Trade: 2293\n",
      "Step 2386, action: [0.6040175], terminated: False, reward: 127.92739016256418, Trade: 2294\n",
      "Step 2387, action: [-0.855663], terminated: False, reward: 127.90273667777191, Trade: 2295\n",
      "Step 2388, action: [-0.11147127], terminated: False, reward: 127.89683836825341, Trade: 2296\n",
      "Step 2389, action: [0.532147], terminated: False, reward: 127.88683836825341, Trade: 2297\n",
      "Step 2390, action: [0.33843943], terminated: False, reward: 127.8768383682534, Trade: 2298\n",
      "Step 2391, action: [-0.16647832], terminated: False, reward: 127.87207595743736, Trade: 2299\n",
      "Step 2392, action: [0.11228299], terminated: False, reward: 127.86207595743736, Trade: 2300\n",
      "Step 2393, action: [-0.5616711], terminated: False, reward: 128.13157774219897, Trade: 2301\n",
      "Step 2394, action: [-0.9175202], terminated: False, reward: 128.17309603606571, Trade: 2302\n",
      "Step 2395, action: [0.51557225], terminated: False, reward: 128.16309603606572, Trade: 2303\n",
      "Step 2396, action: [0.40407506], terminated: False, reward: 128.15309603606573, Trade: 2304\n",
      "Step 2397, action: [0.08847381], terminated: False, reward: 128.14309603606574, Trade: 2305\n",
      "Step 2398, action: [-0.1978238], terminated: False, reward: 129.00925247039848, Trade: 2306\n",
      "Step 2399, action: [0.89273036], terminated: False, reward: 128.9992524703985, Trade: 2307\n",
      "Step 2400, action: [-0.7130586], terminated: False, reward: 131.10660909225265, Trade: 2308\n",
      "Step 2401, action: [-0.62688166], terminated: False, reward: 130.0280998709074, Trade: 2309\n",
      "Step 2402, action: [-0.02588308], terminated: False, reward: 130.01756678841443, Trade: 2310\n",
      "Step 2403, action: [0.15245034], terminated: False, reward: 130.00756678841444, Trade: 2311\n",
      "Step 2404, action: [-0.25493956], terminated: False, reward: 130.45863516870347, Trade: 2312\n",
      "Step 2405, action: [0.29497224], terminated: False, reward: 130.44863516870348, Trade: 2313\n",
      "Step 2406, action: [-0.58312905], terminated: False, reward: 130.43191283350072, Trade: 2314\n",
      "Step 2407, action: [0.94693476], terminated: False, reward: 130.42191283350073, Trade: 2315\n",
      "Step 2408, action: [0.2332062], terminated: False, reward: 130.41191283350074, Trade: 2316\n",
      "Step 2409, action: [0.4319627], terminated: False, reward: 130.40191283350075, Trade: 2317\n",
      "Step 2410, action: [-0.59227204], terminated: False, reward: 132.66435770670185, Trade: 2318\n",
      "Step 2411, action: [-0.87716585], terminated: False, reward: 132.7835154120065, Trade: 2319\n",
      "Step 2412, action: [0.26122418], terminated: False, reward: 132.7735154120065, Trade: 2320\n",
      "Step 2413, action: [-0.57305723], terminated: False, reward: 132.8792248254367, Trade: 2321\n",
      "Step 2414, action: [0.40578637], terminated: False, reward: 132.8692248254367, Trade: 2322\n",
      "Step 2415, action: [0.10946921], terminated: False, reward: 132.8592248254367, Trade: 2323\n",
      "Step 2416, action: [-0.02749151], terminated: False, reward: 132.85039554845727, Trade: 2324\n",
      "Step 2417, action: [-0.29666317], terminated: False, reward: 133.2085919852567, Trade: 2325\n",
      "Step 2418, action: [-0.03660252], terminated: False, reward: 133.1996660621856, Trade: 2326\n",
      "Step 2419, action: [-0.25443298], terminated: False, reward: 133.20460970118322, Trade: 2327\n",
      "Step 2420, action: [0.33166102], terminated: False, reward: 133.19460970118323, Trade: 2328\n",
      "Step 2421, action: [-0.99950945], terminated: False, reward: 133.27967379454887, Trade: 2329\n",
      "Step 2422, action: [0.52582115], terminated: False, reward: 133.26967379454888, Trade: 2330\n",
      "Step 2423, action: [-0.8828823], terminated: False, reward: 133.13664644451927, Trade: 2331\n",
      "Step 2424, action: [0.57622945], terminated: False, reward: 133.12664644451928, Trade: 2332\n",
      "Step 2425, action: [-0.44247293], terminated: False, reward: 133.52017937174702, Trade: 2333\n",
      "Step 2426, action: [-0.05923979], terminated: False, reward: 133.78007259512125, Trade: 2334\n",
      "Step 2427, action: [-0.2900005], terminated: False, reward: 134.15444876133373, Trade: 2335\n",
      "Step 2428, action: [0.53949136], terminated: False, reward: 134.14444876133373, Trade: 2336\n",
      "Step 2429, action: [-0.21918009], terminated: False, reward: 133.9826303178892, Trade: 2337\n",
      "Step 2430, action: [0.17406836], terminated: False, reward: 133.9726303178892, Trade: 2338\n",
      "Step 2431, action: [0.03038556], terminated: False, reward: 133.96263031788922, Trade: 2339\n",
      "Step 2432, action: [0.03132254], terminated: False, reward: 133.95263031788923, Trade: 2340\n",
      "Step 2433, action: [0.7393492], terminated: False, reward: 133.94263031788924, Trade: 2341\n",
      "Step 2434, action: [0.22719276], terminated: False, reward: 133.93263031788925, Trade: 2342\n",
      "Step 2435, action: [0.20110673], terminated: False, reward: 133.92263031788926, Trade: 2343\n",
      "Step 2436, action: [0.983876], terminated: False, reward: 133.91263031788927, Trade: 2344\n",
      "Step 2437, action: [0.39954907], terminated: False, reward: 133.90263031788928, Trade: 2345\n",
      "Step 2438, action: [0.83432394], terminated: False, reward: 133.89263031788929, Trade: 2346\n",
      "Step 2439, action: [0.46529892], terminated: False, reward: 133.7826303178893, Trade: 2346\n",
      "Step 2440, action: [0.44183925], terminated: False, reward: 133.67263031788931, Trade: 2346\n",
      "Step 2441, action: [-0.90160066], terminated: False, reward: 133.71465285536186, Trade: 2347\n",
      "Step 2442, action: [0.15200451], terminated: False, reward: 133.70465285536187, Trade: 2348\n",
      "Step 2443, action: [0.78113675], terminated: False, reward: 133.69465285536188, Trade: 2349\n",
      "Step 2444, action: [0.09602874], terminated: False, reward: 133.6846528553619, Trade: 2350\n",
      "Step 2445, action: [0.8532291], terminated: False, reward: 133.6746528553619, Trade: 2351\n",
      "Step 2446, action: [-0.29379028], terminated: False, reward: 133.6998100506384, Trade: 2352\n",
      "Step 2447, action: [0.7374462], terminated: False, reward: 133.6898100506384, Trade: 2353\n",
      "Step 2448, action: [0.81038076], terminated: False, reward: 133.67981005063842, Trade: 2354\n",
      "Step 2449, action: [0.62840354], terminated: False, reward: 133.66981005063843, Trade: 2355\n",
      "Step 2450, action: [0.29276127], terminated: False, reward: 133.65981005063844, Trade: 2356\n",
      "Step 2451, action: [-0.03040299], terminated: False, reward: 133.6496258820362, Trade: 2357\n",
      "Step 2452, action: [-0.83553356], terminated: False, reward: 133.80572943186854, Trade: 2358\n",
      "Step 2453, action: [0.77616066], terminated: False, reward: 133.79572943186855, Trade: 2359\n",
      "Step 2454, action: [0.7759815], terminated: False, reward: 133.78572943186856, Trade: 2360\n",
      "Step 2455, action: [-0.8924306], terminated: False, reward: 135.09819536493924, Trade: 2361\n",
      "Step 2456, action: [-0.71572614], terminated: False, reward: 136.0312821472044, Trade: 2362\n",
      "Step 2457, action: [-0.9211862], terminated: False, reward: 135.60173433868712, Trade: 2363\n",
      "Step 2458, action: [0.26082596], terminated: False, reward: 135.59173433868713, Trade: 2364\n",
      "Step 2459, action: [-0.17997062], terminated: False, reward: 135.61597501328842, Trade: 2365\n",
      "Step 2460, action: [-0.64873046], terminated: False, reward: 136.22783044522555, Trade: 2366\n",
      "Step 2461, action: [0.25115672], terminated: False, reward: 136.21783044522556, Trade: 2367\n",
      "Step 2462, action: [-0.20138209], terminated: False, reward: 136.20000259650882, Trade: 2368\n",
      "Step 2463, action: [-0.09081857], terminated: False, reward: 136.1682505255275, Trade: 2369\n",
      "Step 2464, action: [0.9573844], terminated: False, reward: 136.1582505255275, Trade: 2370\n",
      "Step 2465, action: [0.96597564], terminated: False, reward: 136.14825052552752, Trade: 2371\n",
      "Step 2466, action: [0.9351089], terminated: False, reward: 136.13825052552752, Trade: 2372\n",
      "Step 2467, action: [-0.60613936], terminated: False, reward: 136.1390289181923, Trade: 2373\n",
      "Step 2468, action: [0.53082234], terminated: False, reward: 136.12902891819232, Trade: 2374\n",
      "Step 2469, action: [0.9831127], terminated: False, reward: 136.11902891819233, Trade: 2375\n",
      "Step 2470, action: [-0.80482775], terminated: False, reward: 140.10394894228713, Trade: 2376\n",
      "Step 2471, action: [-0.64102775], terminated: False, reward: 140.2788972758988, Trade: 2377\n",
      "Step 2472, action: [-0.2142216], terminated: False, reward: 140.29103884497133, Trade: 2378\n",
      "Step 2473, action: [-0.58227164], terminated: False, reward: 140.99731861241125, Trade: 2379\n",
      "Step 2474, action: [-0.64560384], terminated: False, reward: 141.06315761146854, Trade: 2380\n",
      "Step 2475, action: [0.65905285], terminated: False, reward: 141.05315761146855, Trade: 2381\n",
      "Step 2476, action: [0.66615385], terminated: False, reward: 141.04315761146856, Trade: 2382\n",
      "Step 2477, action: [-0.8415331], terminated: False, reward: 141.03357191833868, Trade: 2383\n",
      "Step 2478, action: [-0.9275359], terminated: False, reward: 141.17752912237694, Trade: 2384\n",
      "Step 2479, action: [-0.2988532], terminated: False, reward: 141.17397981533318, Trade: 2385\n",
      "Step 2480, action: [-0.04864142], terminated: False, reward: 141.16699004717452, Trade: 2386\n",
      "Step 2481, action: [0.897069], terminated: False, reward: 141.15699004717453, Trade: 2387\n",
      "Step 2482, action: [-0.40985042], terminated: False, reward: 144.58312117398958, Trade: 2388\n",
      "Step 2483, action: [-0.70942897], terminated: False, reward: 144.70559816873933, Trade: 2389\n",
      "Step 2484, action: [0.5594432], terminated: False, reward: 144.69559816873934, Trade: 2390\n",
      "Step 2485, action: [-0.07501449], terminated: False, reward: 144.6837881828829, Trade: 2391\n",
      "Step 2486, action: [0.6571064], terminated: False, reward: 144.6737881828829, Trade: 2392\n",
      "Step 2487, action: [0.9370739], terminated: False, reward: 144.6637881828829, Trade: 2393\n",
      "Step 2488, action: [-0.4441844], terminated: False, reward: 144.82149383312856, Trade: 2394\n",
      "Step 2489, action: [-0.36246285], terminated: False, reward: 145.21357961886181, Trade: 2395\n",
      "Step 2490, action: [0.48096612], terminated: False, reward: 145.20357961886182, Trade: 2396\n",
      "Step 2491, action: [0.40413988], terminated: False, reward: 145.19357961886183, Trade: 2397\n",
      "Step 2492, action: [-0.83623123], terminated: False, reward: 145.8038598455463, Trade: 2398\n",
      "Step 2493, action: [0.6769495], terminated: False, reward: 145.7938598455463, Trade: 2399\n",
      "Step 2494, action: [-0.63034743], terminated: False, reward: 146.95300240180075, Trade: 2400\n",
      "Step 2495, action: [-0.06170407], terminated: False, reward: 146.94300240180075, Trade: 2401\n",
      "Step 2496, action: [-0.8308047], terminated: False, reward: 146.97346053555856, Trade: 2402\n",
      "Step 2497, action: [0.9826135], terminated: False, reward: 146.96346053555857, Trade: 2403\n",
      "Step 2498, action: [0.31118613], terminated: False, reward: 146.95346053555858, Trade: 2404\n",
      "Step 2499, action: [-0.8681948], terminated: False, reward: 146.87781993781803, Trade: 2405\n",
      "Step 2500, action: [-0.71787816], terminated: False, reward: 146.93974714409933, Trade: 2406\n",
      "Step 2501, action: [0.09272937], terminated: False, reward: 146.92974714409934, Trade: 2407\n",
      "Step 2502, action: [0.4032985], terminated: False, reward: 146.91974714409935, Trade: 2408\n",
      "Step 2503, action: [0.57101303], terminated: False, reward: 146.90974714409936, Trade: 2409\n",
      "Step 2504, action: [-0.5125539], terminated: False, reward: 147.08853333940448, Trade: 2410\n",
      "Step 2505, action: [-0.1096035], terminated: False, reward: 147.0785333394045, Trade: 2411\n",
      "Step 2506, action: [-0.5107781], terminated: False, reward: 147.06825895245015, Trade: 2412\n",
      "Step 2507, action: [-0.19553132], terminated: False, reward: 147.05874158889296, Trade: 2413\n",
      "Step 2508, action: [0.25051054], terminated: False, reward: 147.04874158889297, Trade: 2414\n",
      "Step 2509, action: [-0.7966524], terminated: False, reward: 148.77902453566344, Trade: 2415\n",
      "Step 2510, action: [0.5348189], terminated: False, reward: 148.76902453566345, Trade: 2416\n",
      "Step 2511, action: [0.7807914], terminated: False, reward: 148.75902453566346, Trade: 2417\n",
      "Step 2512, action: [-0.5142085], terminated: False, reward: 148.91882824733258, Trade: 2418\n",
      "Step 2513, action: [-0.53795546], terminated: False, reward: 148.90762831981925, Trade: 2419\n",
      "Step 2514, action: [-0.467995], terminated: False, reward: 149.44865639706293, Trade: 2420\n",
      "Step 2515, action: [0.13110395], terminated: False, reward: 149.43865639706294, Trade: 2421\n",
      "Step 2516, action: [-0.825407], terminated: False, reward: 149.82289184925466, Trade: 2422\n",
      "Step 2517, action: [0.31308857], terminated: False, reward: 149.81289184925467, Trade: 2423\n",
      "Step 2518, action: [-0.37776098], terminated: False, reward: 149.8190867748512, Trade: 2424\n",
      "Step 2519, action: [-0.2271245], terminated: False, reward: 150.1385533036698, Trade: 2425\n",
      "Step 2520, action: [0.13061476], terminated: False, reward: 150.1285533036698, Trade: 2426\n",
      "Step 2521, action: [-0.4267502], terminated: False, reward: 151.07023664654946, Trade: 2427\n",
      "Step 2522, action: [-0.26702994], terminated: False, reward: 151.23169151280408, Trade: 2428\n",
      "Step 2523, action: [0.24685174], terminated: False, reward: 151.22169151280409, Trade: 2429\n",
      "Step 2524, action: [0.10496764], terminated: False, reward: 151.2116915128041, Trade: 2430\n",
      "Step 2525, action: [0.45116815], terminated: False, reward: 151.2016915128041, Trade: 2431\n",
      "Step 2526, action: [-0.90871453], terminated: False, reward: 152.33176450419973, Trade: 2432\n",
      "Step 2527, action: [-0.05900629], terminated: False, reward: 152.32110985511318, Trade: 2433\n",
      "Step 2528, action: [0.28734916], terminated: False, reward: 152.3111098551132, Trade: 2434\n",
      "Step 2529, action: [0.3820316], terminated: False, reward: 152.3011098551132, Trade: 2435\n",
      "Step 2530, action: [-0.39786044], terminated: False, reward: 152.3062156566396, Trade: 2436\n",
      "Step 2531, action: [-0.57333654], terminated: False, reward: 153.48230575514842, Trade: 2437\n",
      "Step 2532, action: [0.15351395], terminated: False, reward: 153.47230575514843, Trade: 2438\n",
      "Step 2533, action: [0.7573539], terminated: False, reward: 153.46230575514844, Trade: 2439\n",
      "Step 2534, action: [0.65010583], terminated: False, reward: 153.45230575514844, Trade: 2440\n",
      "Step 2535, action: [0.3887024], terminated: False, reward: 153.44230575514845, Trade: 2441\n",
      "Step 2536, action: [-0.5627638], terminated: False, reward: 153.3000873888065, Trade: 2442\n",
      "Step 2537, action: [-0.3505587], terminated: False, reward: 153.57041546343183, Trade: 2443\n",
      "Step 2538, action: [-0.00507726], terminated: False, reward: 153.59112036242544, Trade: 2444\n",
      "Step 2539, action: [0.496335], terminated: False, reward: 153.58112036242545, Trade: 2445\n",
      "Step 2540, action: [-0.9478799], terminated: False, reward: 154.17626827092332, Trade: 2446\n",
      "Step 2541, action: [-0.98494893], terminated: False, reward: 154.1705265094428, Trade: 2447\n",
      "Step 2542, action: [0.93195325], terminated: False, reward: 154.1605265094428, Trade: 2448\n",
      "Step 2543, action: [-0.68327814], terminated: False, reward: 154.60507491455883, Trade: 2449\n",
      "Step 2544, action: [-0.8224615], terminated: False, reward: 154.6678924065134, Trade: 2450\n",
      "Step 2545, action: [-0.5228264], terminated: False, reward: 155.39456081790743, Trade: 2451\n",
      "Step 2546, action: [0.19925432], terminated: False, reward: 155.38456081790744, Trade: 2452\n",
      "Step 2547, action: [-0.32117638], terminated: False, reward: 156.79918973281374, Trade: 2453\n",
      "Step 2548, action: [0.5325957], terminated: False, reward: 156.78918973281375, Trade: 2454\n",
      "Step 2549, action: [0.44881317], terminated: False, reward: 156.77918973281376, Trade: 2455\n",
      "Step 2550, action: [0.6801822], terminated: False, reward: 156.76918973281377, Trade: 2456\n",
      "Step 2551, action: [0.06504416], terminated: False, reward: 156.75918973281378, Trade: 2457\n",
      "Step 2552, action: [-0.13930282], terminated: False, reward: 156.81718428133414, Trade: 2458\n",
      "Step 2553, action: [-0.02434855], terminated: False, reward: 156.65626348479748, Trade: 2459\n",
      "Step 2554, action: [-0.7106342], terminated: False, reward: 156.8032256590544, Trade: 2460\n",
      "Step 2555, action: [0.22762358], terminated: False, reward: 156.7932256590544, Trade: 2461\n",
      "Step 2556, action: [0.09064633], terminated: False, reward: 156.7832256590544, Trade: 2462\n",
      "Step 2557, action: [-0.5149227], terminated: False, reward: 157.39080815107857, Trade: 2463\n",
      "Step 2558, action: [0.30571038], terminated: False, reward: 157.38080815107858, Trade: 2464\n",
      "Step 2559, action: [-0.1707986], terminated: False, reward: 157.64248323538627, Trade: 2465\n",
      "Step 2560, action: [0.26506084], terminated: False, reward: 157.63248323538627, Trade: 2466\n",
      "Step 2561, action: [-0.20057748], terminated: False, reward: 157.05492141395314, Trade: 2467\n",
      "Step 2562, action: [-0.8732782], terminated: False, reward: 157.49879525114008, Trade: 2468\n",
      "Step 2563, action: [0.11612988], terminated: False, reward: 157.4887952511401, Trade: 2469\n",
      "Step 2564, action: [-0.5115036], terminated: False, reward: 157.43796601450214, Trade: 2470\n",
      "Step 2565, action: [0.27139822], terminated: False, reward: 157.42796601450215, Trade: 2471\n",
      "Step 2566, action: [0.46651626], terminated: False, reward: 157.41796601450216, Trade: 2472\n",
      "Step 2567, action: [0.00157824], terminated: False, reward: 157.30796601450217, Trade: 2472\n",
      "Step 2568, action: [-0.64473283], terminated: False, reward: 157.32292192823843, Trade: 2473\n",
      "Step 2569, action: [-0.39291185], terminated: False, reward: 157.31292192823844, Trade: 2474\n",
      "Step 2570, action: [0.01445093], terminated: False, reward: 157.30292192823845, Trade: 2475\n",
      "Step 2571, action: [0.11899553], terminated: False, reward: 157.29292192823846, Trade: 2476\n",
      "Step 2572, action: [-0.98901606], terminated: False, reward: 157.30779112626644, Trade: 2477\n",
      "Step 2573, action: [-0.3066615], terminated: False, reward: 157.76339840480307, Trade: 2478\n",
      "Step 2574, action: [-0.79227215], terminated: False, reward: 157.99915455400844, Trade: 2479\n",
      "Step 2575, action: [-0.7716768], terminated: False, reward: 160.2228170326882, Trade: 2480\n",
      "Step 2576, action: [-0.9660922], terminated: False, reward: 160.8277563554779, Trade: 2481\n",
      "Step 2577, action: [0.48955435], terminated: False, reward: 160.8177563554779, Trade: 2482\n",
      "Step 2578, action: [0.14951472], terminated: False, reward: 160.80775635547792, Trade: 2483\n",
      "Step 2579, action: [-0.2114471], terminated: False, reward: 160.97769442462217, Trade: 2484\n",
      "Step 2580, action: [-0.26786956], terminated: False, reward: 161.1528821262574, Trade: 2485\n",
      "Step 2581, action: [-0.9097003], terminated: False, reward: 155.7388499196012, Trade: 2486\n",
      "Step 2582, action: [-0.3190343], terminated: False, reward: 155.75045769405682, Trade: 2487\n",
      "Step 2583, action: [-0.97596836], terminated: False, reward: 155.84450956051668, Trade: 2488\n",
      "Step 2584, action: [-0.5168482], terminated: False, reward: 155.83802344566692, Trade: 2489\n",
      "Step 2585, action: [0.5634347], terminated: False, reward: 155.82802344566693, Trade: 2490\n",
      "Step 2586, action: [-0.5797917], terminated: False, reward: 156.04589157651307, Trade: 2491\n",
      "Step 2587, action: [0.19052601], terminated: False, reward: 156.03589157651308, Trade: 2492\n",
      "Step 2588, action: [-0.35102296], terminated: False, reward: 156.63062922044475, Trade: 2493\n",
      "Step 2589, action: [0.37732878], terminated: False, reward: 156.62062922044475, Trade: 2494\n",
      "Step 2590, action: [-0.67993027], terminated: False, reward: 156.7037525499146, Trade: 2495\n",
      "Step 2591, action: [-0.7750007], terminated: False, reward: 156.69024424683585, Trade: 2496\n",
      "Step 2592, action: [-0.27195626], terminated: False, reward: 156.66635089248632, Trade: 2497\n",
      "Step 2593, action: [0.32201412], terminated: False, reward: 156.65635089248633, Trade: 2498\n",
      "Step 2594, action: [0.7839096], terminated: False, reward: 156.64635089248634, Trade: 2499\n",
      "Step 2595, action: [0.6348357], terminated: False, reward: 156.63635089248635, Trade: 2500\n",
      "Step 2596, action: [-0.05892682], terminated: False, reward: 156.62635089248636, Trade: 2501\n",
      "Step 2597, action: [0.06105212], terminated: False, reward: 156.61635089248637, Trade: 2502\n",
      "Step 2598, action: [-0.6205693], terminated: False, reward: 157.7849431138185, Trade: 2503\n",
      "Step 2599, action: [-0.36705548], terminated: False, reward: 157.90889165206534, Trade: 2504\n",
      "Step 2600, action: [0.42744815], terminated: False, reward: 157.89889165206534, Trade: 2505\n",
      "Step 2601, action: [-0.7126383], terminated: False, reward: 158.5550404611533, Trade: 2506\n",
      "Step 2602, action: [-0.6522289], terminated: False, reward: 158.58349843560876, Trade: 2507\n",
      "Step 2603, action: [-0.78302824], terminated: False, reward: 159.16278714703807, Trade: 2508\n",
      "Step 2604, action: [-0.1616334], terminated: False, reward: 159.15627818685059, Trade: 2509\n",
      "Step 2605, action: [-0.4787053], terminated: False, reward: 161.24491409791509, Trade: 2510\n",
      "Step 2606, action: [-0.01032595], terminated: False, reward: 161.24224797750722, Trade: 2511\n",
      "Step 2607, action: [0.22977655], terminated: False, reward: 161.23224797750723, Trade: 2512\n",
      "Step 2608, action: [0.19429433], terminated: False, reward: 161.22224797750724, Trade: 2513\n",
      "Step 2609, action: [-0.17451401], terminated: False, reward: 161.13572216319264, Trade: 2514\n",
      "Step 2610, action: [-0.08927663], terminated: False, reward: 161.12957849234286, Trade: 2515\n",
      "Step 2611, action: [-0.67037356], terminated: False, reward: 161.1224321689952, Trade: 2516\n",
      "Step 2612, action: [0.84394294], terminated: False, reward: 161.1124321689952, Trade: 2517\n",
      "Step 2613, action: [0.60273755], terminated: False, reward: 161.10243216899522, Trade: 2518\n",
      "Step 2614, action: [0.83139086], terminated: False, reward: 161.09243216899523, Trade: 2519\n",
      "Step 2615, action: [0.549321], terminated: False, reward: 161.08243216899524, Trade: 2520\n",
      "Step 2616, action: [0.95824933], terminated: False, reward: 161.07243216899525, Trade: 2521\n",
      "Step 2617, action: [-0.0701303], terminated: False, reward: 160.99859470357674, Trade: 2522\n",
      "Step 2618, action: [-0.5227115], terminated: False, reward: 161.01421705906566, Trade: 2523\n",
      "Step 2619, action: [-0.6095187], terminated: False, reward: 160.99969031136234, Trade: 2524\n",
      "Step 2620, action: [0.1310449], terminated: False, reward: 160.98969031136235, Trade: 2525\n",
      "Step 2621, action: [0.44332427], terminated: False, reward: 160.97969031136236, Trade: 2526\n",
      "Step 2622, action: [0.6874386], terminated: False, reward: 160.96969031136237, Trade: 2527\n",
      "Step 2623, action: [0.7588823], terminated: False, reward: 160.95969031136238, Trade: 2528\n",
      "Step 2624, action: [-0.01665577], terminated: False, reward: 160.9496903113624, Trade: 2529\n",
      "Step 2625, action: [0.96276945], terminated: False, reward: 160.9396903113624, Trade: 2530\n",
      "Step 2626, action: [0.3029721], terminated: False, reward: 160.8296903113624, Trade: 2530\n",
      "Step 2627, action: [0.50658727], terminated: False, reward: 160.71969031136243, Trade: 2530\n",
      "Step 2628, action: [-0.82204705], terminated: False, reward: 160.97728341859113, Trade: 2531\n",
      "Step 2629, action: [-0.90925246], terminated: False, reward: 161.2892375453544, Trade: 2532\n",
      "Step 2630, action: [0.15984198], terminated: False, reward: 161.27923754535442, Trade: 2533\n",
      "Step 2631, action: [-0.08960666], terminated: False, reward: 161.2865628455776, Trade: 2534\n",
      "Step 2632, action: [0.8968784], terminated: False, reward: 161.27656284557762, Trade: 2535\n",
      "Step 2633, action: [0.7321754], terminated: False, reward: 161.26656284557762, Trade: 2536\n",
      "Step 2634, action: [-0.12780388], terminated: False, reward: 161.41734332402427, Trade: 2537\n",
      "Step 2635, action: [-0.25553498], terminated: False, reward: 161.55476645028415, Trade: 2538\n",
      "Step 2636, action: [-0.48310074], terminated: False, reward: 162.0163327823029, Trade: 2539\n",
      "Step 2637, action: [-0.08233913], terminated: False, reward: 161.98952554772822, Trade: 2540\n",
      "Step 2638, action: [-0.01628542], terminated: False, reward: 161.97952554772823, Trade: 2541\n",
      "Step 2639, action: [0.8245066], terminated: False, reward: 161.96952554772824, Trade: 2542\n",
      "Step 2640, action: [-0.42345682], terminated: False, reward: 161.43849022571524, Trade: 2543\n",
      "Step 2641, action: [-0.5288718], terminated: False, reward: 164.32625019964237, Trade: 2544\n",
      "Step 2642, action: [-0.45938405], terminated: False, reward: 164.46136827654533, Trade: 2545\n",
      "Step 2643, action: [-0.19157264], terminated: False, reward: 165.15929992292948, Trade: 2546\n",
      "Step 2644, action: [0.7941829], terminated: False, reward: 165.1492999229295, Trade: 2547\n",
      "Step 2645, action: [-0.78921497], terminated: False, reward: 165.19802761844366, Trade: 2548\n",
      "Step 2646, action: [0.11564846], terminated: False, reward: 165.18802761844367, Trade: 2549\n",
      "Step 2647, action: [0.17020331], terminated: False, reward: 165.17802761844368, Trade: 2550\n",
      "Step 2648, action: [0.8761587], terminated: False, reward: 165.1680276184437, Trade: 2551\n",
      "Step 2649, action: [-0.72320056], terminated: False, reward: 165.50939064270793, Trade: 2552\n",
      "Step 2650, action: [-0.97201896], terminated: False, reward: 190.06951856345609, Trade: 2553\n",
      "Step 2651, action: [-0.85446876], terminated: False, reward: 193.44019846013555, Trade: 2554\n",
      "Step 2652, action: [-0.6801341], terminated: False, reward: 193.44823530303245, Trade: 2555\n",
      "Step 2653, action: [-0.6528916], terminated: False, reward: 193.45219408264796, Trade: 2556\n",
      "Step 2654, action: [-0.53377575], terminated: False, reward: 193.49938507026553, Trade: 2557\n",
      "Step 2655, action: [0.55449116], terminated: False, reward: 193.48938507026554, Trade: 2558\n",
      "Step 2656, action: [0.2454897], terminated: False, reward: 193.47938507026555, Trade: 2559\n",
      "Step 2657, action: [0.82695484], terminated: False, reward: 193.46938507026556, Trade: 2560\n",
      "Step 2658, action: [0.46653405], terminated: False, reward: 193.45938507026557, Trade: 2561\n",
      "Step 2659, action: [0.6152147], terminated: False, reward: 193.44938507026558, Trade: 2562\n",
      "Step 2660, action: [-0.94580007], terminated: False, reward: 193.15977414969214, Trade: 2563\n",
      "Step 2661, action: [0.442901], terminated: False, reward: 193.14977414969215, Trade: 2564\n",
      "Step 2662, action: [-0.6210165], terminated: False, reward: 193.05623347939408, Trade: 2565\n",
      "Step 2663, action: [-0.42956054], terminated: False, reward: 192.861932643118, Trade: 2566\n",
      "Step 2664, action: [0.00583121], terminated: False, reward: 192.851932643118, Trade: 2567\n",
      "Step 2665, action: [-0.6970143], terminated: False, reward: 192.5381198047047, Trade: 2568\n",
      "Step 2666, action: [-0.26878357], terminated: False, reward: 192.54453098491044, Trade: 2569\n",
      "Step 2667, action: [-0.5086633], terminated: False, reward: 192.4501230456734, Trade: 2570\n",
      "Step 2668, action: [-0.82220185], terminated: False, reward: 190.87579331595896, Trade: 2571\n",
      "Step 2669, action: [-0.6149989], terminated: False, reward: 191.4427901390578, Trade: 2572\n",
      "Step 2670, action: [0.21361054], terminated: False, reward: 191.4327901390578, Trade: 2573\n",
      "Step 2671, action: [0.6921581], terminated: False, reward: 191.4227901390578, Trade: 2574\n",
      "Step 2672, action: [-0.65913516], terminated: False, reward: 188.97191328600516, Trade: 2575\n",
      "Step 2673, action: [0.7507983], terminated: False, reward: 188.96191328600517, Trade: 2576\n",
      "Step 2674, action: [-0.939679], terminated: False, reward: 188.46467788334795, Trade: 2577\n",
      "Step 2675, action: [-0.7674927], terminated: False, reward: 188.25333832951935, Trade: 2578\n",
      "Step 2676, action: [-0.9965839], terminated: False, reward: 186.7908620334593, Trade: 2579\n",
      "Step 2677, action: [0.5706266], terminated: False, reward: 186.7808620334593, Trade: 2580\n",
      "Step 2678, action: [0.9030696], terminated: False, reward: 186.7708620334593, Trade: 2581\n",
      "Step 2679, action: [-0.36551595], terminated: False, reward: 186.912977106362, Trade: 2582\n",
      "Step 2680, action: [-0.09218743], terminated: False, reward: 186.90297710636202, Trade: 2583\n",
      "Step 2681, action: [0.0507139], terminated: False, reward: 186.89297710636203, Trade: 2584\n",
      "Step 2682, action: [0.5412388], terminated: False, reward: 186.88297710636203, Trade: 2585\n",
      "Step 2683, action: [-0.6681869], terminated: False, reward: 185.3074739703799, Trade: 2586\n",
      "Step 2684, action: [0.38957623], terminated: False, reward: 185.2974739703799, Trade: 2587\n",
      "Step 2685, action: [0.40234596], terminated: False, reward: 185.28747397037992, Trade: 2588\n",
      "Step 2686, action: [-0.9702139], terminated: False, reward: 185.20040814741972, Trade: 2589\n",
      "Step 2687, action: [-0.48514748], terminated: False, reward: 185.35923102398235, Trade: 2590\n",
      "Step 2688, action: [0.2961666], terminated: False, reward: 185.34923102398236, Trade: 2591\n",
      "Step 2689, action: [0.5164042], terminated: False, reward: 185.33923102398236, Trade: 2592\n",
      "Step 2690, action: [0.9740225], terminated: False, reward: 185.32923102398237, Trade: 2593\n",
      "Step 2691, action: [0.81243944], terminated: False, reward: 185.31923102398238, Trade: 2594\n",
      "Step 2692, action: [0.76793456], terminated: False, reward: 185.3092310239824, Trade: 2595\n",
      "Step 2693, action: [0.7176354], terminated: False, reward: 185.2992310239824, Trade: 2596\n",
      "Step 2694, action: [0.3180408], terminated: False, reward: 185.18923102398242, Trade: 2596\n",
      "Step 2695, action: [0.64010566], terminated: False, reward: 185.17923102398242, Trade: 2597\n",
      "Step 2696, action: [-0.6728869], terminated: False, reward: 184.95580934680046, Trade: 2598\n",
      "Step 2697, action: [0.6425771], terminated: False, reward: 184.94580934680047, Trade: 2599\n",
      "Step 2698, action: [-0.6511792], terminated: False, reward: 184.6273064935761, Trade: 2600\n",
      "Step 2699, action: [-0.53003997], terminated: False, reward: 185.50923483386214, Trade: 2601\n",
      "Step 2700, action: [-0.29232374], terminated: False, reward: 185.13788951189292, Trade: 2602\n",
      "Step 2701, action: [0.43793562], terminated: False, reward: 185.12788951189293, Trade: 2603\n",
      "Step 2702, action: [-0.12077403], terminated: False, reward: 185.11401993284824, Trade: 2604\n",
      "Step 2703, action: [-0.27332312], terminated: False, reward: 185.08324192899255, Trade: 2605\n",
      "Step 2704, action: [0.5833255], terminated: False, reward: 185.07324192899256, Trade: 2606\n",
      "Step 2705, action: [-0.9140495], terminated: False, reward: 186.3735286760732, Trade: 2607\n",
      "Step 2706, action: [0.5477619], terminated: False, reward: 186.3635286760732, Trade: 2608\n",
      "Step 2707, action: [-0.8976152], terminated: False, reward: 186.56193145506913, Trade: 2609\n",
      "Step 2708, action: [0.52020544], terminated: False, reward: 186.55193145506914, Trade: 2610\n",
      "Step 2709, action: [0.8817386], terminated: False, reward: 186.54193145506915, Trade: 2611\n",
      "Step 2710, action: [0.40086386], terminated: False, reward: 186.53193145506916, Trade: 2612\n",
      "Step 2711, action: [0.6187806], terminated: False, reward: 186.52193145506916, Trade: 2613\n",
      "Step 2712, action: [0.18870035], terminated: False, reward: 186.51193145506917, Trade: 2614\n",
      "Step 2713, action: [0.5579185], terminated: False, reward: 186.50193145506918, Trade: 2615\n",
      "Step 2714, action: [-0.33258662], terminated: False, reward: 186.48951503219124, Trade: 2616\n",
      "Step 2715, action: [0.9104836], terminated: False, reward: 186.47951503219124, Trade: 2617\n",
      "Step 2716, action: [-0.22178768], terminated: False, reward: 186.44548156532232, Trade: 2618\n",
      "Step 2717, action: [0.93081385], terminated: False, reward: 186.43548156532233, Trade: 2619\n",
      "Step 2718, action: [0.40275842], terminated: False, reward: 186.42548156532234, Trade: 2620\n",
      "Step 2719, action: [0.6172271], terminated: False, reward: 186.41548156532235, Trade: 2621\n",
      "Step 2720, action: [-0.3631701], terminated: False, reward: 186.18757654224268, Trade: 2622\n",
      "Step 2721, action: [0.83907974], terminated: False, reward: 186.1775765422427, Trade: 2623\n",
      "Step 2722, action: [0.89091533], terminated: False, reward: 186.1675765422427, Trade: 2624\n",
      "Step 2723, action: [-0.4578908], terminated: False, reward: 186.16749961197593, Trade: 2625\n",
      "Step 2724, action: [-0.8380323], terminated: False, reward: 186.0242888661052, Trade: 2626\n",
      "Step 2725, action: [-0.6750208], terminated: False, reward: 185.96226828817063, Trade: 2627\n",
      "Step 2726, action: [-0.8938198], terminated: False, reward: 186.15021702674696, Trade: 2628\n",
      "Step 2727, action: [0.8025124], terminated: False, reward: 186.14021702674697, Trade: 2629\n",
      "Step 2728, action: [-0.76832324], terminated: False, reward: 185.83620033005866, Trade: 2630\n",
      "Step 2729, action: [0.9658108], terminated: False, reward: 185.82620033005867, Trade: 2631\n",
      "Step 2730, action: [-0.7192444], terminated: False, reward: 185.795242274898, Trade: 2632\n",
      "Step 2731, action: [-0.4558617], terminated: False, reward: 185.8049641473507, Trade: 2633\n",
      "Step 2732, action: [-0.69156605], terminated: False, reward: 186.07424127396115, Trade: 2634\n",
      "Step 2733, action: [-0.03934861], terminated: False, reward: 186.06843571685357, Trade: 2635\n",
      "Step 2734, action: [-0.43338037], terminated: False, reward: 187.24872470229965, Trade: 2636\n",
      "Step 2735, action: [-0.95349115], terminated: False, reward: 187.2722238828817, Trade: 2637\n",
      "Step 2736, action: [0.883609], terminated: False, reward: 187.2622238828817, Trade: 2638\n",
      "Step 2737, action: [-0.7525109], terminated: False, reward: 187.06940967850693, Trade: 2639\n",
      "Step 2738, action: [-0.9116514], terminated: False, reward: 187.51783006406026, Trade: 2640\n",
      "Step 2739, action: [0.808848], terminated: False, reward: 187.50783006406027, Trade: 2641\n",
      "Step 2740, action: [0.3423052], terminated: False, reward: 187.49783006406028, Trade: 2642\n",
      "Step 2741, action: [-0.0690151], terminated: False, reward: 187.47311944663045, Trade: 2643\n",
      "Step 2742, action: [-0.50098354], terminated: False, reward: 187.45930105182802, Trade: 2644\n",
      "Step 2743, action: [-0.5292727], terminated: False, reward: 187.60029525517197, Trade: 2645\n",
      "Step 2744, action: [-0.4548955], terminated: False, reward: 187.44734128219685, Trade: 2646\n",
      "Step 2745, action: [-0.6461861], terminated: False, reward: 188.8177329740045, Trade: 2647\n",
      "Step 2746, action: [-0.40845713], terminated: False, reward: 188.763633185333, Trade: 2648\n",
      "Step 2747, action: [0.00640795], terminated: False, reward: 188.753633185333, Trade: 2649\n",
      "Step 2748, action: [-0.66022825], terminated: False, reward: 188.5288990297075, Trade: 2650\n",
      "Step 2749, action: [0.4230056], terminated: False, reward: 188.5188990297075, Trade: 2651\n",
      "Step 2750, action: [0.09785967], terminated: False, reward: 188.50889902970752, Trade: 2652\n",
      "Step 2751, action: [-0.9844703], terminated: False, reward: 188.63112592902598, Trade: 2653\n",
      "Step 2752, action: [-0.37649524], terminated: False, reward: 188.61236688674626, Trade: 2654\n",
      "Step 2753, action: [0.6209002], terminated: False, reward: 188.60236688674627, Trade: 2655\n",
      "Step 2754, action: [0.09422235], terminated: False, reward: 188.59236688674628, Trade: 2656\n",
      "Step 2755, action: [0.03320224], terminated: False, reward: 188.58236688674629, Trade: 2657\n",
      "Step 2756, action: [0.957368], terminated: False, reward: 188.5723668867463, Trade: 2658\n",
      "Step 2757, action: [0.72044253], terminated: False, reward: 188.5623668867463, Trade: 2659\n",
      "Step 2758, action: [-0.7890309], terminated: False, reward: 188.54377317053547, Trade: 2660\n",
      "Step 2759, action: [-0.6401405], terminated: False, reward: 188.54613482506352, Trade: 2661\n",
      "Step 2760, action: [0.9797938], terminated: False, reward: 188.53613482506353, Trade: 2662\n",
      "Step 2761, action: [0.6329192], terminated: False, reward: 188.52613482506354, Trade: 2663\n",
      "Step 2762, action: [-0.1152605], terminated: False, reward: 188.5884889838093, Trade: 2664\n",
      "Step 2763, action: [0.5698618], terminated: False, reward: 188.5784889838093, Trade: 2665\n",
      "Step 2764, action: [0.53362525], terminated: False, reward: 188.56848898380932, Trade: 2666\n",
      "Step 2765, action: [0.70507956], terminated: False, reward: 188.55848898380933, Trade: 2667\n",
      "Step 2766, action: [0.3628288], terminated: False, reward: 188.54848898380934, Trade: 2668\n",
      "Step 2767, action: [-0.2993307], terminated: False, reward: 187.5153455510932, Trade: 2669\n",
      "Step 2768, action: [-0.9566326], terminated: False, reward: 189.99981664983775, Trade: 2670\n",
      "Step 2769, action: [0.7417602], terminated: False, reward: 189.98981664983776, Trade: 2671\n",
      "Step 2770, action: [-0.6625207], terminated: False, reward: 189.97660295983945, Trade: 2672\n",
      "Step 2771, action: [0.7391144], terminated: False, reward: 189.96660295983946, Trade: 2673\n",
      "Step 2772, action: [-0.37351403], terminated: False, reward: 189.90573877548786, Trade: 2674\n",
      "Step 2773, action: [-0.44565484], terminated: False, reward: 190.0823865043138, Trade: 2675\n",
      "Step 2774, action: [-0.37994313], terminated: False, reward: 190.1224656178727, Trade: 2676\n",
      "Step 2775, action: [0.72484785], terminated: False, reward: 190.11246561787272, Trade: 2677\n",
      "Step 2776, action: [0.7454258], terminated: False, reward: 190.10246561787272, Trade: 2678\n",
      "Step 2777, action: [-0.05600979], terminated: False, reward: 190.11710553881707, Trade: 2679\n",
      "Step 2778, action: [-0.8186719], terminated: False, reward: 190.16146757913617, Trade: 2680\n",
      "Step 2779, action: [-0.7752096], terminated: False, reward: 190.15591116843328, Trade: 2681\n",
      "Step 2780, action: [0.9557108], terminated: False, reward: 190.1459111684333, Trade: 2682\n",
      "Step 2781, action: [-0.8120402], terminated: False, reward: 189.49400616286886, Trade: 2683\n",
      "Step 2782, action: [0.93238837], terminated: False, reward: 189.48400616286887, Trade: 2684\n",
      "Step 2783, action: [-0.46606696], terminated: False, reward: 191.0166676290256, Trade: 2685\n",
      "Step 2784, action: [0.85452735], terminated: False, reward: 191.0066676290256, Trade: 2686\n",
      "Step 2785, action: [0.44636193], terminated: False, reward: 190.9966676290256, Trade: 2687\n",
      "Step 2786, action: [0.04179106], terminated: False, reward: 190.98666762902562, Trade: 2688\n",
      "Step 2787, action: [0.05052055], terminated: False, reward: 190.97666762902563, Trade: 2689\n",
      "Step 2788, action: [-0.17606455], terminated: False, reward: 191.0519379152316, Trade: 2690\n",
      "Step 2789, action: [0.9969138], terminated: False, reward: 191.0419379152316, Trade: 2691\n",
      "Step 2790, action: [-0.02075213], terminated: False, reward: 191.06272692121024, Trade: 2692\n",
      "Step 2791, action: [-0.05774492], terminated: False, reward: 191.05739683701395, Trade: 2693\n",
      "Step 2792, action: [-0.03048467], terminated: False, reward: 191.11967945780188, Trade: 2694\n",
      "Step 2793, action: [-0.19374393], terminated: False, reward: 191.09671311812775, Trade: 2695\n",
      "Step 2794, action: [0.85301447], terminated: False, reward: 191.08671311812776, Trade: 2696\n",
      "Step 2795, action: [-0.8006985], terminated: False, reward: 190.3249972395532, Trade: 2697\n",
      "Step 2796, action: [-0.403662], terminated: False, reward: 190.36756206596442, Trade: 2698\n",
      "Step 2797, action: [0.61142236], terminated: False, reward: 190.35756206596443, Trade: 2699\n",
      "Step 2798, action: [0.7974065], terminated: False, reward: 190.34756206596444, Trade: 2700\n",
      "Step 2799, action: [-0.13348074], terminated: False, reward: 190.30887801782052, Trade: 2701\n",
      "Step 2800, action: [-0.59596694], terminated: False, reward: 190.33648144289722, Trade: 2702\n",
      "Step 2801, action: [0.25430194], terminated: False, reward: 190.32648144289723, Trade: 2703\n",
      "Step 2802, action: [0.52815664], terminated: False, reward: 190.31648144289724, Trade: 2704\n",
      "Step 2803, action: [-0.22746545], terminated: False, reward: 190.26610215835453, Trade: 2705\n",
      "Step 2804, action: [-0.5435143], terminated: False, reward: 190.3342979289501, Trade: 2706\n",
      "Step 2805, action: [0.48617494], terminated: False, reward: 190.3242979289501, Trade: 2707\n",
      "Step 2806, action: [-0.66702044], terminated: False, reward: 190.34472847132272, Trade: 2708\n",
      "Step 2807, action: [0.31719655], terminated: False, reward: 190.33472847132273, Trade: 2709\n",
      "Step 2808, action: [-0.7816075], terminated: False, reward: 190.44676370690343, Trade: 2710\n",
      "Step 2809, action: [-0.45338768], terminated: False, reward: 190.4536778079989, Trade: 2711\n",
      "Step 2810, action: [-0.32119632], terminated: False, reward: 190.59352320410673, Trade: 2712\n",
      "Step 2811, action: [0.34612262], terminated: False, reward: 190.58352320410674, Trade: 2713\n",
      "Step 2812, action: [-0.07455052], terminated: False, reward: 190.66421189047253, Trade: 2714\n",
      "Step 2813, action: [-0.8354299], terminated: False, reward: 190.6979315456241, Trade: 2715\n",
      "Step 2814, action: [0.06033593], terminated: False, reward: 190.6879315456241, Trade: 2716\n",
      "Step 2815, action: [0.50358933], terminated: False, reward: 190.67793154562412, Trade: 2717\n",
      "Step 2816, action: [0.79593235], terminated: False, reward: 190.66793154562413, Trade: 2718\n",
      "Step 2817, action: [0.7302997], terminated: False, reward: 190.65793154562414, Trade: 2719\n",
      "Step 2818, action: [-0.79861915], terminated: False, reward: 191.43086286031763, Trade: 2720\n",
      "Step 2819, action: [0.86190295], terminated: False, reward: 191.42086286031764, Trade: 2721\n",
      "Step 2820, action: [0.6762531], terminated: False, reward: 191.41086286031765, Trade: 2722\n",
      "Step 2821, action: [-0.73005867], terminated: False, reward: 191.51250842106518, Trade: 2723\n",
      "Step 2822, action: [0.11739405], terminated: False, reward: 191.5025084210652, Trade: 2724\n",
      "Step 2823, action: [0.14991081], terminated: False, reward: 191.4925084210652, Trade: 2725\n",
      "Step 2824, action: [-0.8722695], terminated: False, reward: 191.56501486541083, Trade: 2726\n",
      "Step 2825, action: [0.96376264], terminated: False, reward: 191.55501486541084, Trade: 2727\n",
      "Step 2826, action: [-0.775669], terminated: False, reward: 191.6294440039299, Trade: 2728\n",
      "Step 2827, action: [0.5449827], terminated: False, reward: 191.6194440039299, Trade: 2729\n",
      "Step 2828, action: [0.79021424], terminated: False, reward: 191.60944400392992, Trade: 2730\n",
      "Step 2829, action: [0.01834149], terminated: False, reward: 191.49944400392994, Trade: 2730\n",
      "Step 2830, action: [-0.6690294], terminated: False, reward: 191.54979335758716, Trade: 2731\n",
      "Step 2831, action: [0.880827], terminated: False, reward: 191.53979335758717, Trade: 2732\n",
      "Step 2832, action: [0.25001267], terminated: False, reward: 191.52979335758718, Trade: 2733\n",
      "Step 2833, action: [0.38325843], terminated: False, reward: 191.5197933575872, Trade: 2734\n",
      "Step 2834, action: [-0.1551891], terminated: False, reward: 191.51295048126667, Trade: 2735\n",
      "Step 2835, action: [-0.8917283], terminated: False, reward: 191.578862621881, Trade: 2736\n",
      "Step 2836, action: [0.16749018], terminated: False, reward: 191.568862621881, Trade: 2737\n",
      "Step 2837, action: [-0.5594282], terminated: False, reward: 191.58087843429882, Trade: 2738\n",
      "Step 2838, action: [0.7752677], terminated: False, reward: 191.57087843429883, Trade: 2739\n",
      "Step 2839, action: [0.43154913], terminated: False, reward: 191.56087843429884, Trade: 2740\n",
      "Step 2840, action: [0.19428793], terminated: False, reward: 191.55087843429885, Trade: 2741\n",
      "Step 2841, action: [-0.33079267], terminated: False, reward: 191.6132459307081, Trade: 2742\n",
      "Step 2842, action: [-0.6576192], terminated: False, reward: 191.80129961269014, Trade: 2743\n",
      "Step 2843, action: [-0.79912484], terminated: False, reward: 191.6190487749349, Trade: 2744\n",
      "Step 2844, action: [0.27368888], terminated: False, reward: 191.6090487749349, Trade: 2745\n",
      "Step 2845, action: [0.90386134], terminated: False, reward: 191.59904877493491, Trade: 2746\n",
      "Step 2846, action: [0.75585115], terminated: False, reward: 191.58904877493492, Trade: 2747\n",
      "Step 2847, action: [-0.06293604], terminated: False, reward: 191.66628630770495, Trade: 2748\n",
      "Step 2848, action: [-0.497602], terminated: False, reward: 195.3547021142014, Trade: 2749\n",
      "Step 2849, action: [-0.46093166], terminated: False, reward: 195.36763305318934, Trade: 2750\n",
      "Step 2850, action: [0.3678823], terminated: False, reward: 195.35763305318935, Trade: 2751\n",
      "Step 2851, action: [-0.69344324], terminated: False, reward: 195.05887866622612, Trade: 2752\n",
      "Step 2852, action: [0.704436], terminated: False, reward: 195.04887866622613, Trade: 2753\n",
      "Step 2853, action: [0.3726242], terminated: False, reward: 195.03887866622614, Trade: 2754\n",
      "Step 2854, action: [-0.51739377], terminated: False, reward: 195.0619244624485, Trade: 2755\n",
      "Step 2855, action: [0.8239303], terminated: False, reward: 195.0519244624485, Trade: 2756\n",
      "Step 2856, action: [-0.4703144], terminated: False, reward: 195.08921220285293, Trade: 2757\n",
      "Step 2857, action: [-0.9666722], terminated: False, reward: 195.8822394886959, Trade: 2758\n",
      "Step 2858, action: [-0.5485729], terminated: False, reward: 195.9351348421126, Trade: 2759\n",
      "Step 2859, action: [0.19881293], terminated: False, reward: 195.9251348421126, Trade: 2760\n",
      "Step 2860, action: [-0.9758241], terminated: False, reward: 195.97748429963386, Trade: 2761\n",
      "Step 2861, action: [-0.21156871], terminated: False, reward: 196.75650663473652, Trade: 2762\n",
      "Step 2862, action: [0.03762924], terminated: False, reward: 196.74650663473653, Trade: 2763\n",
      "Step 2863, action: [0.85201], terminated: False, reward: 196.73650663473654, Trade: 2764\n",
      "Step 2864, action: [0.10209545], terminated: False, reward: 196.72650663473655, Trade: 2765\n",
      "Step 2865, action: [0.2377037], terminated: False, reward: 196.71650663473656, Trade: 2766\n",
      "Step 2866, action: [-0.94768703], terminated: False, reward: 197.46981961419647, Trade: 2767\n",
      "Step 2867, action: [-0.95702785], terminated: False, reward: 201.69974906362808, Trade: 2768\n",
      "Step 2868, action: [-0.40484887], terminated: False, reward: 202.45301649536455, Trade: 2769\n",
      "Step 2869, action: [-0.42828867], terminated: False, reward: 202.69721322170656, Trade: 2770\n",
      "Step 2870, action: [-0.43972436], terminated: False, reward: 202.71999134117456, Trade: 2771\n",
      "Step 2871, action: [-0.60289013], terminated: False, reward: 202.5760279156024, Trade: 2772\n",
      "Step 2872, action: [0.9939772], terminated: False, reward: 202.5660279156024, Trade: 2773\n",
      "Step 2873, action: [-0.2919618], terminated: False, reward: 202.41786292766915, Trade: 2774\n",
      "Step 2874, action: [-0.5280682], terminated: False, reward: 202.5361585653281, Trade: 2775\n",
      "Step 2875, action: [-0.7237778], terminated: False, reward: 201.38992903285285, Trade: 2776\n",
      "Step 2876, action: [-0.6875599], terminated: False, reward: 202.14092314661764, Trade: 2777\n",
      "Step 2877, action: [0.46424204], terminated: False, reward: 202.13092314661765, Trade: 2778\n",
      "Step 2878, action: [-0.14121427], terminated: False, reward: 202.00228659826217, Trade: 2779\n",
      "Step 2879, action: [0.6052375], terminated: False, reward: 201.99228659826218, Trade: 2780\n",
      "Step 2880, action: [-0.68787205], terminated: False, reward: 200.81044782864905, Trade: 2781\n",
      "Step 2881, action: [0.35496208], terminated: False, reward: 200.80044782864906, Trade: 2782\n",
      "Step 2882, action: [0.745238], terminated: False, reward: 200.79044782864906, Trade: 2783\n",
      "Step 2883, action: [0.85098535], terminated: False, reward: 200.78044782864907, Trade: 2784\n",
      "Step 2884, action: [-0.9444489], terminated: False, reward: 200.83629083107704, Trade: 2785\n",
      "Step 2885, action: [-0.0871676], terminated: False, reward: 200.82766461991469, Trade: 2786\n",
      "Step 2886, action: [0.5028937], terminated: False, reward: 200.8176646199147, Trade: 2787\n",
      "Step 2887, action: [-0.984967], terminated: False, reward: 202.62781474286658, Trade: 2788\n",
      "Step 2888, action: [0.723888], terminated: False, reward: 202.61781474286659, Trade: 2789\n",
      "Step 2889, action: [-0.87485343], terminated: False, reward: 205.80377505462724, Trade: 2790\n",
      "Step 2890, action: [0.29025197], terminated: False, reward: 205.79377505462725, Trade: 2791\n",
      "Step 2891, action: [-0.22809124], terminated: False, reward: 205.44985109091314, Trade: 2792\n",
      "Step 2892, action: [-0.77206445], terminated: False, reward: 205.5638086878614, Trade: 2793\n",
      "Step 2893, action: [-0.41343328], terminated: False, reward: 205.54042022572108, Trade: 2794\n",
      "Step 2894, action: [0.5254237], terminated: False, reward: 205.5304202257211, Trade: 2795\n",
      "Step 2895, action: [0.07691467], terminated: False, reward: 205.5204202257211, Trade: 2796\n",
      "Step 2896, action: [-0.5152964], terminated: False, reward: 206.66609426517337, Trade: 2797\n",
      "Step 2897, action: [0.98827744], terminated: False, reward: 206.65609426517338, Trade: 2798\n",
      "Step 2898, action: [-0.9033811], terminated: False, reward: 206.73086023296386, Trade: 2799\n",
      "Step 2899, action: [0.7629731], terminated: False, reward: 206.72086023296387, Trade: 2800\n",
      "Step 2900, action: [-0.4296701], terminated: False, reward: 209.41660447343506, Trade: 2801\n",
      "Step 2901, action: [0.8586751], terminated: False, reward: 209.40660447343507, Trade: 2802\n",
      "Step 2902, action: [-0.9189101], terminated: False, reward: 209.4633942674606, Trade: 2803\n",
      "Step 2903, action: [-0.9872139], terminated: False, reward: 209.3988958432293, Trade: 2804\n",
      "Step 2904, action: [-0.19652078], terminated: False, reward: 209.4974156935736, Trade: 2805\n",
      "Step 2905, action: [0.21194966], terminated: False, reward: 209.4874156935736, Trade: 2806\n",
      "Step 2906, action: [-0.01222098], terminated: False, reward: 209.47575814894202, Trade: 2807\n",
      "Step 2907, action: [0.6094609], terminated: False, reward: 209.46575814894203, Trade: 2808\n",
      "Step 2908, action: [0.7288436], terminated: False, reward: 209.45575814894204, Trade: 2809\n",
      "Step 2909, action: [-0.6785183], terminated: False, reward: 211.58651794685616, Trade: 2810\n",
      "Step 2910, action: [-0.4744713], terminated: False, reward: 211.81799061511978, Trade: 2811\n",
      "Step 2911, action: [-0.7135171], terminated: False, reward: 212.07838930659267, Trade: 2812\n",
      "Step 2912, action: [-0.70895296], terminated: False, reward: 212.07375001826233, Trade: 2813\n",
      "Step 2913, action: [0.4370875], terminated: False, reward: 212.06375001826234, Trade: 2814\n",
      "Step 2914, action: [-0.95315945], terminated: False, reward: 212.23138772375145, Trade: 2815\n",
      "Step 2915, action: [0.8927237], terminated: False, reward: 212.22138772375146, Trade: 2816\n",
      "Step 2916, action: [0.37362036], terminated: False, reward: 212.21138772375147, Trade: 2817\n",
      "Step 2917, action: [0.618852], terminated: False, reward: 212.20138772375148, Trade: 2818\n",
      "Step 2918, action: [0.74455506], terminated: False, reward: 212.1913877237515, Trade: 2819\n",
      "Step 2919, action: [-0.06071566], terminated: False, reward: 212.11510373181912, Trade: 2820\n",
      "Step 2920, action: [-0.6799829], terminated: False, reward: 212.14485614722602, Trade: 2821\n",
      "Step 2921, action: [0.58637714], terminated: False, reward: 212.13485614722603, Trade: 2822\n",
      "Step 2922, action: [-0.16626301], terminated: False, reward: 212.2767038226166, Trade: 2823\n",
      "Step 2923, action: [-0.1163587], terminated: False, reward: 212.2842205082333, Trade: 2824\n",
      "Step 2924, action: [-0.6015243], terminated: False, reward: 213.173548372835, Trade: 2825\n",
      "Step 2925, action: [-0.4506568], terminated: False, reward: 214.12861119276013, Trade: 2826\n",
      "Step 2926, action: [0.6529789], terminated: False, reward: 214.11861119276014, Trade: 2827\n",
      "Step 2927, action: [0.35451108], terminated: False, reward: 214.10861119276015, Trade: 2828\n",
      "Step 2928, action: [0.6378445], terminated: False, reward: 214.09861119276016, Trade: 2829\n",
      "Step 2929, action: [-0.0933125], terminated: False, reward: 213.44634779334928, Trade: 2830\n",
      "Step 2930, action: [-0.7907913], terminated: False, reward: 213.43116849883475, Trade: 2831\n",
      "Step 2931, action: [0.5751427], terminated: False, reward: 213.42116849883476, Trade: 2832\n",
      "Step 2932, action: [0.26619014], terminated: False, reward: 213.41116849883477, Trade: 2833\n",
      "Step 2933, action: [-0.25820002], terminated: False, reward: 213.1394250827283, Trade: 2834\n",
      "Step 2934, action: [0.6744499], terminated: False, reward: 213.12942508272832, Trade: 2835\n",
      "Step 2935, action: [-0.78253794], terminated: False, reward: 210.0508491649018, Trade: 2836\n",
      "Step 2936, action: [0.37509745], terminated: False, reward: 210.0408491649018, Trade: 2837\n",
      "Step 2937, action: [-0.5981045], terminated: False, reward: 208.94230364726002, Trade: 2838\n",
      "Step 2938, action: [0.4550114], terminated: False, reward: 208.93230364726003, Trade: 2839\n",
      "Step 2939, action: [-0.72836137], terminated: False, reward: 208.85451199287147, Trade: 2840\n",
      "Step 2940, action: [-0.38118258], terminated: False, reward: 208.84451199287147, Trade: 2841\n",
      "Step 2941, action: [-0.3241416], terminated: False, reward: 207.52471105404058, Trade: 2842\n",
      "Step 2942, action: [-0.12778407], terminated: False, reward: 207.51508206007293, Trade: 2843\n",
      "Step 2943, action: [0.81324893], terminated: False, reward: 207.50508206007294, Trade: 2844\n",
      "Step 2944, action: [-0.7822511], terminated: False, reward: 207.4612015476635, Trade: 2845\n",
      "Step 2945, action: [0.19712573], terminated: False, reward: 207.45120154766352, Trade: 2846\n",
      "Step 2946, action: [0.4541448], terminated: False, reward: 207.44120154766352, Trade: 2847\n",
      "Step 2947, action: [-0.86992425], terminated: False, reward: 206.4400695231445, Trade: 2848\n",
      "Step 2948, action: [-0.1715609], terminated: False, reward: 206.4323579672921, Trade: 2849\n",
      "Step 2949, action: [-0.8054132], terminated: False, reward: 206.34734050830673, Trade: 2850\n",
      "Step 2950, action: [-0.16054794], terminated: False, reward: 206.27502483703893, Trade: 2851\n",
      "Step 2951, action: [-0.27200222], terminated: False, reward: 206.27431422363043, Trade: 2852\n",
      "Step 2952, action: [-0.08604544], terminated: False, reward: 206.29783138058147, Trade: 2853\n",
      "Step 2953, action: [-0.3158934], terminated: False, reward: 205.90750085350066, Trade: 2854\n",
      "Step 2954, action: [-0.15008268], terminated: False, reward: 205.82705416010984, Trade: 2855\n",
      "Step 2955, action: [0.18167068], terminated: False, reward: 205.81705416010985, Trade: 2856\n",
      "Step 2956, action: [-0.34056047], terminated: False, reward: 205.1898004897644, Trade: 2857\n",
      "Step 2957, action: [-0.80777663], terminated: False, reward: 202.93576245862965, Trade: 2858\n",
      "Step 2958, action: [0.44231144], terminated: False, reward: 202.92576245862966, Trade: 2859\n",
      "Step 2959, action: [0.87372357], terminated: False, reward: 202.91576245862967, Trade: 2860\n",
      "Step 2960, action: [0.29449588], terminated: False, reward: 202.90576245862968, Trade: 2861\n",
      "Step 2961, action: [0.64097065], terminated: False, reward: 202.8957624586297, Trade: 2862\n",
      "Step 2962, action: [0.82076997], terminated: False, reward: 202.8857624586297, Trade: 2863\n",
      "Step 2963, action: [0.27023846], terminated: False, reward: 202.8757624586297, Trade: 2864\n",
      "Step 2964, action: [0.8838369], terminated: False, reward: 202.86576245862972, Trade: 2865\n",
      "Step 2965, action: [-0.8294836], terminated: False, reward: 202.9923236673477, Trade: 2866\n",
      "Step 2966, action: [-0.5639355], terminated: False, reward: 204.40713540202208, Trade: 2867\n",
      "Step 2967, action: [0.51499027], terminated: False, reward: 204.3971354020221, Trade: 2868\n",
      "Step 2968, action: [0.77686745], terminated: False, reward: 204.3871354020221, Trade: 2869\n",
      "Step 2969, action: [-0.49108124], terminated: False, reward: 203.69882033755877, Trade: 2870\n",
      "Step 2970, action: [0.56504744], terminated: False, reward: 203.68882033755878, Trade: 2871\n",
      "Step 2971, action: [0.61691475], terminated: False, reward: 203.6788203375588, Trade: 2872\n",
      "Step 2972, action: [-0.7578122], terminated: False, reward: 203.79895845435667, Trade: 2873\n",
      "Step 2973, action: [0.08482147], terminated: False, reward: 203.78895845435667, Trade: 2874\n",
      "Step 2974, action: [-0.06896693], terminated: False, reward: 203.77635899457553, Trade: 2875\n",
      "Step 2975, action: [0.37245813], terminated: False, reward: 203.76635899457554, Trade: 2876\n",
      "Step 2976, action: [0.27038795], terminated: False, reward: 203.75635899457555, Trade: 2877\n",
      "Step 2977, action: [-0.14884715], terminated: False, reward: 203.74552804484966, Trade: 2878\n",
      "Step 2978, action: [0.46297607], terminated: False, reward: 203.73552804484967, Trade: 2879\n",
      "Step 2979, action: [0.05966537], terminated: False, reward: 203.72552804484968, Trade: 2880\n",
      "Step 2980, action: [-0.9270899], terminated: False, reward: 204.0203513974578, Trade: 2881\n",
      "Step 2981, action: [-0.7522273], terminated: False, reward: 203.68470025711255, Trade: 2882\n",
      "Step 2982, action: [-0.85897475], terminated: False, reward: 203.56114077331586, Trade: 2883\n",
      "Step 2983, action: [-0.797048], terminated: False, reward: 203.41552938461172, Trade: 2884\n",
      "Step 2984, action: [0.8001409], terminated: False, reward: 203.40552938461173, Trade: 2885\n",
      "Step 2985, action: [-0.57224494], terminated: False, reward: 203.33737077633583, Trade: 2886\n",
      "Step 2986, action: [-0.04695255], terminated: False, reward: 203.54590652023813, Trade: 2887\n",
      "Step 2987, action: [-0.99808496], terminated: False, reward: 204.8958683783851, Trade: 2888\n",
      "Step 2988, action: [0.566919], terminated: False, reward: 204.8858683783851, Trade: 2889\n",
      "Step 2989, action: [0.22994304], terminated: False, reward: 204.87586837838512, Trade: 2890\n",
      "Step 2990, action: [-0.6669231], terminated: False, reward: 205.18441160139176, Trade: 2891\n",
      "Step 2991, action: [0.5112022], terminated: False, reward: 205.17441160139177, Trade: 2892\n",
      "Step 2992, action: [0.71044], terminated: False, reward: 205.16441160139178, Trade: 2893\n",
      "Step 2993, action: [-0.08272913], terminated: False, reward: 205.16880668541037, Trade: 2894\n",
      "Step 2994, action: [-0.9150626], terminated: False, reward: 206.43568753606223, Trade: 2895\n",
      "Step 2995, action: [0.36543432], terminated: False, reward: 206.42568753606224, Trade: 2896\n",
      "Step 2996, action: [-0.24076302], terminated: False, reward: 206.4712950941688, Trade: 2897\n",
      "Step 2997, action: [-0.47692868], terminated: False, reward: 206.16796775636462, Trade: 2898\n",
      "Step 2998, action: [0.8223123], terminated: False, reward: 206.15796775636463, Trade: 2899\n",
      "Step 2999, action: [0.97948164], terminated: False, reward: 206.14796775636464, Trade: 2900\n",
      "Step 3000, action: [0.8804161], terminated: False, reward: 206.13796775636465, Trade: 2901\n",
      "Step 3001, action: [-0.7573857], terminated: False, reward: 206.9152508058131, Trade: 2902\n",
      "Step 3002, action: [0.76576036], terminated: False, reward: 206.9052508058131, Trade: 2903\n",
      "Step 3003, action: [0.16438444], terminated: False, reward: 206.8952508058131, Trade: 2904\n",
      "Step 3004, action: [0.7173568], terminated: False, reward: 206.88525080581311, Trade: 2905\n",
      "Step 3005, action: [0.780979], terminated: False, reward: 206.87525080581312, Trade: 2906\n",
      "Step 3006, action: [0.5285821], terminated: False, reward: 206.86525080581313, Trade: 2907\n",
      "Step 3007, action: [-0.61452067], terminated: False, reward: 206.9552410556204, Trade: 2908\n",
      "Step 3008, action: [-0.29579192], terminated: False, reward: 206.95416890438293, Trade: 2909\n",
      "Step 3009, action: [-0.98077494], terminated: False, reward: 206.82391183369563, Trade: 2910\n",
      "Step 3010, action: [-0.08850403], terminated: False, reward: 206.81615384967873, Trade: 2911\n",
      "Step 3011, action: [-0.2112558], terminated: False, reward: 206.83681812189795, Trade: 2912\n",
      "Step 3012, action: [0.47625846], terminated: False, reward: 206.82681812189796, Trade: 2913\n",
      "Step 3013, action: [0.55420744], terminated: False, reward: 206.81681812189797, Trade: 2914\n",
      "Step 3014, action: [0.6204641], terminated: False, reward: 206.80681812189798, Trade: 2915\n",
      "Step 3015, action: [-0.4383397], terminated: False, reward: 206.7975694949875, Trade: 2916\n",
      "Step 3016, action: [0.37650055], terminated: False, reward: 206.7875694949875, Trade: 2917\n",
      "Step 3017, action: [0.12561324], terminated: False, reward: 206.77756949498752, Trade: 2918\n",
      "Step 3018, action: [0.34171787], terminated: False, reward: 206.76756949498753, Trade: 2919\n",
      "Step 3019, action: [-0.42495307], terminated: False, reward: 206.4508183401642, Trade: 2920\n",
      "Step 3020, action: [0.65434057], terminated: False, reward: 206.4408183401642, Trade: 2921\n",
      "Step 3021, action: [0.53609097], terminated: False, reward: 206.43081834016422, Trade: 2922\n",
      "Step 3022, action: [-0.4650934], terminated: False, reward: 206.4818958356398, Trade: 2923\n",
      "Step 3023, action: [0.31647453], terminated: False, reward: 206.4718958356398, Trade: 2924\n",
      "Step 3024, action: [0.96034247], terminated: False, reward: 206.4618958356398, Trade: 2925\n",
      "Step 3025, action: [0.12026571], terminated: False, reward: 206.35189583563982, Trade: 2925\n",
      "Step 3026, action: [0.3963844], terminated: False, reward: 206.34189583563983, Trade: 2926\n",
      "Step 3027, action: [0.76484835], terminated: False, reward: 206.33189583563984, Trade: 2927\n",
      "Step 3028, action: [-0.38500437], terminated: False, reward: 206.3529419670838, Trade: 2928\n",
      "Step 3029, action: [0.6279365], terminated: False, reward: 206.34294196708382, Trade: 2929\n",
      "Step 3030, action: [0.556873], terminated: False, reward: 206.33294196708383, Trade: 2930\n",
      "Step 3031, action: [0.6147939], terminated: False, reward: 206.32294196708384, Trade: 2931\n",
      "Step 3032, action: [-0.515277], terminated: False, reward: 206.3894497421738, Trade: 2932\n",
      "Step 3033, action: [0.44832352], terminated: False, reward: 206.37944974217382, Trade: 2933\n",
      "Step 3034, action: [0.87198275], terminated: False, reward: 206.36944974217383, Trade: 2934\n",
      "Step 3035, action: [-0.16430026], terminated: False, reward: 206.3726034379853, Trade: 2935\n",
      "Step 3036, action: [0.6633079], terminated: False, reward: 206.3626034379853, Trade: 2936\n",
      "Step 3037, action: [-0.9520218], terminated: False, reward: 206.3464874079844, Trade: 2937\n",
      "Step 3038, action: [0.2008355], terminated: False, reward: 206.3364874079844, Trade: 2938\n",
      "Step 3039, action: [-0.17131132], terminated: False, reward: 206.36152499300061, Trade: 2939\n",
      "Step 3040, action: [0.47544715], terminated: False, reward: 206.35152499300062, Trade: 2940\n",
      "Step 3041, action: [0.24879202], terminated: False, reward: 206.34152499300063, Trade: 2941\n",
      "Step 3042, action: [0.39531848], terminated: False, reward: 206.33152499300064, Trade: 2942\n",
      "Step 3043, action: [-0.60140145], terminated: False, reward: 206.32287207371044, Trade: 2943\n",
      "Step 3044, action: [0.13802484], terminated: False, reward: 206.31287207371045, Trade: 2944\n",
      "Step 3045, action: [-0.38471588], terminated: False, reward: 207.7673787700705, Trade: 2945\n",
      "Step 3046, action: [-0.9445502], terminated: False, reward: 207.92372531176642, Trade: 2946\n",
      "Step 3047, action: [0.01760911], terminated: False, reward: 207.91372531176643, Trade: 2947\n",
      "Step 3048, action: [0.25389397], terminated: False, reward: 207.90372531176644, Trade: 2948\n",
      "Step 3049, action: [-0.1658698], terminated: False, reward: 207.98078848034058, Trade: 2949\n",
      "Step 3050, action: [-0.82120335], terminated: False, reward: 208.0259724289986, Trade: 2950\n",
      "Step 3051, action: [-0.9366973], terminated: False, reward: 208.7353921313912, Trade: 2951\n",
      "Step 3052, action: [0.7571453], terminated: False, reward: 208.7253921313912, Trade: 2952\n",
      "Step 3053, action: [-0.7967911], terminated: False, reward: 208.9998934981981, Trade: 2953\n",
      "Step 3054, action: [-0.8748586], terminated: False, reward: 210.06146769401738, Trade: 2954\n",
      "Step 3055, action: [-0.2044772], terminated: False, reward: 211.09949302992945, Trade: 2955\n",
      "Step 3056, action: [0.9263136], terminated: False, reward: 211.08949302992946, Trade: 2956\n",
      "Step 3057, action: [0.81486547], terminated: False, reward: 211.07949302992947, Trade: 2957\n",
      "Step 3058, action: [-0.11345088], terminated: False, reward: 211.5493592423363, Trade: 2958\n",
      "Step 3059, action: [-0.8405052], terminated: False, reward: 211.7156228225053, Trade: 2959\n",
      "Step 3060, action: [0.591102], terminated: False, reward: 211.70562282250532, Trade: 2960\n",
      "Step 3061, action: [-0.7881724], terminated: False, reward: 211.75514028319063, Trade: 2961\n",
      "Step 3062, action: [-0.09550325], terminated: False, reward: 211.65207173901806, Trade: 2962\n",
      "Step 3063, action: [-0.01593284], terminated: False, reward: 211.64207173901806, Trade: 2963\n",
      "Step 3064, action: [0.38333228], terminated: False, reward: 211.63207173901807, Trade: 2964\n",
      "Step 3065, action: [-0.41046074], terminated: False, reward: 211.62207173901808, Trade: 2965\n",
      "Step 3066, action: [0.7329065], terminated: False, reward: 211.6120717390181, Trade: 2966\n",
      "Step 3067, action: [-0.40307468], terminated: False, reward: 211.60027691167912, Trade: 2967\n",
      "Step 3068, action: [0.27479243], terminated: False, reward: 211.59027691167913, Trade: 2968\n",
      "Step 3069, action: [-0.29095474], terminated: False, reward: 211.65998076834165, Trade: 2969\n",
      "Step 3070, action: [-0.19805188], terminated: False, reward: 211.0083421321636, Trade: 2970\n",
      "Step 3071, action: [0.73054796], terminated: False, reward: 210.9983421321636, Trade: 2971\n",
      "Step 3072, action: [-0.8943958], terminated: False, reward: 209.68145078966427, Trade: 2972\n",
      "Step 3073, action: [-0.33881122], terminated: False, reward: 210.11576622678422, Trade: 2973\n",
      "Step 3074, action: [-0.42919904], terminated: False, reward: 210.10520348123407, Trade: 2974\n",
      "Step 3075, action: [-0.13267839], terminated: False, reward: 209.97898286821504, Trade: 2975\n",
      "Step 3076, action: [0.47421804], terminated: False, reward: 209.96898286821505, Trade: 2976\n",
      "Step 3077, action: [-0.43909383], terminated: False, reward: 210.08691250300566, Trade: 2977\n",
      "Step 3078, action: [-0.5900044], terminated: False, reward: 210.0815554189293, Trade: 2978\n",
      "Step 3079, action: [-0.5227182], terminated: False, reward: 210.02696398622052, Trade: 2979\n",
      "Step 3080, action: [-0.617823], terminated: False, reward: 209.1778223729994, Trade: 2980\n",
      "Step 3081, action: [-0.9116408], terminated: False, reward: 209.13238866972202, Trade: 2981\n",
      "Step 3082, action: [0.12286792], terminated: False, reward: 209.12238866972203, Trade: 2982\n",
      "Step 3083, action: [0.71519154], terminated: False, reward: 209.11238866972204, Trade: 2983\n",
      "Step 3084, action: [-0.39025983], terminated: False, reward: 206.73100282832323, Trade: 2984\n",
      "Step 3085, action: [-0.62566644], terminated: False, reward: 206.855518989312, Trade: 2985\n",
      "Step 3086, action: [-0.7437411], terminated: False, reward: 208.89856226247613, Trade: 2986\n",
      "Step 3087, action: [-0.8404807], terminated: False, reward: 208.85708431464096, Trade: 2987\n",
      "Step 3088, action: [0.23557752], terminated: False, reward: 208.84708431464097, Trade: 2988\n",
      "Step 3089, action: [-0.9065454], terminated: False, reward: 208.85410636078382, Trade: 2989\n",
      "Step 3090, action: [-0.5640701], terminated: False, reward: 208.50955850943367, Trade: 2990\n",
      "Step 3091, action: [-0.5153718], terminated: False, reward: 208.5436711768617, Trade: 2991\n",
      "Step 3092, action: [0.48453054], terminated: False, reward: 208.5336711768617, Trade: 2992\n",
      "Step 3093, action: [0.15185502], terminated: False, reward: 208.5236711768617, Trade: 2993\n",
      "Step 3094, action: [0.03100287], terminated: False, reward: 208.51367117686172, Trade: 2994\n",
      "Step 3095, action: [-0.7763134], terminated: False, reward: 208.57605357979142, Trade: 2995\n",
      "Step 3096, action: [-0.76678693], terminated: False, reward: 207.33001798050014, Trade: 2996\n",
      "Step 3097, action: [0.0101443], terminated: False, reward: 207.32001798050015, Trade: 2997\n",
      "Step 3098, action: [-0.21441856], terminated: False, reward: 207.06314719675768, Trade: 2998\n",
      "Step 3099, action: [0.6333411], terminated: False, reward: 207.0531471967577, Trade: 2999\n",
      "Step 3100, action: [0.9448818], terminated: False, reward: 207.0431471967577, Trade: 3000\n",
      "Step 3101, action: [-0.33588475], terminated: False, reward: 207.48213977481387, Trade: 3001\n",
      "Step 3102, action: [-0.08059992], terminated: False, reward: 207.4729495604175, Trade: 3002\n",
      "Step 3103, action: [-0.73678803], terminated: False, reward: 207.6321326049229, Trade: 3003\n",
      "Step 3104, action: [-0.74641806], terminated: False, reward: 211.60637501946496, Trade: 3004\n",
      "Step 3105, action: [0.757894], terminated: False, reward: 211.59637501946497, Trade: 3005\n",
      "Step 3106, action: [-0.660921], terminated: False, reward: 211.58836395840834, Trade: 3006\n",
      "Step 3107, action: [0.9966099], terminated: False, reward: 211.57836395840835, Trade: 3007\n",
      "Step 3108, action: [-0.06003122], terminated: False, reward: 211.5722720835056, Trade: 3008\n",
      "Step 3109, action: [-0.0186924], terminated: False, reward: 211.5622720835056, Trade: 3009\n",
      "Step 3110, action: [-0.6307796], terminated: False, reward: 211.84929155571166, Trade: 3010\n",
      "Step 3111, action: [0.4728219], terminated: False, reward: 211.83929155571167, Trade: 3011\n",
      "Step 3112, action: [-0.5106315], terminated: False, reward: 210.8428176649875, Trade: 3012\n",
      "Step 3113, action: [0.6913841], terminated: False, reward: 210.83281766498752, Trade: 3013\n",
      "Step 3114, action: [0.13721557], terminated: False, reward: 210.82281766498753, Trade: 3014\n",
      "Step 3115, action: [-0.7286977], terminated: False, reward: 210.81380158244292, Trade: 3015\n",
      "Step 3116, action: [0.14392227], terminated: False, reward: 210.80380158244293, Trade: 3016\n",
      "Step 3117, action: [0.90045387], terminated: False, reward: 210.79380158244294, Trade: 3017\n",
      "Step 3118, action: [-0.29672262], terminated: False, reward: 210.72239517135915, Trade: 3018\n",
      "Step 3119, action: [0.50544244], terminated: False, reward: 210.71239517135916, Trade: 3019\n",
      "Step 3120, action: [-0.89722246], terminated: False, reward: 211.50502877865665, Trade: 3020\n",
      "Step 3121, action: [-0.7703831], terminated: False, reward: 211.72594529922793, Trade: 3021\n",
      "Step 3122, action: [-0.6910438], terminated: False, reward: 211.98043766431815, Trade: 3022\n",
      "Step 3123, action: [0.6866198], terminated: False, reward: 211.97043766431815, Trade: 3023\n",
      "Step 3124, action: [0.50546306], terminated: False, reward: 211.96043766431816, Trade: 3024\n",
      "Step 3125, action: [-0.9261824], terminated: False, reward: 212.43680188746413, Trade: 3025\n",
      "Step 3126, action: [-0.55619705], terminated: False, reward: 211.27300081323995, Trade: 3026\n",
      "Step 3127, action: [-0.8684603], terminated: False, reward: 210.8632032350547, Trade: 3027\n",
      "Step 3128, action: [-0.10810531], terminated: False, reward: 210.88399485226253, Trade: 3028\n",
      "Step 3129, action: [-0.8160503], terminated: False, reward: 211.6947197480246, Trade: 3029\n",
      "Step 3130, action: [0.59761494], terminated: False, reward: 211.6847197480246, Trade: 3030\n",
      "Step 3131, action: [0.5075504], terminated: False, reward: 211.67471974802461, Trade: 3031\n",
      "Step 3132, action: [-0.96204966], terminated: False, reward: 213.3162316462535, Trade: 3032\n",
      "Step 3133, action: [0.34720853], terminated: False, reward: 213.3062316462535, Trade: 3033\n",
      "Step 3134, action: [0.02847155], terminated: False, reward: 213.29623164625352, Trade: 3034\n",
      "Step 3135, action: [-0.6798264], terminated: False, reward: 213.75256146939918, Trade: 3035\n",
      "Step 3136, action: [-0.10152961], terminated: False, reward: 213.68675886126815, Trade: 3036\n",
      "Step 3137, action: [0.77789575], terminated: False, reward: 213.67675886126815, Trade: 3037\n",
      "Step 3138, action: [-0.42192894], terminated: False, reward: 213.7790351769297, Trade: 3038\n",
      "Step 3139, action: [0.49053082], terminated: False, reward: 213.76903517692972, Trade: 3039\n",
      "Step 3140, action: [-0.44131365], terminated: False, reward: 213.38124985265952, Trade: 3040\n",
      "Step 3141, action: [0.23306887], terminated: False, reward: 213.37124985265953, Trade: 3041\n",
      "Step 3142, action: [-0.87135947], terminated: False, reward: 214.42342622886275, Trade: 3042\n",
      "Step 3143, action: [-0.43510723], terminated: False, reward: 214.4137470224044, Trade: 3043\n",
      "Step 3144, action: [-0.6922158], terminated: False, reward: 215.90241837297572, Trade: 3044\n",
      "Step 3145, action: [-0.04200948], terminated: False, reward: 215.89007941067908, Trade: 3045\n",
      "Step 3146, action: [0.5573715], terminated: False, reward: 215.8800794106791, Trade: 3046\n",
      "Step 3147, action: [-0.14446384], terminated: False, reward: 215.88270688027313, Trade: 3047\n",
      "Step 3148, action: [-0.02850858], terminated: False, reward: 215.87397058780482, Trade: 3048\n",
      "Step 3149, action: [0.19971918], terminated: False, reward: 215.86397058780483, Trade: 3049\n",
      "Step 3150, action: [0.94538593], terminated: False, reward: 215.85397058780484, Trade: 3050\n",
      "Step 3151, action: [0.5059038], terminated: False, reward: 215.84397058780485, Trade: 3051\n",
      "Step 3152, action: [-0.19357468], terminated: False, reward: 216.1933504520761, Trade: 3052\n",
      "Step 3153, action: [0.61746377], terminated: False, reward: 216.1833504520761, Trade: 3053\n",
      "Step 3154, action: [-0.15812331], terminated: False, reward: 216.1190712777906, Trade: 3054\n",
      "Step 3155, action: [0.20664054], terminated: False, reward: 216.1090712777906, Trade: 3055\n",
      "Step 3156, action: [-0.8335576], terminated: False, reward: 216.50372984846172, Trade: 3056\n",
      "Step 3157, action: [-0.10694505], terminated: False, reward: 216.49387425835516, Trade: 3057\n",
      "Step 3158, action: [-0.5096726], terminated: False, reward: 215.8042610998977, Trade: 3058\n",
      "Step 3159, action: [0.49885753], terminated: False, reward: 215.7942610998977, Trade: 3059\n",
      "Step 3160, action: [0.47451708], terminated: False, reward: 215.78426109989772, Trade: 3060\n",
      "Step 3161, action: [0.44876167], terminated: False, reward: 215.77426109989773, Trade: 3061\n",
      "Step 3162, action: [0.15038165], terminated: False, reward: 215.76426109989774, Trade: 3062\n",
      "Step 3163, action: [0.22772816], terminated: False, reward: 215.75426109989775, Trade: 3063\n",
      "Step 3164, action: [-0.13822308], terminated: False, reward: 215.66880771480334, Trade: 3064\n",
      "Step 3165, action: [0.25556466], terminated: False, reward: 215.65880771480334, Trade: 3065\n",
      "Step 3166, action: [0.47824246], terminated: False, reward: 215.64880771480335, Trade: 3066\n",
      "Step 3167, action: [0.7542819], terminated: False, reward: 215.63880771480336, Trade: 3067\n",
      "Step 3168, action: [-0.1829755], terminated: False, reward: 215.466246684614, Trade: 3068\n",
      "Step 3169, action: [0.7652179], terminated: False, reward: 215.456246684614, Trade: 3069\n",
      "Step 3170, action: [0.24846442], terminated: False, reward: 215.446246684614, Trade: 3070\n",
      "Step 3171, action: [-0.9302993], terminated: False, reward: 215.43663878998342, Trade: 3071\n",
      "Step 3172, action: [-0.46086854], terminated: False, reward: 215.77826372565374, Trade: 3072\n",
      "Step 3173, action: [0.26587993], terminated: False, reward: 215.76826372565375, Trade: 3073\n",
      "Step 3174, action: [-0.9472187], terminated: False, reward: 214.75355775465826, Trade: 3074\n",
      "Step 3175, action: [0.0332483], terminated: False, reward: 214.74355775465827, Trade: 3075\n",
      "Step 3176, action: [0.28016767], terminated: False, reward: 214.73355775465828, Trade: 3076\n",
      "Step 3177, action: [-0.37172732], terminated: False, reward: 214.69276046714094, Trade: 3077\n",
      "Step 3178, action: [-0.78948504], terminated: False, reward: 215.0650154167941, Trade: 3078\n",
      "Step 3179, action: [0.65746665], terminated: False, reward: 215.0550154167941, Trade: 3079\n",
      "Step 3180, action: [-0.20710716], terminated: False, reward: 215.12988500289342, Trade: 3080\n",
      "Step 3181, action: [-0.9166159], terminated: False, reward: 215.10095298086298, Trade: 3081\n",
      "Step 3182, action: [-0.4281441], terminated: False, reward: 215.10015007457523, Trade: 3082\n",
      "Step 3183, action: [-0.80338943], terminated: False, reward: 214.87804640510882, Trade: 3083\n",
      "Step 3184, action: [-0.6713494], terminated: False, reward: 214.7974214119467, Trade: 3084\n",
      "Step 3185, action: [-0.35056937], terminated: False, reward: 214.805252071049, Trade: 3085\n",
      "Step 3186, action: [0.46918797], terminated: False, reward: 214.79525207104902, Trade: 3086\n",
      "Step 3187, action: [-0.88815284], terminated: False, reward: 214.68525207104904, Trade: 3086\n",
      "Step 3188, action: [-0.136896], terminated: False, reward: 214.63603844926422, Trade: 3087\n",
      "Step 3189, action: [0.17554908], terminated: False, reward: 214.62603844926423, Trade: 3088\n",
      "Step 3190, action: [-0.1927462], terminated: False, reward: 214.45998208374553, Trade: 3089\n",
      "Step 3191, action: [-0.4148428], terminated: False, reward: 214.47661114295659, Trade: 3090\n",
      "Step 3192, action: [-0.4018136], terminated: False, reward: 214.63848869811906, Trade: 3091\n",
      "Step 3193, action: [0.90595156], terminated: False, reward: 214.62848869811907, Trade: 3092\n",
      "Step 3194, action: [0.8464757], terminated: False, reward: 214.61848869811908, Trade: 3093\n",
      "Step 3195, action: [0.1048476], terminated: False, reward: 214.6084886981191, Trade: 3094\n",
      "Step 3196, action: [0.42578837], terminated: False, reward: 214.5984886981191, Trade: 3095\n",
      "Step 3197, action: [-0.31033015], terminated: False, reward: 214.3874341980374, Trade: 3096\n",
      "Step 3198, action: [-0.39766672], terminated: False, reward: 214.5091536917489, Trade: 3097\n",
      "Step 3199, action: [0.52976626], terminated: False, reward: 214.49915369174892, Trade: 3098\n",
      "Step 3200, action: [-0.74762845], terminated: False, reward: 214.48915369174892, Trade: 3099\n",
      "Step 3201, action: [-0.42914376], terminated: False, reward: 214.69724253138432, Trade: 3100\n",
      "Step 3202, action: [0.37314245], terminated: False, reward: 214.68724253138433, Trade: 3101\n",
      "Step 3203, action: [-0.24984474], terminated: False, reward: 214.65310100875607, Trade: 3102\n",
      "Step 3204, action: [-0.3561902], terminated: False, reward: 214.6510625098371, Trade: 3103\n",
      "Step 3205, action: [-0.9608075], terminated: False, reward: 215.0121541361917, Trade: 3104\n",
      "Step 3206, action: [-0.82541305], terminated: False, reward: 215.07165010368692, Trade: 3105\n",
      "Step 3207, action: [0.2846165], terminated: False, reward: 215.06165010368693, Trade: 3106\n",
      "Step 3208, action: [0.10854956], terminated: False, reward: 215.05165010368694, Trade: 3107\n",
      "Step 3209, action: [0.91319156], terminated: False, reward: 215.04165010368695, Trade: 3108\n",
      "Step 3210, action: [-0.04152791], terminated: False, reward: 215.03165010368696, Trade: 3109\n",
      "Step 3211, action: [-0.4254888], terminated: False, reward: 214.834684473943, Trade: 3110\n",
      "Step 3212, action: [-0.64322543], terminated: False, reward: 214.86927438677972, Trade: 3111\n",
      "Step 3213, action: [0.33477628], terminated: False, reward: 214.85927438677973, Trade: 3112\n",
      "Step 3214, action: [0.514747], terminated: False, reward: 214.84927438677974, Trade: 3113\n",
      "Step 3215, action: [-0.8699581], terminated: False, reward: 213.85412668930516, Trade: 3114\n",
      "Step 3216, action: [0.07477691], terminated: False, reward: 213.84412668930517, Trade: 3115\n",
      "Step 3217, action: [0.47496086], terminated: False, reward: 213.83412668930518, Trade: 3116\n",
      "Step 3218, action: [-0.17200586], terminated: False, reward: 213.9068963975845, Trade: 3117\n",
      "Step 3219, action: [-0.02282579], terminated: False, reward: 213.90205205982923, Trade: 3118\n",
      "Step 3220, action: [-0.27505225], terminated: False, reward: 213.88414319679734, Trade: 3119\n",
      "Step 3221, action: [-0.41914368], terminated: False, reward: 214.11674614186006, Trade: 3120\n",
      "Step 3222, action: [-0.5195841], terminated: False, reward: 214.20875501619201, Trade: 3121\n",
      "Step 3223, action: [0.28242427], terminated: False, reward: 214.19875501619202, Trade: 3122\n",
      "Step 3224, action: [0.29373008], terminated: False, reward: 214.18875501619203, Trade: 3123\n",
      "Step 3225, action: [0.9007346], terminated: False, reward: 214.17875501619204, Trade: 3124\n",
      "Step 3226, action: [0.36858553], terminated: False, reward: 214.16875501619205, Trade: 3125\n",
      "Step 3227, action: [0.7719066], terminated: False, reward: 214.15875501619206, Trade: 3126\n",
      "Step 3228, action: [-0.5531789], terminated: False, reward: 214.32927780308302, Trade: 3127\n",
      "Step 3229, action: [-0.5676662], terminated: False, reward: 214.31927780308303, Trade: 3128\n",
      "Step 3230, action: [-0.42562538], terminated: False, reward: 214.4390016059475, Trade: 3129\n",
      "Step 3231, action: [-0.23733218], terminated: False, reward: 214.27723504260362, Trade: 3130\n",
      "Step 3232, action: [-0.5746924], terminated: False, reward: 214.2719059971762, Trade: 3131\n",
      "Step 3233, action: [0.57719636], terminated: False, reward: 214.2619059971762, Trade: 3132\n",
      "Step 3234, action: [-0.7888418], terminated: False, reward: 214.26657880004737, Trade: 3133\n",
      "Step 3235, action: [-0.38904995], terminated: False, reward: 214.26112209058013, Trade: 3134\n",
      "Step 3236, action: [-0.84508693], terminated: False, reward: 214.34639712825648, Trade: 3135\n",
      "Step 3237, action: [-0.79869187], terminated: False, reward: 219.9990119570185, Trade: 3136\n",
      "Step 3238, action: [-0.6728847], terminated: False, reward: 222.33493039581623, Trade: 3137\n",
      "Step 3239, action: [-0.21875177], terminated: False, reward: 222.3254465844146, Trade: 3138\n",
      "Step 3240, action: [0.11847217], terminated: False, reward: 222.31544658441462, Trade: 3139\n",
      "Step 3241, action: [0.48456955], terminated: False, reward: 222.30544658441463, Trade: 3140\n",
      "Step 3242, action: [0.8359307], terminated: False, reward: 222.29544658441463, Trade: 3141\n",
      "Step 3243, action: [-0.8354628], terminated: False, reward: 222.23204897099401, Trade: 3142\n",
      "Step 3244, action: [-0.7895314], terminated: False, reward: 222.15989915810692, Trade: 3143\n",
      "Step 3245, action: [0.2660458], terminated: False, reward: 222.14989915810693, Trade: 3144\n",
      "Step 3246, action: [0.06718191], terminated: False, reward: 222.13989915810694, Trade: 3145\n",
      "Step 3247, action: [0.64113355], terminated: False, reward: 222.12989915810695, Trade: 3146\n",
      "Step 3248, action: [0.49798176], terminated: False, reward: 222.11989915810696, Trade: 3147\n",
      "Step 3249, action: [0.41691566], terminated: False, reward: 222.10989915810697, Trade: 3148\n",
      "Step 3250, action: [0.38263083], terminated: False, reward: 222.09989915810698, Trade: 3149\n",
      "Step 3251, action: [0.24528225], terminated: False, reward: 222.089899158107, Trade: 3150\n",
      "Step 3252, action: [-0.61699027], terminated: False, reward: 224.55452196053926, Trade: 3151\n",
      "Step 3253, action: [-0.981083], terminated: False, reward: 224.6270966371567, Trade: 3152\n",
      "Step 3254, action: [0.3303044], terminated: False, reward: 224.61709663715672, Trade: 3153\n",
      "Step 3255, action: [0.36858258], terminated: False, reward: 224.60709663715673, Trade: 3154\n",
      "Step 3256, action: [0.16932873], terminated: False, reward: 224.59709663715674, Trade: 3155\n",
      "Step 3257, action: [0.7308832], terminated: False, reward: 224.58709663715675, Trade: 3156\n",
      "Step 3258, action: [0.5048331], terminated: False, reward: 224.57709663715676, Trade: 3157\n",
      "Step 3259, action: [0.7202815], terminated: False, reward: 224.56709663715677, Trade: 3158\n",
      "Step 3260, action: [-0.37357157], terminated: False, reward: 224.4347211958675, Trade: 3159\n",
      "Step 3261, action: [0.9381387], terminated: False, reward: 224.4247211958675, Trade: 3160\n",
      "Step 3262, action: [0.8587274], terminated: False, reward: 224.41472119586751, Trade: 3161\n",
      "Step 3263, action: [0.9649582], terminated: False, reward: 224.40472119586752, Trade: 3162\n",
      "Step 3264, action: [0.91215223], terminated: False, reward: 224.29472119586754, Trade: 3162\n",
      "Step 3265, action: [-0.15263256], terminated: False, reward: 224.28925519899806, Trade: 3163\n",
      "Step 3266, action: [-0.5442531], terminated: False, reward: 225.467032762887, Trade: 3164\n",
      "Step 3267, action: [0.69804347], terminated: False, reward: 225.457032762887, Trade: 3165\n",
      "Step 3268, action: [0.26207194], terminated: False, reward: 225.447032762887, Trade: 3166\n",
      "Step 3269, action: [-0.31232882], terminated: False, reward: 225.12413663761967, Trade: 3167\n",
      "Step 3270, action: [0.56268626], terminated: False, reward: 225.11413663761968, Trade: 3168\n",
      "Step 3271, action: [-0.28081352], terminated: False, reward: 225.12372157426165, Trade: 3169\n",
      "Step 3272, action: [-0.01049591], terminated: False, reward: 225.11372157426166, Trade: 3170\n",
      "Step 3273, action: [0.32976556], terminated: False, reward: 225.10372157426167, Trade: 3171\n",
      "Step 3274, action: [0.16773131], terminated: False, reward: 225.09372157426168, Trade: 3172\n",
      "Step 3275, action: [-0.6761571], terminated: False, reward: 224.9837215742617, Trade: 3172\n",
      "Step 3276, action: [-0.47347865], terminated: False, reward: 226.97435750882343, Trade: 3173\n",
      "Step 3277, action: [-0.7250327], terminated: False, reward: 226.73183355363224, Trade: 3174\n",
      "Step 3278, action: [0.88026613], terminated: False, reward: 226.72183355363225, Trade: 3175\n",
      "Step 3279, action: [0.7730439], terminated: False, reward: 226.71183355363226, Trade: 3176\n",
      "Step 3280, action: [0.2482015], terminated: False, reward: 226.70183355363227, Trade: 3177\n",
      "Step 3281, action: [-0.9895272], terminated: False, reward: 228.49381509281017, Trade: 3178\n",
      "Step 3282, action: [0.53023297], terminated: False, reward: 228.48381509281018, Trade: 3179\n",
      "Step 3283, action: [0.74370855], terminated: False, reward: 228.47381509281018, Trade: 3180\n",
      "Step 3284, action: [-0.93881696], terminated: False, reward: 233.3241609083574, Trade: 3181\n",
      "Step 3285, action: [-0.4357804], terminated: False, reward: 233.39859121211066, Trade: 3182\n",
      "Step 3286, action: [0.76400363], terminated: False, reward: 233.38859121211067, Trade: 3183\n",
      "Step 3287, action: [0.56550586], terminated: False, reward: 233.37859121211068, Trade: 3184\n",
      "Step 3288, action: [0.86156803], terminated: False, reward: 233.3685912121107, Trade: 3185\n",
      "Step 3289, action: [-0.55513453], terminated: False, reward: 233.47174348303975, Trade: 3186\n",
      "Step 3290, action: [0.9636628], terminated: False, reward: 233.46174348303975, Trade: 3187\n",
      "Step 3291, action: [0.1831482], terminated: False, reward: 233.35174348303977, Trade: 3187\n",
      "Step 3292, action: [0.95809674], terminated: False, reward: 233.34174348303978, Trade: 3188\n",
      "Step 3293, action: [-0.24254535], terminated: False, reward: 233.33294659069995, Trade: 3189\n",
      "Step 3294, action: [-0.03598897], terminated: False, reward: 233.3234813739933, Trade: 3190\n",
      "Step 3295, action: [-0.21528433], terminated: False, reward: 233.31930885519213, Trade: 3191\n",
      "Step 3296, action: [-0.47795612], terminated: False, reward: 233.8830840084821, Trade: 3192\n",
      "Step 3297, action: [-0.8660418], terminated: False, reward: 234.09462605138418, Trade: 3193\n",
      "Step 3298, action: [-0.7380636], terminated: False, reward: 234.10985074131207, Trade: 3194\n",
      "Step 3299, action: [0.34713107], terminated: False, reward: 234.09985074131208, Trade: 3195\n",
      "Step 3300, action: [0.72373503], terminated: False, reward: 234.0898507413121, Trade: 3196\n",
      "Step 3301, action: [0.5545867], terminated: False, reward: 234.0798507413121, Trade: 3197\n",
      "Step 3302, action: [-0.15781307], terminated: False, reward: 234.06912126959256, Trade: 3198\n",
      "Step 3303, action: [0.09368829], terminated: False, reward: 234.05912126959257, Trade: 3199\n",
      "Step 3304, action: [0.9314165], terminated: False, reward: 234.04912126959258, Trade: 3200\n",
      "Step 3305, action: [0.12856531], terminated: False, reward: 234.03912126959258, Trade: 3201\n",
      "Step 3306, action: [0.98315686], terminated: False, reward: 234.0291212695926, Trade: 3202\n",
      "Step 3307, action: [0.3552718], terminated: False, reward: 233.9191212695926, Trade: 3202\n",
      "Step 3308, action: [-0.2230588], terminated: False, reward: 233.86568164179494, Trade: 3203\n",
      "Step 3309, action: [-0.22618617], terminated: False, reward: 233.92223033905114, Trade: 3204\n",
      "Step 3310, action: [-0.02267302], terminated: False, reward: 233.92653817765867, Trade: 3205\n",
      "Step 3311, action: [0.5590593], terminated: False, reward: 233.91653817765868, Trade: 3206\n",
      "Step 3312, action: [0.83992624], terminated: False, reward: 233.9065381776587, Trade: 3207\n",
      "Step 3313, action: [0.2366736], terminated: False, reward: 233.8965381776587, Trade: 3208\n",
      "Step 3314, action: [0.05301803], terminated: False, reward: 233.8865381776587, Trade: 3209\n",
      "Step 3315, action: [-0.2825157], terminated: False, reward: 233.69944241280405, Trade: 3210\n",
      "Step 3316, action: [0.82549495], terminated: False, reward: 233.68944241280406, Trade: 3211\n",
      "Step 3317, action: [0.06827167], terminated: False, reward: 233.67944241280406, Trade: 3212\n",
      "Step 3318, action: [-0.1519577], terminated: False, reward: 233.59872708826921, Trade: 3213\n",
      "Step 3319, action: [-0.95810527], terminated: False, reward: 233.67854608026943, Trade: 3214\n",
      "Step 3320, action: [0.39359987], terminated: False, reward: 233.66854608026944, Trade: 3215\n",
      "Step 3321, action: [-0.7083195], terminated: False, reward: 233.64820962659942, Trade: 3216\n",
      "Step 3322, action: [0.0395097], terminated: False, reward: 233.63820962659943, Trade: 3217\n",
      "Step 3323, action: [0.6125251], terminated: False, reward: 233.62820962659944, Trade: 3218\n",
      "Step 3324, action: [0.7519038], terminated: False, reward: 233.61820962659945, Trade: 3219\n",
      "Step 3325, action: [-0.34298033], terminated: False, reward: 233.6085525111107, Trade: 3220\n",
      "Step 3326, action: [-0.9812819], terminated: False, reward: 233.97629227231937, Trade: 3221\n",
      "Step 3327, action: [-0.01795163], terminated: False, reward: 233.96551090730892, Trade: 3222\n",
      "Step 3328, action: [-0.61963576], terminated: False, reward: 233.94621771106037, Trade: 3223\n",
      "Step 3329, action: [-0.48086432], terminated: False, reward: 232.9992699907394, Trade: 3224\n",
      "Step 3330, action: [0.8556875], terminated: False, reward: 232.98926999073942, Trade: 3225\n",
      "Step 3331, action: [-0.00936388], terminated: False, reward: 232.98567198117848, Trade: 3226\n",
      "Step 3332, action: [-0.46095568], terminated: False, reward: 232.96052549452943, Trade: 3227\n",
      "Step 3333, action: [0.5226493], terminated: False, reward: 232.95052549452944, Trade: 3228\n",
      "Step 3334, action: [-0.5776337], terminated: False, reward: 232.4134801321853, Trade: 3229\n",
      "Step 3335, action: [0.4222971], terminated: False, reward: 232.4034801321853, Trade: 3230\n",
      "Step 3336, action: [0.141384], terminated: False, reward: 232.39348013218532, Trade: 3231\n",
      "Step 3337, action: [-0.05784346], terminated: False, reward: 232.37798750906023, Trade: 3232\n",
      "Step 3338, action: [-0.71892905], terminated: False, reward: 229.80094548823837, Trade: 3233\n",
      "Step 3339, action: [0.6404167], terminated: False, reward: 229.79094548823838, Trade: 3234\n",
      "Step 3340, action: [-0.9091849], terminated: False, reward: 230.04428273016177, Trade: 3235\n",
      "Step 3341, action: [-0.9673156], terminated: False, reward: 229.156519080638, Trade: 3236\n",
      "Step 3342, action: [0.8466364], terminated: False, reward: 229.146519080638, Trade: 3237\n",
      "Step 3343, action: [-0.5451396], terminated: False, reward: 229.00757362550078, Trade: 3238\n",
      "Step 3344, action: [0.924689], terminated: False, reward: 228.9975736255008, Trade: 3239\n",
      "Step 3345, action: [-0.23318797], terminated: False, reward: 228.8276959925284, Trade: 3240\n",
      "Step 3346, action: [0.8631863], terminated: False, reward: 228.8176959925284, Trade: 3241\n",
      "Step 3347, action: [-0.02037009], terminated: False, reward: 228.83868032153464, Trade: 3242\n",
      "Step 3348, action: [-0.20657694], terminated: False, reward: 228.6092341481789, Trade: 3243\n",
      "Step 3349, action: [-0.51571774], terminated: False, reward: 228.59939110229612, Trade: 3244\n",
      "Step 3350, action: [-0.48107412], terminated: False, reward: 228.1355044211807, Trade: 3245\n",
      "Step 3351, action: [-0.85641646], terminated: False, reward: 228.08889788467494, Trade: 3246\n",
      "Step 3352, action: [-0.99067724], terminated: False, reward: 228.1857142477261, Trade: 3247\n",
      "Step 3353, action: [0.06869083], terminated: False, reward: 228.17571424772612, Trade: 3248\n",
      "Step 3354, action: [-0.56868917], terminated: False, reward: 228.1046224550386, Trade: 3249\n",
      "Step 3355, action: [0.2892354], terminated: False, reward: 228.0946224550386, Trade: 3250\n",
      "Step 3356, action: [0.71491736], terminated: False, reward: 228.0846224550386, Trade: 3251\n",
      "Step 3357, action: [0.50000376], terminated: False, reward: 228.07462245503862, Trade: 3252\n",
      "Step 3358, action: [0.994093], terminated: False, reward: 228.06462245503863, Trade: 3253\n",
      "Step 3359, action: [-0.07463332], terminated: False, reward: 227.8577975511596, Trade: 3254\n",
      "Step 3360, action: [0.52014846], terminated: False, reward: 227.8477975511596, Trade: 3255\n",
      "Step 3361, action: [0.9320775], terminated: False, reward: 227.8377975511596, Trade: 3256\n",
      "Step 3362, action: [0.5456867], terminated: False, reward: 227.82779755115962, Trade: 3257\n",
      "Step 3363, action: [-0.7453717], terminated: False, reward: 226.7345140821731, Trade: 3258\n",
      "Step 3364, action: [0.30897546], terminated: False, reward: 226.7245140821731, Trade: 3259\n",
      "Step 3365, action: [-0.31949347], terminated: False, reward: 226.59192023409636, Trade: 3260\n",
      "Step 3366, action: [-0.06646797], terminated: False, reward: 226.19698245959657, Trade: 3261\n",
      "Step 3367, action: [0.1381296], terminated: False, reward: 226.18698245959658, Trade: 3262\n",
      "Step 3368, action: [0.14760797], terminated: False, reward: 226.1769824595966, Trade: 3263\n",
      "Step 3369, action: [-0.7042755], terminated: False, reward: 223.00695523137793, Trade: 3264\n",
      "Step 3370, action: [-0.9831631], terminated: False, reward: 223.01724841873573, Trade: 3265\n",
      "Step 3371, action: [-0.12674463], terminated: False, reward: 223.0027845685072, Trade: 3266\n",
      "Step 3372, action: [-0.38583818], terminated: False, reward: 217.857893427768, Trade: 3267\n",
      "Step 3373, action: [-0.72537017], terminated: False, reward: 217.41821151533463, Trade: 3268\n",
      "Step 3374, action: [0.93845373], terminated: False, reward: 217.40821151533464, Trade: 3269\n",
      "Step 3375, action: [0.8178186], terminated: False, reward: 217.39821151533465, Trade: 3270\n",
      "Step 3376, action: [-0.1967441], terminated: False, reward: 214.60715220445059, Trade: 3271\n",
      "Step 3377, action: [0.35297197], terminated: False, reward: 214.5971522044506, Trade: 3272\n",
      "Step 3378, action: [0.39417818], terminated: False, reward: 214.5871522044506, Trade: 3273\n",
      "Step 3379, action: [0.06441053], terminated: False, reward: 214.5771522044506, Trade: 3274\n",
      "Step 3380, action: [0.59970015], terminated: False, reward: 214.56715220445062, Trade: 3275\n",
      "Step 3381, action: [-0.4995977], terminated: False, reward: 214.5548993284905, Trade: 3276\n",
      "Step 3382, action: [-0.08106486], terminated: False, reward: 214.54489932849052, Trade: 3277\n",
      "Step 3383, action: [0.47895476], terminated: False, reward: 214.53489932849052, Trade: 3278\n",
      "Step 3384, action: [-0.15608408], terminated: False, reward: 214.5180075222483, Trade: 3279\n",
      "Step 3385, action: [-0.9057445], terminated: False, reward: 214.66066985978003, Trade: 3280\n",
      "Step 3386, action: [-0.9295154], terminated: False, reward: 215.3853743806465, Trade: 3281\n",
      "Step 3387, action: [0.91021407], terminated: False, reward: 215.37537438064652, Trade: 3282\n",
      "Step 3388, action: [-0.6125019], terminated: False, reward: 215.400014599848, Trade: 3283\n",
      "Step 3389, action: [0.07498554], terminated: False, reward: 215.390014599848, Trade: 3284\n",
      "Step 3390, action: [0.61043406], terminated: False, reward: 215.380014599848, Trade: 3285\n",
      "Step 3391, action: [0.09270808], terminated: False, reward: 215.37001459984802, Trade: 3286\n",
      "Step 3392, action: [-0.97183585], terminated: False, reward: 215.34966962658186, Trade: 3287\n",
      "Step 3393, action: [0.49581903], terminated: False, reward: 215.33966962658187, Trade: 3288\n",
      "Step 3394, action: [-0.87685424], terminated: False, reward: 214.90674559138301, Trade: 3289\n",
      "Step 3395, action: [0.9793504], terminated: False, reward: 214.89674559138302, Trade: 3290\n",
      "Step 3396, action: [-0.9932424], terminated: False, reward: 212.4247098475878, Trade: 3291\n",
      "Step 3397, action: [-0.98078847], terminated: False, reward: 212.44525654001268, Trade: 3292\n",
      "Step 3398, action: [-0.7076796], terminated: False, reward: 210.3783246714793, Trade: 3293\n",
      "Step 3399, action: [-0.16542317], terminated: False, reward: 210.3120344415784, Trade: 3294\n",
      "Step 3400, action: [-0.25763592], terminated: False, reward: 210.3020344415784, Trade: 3295\n",
      "Step 3401, action: [-0.15781128], terminated: False, reward: 210.29265392837, Trade: 3296\n",
      "Step 3402, action: [-0.130936], terminated: False, reward: 209.4377350627359, Trade: 3297\n",
      "Step 3403, action: [0.6617536], terminated: False, reward: 209.4277350627359, Trade: 3298\n",
      "Step 3404, action: [-0.4739673], terminated: False, reward: 211.45166762637973, Trade: 3299\n",
      "Step 3405, action: [-0.84652406], terminated: False, reward: 211.2155767695639, Trade: 3300\n",
      "Step 3406, action: [-0.34694108], terminated: False, reward: 208.05398931213205, Trade: 3301\n",
      "Step 3407, action: [0.5676307], terminated: False, reward: 208.04398931213206, Trade: 3302\n",
      "Step 3408, action: [0.11138572], terminated: False, reward: 208.03398931213206, Trade: 3303\n",
      "Step 3409, action: [0.85142773], terminated: False, reward: 208.02398931213207, Trade: 3304\n",
      "Step 3410, action: [0.23772454], terminated: False, reward: 208.01398931213208, Trade: 3305\n",
      "Step 3411, action: [-0.46038023], terminated: False, reward: 208.005800318661, Trade: 3306\n",
      "Step 3412, action: [-0.22983381], terminated: False, reward: 207.995800318661, Trade: 3307\n",
      "Step 3413, action: [-0.34656328], terminated: False, reward: 208.0225361417767, Trade: 3308\n",
      "Step 3414, action: [0.87436754], terminated: False, reward: 208.0125361417767, Trade: 3309\n",
      "Step 3415, action: [-0.3461496], terminated: False, reward: 208.01568199277992, Trade: 3310\n",
      "Step 3416, action: [0.15105066], terminated: False, reward: 208.00568199277993, Trade: 3311\n",
      "Step 3417, action: [0.922044], terminated: False, reward: 207.99568199277994, Trade: 3312\n",
      "Step 3418, action: [0.21931285], terminated: False, reward: 207.98568199277994, Trade: 3313\n",
      "Step 3419, action: [0.39959267], terminated: False, reward: 207.97568199277995, Trade: 3314\n",
      "Step 3420, action: [0.51736677], terminated: False, reward: 207.96568199277996, Trade: 3315\n",
      "Step 3421, action: [-0.03786833], terminated: False, reward: 207.99972207929656, Trade: 3316\n",
      "Step 3422, action: [0.7324198], terminated: False, reward: 207.98972207929657, Trade: 3317\n",
      "Step 3423, action: [0.8163334], terminated: False, reward: 207.97972207929658, Trade: 3318\n",
      "Step 3424, action: [0.01311478], terminated: False, reward: 207.8697220792966, Trade: 3318\n",
      "Step 3425, action: [0.29140747], terminated: False, reward: 207.8597220792966, Trade: 3319\n",
      "Step 3426, action: [0.63033515], terminated: False, reward: 207.74972207929662, Trade: 3319\n",
      "Step 3427, action: [-0.27776498], terminated: False, reward: 207.74247378478879, Trade: 3320\n",
      "Step 3428, action: [-0.35750735], terminated: False, reward: 207.47936550253846, Trade: 3321\n",
      "Step 3429, action: [0.92845815], terminated: False, reward: 207.46936550253847, Trade: 3322\n",
      "Step 3430, action: [0.866502], terminated: False, reward: 207.45936550253847, Trade: 3323\n",
      "Step 3431, action: [0.21352577], terminated: False, reward: 207.3493655025385, Trade: 3323\n",
      "Step 3432, action: [-0.56641734], terminated: False, reward: 204.35804941621564, Trade: 3324\n",
      "Step 3433, action: [0.49075162], terminated: False, reward: 204.34804941621564, Trade: 3325\n",
      "Step 3434, action: [-0.9498942], terminated: False, reward: 206.48223728362586, Trade: 3326\n",
      "Step 3435, action: [-0.84706193], terminated: False, reward: 206.4662384665699, Trade: 3327\n",
      "Step 3436, action: [0.48983833], terminated: False, reward: 206.4562384665699, Trade: 3328\n",
      "Step 3437, action: [-0.10717501], terminated: False, reward: 207.2128891263384, Trade: 3329\n",
      "Step 3438, action: [0.28286618], terminated: False, reward: 207.20288912633842, Trade: 3330\n",
      "Step 3439, action: [0.5977344], terminated: False, reward: 207.19288912633843, Trade: 3331\n",
      "Step 3440, action: [-0.77548456], terminated: False, reward: 206.84912922481078, Trade: 3332\n",
      "Step 3441, action: [0.895058], terminated: False, reward: 206.8391292248108, Trade: 3333\n",
      "Step 3442, action: [0.566932], terminated: False, reward: 206.8291292248108, Trade: 3334\n",
      "Step 3443, action: [0.623866], terminated: False, reward: 206.8191292248108, Trade: 3335\n",
      "Step 3444, action: [-0.94727993], terminated: False, reward: 206.76168600536593, Trade: 3336\n",
      "Step 3445, action: [-0.3697936], terminated: False, reward: 206.76311922721857, Trade: 3337\n",
      "Step 3446, action: [0.6462244], terminated: False, reward: 206.75311922721858, Trade: 3338\n",
      "Step 3447, action: [-0.19910504], terminated: False, reward: 206.79712497966733, Trade: 3339\n",
      "Step 3448, action: [0.99273485], terminated: False, reward: 206.78712497966734, Trade: 3340\n",
      "Step 3449, action: [0.76751703], terminated: False, reward: 206.77712497966735, Trade: 3341\n",
      "Step 3450, action: [0.8348443], terminated: False, reward: 206.66712497966736, Trade: 3341\n",
      "Step 3451, action: [0.7215701], terminated: False, reward: 206.55712497966738, Trade: 3341\n",
      "Step 3452, action: [-0.8895095], terminated: False, reward: 206.53577873770055, Trade: 3342\n",
      "Step 3453, action: [0.8394716], terminated: False, reward: 206.52577873770056, Trade: 3343\n",
      "Step 3454, action: [0.18899688], terminated: False, reward: 206.51577873770057, Trade: 3344\n",
      "Step 3455, action: [-0.90840906], terminated: False, reward: 206.81805453272256, Trade: 3345\n",
      "Step 3456, action: [0.69731873], terminated: False, reward: 206.80805453272256, Trade: 3346\n",
      "Step 3457, action: [-0.6989498], terminated: False, reward: 206.8041981872219, Trade: 3347\n",
      "Step 3458, action: [-0.7359777], terminated: False, reward: 206.44183531607177, Trade: 3348\n",
      "Step 3459, action: [0.01029539], terminated: False, reward: 206.43183531607178, Trade: 3349\n",
      "Step 3460, action: [-0.49177966], terminated: False, reward: 206.4201258063923, Trade: 3350\n",
      "Step 3461, action: [-0.75074416], terminated: False, reward: 206.40188570084132, Trade: 3351\n",
      "Step 3462, action: [0.568087], terminated: False, reward: 206.39188570084133, Trade: 3352\n",
      "Step 3463, action: [0.00578031], terminated: False, reward: 206.38188570084134, Trade: 3353\n",
      "Step 3464, action: [0.7405952], terminated: False, reward: 206.37188570084135, Trade: 3354\n",
      "Step 3465, action: [0.45934698], terminated: False, reward: 206.36188570084136, Trade: 3355\n",
      "Step 3466, action: [-0.9367005], terminated: False, reward: 199.44966951696819, Trade: 3356\n",
      "Step 3467, action: [0.18616852], terminated: False, reward: 199.4396695169682, Trade: 3357\n",
      "Step 3468, action: [-0.5495478], terminated: False, reward: 200.03406110188973, Trade: 3358\n",
      "Step 3469, action: [0.22700036], terminated: False, reward: 200.02406110188974, Trade: 3359\n",
      "Step 3470, action: [0.60684496], terminated: False, reward: 200.01406110188975, Trade: 3360\n",
      "Step 3471, action: [0.15053454], terminated: False, reward: 200.00406110188976, Trade: 3361\n",
      "Step 3472, action: [0.3142124], terminated: False, reward: 199.99406110188977, Trade: 3362\n",
      "Step 3473, action: [-0.4869823], terminated: False, reward: 199.95783197244944, Trade: 3363\n",
      "Step 3474, action: [0.2597022], terminated: False, reward: 199.94783197244945, Trade: 3364\n",
      "Step 3475, action: [-0.47557494], terminated: False, reward: 199.944764751823, Trade: 3365\n",
      "Step 3476, action: [0.643351], terminated: False, reward: 199.934764751823, Trade: 3366\n",
      "Step 3477, action: [-0.7633015], terminated: False, reward: 200.36840579019488, Trade: 3367\n",
      "Step 3478, action: [-0.92001], terminated: False, reward: 200.33137597833513, Trade: 3368\n",
      "Step 3479, action: [0.8741649], terminated: False, reward: 200.32137597833514, Trade: 3369\n",
      "Step 3480, action: [-0.37942985], terminated: False, reward: 200.02929330111277, Trade: 3370\n",
      "Step 3481, action: [-0.16383834], terminated: False, reward: 200.53126686806326, Trade: 3371\n",
      "Step 3482, action: [-0.33314887], terminated: False, reward: 200.52113070078948, Trade: 3372\n",
      "Step 3483, action: [-0.02192303], terminated: False, reward: 200.50524567290228, Trade: 3373\n",
      "Step 3484, action: [-0.30632573], terminated: False, reward: 200.4848940650423, Trade: 3374\n",
      "Step 3485, action: [-0.5620736], terminated: False, reward: 200.4939176767651, Trade: 3375\n",
      "Step 3486, action: [-0.24143295], terminated: False, reward: 200.48284433057427, Trade: 3376\n",
      "Step 3487, action: [-0.48026296], terminated: False, reward: 200.47284433057428, Trade: 3377\n",
      "Step 3488, action: [0.8727151], terminated: False, reward: 200.46284433057428, Trade: 3378\n",
      "Step 3489, action: [-0.11435345], terminated: False, reward: 200.41174280616167, Trade: 3379\n",
      "Step 3490, action: [-0.77483934], terminated: False, reward: 200.3926253237114, Trade: 3380\n",
      "Step 3491, action: [0.05446341], terminated: False, reward: 200.3826253237114, Trade: 3381\n",
      "Step 3492, action: [0.56856424], terminated: False, reward: 200.37262532371142, Trade: 3382\n",
      "Step 3493, action: [-0.55030984], terminated: False, reward: 200.87903101766003, Trade: 3383\n",
      "Step 3494, action: [0.0065966], terminated: False, reward: 200.86903101766003, Trade: 3384\n",
      "Step 3495, action: [-0.82880557], terminated: False, reward: 200.84875208291632, Trade: 3385\n",
      "Step 3496, action: [0.01132153], terminated: False, reward: 200.83875208291633, Trade: 3386\n",
      "Step 3497, action: [-0.7410187], terminated: False, reward: 211.7468226607807, Trade: 3387\n",
      "Step 3498, action: [0.57663786], terminated: False, reward: 211.73682266078072, Trade: 3388\n",
      "Step 3499, action: [-0.509394], terminated: False, reward: 214.60175453419723, Trade: 3389\n",
      "Step 3500, action: [0.21129405], terminated: False, reward: 214.59175453419724, Trade: 3390\n",
      "Step 3501, action: [0.6552225], terminated: False, reward: 214.58175453419724, Trade: 3391\n",
      "Step 3502, action: [-0.3197432], terminated: False, reward: 214.54204933679554, Trade: 3392\n",
      "Step 3503, action: [-0.46542147], terminated: False, reward: 214.5571774246177, Trade: 3393\n",
      "Step 3504, action: [-0.7087438], terminated: False, reward: 214.44446080240922, Trade: 3394\n",
      "Step 3505, action: [-0.1432044], terminated: False, reward: 214.435835902103, Trade: 3395\n",
      "Step 3506, action: [0.57809114], terminated: False, reward: 214.42583590210302, Trade: 3396\n",
      "Step 3507, action: [-0.9187039], terminated: False, reward: 214.63565388388457, Trade: 3397\n",
      "Step 3508, action: [0.83577037], terminated: False, reward: 214.62565388388458, Trade: 3398\n",
      "Step 3509, action: [-0.23338953], terminated: False, reward: 214.34377521284344, Trade: 3399\n",
      "Step 3510, action: [0.656543], terminated: False, reward: 214.33377521284345, Trade: 3400\n",
      "Step 3511, action: [0.7355514], terminated: False, reward: 214.32377521284346, Trade: 3401\n",
      "Step 3512, action: [-0.6211347], terminated: False, reward: 214.31094253448913, Trade: 3402\n",
      "Step 3513, action: [0.9161313], terminated: False, reward: 214.30094253448914, Trade: 3403\n",
      "Step 3514, action: [-0.81284016], terminated: False, reward: 214.29666274928493, Trade: 3404\n",
      "Step 3515, action: [-0.6377849], terminated: False, reward: 214.30704397898504, Trade: 3405\n",
      "Step 3516, action: [0.5463301], terminated: False, reward: 214.29704397898504, Trade: 3406\n",
      "Step 3517, action: [0.2897376], terminated: False, reward: 214.28704397898505, Trade: 3407\n",
      "Step 3518, action: [-0.39919746], terminated: False, reward: 215.0254203738866, Trade: 3408\n",
      "Step 3519, action: [0.11223954], terminated: False, reward: 215.0154203738866, Trade: 3409\n",
      "Step 3520, action: [-0.9389693], terminated: False, reward: 215.0034571513419, Trade: 3410\n",
      "Step 3521, action: [-0.8094572], terminated: False, reward: 215.00470573082399, Trade: 3411\n",
      "Step 3522, action: [-0.66673964], terminated: False, reward: 213.8580037511552, Trade: 3412\n",
      "Step 3523, action: [-0.30457592], terminated: False, reward: 214.19161003719324, Trade: 3413\n",
      "Step 3524, action: [-0.5544516], terminated: False, reward: 214.46084330191397, Trade: 3414\n",
      "Step 3525, action: [0.49118316], terminated: False, reward: 214.45084330191398, Trade: 3415\n",
      "Step 3526, action: [-0.5621845], terminated: False, reward: 214.41921595929864, Trade: 3416\n",
      "Step 3527, action: [0.61416835], terminated: False, reward: 214.40921595929865, Trade: 3417\n",
      "Step 3528, action: [-0.2757853], terminated: False, reward: 216.96602968033423, Trade: 3418\n",
      "Step 3529, action: [0.44377485], terminated: False, reward: 216.95602968033424, Trade: 3419\n",
      "Step 3530, action: [-0.16703108], terminated: False, reward: 217.066058944731, Trade: 3420\n",
      "Step 3531, action: [-0.81336135], terminated: False, reward: 218.3025358959158, Trade: 3421\n",
      "Step 3532, action: [-0.96977127], terminated: False, reward: 218.66986019820104, Trade: 3422\n",
      "Step 3533, action: [0.17464198], terminated: False, reward: 218.65986019820105, Trade: 3423\n",
      "Step 3534, action: [0.9705604], terminated: False, reward: 218.64986019820105, Trade: 3424\n",
      "Step 3535, action: [0.302057], terminated: False, reward: 218.63986019820106, Trade: 3425\n",
      "Step 3536, action: [-0.4860041], terminated: False, reward: 218.78104467365443, Trade: 3426\n",
      "Step 3537, action: [-0.13461772], terminated: False, reward: 218.77329625363907, Trade: 3427\n",
      "Step 3538, action: [-0.49638218], terminated: False, reward: 218.70687930230596, Trade: 3428\n",
      "Step 3539, action: [-0.7766356], terminated: False, reward: 217.62525471782718, Trade: 3429\n",
      "Step 3540, action: [0.7208041], terminated: False, reward: 217.61525471782718, Trade: 3430\n",
      "Step 3541, action: [0.4483115], terminated: False, reward: 217.6052547178272, Trade: 3431\n",
      "Step 3542, action: [0.16365846], terminated: False, reward: 217.5952547178272, Trade: 3432\n",
      "Step 3543, action: [0.04462777], terminated: False, reward: 217.5852547178272, Trade: 3433\n",
      "Step 3544, action: [0.9372728], terminated: False, reward: 217.57525471782722, Trade: 3434\n",
      "Step 3545, action: [-0.0336279], terminated: False, reward: 217.56525471782723, Trade: 3435\n",
      "Step 3546, action: [-0.44954526], terminated: False, reward: 217.57039838269915, Trade: 3436\n",
      "Step 3547, action: [0.07054534], terminated: False, reward: 217.56039838269916, Trade: 3437\n",
      "Step 3548, action: [0.98011], terminated: False, reward: 217.55039838269917, Trade: 3438\n",
      "Step 3549, action: [0.06521319], terminated: False, reward: 217.4403983826992, Trade: 3438\n",
      "Step 3550, action: [-0.5447471], terminated: False, reward: 217.4303983826992, Trade: 3439\n",
      "Step 3551, action: [0.47441393], terminated: False, reward: 217.3203983826992, Trade: 3439\n",
      "Step 3552, action: [-0.1264691], terminated: False, reward: 217.2159904323718, Trade: 3440\n",
      "Step 3553, action: [-0.6152912], terminated: False, reward: 217.72063635781268, Trade: 3441\n",
      "Step 3554, action: [-0.7199274], terminated: False, reward: 217.90054874483812, Trade: 3442\n",
      "Step 3555, action: [0.7644445], terminated: False, reward: 217.89054874483813, Trade: 3443\n",
      "Step 3556, action: [0.61817324], terminated: False, reward: 217.88054874483814, Trade: 3444\n",
      "Step 3557, action: [0.64157313], terminated: False, reward: 217.87054874483815, Trade: 3445\n",
      "Step 3558, action: [0.45478502], terminated: False, reward: 217.86054874483816, Trade: 3446\n",
      "Step 3559, action: [0.8908959], terminated: False, reward: 217.85054874483816, Trade: 3447\n",
      "Step 3560, action: [0.44259104], terminated: False, reward: 217.84054874483817, Trade: 3448\n",
      "Step 3561, action: [0.77032954], terminated: False, reward: 217.7305487448382, Trade: 3448\n",
      "Step 3562, action: [0.8274126], terminated: False, reward: 217.6205487448382, Trade: 3448\n",
      "Step 3563, action: [-0.2717993], terminated: False, reward: 217.63494622357103, Trade: 3449\n",
      "Step 3564, action: [0.2849582], terminated: False, reward: 217.62494622357104, Trade: 3450\n",
      "Step 3565, action: [-0.51773524], terminated: False, reward: 217.62606113119617, Trade: 3451\n",
      "Step 3566, action: [0.75305676], terminated: False, reward: 217.61606113119618, Trade: 3452\n",
      "Step 3567, action: [0.82378083], terminated: False, reward: 217.60606113119618, Trade: 3453\n",
      "Step 3568, action: [-0.25549045], terminated: False, reward: 217.47202782919666, Trade: 3454\n",
      "Step 3569, action: [-0.7200434], terminated: False, reward: 216.99214354363016, Trade: 3455\n",
      "Step 3570, action: [0.15429536], terminated: False, reward: 216.98214354363017, Trade: 3456\n",
      "Step 3571, action: [0.92167974], terminated: False, reward: 216.97214354363018, Trade: 3457\n",
      "Step 3572, action: [-0.6170292], terminated: False, reward: 216.92678133655681, Trade: 3458\n",
      "Step 3573, action: [-0.7774485], terminated: False, reward: 216.41653102157696, Trade: 3459\n",
      "Step 3574, action: [-0.62037665], terminated: False, reward: 216.35987665314505, Trade: 3460\n",
      "Step 3575, action: [0.38925377], terminated: False, reward: 216.34987665314506, Trade: 3461\n",
      "Step 3576, action: [-0.11431389], terminated: False, reward: 216.33423032151146, Trade: 3462\n",
      "Step 3577, action: [0.11064611], terminated: False, reward: 216.32423032151146, Trade: 3463\n",
      "Step 3578, action: [-0.10940454], terminated: False, reward: 216.43257504791373, Trade: 3464\n",
      "Step 3579, action: [-0.23580313], terminated: False, reward: 216.18648825196772, Trade: 3465\n",
      "Step 3580, action: [0.34043583], terminated: False, reward: 216.17648825196773, Trade: 3466\n",
      "Step 3581, action: [0.66575056], terminated: False, reward: 216.16648825196773, Trade: 3467\n",
      "Step 3582, action: [0.20031574], terminated: False, reward: 216.15648825196774, Trade: 3468\n",
      "Step 3583, action: [-0.41447935], terminated: False, reward: 216.23459532856612, Trade: 3469\n",
      "Step 3584, action: [-0.9937701], terminated: False, reward: 216.2850262096046, Trade: 3470\n",
      "Step 3585, action: [-0.34309125], terminated: False, reward: 216.19542705227408, Trade: 3471\n",
      "Step 3586, action: [-0.8913785], terminated: False, reward: 215.86719153022858, Trade: 3472\n",
      "Step 3587, action: [0.6507268], terminated: False, reward: 215.8571915302286, Trade: 3473\n",
      "Step 3588, action: [0.92495364], terminated: False, reward: 215.8471915302286, Trade: 3474\n",
      "Step 3589, action: [0.05602061], terminated: False, reward: 215.8371915302286, Trade: 3475\n",
      "Step 3590, action: [-0.6988658], terminated: False, reward: 217.50618406549745, Trade: 3476\n",
      "Step 3591, action: [0.926784], terminated: False, reward: 217.49618406549746, Trade: 3477\n",
      "Step 3592, action: [0.36677963], terminated: False, reward: 217.48618406549747, Trade: 3478\n",
      "Step 3593, action: [-0.76404077], terminated: False, reward: 217.3086154299798, Trade: 3479\n",
      "Step 3594, action: [-0.05513236], terminated: False, reward: 216.98184488940885, Trade: 3480\n",
      "Step 3595, action: [-0.15017378], terminated: False, reward: 216.97310321586681, Trade: 3481\n",
      "Step 3596, action: [0.8337299], terminated: False, reward: 216.96310321586682, Trade: 3482\n",
      "Step 3597, action: [-0.12585561], terminated: False, reward: 216.9544490368551, Trade: 3483\n",
      "Step 3598, action: [-0.967395], terminated: False, reward: 217.58018383625156, Trade: 3484\n",
      "Step 3599, action: [0.19807367], terminated: False, reward: 217.57018383625157, Trade: 3485\n",
      "Step 3600, action: [0.24364278], terminated: False, reward: 217.56018383625158, Trade: 3486\n",
      "Step 3601, action: [0.15142918], terminated: False, reward: 217.5501838362516, Trade: 3487\n",
      "Step 3602, action: [0.5031174], terminated: False, reward: 217.5401838362516, Trade: 3488\n",
      "Step 3603, action: [-0.4986444], terminated: False, reward: 217.51382915202004, Trade: 3489\n",
      "Step 3604, action: [-0.58206993], terminated: False, reward: 217.63382949086713, Trade: 3490\n",
      "Step 3605, action: [0.8454276], terminated: False, reward: 217.62382949086714, Trade: 3491\n",
      "Step 3606, action: [0.30229756], terminated: False, reward: 217.61382949086715, Trade: 3492\n",
      "Step 3607, action: [0.48664355], terminated: False, reward: 217.60382949086716, Trade: 3493\n",
      "Step 3608, action: [0.51151747], terminated: False, reward: 217.59382949086717, Trade: 3494\n",
      "Step 3609, action: [-0.50375503], terminated: False, reward: 217.55948561895468, Trade: 3495\n",
      "Step 3610, action: [0.73902184], terminated: False, reward: 217.5494856189547, Trade: 3496\n",
      "Step 3611, action: [0.825443], terminated: False, reward: 217.5394856189547, Trade: 3497\n",
      "Step 3612, action: [-0.22720061], terminated: False, reward: 217.597718867614, Trade: 3498\n",
      "Step 3613, action: [0.78783464], terminated: False, reward: 217.587718867614, Trade: 3499\n",
      "Step 3614, action: [0.9128605], terminated: False, reward: 217.577718867614, Trade: 3500\n",
      "Step 3615, action: [-0.78671485], terminated: False, reward: 218.23837577128745, Trade: 3501\n",
      "Step 3616, action: [-0.6423502], terminated: False, reward: 218.21749915025853, Trade: 3502\n",
      "Step 3617, action: [-0.9762983], terminated: False, reward: 223.06521073317464, Trade: 3503\n",
      "Step 3618, action: [-0.98248255], terminated: False, reward: 240.09674993106287, Trade: 3504\n",
      "Step 3619, action: [-0.99604756], terminated: False, reward: 244.62552713774525, Trade: 3505\n",
      "Step 3620, action: [-0.75293154], terminated: False, reward: 245.8200060762439, Trade: 3506\n",
      "Step 3621, action: [0.44035697], terminated: False, reward: 245.81000607624392, Trade: 3507\n",
      "Step 3622, action: [-0.48512834], terminated: False, reward: 245.86080092088605, Trade: 3508\n",
      "Step 3623, action: [0.0446017], terminated: False, reward: 245.85080092088606, Trade: 3509\n",
      "Step 3624, action: [-0.19953446], terminated: False, reward: 245.941628101639, Trade: 3510\n",
      "Step 3625, action: [0.2645125], terminated: False, reward: 245.931628101639, Trade: 3511\n",
      "Step 3626, action: [-0.39613986], terminated: False, reward: 247.22660132270263, Trade: 3512\n",
      "Step 3627, action: [-0.8380479], terminated: False, reward: 247.24380561705482, Trade: 3513\n",
      "Step 3628, action: [0.67893434], terminated: False, reward: 247.23380561705483, Trade: 3514\n",
      "Step 3629, action: [0.06083843], terminated: False, reward: 247.22380561705484, Trade: 3515\n",
      "Step 3630, action: [0.42464864], terminated: False, reward: 247.21380561705485, Trade: 3516\n",
      "Step 3631, action: [0.07657479], terminated: False, reward: 247.20380561705485, Trade: 3517\n",
      "Step 3632, action: [-0.41023183], terminated: False, reward: 247.23439963723428, Trade: 3518\n",
      "Step 3633, action: [-0.41903836], terminated: False, reward: 247.21433222040582, Trade: 3519\n",
      "Step 3634, action: [0.4448549], terminated: False, reward: 247.20433222040583, Trade: 3520\n",
      "Step 3635, action: [-0.20748457], terminated: False, reward: 247.29442626167003, Trade: 3521\n",
      "Step 3636, action: [-0.11198141], terminated: False, reward: 247.32590976470092, Trade: 3522\n",
      "Step 3637, action: [0.23818639], terminated: False, reward: 247.31590976470093, Trade: 3523\n",
      "Step 3638, action: [-0.07836619], terminated: False, reward: 247.64410508614216, Trade: 3524\n",
      "Step 3639, action: [0.6480745], terminated: False, reward: 247.63410508614217, Trade: 3525\n",
      "Step 3640, action: [0.59248984], terminated: False, reward: 247.62410508614218, Trade: 3526\n",
      "Step 3641, action: [-0.08970877], terminated: False, reward: 247.65247724755852, Trade: 3527\n",
      "Step 3642, action: [-0.48012558], terminated: False, reward: 247.9002756926899, Trade: 3528\n",
      "Step 3643, action: [0.78871983], terminated: False, reward: 247.8902756926899, Trade: 3529\n",
      "Step 3644, action: [0.62759036], terminated: False, reward: 247.8802756926899, Trade: 3530\n",
      "Step 3645, action: [-0.29213282], terminated: False, reward: 247.93202966841233, Trade: 3531\n",
      "Step 3646, action: [-0.06870674], terminated: False, reward: 247.92185453784865, Trade: 3532\n",
      "Step 3647, action: [-0.00129733], terminated: False, reward: 247.91185453784865, Trade: 3533\n",
      "Step 3648, action: [-0.4549814], terminated: False, reward: 248.06504920805742, Trade: 3534\n",
      "Step 3649, action: [0.6453605], terminated: False, reward: 248.05504920805743, Trade: 3535\n",
      "Step 3650, action: [0.92653245], terminated: False, reward: 248.04504920805743, Trade: 3536\n",
      "Step 3651, action: [-0.7157935], terminated: False, reward: 254.19863432870318, Trade: 3537\n",
      "Step 3652, action: [-0.20792869], terminated: False, reward: 254.20593944762047, Trade: 3538\n",
      "Step 3653, action: [0.2498743], terminated: False, reward: 254.19593944762047, Trade: 3539\n",
      "Step 3654, action: [-0.79745823], terminated: False, reward: 581.7369369200042, Trade: 3540\n",
      "Episode: 1\n",
      "Step 0, action: [-0.14606653], terminated: True, reward: 0, Trade: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test_train_gym.df)-1):\n",
    "    action = test_train_gym.action_space.sample()\n",
    "    state,reward,terminal,truncated,info = test_train_gym.step(action)\n",
    "    if terminal:\n",
    "        test_train_gym.reset()\n",
    "    print(f'Step {test_train_gym.row}, action: {action}, terminated: {terminal}, reward: {test_train_gym.reward}, Trade: {test_train_gym.trades}')\n",
    "    # print(test_train_gym.portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Train DRL Agents\n",
    "* The DRL algorithms are from **Stable Baselines 3**.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935424"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_length = len(e_train_gym.df) - 1\n",
    "episode_amount = 512\n",
    "total_training_step = episode_length*episode_amount\n",
    "total_training_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8.1'></a>\n",
    "If the training starts from the previous model, the section should **run all cells above** this line and then jump to [**Load trained model**](#7.2.1) to keep the traning going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 3655, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 3655, 'clip_range': 0.1}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent_ppo = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": episode_length,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": episode_length,\n",
    "    \"clip_range\":0.1\n",
    "}\n",
    "\n",
    "policy_kwargs = dict(net_arch=dict(pi=[128, 128], vf=[128, 128]))\n",
    "\n",
    "model_ppo = agent_ppo.get_model(\"ppo\",model_kwargs = PPO_PARAMS, policy_kwargs=policy_kwargs,tensorboard_log=TENSORBOARD_LOG_DIR + \"/test_ppo/\",verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m agent_ppo \u001b[38;5;241m=\u001b[39m DRLAgent(env \u001b[38;5;241m=\u001b[39m env_train)\n\u001b[0;32m----> 3\u001b[0m trained_ppo \u001b[38;5;241m=\u001b[39m agent_ppo\u001b[38;5;241m.\u001b[39mtrain_model(model\u001b[38;5;241m=\u001b[39m\u001b[43mtrained_ppo\u001b[49m, \n\u001b[1;32m      4\u001b[0m                              tb_log_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                              total_timesteps\u001b[38;5;241m=\u001b[39mtotal_training_step)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent_ppo.train_model(model=trained_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.1'></a>\n",
    "Continue training from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/test_ppo/ppo_14\n",
      "Episode: 262\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 222       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 3655      |\n",
      "| train/             |           |\n",
      "|    reward          | 82.280266 |\n",
      "----------------------------------\n",
      "Episode: 263\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 7310         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.056346e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 1.18e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.22e+05     |\n",
      "|    n_updates            | 12810        |\n",
      "|    policy_gradient_loss | -0.000136    |\n",
      "|    reward               | -49.06183    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 4.45e+05     |\n",
      "------------------------------------------\n",
      "Episode: 264\n",
      "row: 3654, episode: 264\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2760275.47\n",
      "total_reward: 1760275.47\n",
      "total_cost: 1318993.81\n",
      "total_trades: 1447\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 10965       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.70206e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 2.24e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09e+05    |\n",
      "|    n_updates            | 12820       |\n",
      "|    policy_gradient_loss | -5.87e-05   |\n",
      "|    reward               | 105.9873    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 1.62e+06    |\n",
      "-----------------------------------------\n",
      "Episode: 265\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 205           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 14620         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3850264e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000122      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.78e+05      |\n",
      "|    n_updates            | 12830         |\n",
      "|    policy_gradient_loss | 2.79e-05      |\n",
      "|    reward               | -91.23335     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 9.56e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 266\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 88            |\n",
      "|    total_timesteps      | 18275         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7475097e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 4.61e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.38e+06      |\n",
      "|    n_updates            | 12840         |\n",
      "|    policy_gradient_loss | -3.77e-07     |\n",
      "|    reward               | 41.923        |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.77e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 267\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 21930        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.261454e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000135     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.9e+05      |\n",
      "|    n_updates            | 12850        |\n",
      "|    policy_gradient_loss | -1.36e-05    |\n",
      "|    reward               | 180.50719    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.38e+06     |\n",
      "------------------------------------------\n",
      "Episode: 268\n",
      "row: 3654, episode: 268\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1382593.15\n",
      "total_reward: 382593.15\n",
      "total_cost: 836618.93\n",
      "total_trades: 1533\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 201           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 127           |\n",
      "|    total_timesteps      | 25585         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0275364e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 5.48e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.49e+05      |\n",
      "|    n_updates            | 12860         |\n",
      "|    policy_gradient_loss | -1.33e-06     |\n",
      "|    reward               | -164.6348     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 6.99e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 269\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 29240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.866099e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 1.3e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.41e+06     |\n",
      "|    n_updates            | 12870        |\n",
      "|    policy_gradient_loss | -1.48e-05    |\n",
      "|    reward               | -119.328514  |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 4.81e+06     |\n",
      "------------------------------------------\n",
      "Episode: 270\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 32895        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.112206e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 3.08e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.32e+06     |\n",
      "|    n_updates            | 12880        |\n",
      "|    policy_gradient_loss | -6.37e-06    |\n",
      "|    reward               | -11.52243    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 2.65e+06     |\n",
      "------------------------------------------\n",
      "Episode: 271\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 36550        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.896725e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 3.56e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12e+06     |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | -2.74e-06    |\n",
      "|    reward               | -210.03711   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 2.24e+06     |\n",
      "------------------------------------------\n",
      "Episode: 272\n",
      "row: 3654, episode: 272\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3465860.97\n",
      "total_reward: 2465860.97\n",
      "total_cost: 1963215.21\n",
      "total_trades: 1521\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 194           |\n",
      "|    total_timesteps      | 40205         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7698348e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 1.64e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.59e+06      |\n",
      "|    n_updates            | 12900         |\n",
      "|    policy_gradient_loss | -2.18e-05     |\n",
      "|    reward               | 258.29327     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 5.17e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 273\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 43860        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.890914e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | -5.4e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.61e+05     |\n",
      "|    n_updates            | 12910        |\n",
      "|    policy_gradient_loss | -2.98e-05    |\n",
      "|    reward               | 285.68198    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.32e+06     |\n",
      "------------------------------------------\n",
      "Episode: 274\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 208           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 228           |\n",
      "|    total_timesteps      | 47515         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033309418 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.0001        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.39e+04      |\n",
      "|    n_updates            | 12920         |\n",
      "|    policy_gradient_loss | -0.0002       |\n",
      "|    reward               | -38.554623    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.68e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 275\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 51170        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003341537 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 2.6e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.68e+05     |\n",
      "|    n_updates            | 12930        |\n",
      "|    policy_gradient_loss | -0.00015     |\n",
      "|    reward               | -84.381584   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.34e+06     |\n",
      "------------------------------------------\n",
      "Episode: 276\n",
      "row: 3654, episode: 276\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1958883.50\n",
      "total_reward: 958883.50\n",
      "total_cost: 1202946.67\n",
      "total_trades: 1576\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 264           |\n",
      "|    total_timesteps      | 54825         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3991407e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 2.4e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.68e+05      |\n",
      "|    n_updates            | 12940         |\n",
      "|    policy_gradient_loss | 2.5e-05       |\n",
      "|    reward               | -43.78532     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.94e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 277\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 281           |\n",
      "|    total_timesteps      | 58480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6183525e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000142      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.95e+05      |\n",
      "|    n_updates            | 12950         |\n",
      "|    policy_gradient_loss | 1.17e-05      |\n",
      "|    reward               | 174.47781     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.59e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 278\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 298           |\n",
      "|    total_timesteps      | 62135         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0925653e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000122      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.19e+05      |\n",
      "|    n_updates            | 12960         |\n",
      "|    policy_gradient_loss | -3.59e-05     |\n",
      "|    reward               | -168.40623    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 6.38e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 279\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 65790        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.111185e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000103     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.03e+06     |\n",
      "|    n_updates            | 12970        |\n",
      "|    policy_gradient_loss | 8.95e-06     |\n",
      "|    reward               | -124.28916   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 4.06e+06     |\n",
      "------------------------------------------\n",
      "Episode: 280\n",
      "row: 3654, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2086385.96\n",
      "total_reward: 1086385.96\n",
      "total_cost: 1323805.86\n",
      "total_trades: 1571\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 208           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 333           |\n",
      "|    total_timesteps      | 69445         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4350776e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000222      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+06      |\n",
      "|    n_updates            | 12980         |\n",
      "|    policy_gradient_loss | 1.82e-06      |\n",
      "|    reward               | -6.0340586    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.25e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 281\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 351           |\n",
      "|    total_timesteps      | 73100         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5997498e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 4.74e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.05e+05      |\n",
      "|    n_updates            | 12990         |\n",
      "|    policy_gradient_loss | -5e-06        |\n",
      "|    reward               | 179.83813     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.21e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 282\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 208           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 368           |\n",
      "|    total_timesteps      | 76755         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0807403e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 4.4e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.57e+05      |\n",
      "|    n_updates            | 13000         |\n",
      "|    policy_gradient_loss | -5.25e-05     |\n",
      "|    reward               | -136.0399     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.15e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 283\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 385          |\n",
      "|    total_timesteps      | 80410        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.031093e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 7.41e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.86e+06     |\n",
      "|    n_updates            | 13010        |\n",
      "|    policy_gradient_loss | -3.08e-05    |\n",
      "|    reward               | -171.82997   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 3.72e+06     |\n",
      "------------------------------------------\n",
      "Episode: 284\n",
      "row: 3654, episode: 284\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1867499.93\n",
      "total_reward: 867499.93\n",
      "total_cost: 1218122.96\n",
      "total_trades: 1451\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 209           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 401           |\n",
      "|    total_timesteps      | 84065         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1429595e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 1.6e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+06      |\n",
      "|    n_updates            | 13020         |\n",
      "|    policy_gradient_loss | 1.38e-05      |\n",
      "|    reward               | -74.38382     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.77e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 285\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 87720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 1.00793e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 2.97e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.18e+05    |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -3.29e-06   |\n",
      "|    reward               | -24.846073  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 1.64e+06    |\n",
      "-----------------------------------------\n",
      "Episode: 286\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 208           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 437           |\n",
      "|    total_timesteps      | 91375         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0890934e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 2.4e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.13e+06      |\n",
      "|    n_updates            | 13040         |\n",
      "|    policy_gradient_loss | -3.86e-06     |\n",
      "|    reward               | 76.78122      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.26e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 287\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 208           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 454           |\n",
      "|    total_timesteps      | 95030         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8012064e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 1.19e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.31e+05      |\n",
      "|    n_updates            | 13050         |\n",
      "|    policy_gradient_loss | -9.29e-05     |\n",
      "|    reward               | 351.58786     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 8.61e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 288\n",
      "row: 3654, episode: 288\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1728562.18\n",
      "total_reward: 728562.18\n",
      "total_cost: 928170.66\n",
      "total_trades: 1602\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 209           |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 471           |\n",
      "|    total_timesteps      | 98685         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8667424e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | -0.000238     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.22e+05      |\n",
      "|    n_updates            | 13060         |\n",
      "|    policy_gradient_loss | 2.13e-05      |\n",
      "|    reward               | -86.55393     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.44e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 289\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 208           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 489           |\n",
      "|    total_timesteps      | 102340        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1727788e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000166      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.45e+06      |\n",
      "|    n_updates            | 13070         |\n",
      "|    policy_gradient_loss | -0.000146     |\n",
      "|    reward               | -9.906622     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.91e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 290\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 208           |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 509           |\n",
      "|    total_timesteps      | 105995        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3594474e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000722      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.41e+05      |\n",
      "|    n_updates            | 13080         |\n",
      "|    policy_gradient_loss | -2.25e-06     |\n",
      "|    reward               | -124.15701    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.48e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 291\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 527           |\n",
      "|    total_timesteps      | 109650        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0921267e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 2.07e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.5e+06       |\n",
      "|    n_updates            | 13090         |\n",
      "|    policy_gradient_loss | 7.87e-06      |\n",
      "|    reward               | -84.115295    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3e+06         |\n",
      "-------------------------------------------\n",
      "Episode: 292\n",
      "row: 3654, episode: 292\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3127900.31\n",
      "total_reward: 2127900.31\n",
      "total_cost: 1370034.39\n",
      "total_trades: 1600\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 544           |\n",
      "|    total_timesteps      | 113305        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7431302e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 9.31e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.25e+06      |\n",
      "|    n_updates            | 13100         |\n",
      "|    policy_gradient_loss | -3.65e-09     |\n",
      "|    reward               | 182.76187     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.49e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 293\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 563           |\n",
      "|    total_timesteps      | 116960        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7223484e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 9.65e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.87e+05      |\n",
      "|    n_updates            | 13110         |\n",
      "|    policy_gradient_loss | -1.11e-05     |\n",
      "|    reward               | 22.699831     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 7.75e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 294\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 581          |\n",
      "|    total_timesteps      | 120615       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.596407e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000156     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.67e+05     |\n",
      "|    n_updates            | 13120        |\n",
      "|    policy_gradient_loss | -2.19e-05    |\n",
      "|    reward               | 221.9259     |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 9.34e+05     |\n",
      "------------------------------------------\n",
      "Episode: 295\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 600           |\n",
      "|    total_timesteps      | 124270        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017653627 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 9.21e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.71e+04      |\n",
      "|    n_updates            | 13130         |\n",
      "|    policy_gradient_loss | -8.4e-05      |\n",
      "|    reward               | 232.02715     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 9.43e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 296\n",
      "row: 3654, episode: 296\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2399345.87\n",
      "total_reward: 1399345.87\n",
      "total_cost: 1237144.70\n",
      "total_trades: 1517\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 618           |\n",
      "|    total_timesteps      | 127925        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018557791 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000164      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.35e+04      |\n",
      "|    n_updates            | 13140         |\n",
      "|    policy_gradient_loss | -8.55e-05     |\n",
      "|    reward               | 37.27447      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 297\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 636          |\n",
      "|    total_timesteps      | 131580       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003824859 |\n",
      "|    clip_fraction        | 2.74e-05     |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000167     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.58e+05     |\n",
      "|    n_updates            | 13150        |\n",
      "|    policy_gradient_loss | -0.000142    |\n",
      "|    reward               | 342.74908    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.12e+06     |\n",
      "------------------------------------------\n",
      "Episode: 298\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 653           |\n",
      "|    total_timesteps      | 135235        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.5377775e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | -0.000367     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.83e+05      |\n",
      "|    n_updates            | 13160         |\n",
      "|    policy_gradient_loss | -5.54e-05     |\n",
      "|    reward               | 255.06447     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.66e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 299\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 671           |\n",
      "|    total_timesteps      | 138890        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1536794e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | -0.000476     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.56e+05      |\n",
      "|    n_updates            | 13170         |\n",
      "|    policy_gradient_loss | -6.7e-05      |\n",
      "|    reward               | 139.52493     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 9.12e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 300\n",
      "row: 3654, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1818934.64\n",
      "total_reward: 818934.64\n",
      "total_cost: 1019475.22\n",
      "total_trades: 1604\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 689           |\n",
      "|    total_timesteps      | 142545        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7367864e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.00097       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.03e+05      |\n",
      "|    n_updates            | 13180         |\n",
      "|    policy_gradient_loss | -4.05e-05     |\n",
      "|    reward               | -99.893394    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.01e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 301\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 708           |\n",
      "|    total_timesteps      | 146200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0792436e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000577      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.14e+06      |\n",
      "|    n_updates            | 13190         |\n",
      "|    policy_gradient_loss | 5.48e-06      |\n",
      "|    reward               | 8.943031      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.27e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 302\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 727           |\n",
      "|    total_timesteps      | 149855        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7319077e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.00021       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.55e+05      |\n",
      "|    n_updates            | 13200         |\n",
      "|    policy_gradient_loss | -1.04e-05     |\n",
      "|    reward               | -54.05486     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.31e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 303\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 744           |\n",
      "|    total_timesteps      | 153510        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4462485e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000308      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.56e+05      |\n",
      "|    n_updates            | 13210         |\n",
      "|    policy_gradient_loss | -1.7e-06      |\n",
      "|    reward               | 100.4797      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.11e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 304\n",
      "row: 3654, episode: 304\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2204863.64\n",
      "total_reward: 1204863.64\n",
      "total_cost: 1238328.43\n",
      "total_trades: 1490\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 762          |\n",
      "|    total_timesteps      | 157165       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.069099e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.00131      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.8e+05      |\n",
      "|    n_updates            | 13220        |\n",
      "|    policy_gradient_loss | -3.66e-05    |\n",
      "|    reward               | -4.267931    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 7.61e+05     |\n",
      "------------------------------------------\n",
      "Episode: 305\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 780          |\n",
      "|    total_timesteps      | 160820       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.789106e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000126     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.11e+05     |\n",
      "|    n_updates            | 13230        |\n",
      "|    policy_gradient_loss | 1.44e-05     |\n",
      "|    reward               | -107.7098    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.22e+06     |\n",
      "------------------------------------------\n",
      "Episode: 306\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 798           |\n",
      "|    total_timesteps      | 164475        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7815245e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.00024       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+06      |\n",
      "|    n_updates            | 13240         |\n",
      "|    policy_gradient_loss | -2.71e-05     |\n",
      "|    reward               | -160.87587    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.04e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 307\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 815           |\n",
      "|    total_timesteps      | 168130        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.6762135e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000166      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.91e+06      |\n",
      "|    n_updates            | 13250         |\n",
      "|    policy_gradient_loss | -3.92e-05     |\n",
      "|    reward               | 59.264065     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.83e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 308\n",
      "row: 3654, episode: 308\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2656614.34\n",
      "total_reward: 1656614.34\n",
      "total_cost: 1404485.42\n",
      "total_trades: 1570\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 832           |\n",
      "|    total_timesteps      | 171785        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6377543e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000336      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.39e+05      |\n",
      "|    n_updates            | 13260         |\n",
      "|    policy_gradient_loss | -1.48e-05     |\n",
      "|    reward               | 66.05323      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.08e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 309\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 850          |\n",
      "|    total_timesteps      | 175440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.063529e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000425     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.67e+05     |\n",
      "|    n_updates            | 13270        |\n",
      "|    policy_gradient_loss | 5.35e-06     |\n",
      "|    reward               | 114.343636   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 3.34e+05     |\n",
      "------------------------------------------\n",
      "Episode: 310\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 866           |\n",
      "|    total_timesteps      | 179095        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3482261e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.00137       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.59e+05      |\n",
      "|    n_updates            | 13280         |\n",
      "|    policy_gradient_loss | -3.75e-05     |\n",
      "|    reward               | -114.20961    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.19e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 311\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 50            |\n",
      "|    time_elapsed         | 884           |\n",
      "|    total_timesteps      | 182750        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1108185e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 6.32e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.53e+06      |\n",
      "|    n_updates            | 13290         |\n",
      "|    policy_gradient_loss | 5.33e-05      |\n",
      "|    reward               | -93.22924     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.05e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 312\n",
      "row: 3654, episode: 312\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1833465.03\n",
      "total_reward: 833465.03\n",
      "total_cost: 865700.96\n",
      "total_trades: 1469\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 904           |\n",
      "|    total_timesteps      | 186405        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3246909e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000182      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.39e+05      |\n",
      "|    n_updates            | 13300         |\n",
      "|    policy_gradient_loss | -1.88e-05     |\n",
      "|    reward               | -93.09553     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.68e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 313\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 922           |\n",
      "|    total_timesteps      | 190060        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7021416e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000239      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.04e+06      |\n",
      "|    n_updates            | 13310         |\n",
      "|    policy_gradient_loss | -4.59e-05     |\n",
      "|    reward               | 174.63768     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 4.08e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 314\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 205           |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 942           |\n",
      "|    total_timesteps      | 193715        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7542486e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | -0.000172     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.54e+05      |\n",
      "|    n_updates            | 13320         |\n",
      "|    policy_gradient_loss | -2e-05        |\n",
      "|    reward               | 729.7178      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.09e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 315\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 205           |\n",
      "|    iterations           | 54            |\n",
      "|    time_elapsed         | 959           |\n",
      "|    total_timesteps      | 197370        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0429276e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | -6.62e-05     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.07e+06      |\n",
      "|    n_updates            | 13330         |\n",
      "|    policy_gradient_loss | -6.26e-05     |\n",
      "|    reward               | -104.63948    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.15e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 316\n",
      "row: 3654, episode: 316\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1268595.00\n",
      "total_reward: 268595.00\n",
      "total_cost: 929096.99\n",
      "total_trades: 1662\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 978          |\n",
      "|    total_timesteps      | 201025       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.085982e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000314     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.46e+06     |\n",
      "|    n_updates            | 13340        |\n",
      "|    policy_gradient_loss | 1.06e-05     |\n",
      "|    reward               | -173.90271   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 4.92e+06     |\n",
      "------------------------------------------\n",
      "Episode: 317\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 997          |\n",
      "|    total_timesteps      | 204680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.686658e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 8.3e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.36e+06     |\n",
      "|    n_updates            | 13350        |\n",
      "|    policy_gradient_loss | 3.38e-06     |\n",
      "|    reward               | 89.411995    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 2.72e+06     |\n",
      "------------------------------------------\n",
      "Episode: 318\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 204           |\n",
      "|    iterations           | 57            |\n",
      "|    time_elapsed         | 1017          |\n",
      "|    total_timesteps      | 208335        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7154645e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 8.86e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.67e+04      |\n",
      "|    n_updates            | 13360         |\n",
      "|    policy_gradient_loss | -6.9e-05      |\n",
      "|    reward               | 229.59076     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 319\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1039         |\n",
      "|    total_timesteps      | 211990       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.827876e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | -5.59e-05    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.18e+05     |\n",
      "|    n_updates            | 13370        |\n",
      "|    policy_gradient_loss | -9.36e-05    |\n",
      "|    reward               | -231.55844   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.04e+06     |\n",
      "------------------------------------------\n",
      "Episode: 320\n",
      "row: 3654, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2363209.20\n",
      "total_reward: 1363209.20\n",
      "total_cost: 1212269.69\n",
      "total_trades: 1676\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 202           |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 1062          |\n",
      "|    total_timesteps      | 215645        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1195847e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 4.05e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.9e+06       |\n",
      "|    n_updates            | 13380         |\n",
      "|    policy_gradient_loss | -0.00011      |\n",
      "|    reward               | 46.920975     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.79e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 321\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 202           |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 1082          |\n",
      "|    total_timesteps      | 219300        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7852806e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000103      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.59e+05      |\n",
      "|    n_updates            | 13390         |\n",
      "|    policy_gradient_loss | -2.99e-05     |\n",
      "|    reward               | 94.02871      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 9.18e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 322\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 202           |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 1102          |\n",
      "|    total_timesteps      | 222955        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3608825e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.00094       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.61e+05      |\n",
      "|    n_updates            | 13400         |\n",
      "|    policy_gradient_loss | -2.25e-05     |\n",
      "|    reward               | -4.546161     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 5.22e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 323\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 201           |\n",
      "|    iterations           | 62            |\n",
      "|    time_elapsed         | 1123          |\n",
      "|    total_timesteps      | 226610        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1205327e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 3.67e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.01e+05      |\n",
      "|    n_updates            | 13410         |\n",
      "|    policy_gradient_loss | -8.08e-05     |\n",
      "|    reward               | 98.10267      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.6e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 324\n",
      "row: 3654, episode: 324\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3135052.06\n",
      "total_reward: 2135052.06\n",
      "total_cost: 1516667.13\n",
      "total_trades: 1552\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 1145         |\n",
      "|    total_timesteps      | 230265       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.983967e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 3.74e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.97e+05     |\n",
      "|    n_updates            | 13420        |\n",
      "|    policy_gradient_loss | -3.32e-05    |\n",
      "|    reward               | 190.96126    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 9.95e+05     |\n",
      "------------------------------------------\n",
      "Episode: 325\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 200           |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 1167          |\n",
      "|    total_timesteps      | 233920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0158454e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 4.8e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+05      |\n",
      "|    n_updates            | 13430         |\n",
      "|    policy_gradient_loss | -1.72e-06     |\n",
      "|    reward               | -105.76645    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 3.21e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 326\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 200          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1185         |\n",
      "|    total_timesteps      | 237575       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.893265e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 5.97e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.63e+06     |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | 3.32e-06     |\n",
      "|    reward               | 39.214188    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 3.27e+06     |\n",
      "------------------------------------------\n",
      "Episode: 327\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 199           |\n",
      "|    iterations           | 66            |\n",
      "|    time_elapsed         | 1206          |\n",
      "|    total_timesteps      | 241230        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.8890577e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.00016       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.63e+05      |\n",
      "|    n_updates            | 13450         |\n",
      "|    policy_gradient_loss | -3.85e-05     |\n",
      "|    reward               | -212.25064    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.33e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 328\n",
      "row: 3654, episode: 328\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2224062.36\n",
      "total_reward: 1224062.36\n",
      "total_cost: 1270248.67\n",
      "total_trades: 1673\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 199           |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 1229          |\n",
      "|    total_timesteps      | 244885        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0848111e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000249      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.26e+06      |\n",
      "|    n_updates            | 13460         |\n",
      "|    policy_gradient_loss | -2.06e-05     |\n",
      "|    reward               | 18.763718     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 4.52e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 329\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1250        |\n",
      "|    total_timesteps      | 248540      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.29392e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 5.38e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.22e+05    |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -1.14e-05   |\n",
      "|    reward               | 237.68445   |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 8.44e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 330\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 198           |\n",
      "|    iterations           | 69            |\n",
      "|    time_elapsed         | 1273          |\n",
      "|    total_timesteps      | 252195        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7192715e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000557      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.81e+04      |\n",
      "|    n_updates            | 13480         |\n",
      "|    policy_gradient_loss | -4.99e-05     |\n",
      "|    reward               | -145.39542    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 9.63e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 331\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 197           |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 1293          |\n",
      "|    total_timesteps      | 255850        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4862626e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000457      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.07e+06      |\n",
      "|    n_updates            | 13490         |\n",
      "|    policy_gradient_loss | 5.68e-06      |\n",
      "|    reward               | -120.6304     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.14e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 332\n",
      "row: 3654, episode: 332\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2152368.58\n",
      "total_reward: 1152368.58\n",
      "total_cost: 986611.11\n",
      "total_trades: 1629\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 197           |\n",
      "|    iterations           | 71            |\n",
      "|    time_elapsed         | 1316          |\n",
      "|    total_timesteps      | 259505        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2246494e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 9.94e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.1e+06       |\n",
      "|    n_updates            | 13500         |\n",
      "|    policy_gradient_loss | -9.42e-06     |\n",
      "|    reward               | -2.5698056    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.19e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 333\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 196           |\n",
      "|    iterations           | 72            |\n",
      "|    time_elapsed         | 1337          |\n",
      "|    total_timesteps      | 263160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5992517e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000466      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.28e+05      |\n",
      "|    n_updates            | 13510         |\n",
      "|    policy_gradient_loss | -5.84e-06     |\n",
      "|    reward               | -86.331924    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.46e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 334\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 196           |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 1361          |\n",
      "|    total_timesteps      | 266815        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6835714e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 4.15e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28e+06      |\n",
      "|    n_updates            | 13520         |\n",
      "|    policy_gradient_loss | -4.65e-07     |\n",
      "|    reward               | 521.935       |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.56e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 335\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1384         |\n",
      "|    total_timesteps      | 270470       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.988395e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | -0.000375    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.82e+05     |\n",
      "|    n_updates            | 13530        |\n",
      "|    policy_gradient_loss | -3.54e-05    |\n",
      "|    reward               | -52.447002   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.76e+06     |\n",
      "------------------------------------------\n",
      "Episode: 336\n",
      "row: 3654, episode: 336\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3072480.45\n",
      "total_reward: 2072480.45\n",
      "total_cost: 1332010.59\n",
      "total_trades: 1629\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 194           |\n",
      "|    iterations           | 75            |\n",
      "|    time_elapsed         | 1406          |\n",
      "|    total_timesteps      | 274125        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7625125e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000339      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.92e+05      |\n",
      "|    n_updates            | 13540         |\n",
      "|    policy_gradient_loss | 1.47e-05      |\n",
      "|    reward               | 185.18027     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.59e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 337\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 194           |\n",
      "|    iterations           | 76            |\n",
      "|    time_elapsed         | 1429          |\n",
      "|    total_timesteps      | 277780        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3839294e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | -5.84e-06     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 13550         |\n",
      "|    policy_gradient_loss | -1.16e-05     |\n",
      "|    reward               | 20.577456     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 2.46e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 338\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 193          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1453         |\n",
      "|    total_timesteps      | 281435       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.522547e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 8.12e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.13e+05     |\n",
      "|    n_updates            | 13560        |\n",
      "|    policy_gradient_loss | -0.000224    |\n",
      "|    reward               | 142.82542    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "Episode: 339\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 193          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1476         |\n",
      "|    total_timesteps      | 285090       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002887386 |\n",
      "|    clip_fraction        | 2.74e-05     |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 1.94e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.1e+05      |\n",
      "|    n_updates            | 13570        |\n",
      "|    policy_gradient_loss | -0.000167    |\n",
      "|    reward               | 22.875753    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 4.2e+05      |\n",
      "------------------------------------------\n",
      "Episode: 340\n",
      "row: 3654, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2091366.53\n",
      "total_reward: 1091366.53\n",
      "total_cost: 971506.60\n",
      "total_trades: 1769\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 192           |\n",
      "|    iterations           | 79            |\n",
      "|    time_elapsed         | 1500          |\n",
      "|    total_timesteps      | 288745        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037795646 |\n",
      "|    clip_fraction        | 0.000301      |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 6.26e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.07e+05      |\n",
      "|    n_updates            | 13580         |\n",
      "|    policy_gradient_loss | 0.000233      |\n",
      "|    reward               | 3.680744      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 8.14e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 341\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 192           |\n",
      "|    iterations           | 80            |\n",
      "|    time_elapsed         | 1522          |\n",
      "|    total_timesteps      | 292400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0671523e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000322      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.38e+05      |\n",
      "|    n_updates            | 13590         |\n",
      "|    policy_gradient_loss | -2.48e-05     |\n",
      "|    reward               | 315.7102      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.88e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 342\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 191           |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 1544          |\n",
      "|    total_timesteps      | 296055        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9112508e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | -8.79e-05     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.33e+05      |\n",
      "|    n_updates            | 13600         |\n",
      "|    policy_gradient_loss | -8.45e-07     |\n",
      "|    reward               | 142.68007     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 6.66e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 343\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 191           |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 1566          |\n",
      "|    total_timesteps      | 299710        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0942112e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000355      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.92e+04      |\n",
      "|    n_updates            | 13610         |\n",
      "|    policy_gradient_loss | -1.33e-06     |\n",
      "|    reward               | 138.92384     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.78e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 344\n",
      "row: 3654, episode: 344\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1818922.13\n",
      "total_reward: 818922.13\n",
      "total_cost: 978398.91\n",
      "total_trades: 1726\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 190           |\n",
      "|    iterations           | 83            |\n",
      "|    time_elapsed         | 1591          |\n",
      "|    total_timesteps      | 303365        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4026194e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000112      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.5e+04       |\n",
      "|    n_updates            | 13620         |\n",
      "|    policy_gradient_loss | -6.99e-05     |\n",
      "|    reward               | -57.493202    |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.7e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 345\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 189           |\n",
      "|    iterations           | 84            |\n",
      "|    time_elapsed         | 1617          |\n",
      "|    total_timesteps      | 307020        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6529804e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000118      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.23e+05      |\n",
      "|    n_updates            | 13630         |\n",
      "|    policy_gradient_loss | 3.4e-05       |\n",
      "|    reward               | -14.7596245   |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.65e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 346\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 189          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1643         |\n",
      "|    total_timesteps      | 310675       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.602534e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 9.03e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.59e+05     |\n",
      "|    n_updates            | 13640        |\n",
      "|    policy_gradient_loss | -1.26e-06    |\n",
      "|    reward               | -89.05136    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.32e+06     |\n",
      "------------------------------------------\n",
      "Episode: 347\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 188           |\n",
      "|    iterations           | 86            |\n",
      "|    time_elapsed         | 1671          |\n",
      "|    total_timesteps      | 314330        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1007421e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 2.77e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.16e+05      |\n",
      "|    n_updates            | 13650         |\n",
      "|    policy_gradient_loss | -3.68e-05     |\n",
      "|    reward               | 150.4111      |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 1.43e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 348\n",
      "row: 3654, episode: 348\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2286751.36\n",
      "total_reward: 1286751.36\n",
      "total_cost: 1239623.55\n",
      "total_trades: 1679\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1692         |\n",
      "|    total_timesteps      | 317985       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.746531e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000177     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.92e+05     |\n",
      "|    n_updates            | 13660        |\n",
      "|    policy_gradient_loss | 3.22e-06     |\n",
      "|    reward               | 30.810846    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 3.85e+05     |\n",
      "------------------------------------------\n",
      "Episode: 349\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 1717         |\n",
      "|    total_timesteps      | 321640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.996826e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.00101      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.4e+05      |\n",
      "|    n_updates            | 13670        |\n",
      "|    policy_gradient_loss | -1.73e-05    |\n",
      "|    reward               | 27.7778      |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 6.8e+05      |\n",
      "------------------------------------------\n",
      "Episode: 350\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 1740         |\n",
      "|    total_timesteps      | 325295       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.569133e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 1.1e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2e+05        |\n",
      "|    n_updates            | 13680        |\n",
      "|    policy_gradient_loss | -1.01e-05    |\n",
      "|    reward               | 216.35786    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 4.01e+05     |\n",
      "------------------------------------------\n",
      "Episode: 351\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1763         |\n",
      "|    total_timesteps      | 328950       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013929793 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | -4.36e-05    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.46e+04     |\n",
      "|    n_updates            | 13690        |\n",
      "|    policy_gradient_loss | -0.000474    |\n",
      "|    reward               | -23.050833   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 4.92e+04     |\n",
      "------------------------------------------\n",
      "Episode: 352\n",
      "row: 3654, episode: 352\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2666954.82\n",
      "total_reward: 1666954.82\n",
      "total_cost: 1308187.51\n",
      "total_trades: 1854\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 186         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1787        |\n",
      "|    total_timesteps      | 332605      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001048519 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 2.49e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.53e+05    |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | 2.9e-06     |\n",
      "|    reward               | 119.16362   |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 1.11e+06    |\n",
      "-----------------------------------------\n",
      "Episode: 353\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 185          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1809         |\n",
      "|    total_timesteps      | 336260       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006207077 |\n",
      "|    clip_fraction        | 0.000492     |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000322     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.48e+04     |\n",
      "|    n_updates            | 13710        |\n",
      "|    policy_gradient_loss | -0.000444    |\n",
      "|    reward               | 91.88492     |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 1.1e+05      |\n",
      "------------------------------------------\n",
      "Episode: 354\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 185          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1830         |\n",
      "|    total_timesteps      | 339915       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003433283 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.000877     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.2e+05      |\n",
      "|    n_updates            | 13720        |\n",
      "|    policy_gradient_loss | -8.74e-05    |\n",
      "|    reward               | 121.32707    |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 2.41e+05     |\n",
      "------------------------------------------\n",
      "Episode: 355\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 185           |\n",
      "|    iterations           | 94            |\n",
      "|    time_elapsed         | 1851          |\n",
      "|    total_timesteps      | 343570        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017752236 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.000106      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.27e+04      |\n",
      "|    n_updates            | 13730         |\n",
      "|    policy_gradient_loss | -4.32e-05     |\n",
      "|    reward               | 110.56174     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 8.55e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 356\n",
      "row: 3654, episode: 356\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2948724.68\n",
      "total_reward: 1948724.68\n",
      "total_cost: 1291252.92\n",
      "total_trades: 1622\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 185           |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 1872          |\n",
      "|    total_timesteps      | 347225        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011300222 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 0.00038       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.14e+05      |\n",
      "|    n_updates            | 13740         |\n",
      "|    policy_gradient_loss | -9.64e-05     |\n",
      "|    reward               | 150.64645     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 4.29e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 357\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 185           |\n",
      "|    iterations           | 96            |\n",
      "|    time_elapsed         | 1892          |\n",
      "|    total_timesteps      | 350880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8008777e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.6          |\n",
      "|    explained_variance   | 4.59e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.39e+05      |\n",
      "|    n_updates            | 13750         |\n",
      "|    policy_gradient_loss | -5.1e-05      |\n",
      "|    reward               | 252.62953     |\n",
      "|    std                  | 1.2           |\n",
      "|    value_loss           | 4.79e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 358\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 185           |\n",
      "|    iterations           | 97            |\n",
      "|    time_elapsed         | 1915          |\n",
      "|    total_timesteps      | 354535        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4700316e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.0014        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+05      |\n",
      "|    n_updates            | 13760         |\n",
      "|    policy_gradient_loss | -8.15e-06     |\n",
      "|    reward               | -81.52205     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.11e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 359\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 185          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 1935         |\n",
      "|    total_timesteps      | 358190       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.733816e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 3.95e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.23e+06     |\n",
      "|    n_updates            | 13770        |\n",
      "|    policy_gradient_loss | -1.35e-05    |\n",
      "|    reward               | 233.48273    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 2.45e+06     |\n",
      "------------------------------------------\n",
      "Episode: 360\n",
      "row: 3654, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1764410.80\n",
      "total_reward: 764410.80\n",
      "total_cost: 1184590.60\n",
      "total_trades: 1562\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 185           |\n",
      "|    iterations           | 99            |\n",
      "|    time_elapsed         | 1955          |\n",
      "|    total_timesteps      | 361845        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9455302e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000172      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.12e+05      |\n",
      "|    n_updates            | 13780         |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    reward               | -82.83702     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 4.23e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 361\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 184          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1976         |\n",
      "|    total_timesteps      | 365500       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.791156e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000135     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.02e+05     |\n",
      "|    n_updates            | 13790        |\n",
      "|    policy_gradient_loss | -0.000124    |\n",
      "|    reward               | 35.318195    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 1.6e+06      |\n",
      "------------------------------------------\n",
      "Episode: 362\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 184           |\n",
      "|    iterations           | 101           |\n",
      "|    time_elapsed         | 1997          |\n",
      "|    total_timesteps      | 369155        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4904975e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 7.62e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.1e+05       |\n",
      "|    n_updates            | 13800         |\n",
      "|    policy_gradient_loss | 2.85e-05      |\n",
      "|    reward               | -58.397583    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 8.19e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 363\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 184           |\n",
      "|    iterations           | 102           |\n",
      "|    time_elapsed         | 2023          |\n",
      "|    total_timesteps      | 372810        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0218168e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 1.78e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.14e+06      |\n",
      "|    n_updates            | 13810         |\n",
      "|    policy_gradient_loss | -1.93e-06     |\n",
      "|    reward               | -175.21095    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.29e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 364\n",
      "row: 3654, episode: 364\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2991201.39\n",
      "total_reward: 1991201.39\n",
      "total_cost: 1331212.26\n",
      "total_trades: 1590\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 183           |\n",
      "|    iterations           | 103           |\n",
      "|    time_elapsed         | 2049          |\n",
      "|    total_timesteps      | 376465        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3385242e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 9.67e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28e+06      |\n",
      "|    n_updates            | 13820         |\n",
      "|    policy_gradient_loss | 3.16e-08      |\n",
      "|    reward               | 162.02943     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.57e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 365\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 183            |\n",
      "|    iterations           | 104            |\n",
      "|    time_elapsed         | 2072           |\n",
      "|    total_timesteps      | 380120         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.05200975e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.61          |\n",
      "|    explained_variance   | 0.000105       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 2.23e+05       |\n",
      "|    n_updates            | 13830          |\n",
      "|    policy_gradient_loss | -1.51e-06      |\n",
      "|    reward               | 10.858044      |\n",
      "|    std                  | 1.21           |\n",
      "|    value_loss           | 4.45e+05       |\n",
      "--------------------------------------------\n",
      "Episode: 366\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 2094         |\n",
      "|    total_timesteps      | 383775       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.822128e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 5.02e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.95e+05     |\n",
      "|    n_updates            | 13840        |\n",
      "|    policy_gradient_loss | -6.54e-06    |\n",
      "|    reward               | -207.93095   |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 1.79e+06     |\n",
      "------------------------------------------\n",
      "Episode: 367\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 2115         |\n",
      "|    total_timesteps      | 387430       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.076925e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 8.17e-06     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.32e+06     |\n",
      "|    n_updates            | 13850        |\n",
      "|    policy_gradient_loss | 3.51e-06     |\n",
      "|    reward               | 187.59093    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 4.63e+06     |\n",
      "------------------------------------------\n",
      "Episode: 368\n",
      "row: 3654, episode: 368\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3279313.58\n",
      "total_reward: 2279313.58\n",
      "total_cost: 1475471.14\n",
      "total_trades: 1572\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 183           |\n",
      "|    iterations           | 107           |\n",
      "|    time_elapsed         | 2135          |\n",
      "|    total_timesteps      | 391085        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8518345e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000121      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.2e+05       |\n",
      "|    n_updates            | 13860         |\n",
      "|    policy_gradient_loss | -1.73e-05     |\n",
      "|    reward               | 224.60905     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 4.4e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 369\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 2156         |\n",
      "|    total_timesteps      | 394740       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.285585e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000142     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.14e+05     |\n",
      "|    n_updates            | 13870        |\n",
      "|    policy_gradient_loss | -1.96e-06    |\n",
      "|    reward               | 0.464957     |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 2.29e+05     |\n",
      "------------------------------------------\n",
      "Episode: 370\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 182           |\n",
      "|    iterations           | 109           |\n",
      "|    time_elapsed         | 2177          |\n",
      "|    total_timesteps      | 398395        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4450205e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 3.33e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.04e+06      |\n",
      "|    n_updates            | 13880         |\n",
      "|    policy_gradient_loss | -4.62e-05     |\n",
      "|    reward               | -170.8357     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.09e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 371\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 182           |\n",
      "|    iterations           | 110           |\n",
      "|    time_elapsed         | 2197          |\n",
      "|    total_timesteps      | 402050        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9621324e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000276      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+06      |\n",
      "|    n_updates            | 13890         |\n",
      "|    policy_gradient_loss | -1.69e-05     |\n",
      "|    reward               | -89.50554     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 3.21e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 372\n",
      "row: 3654, episode: 372\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2101758.11\n",
      "total_reward: 1101758.11\n",
      "total_cost: 1128339.67\n",
      "total_trades: 1503\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 182          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 2218         |\n",
      "|    total_timesteps      | 405705       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.211969e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000296     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.43e+06     |\n",
      "|    n_updates            | 13900        |\n",
      "|    policy_gradient_loss | -2.11e-05    |\n",
      "|    reward               | -25.587875   |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 2.87e+06     |\n",
      "------------------------------------------\n",
      "Episode: 373\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 182           |\n",
      "|    iterations           | 112           |\n",
      "|    time_elapsed         | 2239          |\n",
      "|    total_timesteps      | 409360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2354244e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 4.04e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.65e+05      |\n",
      "|    n_updates            | 13910         |\n",
      "|    policy_gradient_loss | 4.41e-06      |\n",
      "|    reward               | 80.17094      |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 1.73e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 374\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 182           |\n",
      "|    iterations           | 113           |\n",
      "|    time_elapsed         | 2260          |\n",
      "|    total_timesteps      | 413015        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.3601307e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 9.6e-06       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.18e+05      |\n",
      "|    n_updates            | 13920         |\n",
      "|    policy_gradient_loss | -3.15e-06     |\n",
      "|    reward               | 5.994812      |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 4.35e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 375\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 182         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 2281        |\n",
      "|    total_timesteps      | 416670      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.83821e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 1.98e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.94e+05    |\n",
      "|    n_updates            | 13930       |\n",
      "|    policy_gradient_loss | -1.45e-05   |\n",
      "|    reward               | 125.22775   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 7.89e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 376\n",
      "row: 3654, episode: 376\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1883117.12\n",
      "total_reward: 883117.12\n",
      "total_cost: 1272917.45\n",
      "total_trades: 1463\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 182           |\n",
      "|    iterations           | 115           |\n",
      "|    time_elapsed         | 2302          |\n",
      "|    total_timesteps      | 420325        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7326992e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000174      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+05      |\n",
      "|    n_updates            | 13940         |\n",
      "|    policy_gradient_loss | -6.04e-05     |\n",
      "|    reward               | -66.48511     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 4.89e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 377\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 182          |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 2328         |\n",
      "|    total_timesteps      | 423980       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.747919e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000214     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.33e+05     |\n",
      "|    n_updates            | 13950        |\n",
      "|    policy_gradient_loss | 2.67e-05     |\n",
      "|    reward               | 71.99359     |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 1.07e+06     |\n",
      "------------------------------------------\n",
      "Episode: 378\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 181          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 2349         |\n",
      "|    total_timesteps      | 427635       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.078888e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.15e+05     |\n",
      "|    n_updates            | 13960        |\n",
      "|    policy_gradient_loss | -4.54e-05    |\n",
      "|    reward               | -76.25471    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 2.3e+05      |\n",
      "------------------------------------------\n",
      "Episode: 379\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 181           |\n",
      "|    iterations           | 118           |\n",
      "|    time_elapsed         | 2378          |\n",
      "|    total_timesteps      | 431290        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9473198e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 8.79e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.31e+06      |\n",
      "|    n_updates            | 13970         |\n",
      "|    policy_gradient_loss | 6.37e-05      |\n",
      "|    reward               | -49.518528    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.62e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 380\n",
      "row: 3654, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3054699.08\n",
      "total_reward: 2054699.08\n",
      "total_cost: 1536449.83\n",
      "total_trades: 1423\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 181           |\n",
      "|    iterations           | 119           |\n",
      "|    time_elapsed         | 2399          |\n",
      "|    total_timesteps      | 434945        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6232681e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 2.06e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.33e+06      |\n",
      "|    n_updates            | 13980         |\n",
      "|    policy_gradient_loss | -0.000175     |\n",
      "|    reward               | 161.89355     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.66e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 381\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 2420        |\n",
      "|    total_timesteps      | 438600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.26967e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.000567    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.31e+04    |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -4.39e-06   |\n",
      "|    reward               | -149.07681  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 1.46e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 382\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 181           |\n",
      "|    iterations           | 121           |\n",
      "|    time_elapsed         | 2441          |\n",
      "|    total_timesteps      | 442255        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8825746e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000157      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+06      |\n",
      "|    n_updates            | 14000         |\n",
      "|    policy_gradient_loss | 2.38e-05      |\n",
      "|    reward               | -18.749533    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 3.21e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 383\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 122           |\n",
      "|    time_elapsed         | 2463          |\n",
      "|    total_timesteps      | 445910        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1590625e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 8.87e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.12e+06      |\n",
      "|    n_updates            | 14010         |\n",
      "|    policy_gradient_loss | -2.57e-05     |\n",
      "|    reward               | -249.8545     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.23e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 384\n",
      "row: 3654, episode: 384\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4163771.74\n",
      "total_reward: 3163771.74\n",
      "total_cost: 1790576.54\n",
      "total_trades: 1445\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 123           |\n",
      "|    time_elapsed         | 2484          |\n",
      "|    total_timesteps      | 449565        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9723186e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000185      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.41e+06      |\n",
      "|    n_updates            | 14020         |\n",
      "|    policy_gradient_loss | 4.93e-06      |\n",
      "|    reward               | 390.98352     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 4.82e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 385\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 181           |\n",
      "|    iterations           | 124           |\n",
      "|    time_elapsed         | 2503          |\n",
      "|    total_timesteps      | 453220        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1950702e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | -6.68e-05     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.06e+05      |\n",
      "|    n_updates            | 14030         |\n",
      "|    policy_gradient_loss | -6.17e-05     |\n",
      "|    reward               | 35.510647     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 6.12e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 386\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 180          |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 2524         |\n",
      "|    total_timesteps      | 456875       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.290169e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000341     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63e+05     |\n",
      "|    n_updates            | 14040        |\n",
      "|    policy_gradient_loss | 4.58e-05     |\n",
      "|    reward               | 175.12177    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 1.13e+06     |\n",
      "------------------------------------------\n",
      "Episode: 387\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 126           |\n",
      "|    time_elapsed         | 2550          |\n",
      "|    total_timesteps      | 460530        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0791725e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 1.86e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.19e+05      |\n",
      "|    n_updates            | 14050         |\n",
      "|    policy_gradient_loss | -1.12e-06     |\n",
      "|    reward               | -169.78593    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.39e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 388\n",
      "row: 3654, episode: 388\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3118970.96\n",
      "total_reward: 2118970.96\n",
      "total_cost: 1540910.50\n",
      "total_trades: 1437\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 127           |\n",
      "|    time_elapsed         | 2570          |\n",
      "|    total_timesteps      | 464185        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2621807e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 7.5e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.74e+06      |\n",
      "|    n_updates            | 14060         |\n",
      "|    policy_gradient_loss | -1.22e-05     |\n",
      "|    reward               | 160.34685     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 3.48e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 389\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 128           |\n",
      "|    time_elapsed         | 2593          |\n",
      "|    total_timesteps      | 467840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0532915e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000352      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.83e+05      |\n",
      "|    n_updates            | 14070         |\n",
      "|    policy_gradient_loss | -3.07e-05     |\n",
      "|    reward               | -83.46579     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 3.67e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 390\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 129           |\n",
      "|    time_elapsed         | 2615          |\n",
      "|    total_timesteps      | 471495        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8344696e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 1.7e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.91e+05      |\n",
      "|    n_updates            | 14080         |\n",
      "|    policy_gradient_loss | 2.32e-05      |\n",
      "|    reward               | -150.16139    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 1.98e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 391\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 180           |\n",
      "|    iterations           | 130           |\n",
      "|    time_elapsed         | 2637          |\n",
      "|    total_timesteps      | 475150        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0457892e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 1.69e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.19e+06      |\n",
      "|    n_updates            | 14090         |\n",
      "|    policy_gradient_loss | -3.2e-06      |\n",
      "|    reward               | -138.09161    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 4.38e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 392\n",
      "row: 3654, episode: 392\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1853333.79\n",
      "total_reward: 853333.79\n",
      "total_cost: 1240609.64\n",
      "total_trades: 1420\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 179           |\n",
      "|    iterations           | 131           |\n",
      "|    time_elapsed         | 2660          |\n",
      "|    total_timesteps      | 478805        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.8276635e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 8.73e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.35e+06      |\n",
      "|    n_updates            | 14100         |\n",
      "|    policy_gradient_loss | -4.87e-05     |\n",
      "|    reward               | -78.38712     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.71e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 393\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 179          |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 2681         |\n",
      "|    total_timesteps      | 482460       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.683585e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.0002       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.1e+06      |\n",
      "|    n_updates            | 14110        |\n",
      "|    policy_gradient_loss | -1.54e-05    |\n",
      "|    reward               | -70.388145   |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 2.21e+06     |\n",
      "------------------------------------------\n",
      "Episode: 394\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 179           |\n",
      "|    iterations           | 133           |\n",
      "|    time_elapsed         | 2706          |\n",
      "|    total_timesteps      | 486115        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9785897e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 4.48e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.59e+06      |\n",
      "|    n_updates            | 14120         |\n",
      "|    policy_gradient_loss | 3.3e-06       |\n",
      "|    reward               | -90.49181     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 3.18e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 395\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 179           |\n",
      "|    iterations           | 134           |\n",
      "|    time_elapsed         | 2729          |\n",
      "|    total_timesteps      | 489770        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9224912e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 3.84e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.95e+05      |\n",
      "|    n_updates            | 14130         |\n",
      "|    policy_gradient_loss | -2.64e-06     |\n",
      "|    reward               | -218.97939    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 1.99e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 396\n",
      "row: 3654, episode: 396\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2325088.12\n",
      "total_reward: 1325088.12\n",
      "total_cost: 1191265.97\n",
      "total_trades: 1465\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 179           |\n",
      "|    iterations           | 135           |\n",
      "|    time_elapsed         | 2751          |\n",
      "|    total_timesteps      | 493425        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7178369e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000367      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.91e+06      |\n",
      "|    n_updates            | 14140         |\n",
      "|    policy_gradient_loss | -1.72e-05     |\n",
      "|    reward               | 13.299453     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 3.83e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 397\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 179           |\n",
      "|    iterations           | 136           |\n",
      "|    time_elapsed         | 2773          |\n",
      "|    total_timesteps      | 497080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5564086e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000244      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.65e+05      |\n",
      "|    n_updates            | 14150         |\n",
      "|    policy_gradient_loss | -8.11e-05     |\n",
      "|    reward               | 8.063376      |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 1.33e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 398\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 179           |\n",
      "|    iterations           | 137           |\n",
      "|    time_elapsed         | 2795          |\n",
      "|    total_timesteps      | 500735        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6024545e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.00024       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.37e+05      |\n",
      "|    n_updates            | 14160         |\n",
      "|    policy_gradient_loss | -6.93e-05     |\n",
      "|    reward               | -3.2492704    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 1.67e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 399\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 178          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 2819         |\n",
      "|    total_timesteps      | 504390       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.721074e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000281     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.17e+05     |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -4.4e-05     |\n",
      "|    reward               | -24.986164   |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 1.43e+06     |\n",
      "------------------------------------------\n",
      "Episode: 400\n",
      "row: 3654, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1619314.94\n",
      "total_reward: 619314.94\n",
      "total_cost: 1003313.80\n",
      "total_trades: 1458\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 139           |\n",
      "|    time_elapsed         | 2843          |\n",
      "|    total_timesteps      | 508045        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8942626e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 3.08e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.5e+05       |\n",
      "|    n_updates            | 14180         |\n",
      "|    policy_gradient_loss | 4.54e-06      |\n",
      "|    reward               | -126.245575   |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 1.9e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 401\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 140           |\n",
      "|    time_elapsed         | 2866          |\n",
      "|    total_timesteps      | 511700        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2714034e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 1.78e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+06      |\n",
      "|    n_updates            | 14190         |\n",
      "|    policy_gradient_loss | -6.19e-05     |\n",
      "|    reward               | 90.04228      |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.98e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 402\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 141           |\n",
      "|    time_elapsed         | 2886          |\n",
      "|    total_timesteps      | 515355        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0787817e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 4.03e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.18e+05      |\n",
      "|    n_updates            | 14200         |\n",
      "|    policy_gradient_loss | -5.87e-05     |\n",
      "|    reward               | -63.66153     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 1.04e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 403\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 178          |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 2910         |\n",
      "|    total_timesteps      | 519010       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.589776e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 7.39e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.33e+06     |\n",
      "|    n_updates            | 14210        |\n",
      "|    policy_gradient_loss | -8.55e-06    |\n",
      "|    reward               | -93.329666   |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 2.67e+06     |\n",
      "------------------------------------------\n",
      "Episode: 404\n",
      "row: 3654, episode: 404\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2066282.26\n",
      "total_reward: 1066282.26\n",
      "total_cost: 973333.19\n",
      "total_trades: 1356\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 143           |\n",
      "|    time_elapsed         | 2930          |\n",
      "|    total_timesteps      | 522665        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9636427e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000683      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.41e+06      |\n",
      "|    n_updates            | 14220         |\n",
      "|    policy_gradient_loss | -1.57e-06     |\n",
      "|    reward               | -45.05512     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.82e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 405\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 178          |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 2951         |\n",
      "|    total_timesteps      | 526320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.127956e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000178     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.07e+06     |\n",
      "|    n_updates            | 14230        |\n",
      "|    policy_gradient_loss | -6.77e-06    |\n",
      "|    reward               | -79.90286    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 4.15e+06     |\n",
      "------------------------------------------\n",
      "Episode: 406\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 145           |\n",
      "|    time_elapsed         | 2975          |\n",
      "|    total_timesteps      | 529975        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3304935e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000481      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.24e+06      |\n",
      "|    n_updates            | 14240         |\n",
      "|    policy_gradient_loss | -2.08e-05     |\n",
      "|    reward               | -96.02785     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.47e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 407\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 178           |\n",
      "|    iterations           | 146           |\n",
      "|    time_elapsed         | 2995          |\n",
      "|    total_timesteps      | 533630        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4274391e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000633      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28e+06      |\n",
      "|    n_updates            | 14250         |\n",
      "|    policy_gradient_loss | -8.66e-05     |\n",
      "|    reward               | -234.71977    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 2.55e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 408\n",
      "row: 3654, episode: 408\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1931584.97\n",
      "total_reward: 931584.97\n",
      "total_cost: 1147583.33\n",
      "total_trades: 1564\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 176           |\n",
      "|    iterations           | 147           |\n",
      "|    time_elapsed         | 3042          |\n",
      "|    total_timesteps      | 537285        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4646794e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000333      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.1e+06       |\n",
      "|    n_updates            | 14260         |\n",
      "|    policy_gradient_loss | -6.07e-05     |\n",
      "|    reward               | -57.857857    |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 6.19e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 409\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 175          |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 3077         |\n",
      "|    total_timesteps      | 540940       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.071631e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 3.8e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79e+05     |\n",
      "|    n_updates            | 14270        |\n",
      "|    policy_gradient_loss | -2.78e-05    |\n",
      "|    reward               | -41.28049    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 1.76e+06     |\n",
      "------------------------------------------\n",
      "Episode: 410\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 174          |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 3112         |\n",
      "|    total_timesteps      | 544595       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.907254e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000604     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.64e+05     |\n",
      "|    n_updates            | 14280        |\n",
      "|    policy_gradient_loss | 4.65e-06     |\n",
      "|    reward               | -169.08325   |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 1.93e+06     |\n",
      "------------------------------------------\n",
      "Episode: 411\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 174           |\n",
      "|    iterations           | 150           |\n",
      "|    time_elapsed         | 3137          |\n",
      "|    total_timesteps      | 548250        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6866285e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 7.99e-06      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.21e+06      |\n",
      "|    n_updates            | 14290         |\n",
      "|    policy_gradient_loss | -2.59e-05     |\n",
      "|    reward               | 219.13243     |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 4.41e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 412\n",
      "row: 3654, episode: 412\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2988950.80\n",
      "total_reward: 1988950.80\n",
      "total_cost: 1360902.05\n",
      "total_trades: 1473\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 174          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 3164         |\n",
      "|    total_timesteps      | 551905       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.493264e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000333     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.64e+05     |\n",
      "|    n_updates            | 14300        |\n",
      "|    policy_gradient_loss | -7.57e-05    |\n",
      "|    reward               | 135.92403    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 3.28e+05     |\n",
      "------------------------------------------\n",
      "Episode: 413\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 174           |\n",
      "|    iterations           | 152           |\n",
      "|    time_elapsed         | 3192          |\n",
      "|    total_timesteps      | 555560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4772281e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 2.61e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.99e+05      |\n",
      "|    n_updates            | 14310         |\n",
      "|    policy_gradient_loss | 4.28e-05      |\n",
      "|    reward               | -3.1772451    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 5.99e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 414\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 153           |\n",
      "|    time_elapsed         | 3216          |\n",
      "|    total_timesteps      | 559215        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0792436e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000142      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.34e+05      |\n",
      "|    n_updates            | 14320         |\n",
      "|    policy_gradient_loss | -5.57e-06     |\n",
      "|    reward               | -134.38141    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.67e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 415\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 154           |\n",
      "|    time_elapsed         | 3239          |\n",
      "|    total_timesteps      | 562870        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5608263e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 6.89e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.1e+06       |\n",
      "|    n_updates            | 14330         |\n",
      "|    policy_gradient_loss | -1.02e-05     |\n",
      "|    reward               | 76.258095     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.2e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 416\n",
      "row: 3654, episode: 416\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3135366.28\n",
      "total_reward: 2135366.28\n",
      "total_cost: 1497992.34\n",
      "total_trades: 1503\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 155           |\n",
      "|    time_elapsed         | 3261          |\n",
      "|    total_timesteps      | 566525        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3180803e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 8.07e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.22e+05      |\n",
      "|    n_updates            | 14340         |\n",
      "|    policy_gradient_loss | -4.05e-06     |\n",
      "|    reward               | 177.25749     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 8.43e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 417\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 156           |\n",
      "|    time_elapsed         | 3287          |\n",
      "|    total_timesteps      | 570180        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1631964e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000157      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.99e+05      |\n",
      "|    n_updates            | 14350         |\n",
      "|    policy_gradient_loss | -7.04e-05     |\n",
      "|    reward               | 269.5048      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 3.99e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 418\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 157           |\n",
      "|    time_elapsed         | 3309          |\n",
      "|    total_timesteps      | 573835        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9030711e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.000757      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.31e+05      |\n",
      "|    n_updates            | 14360         |\n",
      "|    policy_gradient_loss | 6.34e-06      |\n",
      "|    reward               | -36.11631     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.61e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 419\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 158           |\n",
      "|    time_elapsed         | 3330          |\n",
      "|    total_timesteps      | 577490        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1220676e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 0.00031       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.02e+05      |\n",
      "|    n_updates            | 14370         |\n",
      "|    policy_gradient_loss | -6.21e-06     |\n",
      "|    reward               | -12.725399    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.8e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 420\n",
      "row: 3654, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2366138.27\n",
      "total_reward: 1366138.27\n",
      "total_cost: 1184157.90\n",
      "total_trades: 1542\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 173           |\n",
      "|    iterations           | 159           |\n",
      "|    time_elapsed         | 3354          |\n",
      "|    total_timesteps      | 581145        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5658621e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.61         |\n",
      "|    explained_variance   | 3.06e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.09e+05      |\n",
      "|    n_updates            | 14380         |\n",
      "|    policy_gradient_loss | -5.48e-05     |\n",
      "|    reward               | 31.759037     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.82e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 421\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 172          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 3391         |\n",
      "|    total_timesteps      | 584800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.553719e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000622     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.33e+05     |\n",
      "|    n_updates            | 14390        |\n",
      "|    policy_gradient_loss | -8.26e-05    |\n",
      "|    reward               | 154.38596    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 1.47e+06     |\n",
      "------------------------------------------\n",
      "Episode: 422\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 3427        |\n",
      "|    total_timesteps      | 588455      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.63074e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.000136    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+05    |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -7.58e-05   |\n",
      "|    reward               | -217.98834  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 2.66e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 423\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 171          |\n",
      "|    iterations           | 162          |\n",
      "|    time_elapsed         | 3451         |\n",
      "|    total_timesteps      | 592110       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.041229e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.000125     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.26e+06     |\n",
      "|    n_updates            | 14410        |\n",
      "|    policy_gradient_loss | -9.61e-05    |\n",
      "|    reward               | -46.917606   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 4.52e+06     |\n",
      "------------------------------------------\n",
      "Episode: 424\n",
      "row: 3654, episode: 424\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1821737.64\n",
      "total_reward: 821737.64\n",
      "total_cost: 1074414.51\n",
      "total_trades: 1436\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 171           |\n",
      "|    iterations           | 163           |\n",
      "|    time_elapsed         | 3479          |\n",
      "|    total_timesteps      | 595765        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7209695e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000424      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2e+06         |\n",
      "|    n_updates            | 14420         |\n",
      "|    policy_gradient_loss | -3e-05        |\n",
      "|    reward               | -84.3509      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 4e+06         |\n",
      "-------------------------------------------\n",
      "Episode: 425\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 170           |\n",
      "|    iterations           | 164           |\n",
      "|    time_elapsed         | 3510          |\n",
      "|    total_timesteps      | 599420        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.3380694e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000429      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.27e+06      |\n",
      "|    n_updates            | 14430         |\n",
      "|    policy_gradient_loss | -2.06e-05     |\n",
      "|    reward               | -1.4326698    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.54e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 426\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 170           |\n",
      "|    iterations           | 165           |\n",
      "|    time_elapsed         | 3539          |\n",
      "|    total_timesteps      | 603075        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0671759e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 5.29e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.56e+05      |\n",
      "|    n_updates            | 14440         |\n",
      "|    policy_gradient_loss | 5.88e-06      |\n",
      "|    reward               | -16.706789    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.51e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 427\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 169          |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 3573         |\n",
      "|    total_timesteps      | 606730       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.230158e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000165     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.08e+05     |\n",
      "|    n_updates            | 14450        |\n",
      "|    policy_gradient_loss | 1.89e-07     |\n",
      "|    reward               | -116.71346   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 1.82e+06     |\n",
      "------------------------------------------\n",
      "Episode: 428\n",
      "row: 3654, episode: 428\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2085960.28\n",
      "total_reward: 1085960.28\n",
      "total_cost: 1090601.70\n",
      "total_trades: 1461\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 169           |\n",
      "|    iterations           | 167           |\n",
      "|    time_elapsed         | 3604          |\n",
      "|    total_timesteps      | 610385        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9412687e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000144      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.9e+06       |\n",
      "|    n_updates            | 14460         |\n",
      "|    policy_gradient_loss | -1.77e-05     |\n",
      "|    reward               | -60.447838    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 3.79e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 429\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 168         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3640        |\n",
      "|    total_timesteps      | 614040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.23087e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 8.64e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+06    |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -3.76e-06   |\n",
      "|    reward               | 317.43414   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 2.58e+06    |\n",
      "-----------------------------------------\n",
      "Episode: 430\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 168           |\n",
      "|    iterations           | 169           |\n",
      "|    time_elapsed         | 3676          |\n",
      "|    total_timesteps      | 617695        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6763844e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000133      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.1e+05       |\n",
      "|    n_updates            | 14480         |\n",
      "|    policy_gradient_loss | -5.23e-06     |\n",
      "|    reward               | 16.47208      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.19e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 431\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 167           |\n",
      "|    iterations           | 170           |\n",
      "|    time_elapsed         | 3709          |\n",
      "|    total_timesteps      | 621350        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1555519e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 1.28e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.88e+05      |\n",
      "|    n_updates            | 14490         |\n",
      "|    policy_gradient_loss | -3.24e-06     |\n",
      "|    reward               | -33.19625     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 7.76e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 432\n",
      "row: 3654, episode: 432\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2010207.99\n",
      "total_reward: 1010207.99\n",
      "total_cost: 1204122.17\n",
      "total_trades: 1417\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 167           |\n",
      "|    iterations           | 171           |\n",
      "|    time_elapsed         | 3742          |\n",
      "|    total_timesteps      | 625005        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1125439e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 4.98e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.18e+05      |\n",
      "|    n_updates            | 14500         |\n",
      "|    policy_gradient_loss | -7.47e-06     |\n",
      "|    reward               | -76.08988     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.84e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 433\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3776        |\n",
      "|    total_timesteps      | 628660      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.06359e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.000222    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.99e+05    |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | -1.96e-05   |\n",
      "|    reward               | 16.91713    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 1.8e+06     |\n",
      "-----------------------------------------\n",
      "Episode: 434\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 166          |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 3807         |\n",
      "|    total_timesteps      | 632315       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.415507e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 2.12e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.87e+05     |\n",
      "|    n_updates            | 14520        |\n",
      "|    policy_gradient_loss | -3.93e-05    |\n",
      "|    reward               | -41.202568   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 1.77e+06     |\n",
      "------------------------------------------\n",
      "Episode: 435\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 165           |\n",
      "|    iterations           | 174           |\n",
      "|    time_elapsed         | 3835          |\n",
      "|    total_timesteps      | 635970        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3104632e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 3.77e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.48e+05      |\n",
      "|    n_updates            | 14530         |\n",
      "|    policy_gradient_loss | 9.19e-06      |\n",
      "|    reward               | -177.30702    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.3e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 436\n",
      "row: 3654, episode: 436\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3107998.96\n",
      "total_reward: 2107998.96\n",
      "total_cost: 1684051.43\n",
      "total_trades: 1412\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 165           |\n",
      "|    iterations           | 175           |\n",
      "|    time_elapsed         | 3867          |\n",
      "|    total_timesteps      | 639625        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4736706e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 6.9e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.84e+06      |\n",
      "|    n_updates            | 14540         |\n",
      "|    policy_gradient_loss | -1.35e-05     |\n",
      "|    reward               | 169.20082     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 3.69e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 437\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 164           |\n",
      "|    iterations           | 176           |\n",
      "|    time_elapsed         | 3901          |\n",
      "|    total_timesteps      | 643280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5488467e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | -6.53e-05     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.32e+05      |\n",
      "|    n_updates            | 14550         |\n",
      "|    policy_gradient_loss | -2.77e-05     |\n",
      "|    reward               | -120.88954    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 4.63e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 438\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 164           |\n",
      "|    iterations           | 177           |\n",
      "|    time_elapsed         | 3939          |\n",
      "|    total_timesteps      | 646935        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2528496e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 2.51e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+06      |\n",
      "|    n_updates            | 14560         |\n",
      "|    policy_gradient_loss | 2.17e-05      |\n",
      "|    reward               | -57.214546    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 3.25e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 439\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 163           |\n",
      "|    iterations           | 178           |\n",
      "|    time_elapsed         | 3974          |\n",
      "|    total_timesteps      | 650590        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8755042e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 2.34e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.1e+06       |\n",
      "|    n_updates            | 14570         |\n",
      "|    policy_gradient_loss | -1.41e-05     |\n",
      "|    reward               | -130.09283    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.19e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 440\n",
      "row: 3654, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2825933.71\n",
      "total_reward: 1825933.71\n",
      "total_cost: 1460489.85\n",
      "total_trades: 1552\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 163           |\n",
      "|    iterations           | 179           |\n",
      "|    time_elapsed         | 4006          |\n",
      "|    total_timesteps      | 654245        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9796377e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 9.86e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.17e+06      |\n",
      "|    n_updates            | 14580         |\n",
      "|    policy_gradient_loss | -2.61e-05     |\n",
      "|    reward               | 121.43838     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 4.34e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 441\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 162           |\n",
      "|    iterations           | 180           |\n",
      "|    time_elapsed         | 4036          |\n",
      "|    total_timesteps      | 657900        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3522035e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000111      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.72e+05      |\n",
      "|    n_updates            | 14590         |\n",
      "|    policy_gradient_loss | -2.22e-05     |\n",
      "|    reward               | 4.114669      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 5.44e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 442\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 162          |\n",
      "|    iterations           | 181          |\n",
      "|    time_elapsed         | 4065         |\n",
      "|    total_timesteps      | 661555       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.095701e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 1.56e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.43e+05     |\n",
      "|    n_updates            | 14600        |\n",
      "|    policy_gradient_loss | 3.34e-06     |\n",
      "|    reward               | 164.60257    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 1.89e+06     |\n",
      "------------------------------------------\n",
      "Episode: 443\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 162           |\n",
      "|    iterations           | 182           |\n",
      "|    time_elapsed         | 4105          |\n",
      "|    total_timesteps      | 665210        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2294082e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | -7.63e-06     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.35e+05      |\n",
      "|    n_updates            | 14610         |\n",
      "|    policy_gradient_loss | -3.29e-05     |\n",
      "|    reward               | -55.02818     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 4.69e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 444\n",
      "row: 3654, episode: 444\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2560097.28\n",
      "total_reward: 1560097.28\n",
      "total_cost: 1199967.12\n",
      "total_trades: 1512\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 160           |\n",
      "|    iterations           | 183           |\n",
      "|    time_elapsed         | 4164          |\n",
      "|    total_timesteps      | 668865        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0424954e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000232      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.14e+05      |\n",
      "|    n_updates            | 14620         |\n",
      "|    policy_gradient_loss | -1.48e-05     |\n",
      "|    reward               | 69.36973      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.63e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 445\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 184        |\n",
      "|    time_elapsed         | 4193       |\n",
      "|    total_timesteps      | 672520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 5.8642e-06 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.62      |\n",
      "|    explained_variance   | 2.42e-05   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.71e+05   |\n",
      "|    n_updates            | 14630      |\n",
      "|    policy_gradient_loss | -9.91e-06  |\n",
      "|    reward               | -47.700836 |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 1.34e+06   |\n",
      "----------------------------------------\n",
      "Episode: 446\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 159           |\n",
      "|    iterations           | 185           |\n",
      "|    time_elapsed         | 4232          |\n",
      "|    total_timesteps      | 676175        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2796653e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000102      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.15e+06      |\n",
      "|    n_updates            | 14640         |\n",
      "|    policy_gradient_loss | -9.63e-06     |\n",
      "|    reward               | -112.43301    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.29e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 447\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 4267         |\n",
      "|    total_timesteps      | 679830       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.095485e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000184     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.69e+06     |\n",
      "|    n_updates            | 14650        |\n",
      "|    policy_gradient_loss | -2.67e-05    |\n",
      "|    reward               | -140.08058   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 3.38e+06     |\n",
      "------------------------------------------\n",
      "Episode: 448\n",
      "row: 3654, episode: 448\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2554241.09\n",
      "total_reward: 1554241.09\n",
      "total_cost: 1222567.22\n",
      "total_trades: 1420\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 4294         |\n",
      "|    total_timesteps      | 683485       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.495811e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 6.32e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84e+06     |\n",
      "|    n_updates            | 14660        |\n",
      "|    policy_gradient_loss | 7.76e-06     |\n",
      "|    reward               | 59.778214    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 3.68e+06     |\n",
      "------------------------------------------\n",
      "Episode: 449\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 158          |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 4323         |\n",
      "|    total_timesteps      | 687140       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.211241e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 3.37e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.55e+05     |\n",
      "|    n_updates            | 14670        |\n",
      "|    policy_gradient_loss | -5.36e-06    |\n",
      "|    reward               | 111.89848    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 1.31e+06     |\n",
      "------------------------------------------\n",
      "Episode: 450\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 158          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 4352         |\n",
      "|    total_timesteps      | 690795       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.455492e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000267     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.42e+05     |\n",
      "|    n_updates            | 14680        |\n",
      "|    policy_gradient_loss | -2.15e-05    |\n",
      "|    reward               | -66.62755    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 6.85e+05     |\n",
      "------------------------------------------\n",
      "Episode: 451\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 158           |\n",
      "|    iterations           | 190           |\n",
      "|    time_elapsed         | 4389          |\n",
      "|    total_timesteps      | 694450        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1667317e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 3.08e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.8e+05       |\n",
      "|    n_updates            | 14690         |\n",
      "|    policy_gradient_loss | -1.32e-05     |\n",
      "|    reward               | -109.679565   |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.76e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 452\n",
      "row: 3654, episode: 452\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2726529.92\n",
      "total_reward: 1726529.92\n",
      "total_cost: 1419365.19\n",
      "total_trades: 1430\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 157            |\n",
      "|    iterations           | 191            |\n",
      "|    time_elapsed         | 4429           |\n",
      "|    total_timesteps      | 698105         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.08234204e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.62          |\n",
      "|    explained_variance   | 0.00019        |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 9.52e+05       |\n",
      "|    n_updates            | 14700          |\n",
      "|    policy_gradient_loss | 3.54e-07       |\n",
      "|    reward               | 91.02537       |\n",
      "|    std                  | 1.22           |\n",
      "|    value_loss           | 1.9e+06        |\n",
      "--------------------------------------------\n",
      "Episode: 453\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 157           |\n",
      "|    iterations           | 192           |\n",
      "|    time_elapsed         | 4463          |\n",
      "|    total_timesteps      | 701760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4425838e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 2.77e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.46e+05      |\n",
      "|    n_updates            | 14710         |\n",
      "|    policy_gradient_loss | -1.1e-05      |\n",
      "|    reward               | -144.35257    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 8.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 454\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 4534         |\n",
      "|    total_timesteps      | 705415       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.461468e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000256     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.83e+06     |\n",
      "|    n_updates            | 14720        |\n",
      "|    policy_gradient_loss | 6.69e-06     |\n",
      "|    reward               | 8.619588     |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 3.67e+06     |\n",
      "------------------------------------------\n",
      "Episode: 455\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 4572         |\n",
      "|    total_timesteps      | 709070       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003464053 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 4.09e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.92e+05     |\n",
      "|    n_updates            | 14730        |\n",
      "|    policy_gradient_loss | -0.000426    |\n",
      "|    reward               | 190.8351     |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 3.83e+05     |\n",
      "------------------------------------------\n",
      "Episode: 456\n",
      "row: 3654, episode: 456\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1694560.31\n",
      "total_reward: 694560.31\n",
      "total_cost: 1234592.24\n",
      "total_trades: 1356\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 4604         |\n",
      "|    total_timesteps      | 712725       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016967306 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | -3.64e-05    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.28e+04     |\n",
      "|    n_updates            | 14740        |\n",
      "|    policy_gradient_loss | -0.000558    |\n",
      "|    reward               | -100.89917   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 8.56e+04     |\n",
      "------------------------------------------\n",
      "Episode: 457\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 154           |\n",
      "|    iterations           | 196           |\n",
      "|    time_elapsed         | 4640          |\n",
      "|    total_timesteps      | 716380        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034779825 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 1.12e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.61e+05      |\n",
      "|    n_updates            | 14750         |\n",
      "|    policy_gradient_loss | 6.65e-05      |\n",
      "|    reward               | -85.69265     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.92e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 458\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 4666         |\n",
      "|    total_timesteps      | 720035       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.732977e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 5.7e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.78e+06     |\n",
      "|    n_updates            | 14760        |\n",
      "|    policy_gradient_loss | -0.000127    |\n",
      "|    reward               | -145.89702   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 3.56e+06     |\n",
      "------------------------------------------\n",
      "Episode: 459\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 198           |\n",
      "|    time_elapsed         | 4704          |\n",
      "|    total_timesteps      | 723690        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9387833e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 1.43e-06      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.55e+06      |\n",
      "|    n_updates            | 14770         |\n",
      "|    policy_gradient_loss | -4.3e-05      |\n",
      "|    reward               | -54.405884    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 3.1e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 460\n",
      "row: 3654, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3240138.71\n",
      "total_reward: 2240138.71\n",
      "total_cost: 1592057.35\n",
      "total_trades: 1319\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 199           |\n",
      "|    time_elapsed         | 4729          |\n",
      "|    total_timesteps      | 727345        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4345087e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 1.23e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.26e+06      |\n",
      "|    n_updates            | 14780         |\n",
      "|    policy_gradient_loss | -8.94e-06     |\n",
      "|    reward               | 193.9469      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.53e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 461\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 200           |\n",
      "|    time_elapsed         | 4753          |\n",
      "|    total_timesteps      | 731000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0635056e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 6.43e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.34e+05      |\n",
      "|    n_updates            | 14790         |\n",
      "|    policy_gradient_loss | -3e-07        |\n",
      "|    reward               | -94.27391     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.67e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 462\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 201           |\n",
      "|    time_elapsed         | 4777          |\n",
      "|    total_timesteps      | 734655        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3093098e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 4.8e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.98e+05      |\n",
      "|    n_updates            | 14800         |\n",
      "|    policy_gradient_loss | -3.97e-06     |\n",
      "|    reward               | -120.185394   |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.4e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 463\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 202           |\n",
      "|    time_elapsed         | 4801          |\n",
      "|    total_timesteps      | 738310        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8256115e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 6.74e-06      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.94e+06      |\n",
      "|    n_updates            | 14810         |\n",
      "|    policy_gradient_loss | -3.71e-05     |\n",
      "|    reward               | -230.68932    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 3.88e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 464\n",
      "row: 3654, episode: 464\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2462236.39\n",
      "total_reward: 1462236.39\n",
      "total_cost: 1191065.53\n",
      "total_trades: 1375\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 203           |\n",
      "|    time_elapsed         | 4825          |\n",
      "|    total_timesteps      | 741965        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8150797e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000257      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.72e+06      |\n",
      "|    n_updates            | 14820         |\n",
      "|    policy_gradient_loss | 7.5e-06       |\n",
      "|    reward               | 32.511368     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 5.45e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 465\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 204           |\n",
      "|    time_elapsed         | 4859          |\n",
      "|    total_timesteps      | 745620        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7433258e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 8.09e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.8e+05       |\n",
      "|    n_updates            | 14830         |\n",
      "|    policy_gradient_loss | -1.01e-05     |\n",
      "|    reward               | -129.69292    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.76e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 466\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 4883         |\n",
      "|    total_timesteps      | 749275       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.008829e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000125     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.47e+06     |\n",
      "|    n_updates            | 14840        |\n",
      "|    policy_gradient_loss | -2.42e-05    |\n",
      "|    reward               | -165.2352    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 2.94e+06     |\n",
      "------------------------------------------\n",
      "Episode: 467\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 206           |\n",
      "|    time_elapsed         | 4904          |\n",
      "|    total_timesteps      | 752930        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351124e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000115      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.47e+06      |\n",
      "|    n_updates            | 14850         |\n",
      "|    policy_gradient_loss | -4.05e-06     |\n",
      "|    reward               | -75.130486    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.94e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 468\n",
      "row: 3654, episode: 468\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1262522.46\n",
      "total_reward: 262522.46\n",
      "total_cost: 1037022.48\n",
      "total_trades: 1385\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 207           |\n",
      "|    time_elapsed         | 4926          |\n",
      "|    total_timesteps      | 756585        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1085856e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.00014       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+06      |\n",
      "|    n_updates            | 14860         |\n",
      "|    policy_gradient_loss | -3.33e-06     |\n",
      "|    reward               | -203.19757    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.43e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 469\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 4953         |\n",
      "|    total_timesteps      | 760240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.741732e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 1.65e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.13e+06     |\n",
      "|    n_updates            | 14870        |\n",
      "|    policy_gradient_loss | -1.47e-05    |\n",
      "|    reward               | 121.15399    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 4.26e+06     |\n",
      "------------------------------------------\n",
      "Episode: 470\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 209           |\n",
      "|    time_elapsed         | 5012          |\n",
      "|    total_timesteps      | 763895        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1055052e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000268      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.72e+05      |\n",
      "|    n_updates            | 14880         |\n",
      "|    policy_gradient_loss | 1.67e-05      |\n",
      "|    reward               | -124.71409    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 5.45e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 471\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 210           |\n",
      "|    time_elapsed         | 5042          |\n",
      "|    total_timesteps      | 767550        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7798224e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 8.88e-06      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.5e+06       |\n",
      "|    n_updates            | 14890         |\n",
      "|    policy_gradient_loss | 1.12e-05      |\n",
      "|    reward               | 95.30697      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.99e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 472\n",
      "row: 3654, episode: 472\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2415452.07\n",
      "total_reward: 1415452.07\n",
      "total_cost: 1135881.97\n",
      "total_trades: 1475\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 211           |\n",
      "|    time_elapsed         | 5071          |\n",
      "|    total_timesteps      | 771205        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2839052e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000443      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.8e+05       |\n",
      "|    n_updates            | 14900         |\n",
      "|    policy_gradient_loss | -5.25e-06     |\n",
      "|    reward               | 31.160568     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 7.61e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 473\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 5098         |\n",
      "|    total_timesteps      | 774860       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.970925e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 6.79e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.58e+05     |\n",
      "|    n_updates            | 14910        |\n",
      "|    policy_gradient_loss | 2.98e-06     |\n",
      "|    reward               | 203.83527    |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 1.72e+06     |\n",
      "------------------------------------------\n",
      "Episode: 474\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 213           |\n",
      "|    time_elapsed         | 5125          |\n",
      "|    total_timesteps      | 778515        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7842744e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.00013       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.74e+05      |\n",
      "|    n_updates            | 14920         |\n",
      "|    policy_gradient_loss | -7.64e-06     |\n",
      "|    reward               | -129.81049    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 3.49e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 475\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 214           |\n",
      "|    time_elapsed         | 5151          |\n",
      "|    total_timesteps      | 782170        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2285914e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000129      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+06      |\n",
      "|    n_updates            | 14930         |\n",
      "|    policy_gradient_loss | -1.16e-05     |\n",
      "|    reward               | -34.027428    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 4.46e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 476\n",
      "row: 3654, episode: 476\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4167661.49\n",
      "total_reward: 3167661.49\n",
      "total_cost: 1683781.08\n",
      "total_trades: 1450\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 215           |\n",
      "|    time_elapsed         | 5183          |\n",
      "|    total_timesteps      | 785825        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7533803e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000354      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.56e+05      |\n",
      "|    n_updates            | 14940         |\n",
      "|    policy_gradient_loss | 3.22e-06      |\n",
      "|    reward               | 389.69278     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 1.51e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 477\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 216           |\n",
      "|    time_elapsed         | 5215          |\n",
      "|    total_timesteps      | 789480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2731258e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | -1.44e-05     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.33e+04      |\n",
      "|    n_updates            | 14950         |\n",
      "|    policy_gradient_loss | -7.06e-06     |\n",
      "|    reward               | 78.11873      |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 8.67e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 478\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 217           |\n",
      "|    time_elapsed         | 5242          |\n",
      "|    total_timesteps      | 793135        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9878484e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 4.98e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.65e+05      |\n",
      "|    n_updates            | 14960         |\n",
      "|    policy_gradient_loss | -0.000111     |\n",
      "|    reward               | -86.05648     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 1.53e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 479\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 218          |\n",
      "|    time_elapsed         | 5268         |\n",
      "|    total_timesteps      | 796790       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.051638e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000112     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.33e+06     |\n",
      "|    n_updates            | 14970        |\n",
      "|    policy_gradient_loss | 2.77e-05     |\n",
      "|    reward               | 124.04406    |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 2.67e+06     |\n",
      "------------------------------------------\n",
      "Episode: 480\n",
      "row: 3654, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2199126.43\n",
      "total_reward: 1199126.43\n",
      "total_cost: 1479944.61\n",
      "total_trades: 1460\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 5294         |\n",
      "|    total_timesteps      | 800445       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012600073 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 3.34e-06     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.06e+05     |\n",
      "|    n_updates            | 14980        |\n",
      "|    policy_gradient_loss | -0.000383    |\n",
      "|    reward               | -18.685478   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 2.11e+05     |\n",
      "------------------------------------------\n",
      "Episode: 481\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 150           |\n",
      "|    iterations           | 220           |\n",
      "|    time_elapsed         | 5325          |\n",
      "|    total_timesteps      | 804100        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038971848 |\n",
      "|    clip_fraction        | 0.000137      |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 2.39e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.3e+05       |\n",
      "|    n_updates            | 14990         |\n",
      "|    policy_gradient_loss | 0.000118      |\n",
      "|    reward               | -72.938156    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 6.61e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 482\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 150           |\n",
      "|    iterations           | 221           |\n",
      "|    time_elapsed         | 5352          |\n",
      "|    total_timesteps      | 807755        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6551774e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.00146       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.13e+06      |\n",
      "|    n_updates            | 15000         |\n",
      "|    policy_gradient_loss | 6.31e-05      |\n",
      "|    reward               | -94.66509     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.27e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 483\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 150           |\n",
      "|    iterations           | 222           |\n",
      "|    time_elapsed         | 5378          |\n",
      "|    total_timesteps      | 811410        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6424806e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 5.66e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.05e+05      |\n",
      "|    n_updates            | 15010         |\n",
      "|    policy_gradient_loss | -2.34e-05     |\n",
      "|    reward               | 47.32912      |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.81e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 484\n",
      "row: 3654, episode: 484\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2043127.52\n",
      "total_reward: 1043127.52\n",
      "total_cost: 1361584.21\n",
      "total_trades: 1358\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 150           |\n",
      "|    iterations           | 223           |\n",
      "|    time_elapsed         | 5406          |\n",
      "|    total_timesteps      | 815065        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0129706e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 9.3e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.18e+05      |\n",
      "|    n_updates            | 15020         |\n",
      "|    policy_gradient_loss | -2.06e-05     |\n",
      "|    reward               | -54.579155    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 6.37e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 485\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 150           |\n",
      "|    iterations           | 224           |\n",
      "|    time_elapsed         | 5430          |\n",
      "|    total_timesteps      | 818720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6180028e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000825      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.6e+05       |\n",
      "|    n_updates            | 15030         |\n",
      "|    policy_gradient_loss | -3.62e-06     |\n",
      "|    reward               | 34.600258     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.12e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 486\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 150            |\n",
      "|    iterations           | 225            |\n",
      "|    time_elapsed         | 5451           |\n",
      "|    total_timesteps      | 822375         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.33482445e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.62          |\n",
      "|    explained_variance   | 0.000528       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 9e+04          |\n",
      "|    n_updates            | 15040          |\n",
      "|    policy_gradient_loss | -3.01e-05      |\n",
      "|    reward               | -96.2878       |\n",
      "|    std                  | 1.22           |\n",
      "|    value_loss           | 1.8e+05        |\n",
      "--------------------------------------------\n",
      "Episode: 487\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 5471         |\n",
      "|    total_timesteps      | 826030       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.920931e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 1.19e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.58e+06     |\n",
      "|    n_updates            | 15050        |\n",
      "|    policy_gradient_loss | 7.88e-05     |\n",
      "|    reward               | -133.25749   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 3.15e+06     |\n",
      "------------------------------------------\n",
      "Episode: 488\n",
      "row: 3654, episode: 488\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1749496.86\n",
      "total_reward: 749496.86\n",
      "total_cost: 1059420.33\n",
      "total_trades: 1325\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 227           |\n",
      "|    time_elapsed         | 5491          |\n",
      "|    total_timesteps      | 829685        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9600108e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000279      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.2e+06       |\n",
      "|    n_updates            | 15060         |\n",
      "|    policy_gradient_loss | 1.13e-06      |\n",
      "|    reward               | -108.40155    |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 4.4e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 489\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 228           |\n",
      "|    time_elapsed         | 5513          |\n",
      "|    total_timesteps      | 833340        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5087766e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 2.83e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.47e+06      |\n",
      "|    n_updates            | 15070         |\n",
      "|    policy_gradient_loss | -2.52e-06     |\n",
      "|    reward               | 180.33209     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 2.94e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 490\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 5533         |\n",
      "|    total_timesteps      | 836995       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009214007 |\n",
      "|    clip_fraction        | 0.00334      |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 6.97e-06     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.31e+05     |\n",
      "|    n_updates            | 15080        |\n",
      "|    policy_gradient_loss | -0.000244    |\n",
      "|    reward               | 179.92023    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 4.61e+05     |\n",
      "------------------------------------------\n",
      "Episode: 491\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 230           |\n",
      "|    time_elapsed         | 5553          |\n",
      "|    total_timesteps      | 840650        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.9422396e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000317      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.11e+04      |\n",
      "|    n_updates            | 15090         |\n",
      "|    policy_gradient_loss | 5.78e-05      |\n",
      "|    reward               | -85.38284     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.42e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 492\n",
      "row: 3654, episode: 492\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2580767.16\n",
      "total_reward: 1580767.16\n",
      "total_cost: 1574676.26\n",
      "total_trades: 1288\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 231           |\n",
      "|    time_elapsed         | 5573          |\n",
      "|    total_timesteps      | 844305        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1476658e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.00075       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.61e+05      |\n",
      "|    n_updates            | 15100         |\n",
      "|    policy_gradient_loss | -0.000162     |\n",
      "|    reward               | 41.268303     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 1.92e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 493\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 5593         |\n",
      "|    total_timesteps      | 847960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.747468e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000114     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.16e+05     |\n",
      "|    n_updates            | 15110        |\n",
      "|    policy_gradient_loss | 1.82e-05     |\n",
      "|    reward               | -27.77483    |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 4.32e+05     |\n",
      "------------------------------------------\n",
      "Episode: 494\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 233           |\n",
      "|    time_elapsed         | 5613          |\n",
      "|    total_timesteps      | 851615        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4292573e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000154      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.37e+06      |\n",
      "|    n_updates            | 15120         |\n",
      "|    policy_gradient_loss | 1.96e-05      |\n",
      "|    reward               | -117.15374    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 2.74e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 495\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 234           |\n",
      "|    time_elapsed         | 5633          |\n",
      "|    total_timesteps      | 855270        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3544939e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000407      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1e+06         |\n",
      "|    n_updates            | 15130         |\n",
      "|    policy_gradient_loss | -5.18e-06     |\n",
      "|    reward               | -20.90058     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 2e+06         |\n",
      "-------------------------------------------\n",
      "Episode: 496\n",
      "row: 3654, episode: 496\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1316290.72\n",
      "total_reward: 316290.72\n",
      "total_cost: 1060442.02\n",
      "total_trades: 1253\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 151           |\n",
      "|    iterations           | 235           |\n",
      "|    time_elapsed         | 5653          |\n",
      "|    total_timesteps      | 858925        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9284346e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000333      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.34e+05      |\n",
      "|    n_updates            | 15140         |\n",
      "|    policy_gradient_loss | -1.48e-05     |\n",
      "|    reward               | -202.56934    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 1.47e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 497\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 5673         |\n",
      "|    total_timesteps      | 862580       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.944273e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 6.34e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.09e+06     |\n",
      "|    n_updates            | 15150        |\n",
      "|    policy_gradient_loss | 3.36e-07     |\n",
      "|    reward               | 46.394978    |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 4.19e+06     |\n",
      "------------------------------------------\n",
      "Episode: 498\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 237           |\n",
      "|    time_elapsed         | 5692          |\n",
      "|    total_timesteps      | 866235        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0512186e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 4.7e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.14e+05      |\n",
      "|    n_updates            | 15160         |\n",
      "|    policy_gradient_loss | -4.11e-05     |\n",
      "|    reward               | 107.3117      |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 4.28e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 499\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 238           |\n",
      "|    time_elapsed         | 5711          |\n",
      "|    total_timesteps      | 869890        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2476837e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000215      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.23e+05      |\n",
      "|    n_updates            | 15170         |\n",
      "|    policy_gradient_loss | 0.000178      |\n",
      "|    reward               | 164.83762     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 1.45e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 500\n",
      "row: 3654, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2563509.81\n",
      "total_reward: 1563509.81\n",
      "total_cost: 1479944.14\n",
      "total_trades: 1213\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 239           |\n",
      "|    time_elapsed         | 5731          |\n",
      "|    total_timesteps      | 873545        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4402207e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000134      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.68e+05      |\n",
      "|    n_updates            | 15180         |\n",
      "|    policy_gradient_loss | -2.81e-05     |\n",
      "|    reward               | 45.41083      |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 7.36e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 501\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 240           |\n",
      "|    time_elapsed         | 5751          |\n",
      "|    total_timesteps      | 877200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7125994e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000562      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.21e+05      |\n",
      "|    n_updates            | 15190         |\n",
      "|    policy_gradient_loss | 9.29e-06      |\n",
      "|    reward               | -62.55458     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 8.42e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 502\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 241           |\n",
      "|    time_elapsed         | 5770          |\n",
      "|    total_timesteps      | 880855        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3007022e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 5.08e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.84e+06      |\n",
      "|    n_updates            | 15200         |\n",
      "|    policy_gradient_loss | -2e-06        |\n",
      "|    reward               | -37.5835      |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 5.69e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 503\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 242           |\n",
      "|    time_elapsed         | 5790          |\n",
      "|    total_timesteps      | 884510        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8936264e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000224      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.24e+06      |\n",
      "|    n_updates            | 15210         |\n",
      "|    policy_gradient_loss | 1.28e-06      |\n",
      "|    reward               | -197.53238    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 2.48e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 504\n",
      "row: 3654, episode: 504\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1799168.41\n",
      "total_reward: 799168.41\n",
      "total_cost: 1034541.04\n",
      "total_trades: 1305\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 243           |\n",
      "|    time_elapsed         | 5810          |\n",
      "|    total_timesteps      | 888165        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0888534e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 4.8e-05       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.78e+06      |\n",
      "|    n_updates            | 15220         |\n",
      "|    policy_gradient_loss | -3.64e-06     |\n",
      "|    reward               | -105.93536    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 5.57e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 505\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 152           |\n",
      "|    iterations           | 244           |\n",
      "|    time_elapsed         | 5830          |\n",
      "|    total_timesteps      | 891820        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7529845e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 3.04e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.71e+06      |\n",
      "|    n_updates            | 15230         |\n",
      "|    policy_gradient_loss | -2.57e-05     |\n",
      "|    reward               | 133.2329      |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 3.42e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 506\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 245          |\n",
      "|    time_elapsed         | 5850         |\n",
      "|    total_timesteps      | 895475       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.197056e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000311     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.47e+05     |\n",
      "|    n_updates            | 15240        |\n",
      "|    policy_gradient_loss | -7.73e-05    |\n",
      "|    reward               | -38.1321     |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 4.94e+05     |\n",
      "------------------------------------------\n",
      "Episode: 507\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 246           |\n",
      "|    time_elapsed         | 5869          |\n",
      "|    total_timesteps      | 899130        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1857736e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000137      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.16e+06      |\n",
      "|    n_updates            | 15250         |\n",
      "|    policy_gradient_loss | -0.000159     |\n",
      "|    reward               | 48.37256      |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 2.32e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 508\n",
      "row: 3654, episode: 508\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1979590.95\n",
      "total_reward: 979590.95\n",
      "total_cost: 1197550.54\n",
      "total_trades: 1217\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 5888         |\n",
      "|    total_timesteps      | 902785       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.694419e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 5.38e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.78e+05     |\n",
      "|    n_updates            | 15260        |\n",
      "|    policy_gradient_loss | 3.72e-05     |\n",
      "|    reward               | -76.849106   |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 7.57e+05     |\n",
      "------------------------------------------\n",
      "Episode: 509\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 5908         |\n",
      "|    total_timesteps      | 906440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.424279e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 3.43e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.16e+06     |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | -2.2e-06     |\n",
      "|    reward               | -23.931694   |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 2.31e+06     |\n",
      "------------------------------------------\n",
      "Episode: 510\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 249           |\n",
      "|    time_elapsed         | 5928          |\n",
      "|    total_timesteps      | 910095        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6549054e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.000192      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.31e+05      |\n",
      "|    n_updates            | 15280         |\n",
      "|    policy_gradient_loss | -7.53e-07     |\n",
      "|    reward               | -91.98802     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 1.86e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 511\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 250           |\n",
      "|    time_elapsed         | 5948          |\n",
      "|    total_timesteps      | 913750        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7081827e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 2.24e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.41e+06      |\n",
      "|    n_updates            | 15290         |\n",
      "|    policy_gradient_loss | -1.62e-05     |\n",
      "|    reward               | -238.09695    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 2.82e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 512\n",
      "row: 3654, episode: 512\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2238920.08\n",
      "total_reward: 1238920.08\n",
      "total_cost: 1418273.72\n",
      "total_trades: 1273\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 251           |\n",
      "|    time_elapsed         | 5968          |\n",
      "|    total_timesteps      | 917405        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2119855e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 2.16e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.49e+06      |\n",
      "|    n_updates            | 15300         |\n",
      "|    policy_gradient_loss | -2.04e-05     |\n",
      "|    reward               | -16.198318    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 4.99e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 513\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 153           |\n",
      "|    iterations           | 252           |\n",
      "|    time_elapsed         | 5987          |\n",
      "|    total_timesteps      | 921060        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9121638e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 1.37e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.51e+05      |\n",
      "|    n_updates            | 15310         |\n",
      "|    policy_gradient_loss | -1.72e-05     |\n",
      "|    reward               | -235.90172    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 1.1e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 514\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 6007         |\n",
      "|    total_timesteps      | 924715       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.214874e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 4.15e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.74e+06     |\n",
      "|    n_updates            | 15320        |\n",
      "|    policy_gradient_loss | -1.64e-05    |\n",
      "|    reward               | -221.59451   |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 5.48e+06     |\n",
      "------------------------------------------\n",
      "Episode: 515\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 254          |\n",
      "|    time_elapsed         | 6027         |\n",
      "|    total_timesteps      | 928370       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.759982e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.000212     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.02e+06     |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | -5.72e-05    |\n",
      "|    reward               | 1.3281085    |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 6.03e+06     |\n",
      "------------------------------------------\n",
      "Episode: 516\n",
      "row: 3654, episode: 516\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2145245.40\n",
      "total_reward: 1145245.40\n",
      "total_cost: 1201843.03\n",
      "total_trades: 1198\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 154           |\n",
      "|    iterations           | 255           |\n",
      "|    time_elapsed         | 6046          |\n",
      "|    total_timesteps      | 932025        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9750344e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 0.00022       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.47e+05      |\n",
      "|    n_updates            | 15340         |\n",
      "|    policy_gradient_loss | -6.03e-06     |\n",
      "|    reward               | -42.996605    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 1.29e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 517\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 154           |\n",
      "|    iterations           | 256           |\n",
      "|    time_elapsed         | 6066          |\n",
      "|    total_timesteps      | 935680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0184485e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.62         |\n",
      "|    explained_variance   | 1.41e-05      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.66e+06      |\n",
      "|    n_updates            | 15350         |\n",
      "|    policy_gradient_loss | -4.17e-06     |\n",
      "|    reward               | -120.10766    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 3.32e+06      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent_ppo = DRLAgent(env = env_train)\n",
    "trained_ppo = agent_ppo.train_model(model=trained_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trained_ppo = PPO(\"MlpPolicy\", env_train,n_steps=episode_length,ent_coef=0.01,learning_rate=0.00025,batch_size=episode_length,clip_range=0.1,\n",
    "#                   policy_kwargs=policy_kwargs,tensorboard_log=TENSORBOARD_LOG_DIR + \"/test_ppo/\",verbose=10)\n",
    "# trained_ppo.learn(total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_ddpg = DRLAgent(env = env_train)\n",
    "# DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": episode_length, \"learning_rate\": 0.001}\n",
    "# model_ddpg = agent_ddpg.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS,tensorboard_log=TENSORBOARD_LOG_DIR + \"/test_ddpg_tensorboard/\")\n",
    "\n",
    "# # set up logger\n",
    "# tmp_path = TENSORBOARD_LOG_DIR + '/ddpg'\n",
    "# new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "# # Set new logger\n",
    "# model_sac.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the training log just show up when total_timesteps higher than 15.000\n",
    "# trained_ddpg = agent_ddpg.train_model(model=model_ddpg,\n",
    "#                              tb_log_name='ddpg',\n",
    "#                              total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "# # The noise objects for DDPG\n",
    "# n_actions = env_train.action_space.shape[-1]\n",
    "# action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# # Train the agent\n",
    "# trained_ddpg = DDPG(\"MlpPolicy\", env_train, action_noise=action_noise, verbose=1)\n",
    "# trained_ddpg.learn(total_timesteps=total_timesteps, log_interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_length = len(e_train_gym.df) + 1\n",
    "# episode_amount = 4\n",
    "# total_training_step = episode_length*episode_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 2048, 'buffer_size': 58204, 'learning_rate': 0.0003, 'learning_starts': 58204, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# agent_sac = DRLAgent(env = env_train)\n",
    "# SAC_PARAMS = {\n",
    "#     \"batch_size\": 2048,\n",
    "#     \"buffer_size\": episode_length,\n",
    "#     \"learning_rate\": 0.0003,\n",
    "#     \"learning_starts\": episode_length,\n",
    "#     \"ent_coef\": \"auto_0.1\",\n",
    "# }\n",
    "\n",
    "# model_sac = agent_sac.get_model(\"sac\",model_kwargs = SAC_PARAMS,tensorboard_log=TENSORBOARD_LOG_DIR + \"/test_sac/\")\n",
    "\n",
    "# # # set up logger\n",
    "# # tmp_path = TENSORBOARD_LOG_DIR + '/test_sac/sac_12'\n",
    "# # new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "# # # Set new logger\n",
    "# # model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# trained_sac = agent_sac.train_model(model=model_sac, \n",
    "#                              tb_log_name='sac',\n",
    "#                              total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_td3 = DRLAgent(env = env_train)\n",
    "# TD3_PARAMS = {\"batch_size\": 100, \n",
    "#               \"buffer_size\": 1000000, \n",
    "#               \"learning_rate\": 0.001}\n",
    "\n",
    "# model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_td3 = agent.train_model(model=model_td3, \n",
    "#                              tb_log_name='td3',\n",
    "#                              total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_a2c = DRLAgent(env = env_train)\n",
    "\n",
    "# A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "# model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_a2c = agent.train_model(model=model_a2c, \n",
    "#                                 tb_log_name='a2c',\n",
    "#                                 total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at the begining. We use the PPO model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2018-12 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = trade_data.reset_index(drop=True)\n",
    "\n",
    "# trade_data = data_split(processed_full, TEST_START_DATE, TEST_END_DATE)\n",
    "e_trade_gym = StockTradingEnv(df = trade_data, **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRL_prediction function allow testing the model using trading_data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRL_prediction(model, environment, deterministic=False):\n",
    "        \"\"\"make a prediction and get results\"\"\"\n",
    "        # test_env, test_obs = environment.get_sb_env()\n",
    "        # account_memory = None  # This help avoid unnecessary list creation\n",
    "        # actions_memory = None  # optimize memory consumption\n",
    "\n",
    "        test_obs = environment.reset()[0]\n",
    "        # max_steps = len(environment.df.index.unique()) - 1\n",
    "\n",
    "        for i in range(0,len(environment.df)):\n",
    "            action = model.predict(np.asarray(test_obs), deterministic=deterministic)\n",
    "            test_obs,reward,terminal,truncated,info = environment.step(action)\n",
    "            # test_obs, rewards, dones, info = test_env.step(action)\n",
    "\n",
    "            # if (i == max_steps - 1):  # more descriptive condition for early termination to clarify the logic\n",
    "            #     account_memory = environment.env_method(method_name=\"save_asset_memory\")\n",
    "            #     actions_memory = environment.env_method(method_name=\"save_action_memory\")\n",
    "\n",
    "            if terminal:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        return pd.DataFrame(e_trade_gym.asset_memory, columns=['account_value']), pd.DataFrame(e_trade_gym.actions_memory,columns=['actions','none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4\n",
      "row: 1139, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1175255.67\n",
      "total_reward: 175255.67\n",
      "total_cost: 245417.74\n",
      "total_trades: 873\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRL_prediction(model=trained_ppo, environment = e_trade_gym)\n",
    "\n",
    "# df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "#     model=trained_ddpg, \n",
    "#     environment = e_trade_gym)\n",
    "\n",
    "# df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "\n",
    "# df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "#     model=trained_a2c, \n",
    "#     environment = e_trade_gym) if if_using_a2c else [None, None]\n",
    "\n",
    "# df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "#     model=trained_td3, \n",
    "#     environment = e_trade_gym) if if_using_td3 else [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140, 1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_ppo.shape\n",
    "# df_account_value_ddpg.shape\n",
    "# df_account_value_sac.shape\n",
    "# df_account_value_td3.shape\n",
    "# df_account_value_a2c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo['date'] = trade_data.date\n",
    "# df_account_value_ddpg['date'] = trade_data.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1.175256e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1.175256e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1.175256e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1.175256e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1.175256e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      account_value       date\n",
       "1135   1.175256e+06 2024-02-29\n",
       "1136   1.175256e+06 2024-02-29\n",
       "1137   1.175256e+06 2024-02-29\n",
       "1138   1.175256e+06 2024-02-29\n",
       "1139   1.175256e+06 2024-02-29"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_ppo.tail()\n",
    "# df_account_value_ddpg.tail()\n",
    "# df_account_value_sac.tail()\n",
    "# df_account_value_td3.tail()\n",
    "# df_account_value_a2c.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_actions_ppo.actions.unique()\n",
    "# df_actions_ddpg.head()\n",
    "# df_actions_sac.head()\n",
    "# df_actions_td3.head()\n",
    "# df_actions_a2c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actions</th>\n",
       "      <th>none</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.45090783]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actions  none       date\n",
       "0         [-1.0]  None 2021-01-31\n",
       "1         [-1.0]  None 2021-01-31\n",
       "2         [-1.0]  None 2021-01-31\n",
       "3         [-1.0]  None 2021-01-31\n",
       "4  [-0.45090783]  None 2021-01-31"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_ppo['date'] = trade_data.date\n",
    "df_actions_ppo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>9.990004e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>9.950660e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>1.004002e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>9.718640e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>9.731815e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  account_value\n",
       "0 2021-01-31   9.990004e+05\n",
       "1 2021-02-28   9.950660e+05\n",
       "2 2021-03-31   1.004002e+06\n",
       "3 2021-04-30   9.718640e+05\n",
       "4 2021-05-31   9.731815e+05"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value = pd.DataFrame(df_account_value_ppo.date.unique())\n",
    "df_account_value.columns = ['date']\n",
    "df_account_value['account_value'] = df_account_value.apply(lambda x: \\\n",
    "                                    df_account_value_ppo[df_account_value_ppo.date == x.date].iloc[-1].account_value, axis=1)\n",
    "df_account_value.head()\n",
    "\n",
    "# df_account_value = pd.DataFrame(df_account_value_ddpg.date.unique())\n",
    "# df_account_value.columns = ['date']\n",
    "# df_account_value['account_value'] = df_account_value.apply(lambda x: \\\n",
    "#                                     df_account_value_ddpg[df_account_value_ddpg.date == x.date].iloc[-1].account_value, axis=1)\n",
    "# df_account_value.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a missmatch between the quarterly computation of df_account_value and the daily frequency of the comparison datasets. We need to transform the df_account_value to a daily basis.\n",
    "To fill up the missing data, th **ffill** function effectively imputes values, providing the continous picture of account value trends until the next recorded change. However, for the entries preceding the first recorded change, we will use the **initial_amount**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>9.990004e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>9.950660e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>1.004002e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>9.718640e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>9.731815e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>9.238103e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>9.638080e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>9.988999e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9.742424e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>1.046619e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>9.712435e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>1.055135e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>1.032284e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9.929022e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>1.001517e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>9.567293e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>9.922257e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>9.693989e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>9.477010e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>9.256988e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>8.766309e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>8.996251e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>1.029237e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>9.377796e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>9.863210e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>9.565460e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>9.354670e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>9.251242e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>8.750034e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>8.983531e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>9.438329e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>9.255804e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>9.250213e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>9.316725e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1.015504e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1.026975e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>1.021773e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>1.175256e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>1.175256e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  account_value\n",
       "0  2021-01-31   9.990004e+05\n",
       "1  2021-02-28   9.950660e+05\n",
       "2  2021-03-31   1.004002e+06\n",
       "3  2021-04-30   9.718640e+05\n",
       "4  2021-05-31   9.731815e+05\n",
       "5  2021-06-30   9.238103e+05\n",
       "6  2021-07-31   9.638080e+05\n",
       "7  2021-08-31   9.988999e+05\n",
       "8  2021-09-30   9.742424e+05\n",
       "9  2021-10-31   1.046619e+06\n",
       "10 2021-11-30   9.712435e+05\n",
       "11 2021-12-31   1.055135e+06\n",
       "12 2022-01-31   1.032284e+06\n",
       "13 2022-02-28   9.929022e+05\n",
       "14 2022-03-31   1.001517e+06\n",
       "15 2022-04-30   9.567293e+05\n",
       "16 2022-05-31   9.922257e+05\n",
       "17 2022-06-30   9.693989e+05\n",
       "18 2022-07-31   9.477010e+05\n",
       "19 2022-08-31   9.256988e+05\n",
       "20 2022-09-30   8.766309e+05\n",
       "21 2022-10-31   8.996251e+05\n",
       "22 2022-11-30   1.029237e+06\n",
       "23 2022-12-31   9.377796e+05\n",
       "24 2023-01-31   9.863210e+05\n",
       "25 2023-02-28   9.565460e+05\n",
       "26 2023-03-31   9.354670e+05\n",
       "27 2023-04-30   9.251242e+05\n",
       "28 2023-05-31   8.750034e+05\n",
       "29 2023-06-30   8.983531e+05\n",
       "30 2023-07-31   9.438329e+05\n",
       "31 2023-08-31   9.255804e+05\n",
       "32 2023-09-30   9.250213e+05\n",
       "33 2023-10-31   9.316725e+05\n",
       "34 2023-11-30   1.015504e+06\n",
       "35 2023-12-31   1.026975e+06\n",
       "36 2024-01-31   1.021773e+06\n",
       "37 2024-02-29   1.175256e+06\n",
       "38 2024-03-31   1.175256e+06"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_account_value = pd.DataFrame(df.date.unique())\n",
    "daily_account_value.columns = ['date']\n",
    "daily_account_value['date'] = pd.to_datetime(daily_account_value.date)\n",
    "daily_account_value = daily_account_value.merge(df_account_value,how='left')\n",
    "daily_account_value.ffill(inplace=True)\n",
    "daily_account_value.fillna(env_kwargs[\"initial_amount\"],inplace=True)\n",
    "daily_account_value = daily_account_value[daily_account_value.date >= TEST_START_DATE]\n",
    "daily_account_value.reset_index(inplace=True,drop=True)\n",
    "daily_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9mKF7GGtj1g",
    "outputId": "99c5e5f8-2e3f-49c3-e5a6-4e66ed92e40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "\n",
      " ppo:\n",
      "Annual return          0.036342\n",
      "Cumulative returns     0.175256\n",
      "Annual volatility      0.142017\n",
      "Sharpe ratio           0.319261\n",
      "Calmar ratio           0.210240\n",
      "Stability              0.019618\n",
      "Max drawdown          -0.172858\n",
      "Omega ratio            1.229746\n",
      "Sortino ratio          0.716963\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.058288\n",
      "Daily value at risk   -0.017713\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "# now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "print(\"\\n ppo:\")\n",
    "perf_stats_all_ppo = backtest_stats(account_value=df_account_value_ppo)\n",
    "perf_stats_all_ppo = pd.DataFrame(perf_stats_all_ppo)\n",
    "# perf_stats_all_ppo.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_ppo_\"+now+'.csv')\n",
    "\n",
    "# print(\"\\n ddpg:\")\n",
    "# perf_stats_all_ddpg = backtest_stats(account_value=df_account_value_ddpg)\n",
    "# perf_stats_all_ddpg = pd.DataFrame(perf_stats_all_ddpg)\n",
    "# perf_stats_all_ddpg.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_ddpg_\"+now+'.csv')\n",
    "\n",
    "# print(\"\\n sac:\")\n",
    "# perf_stats_all_sac = backtest_stats(account_value=df_account_value_sac)\n",
    "# perf_stats_all_sac = pd.DataFrame(perf_stats_all_sac)\n",
    "#   perf_stats_all_sac.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_sac_\"+now+'.csv')\n",
    "\n",
    "#   print(\"\\n atd3:\")\n",
    "#   perf_stats_all_td3 = backtest_stats(account_value=df_account_value_td3)\n",
    "#   perf_stats_all_td3 = pd.DataFrame(perf_stats_all_td3)\n",
    "#   perf_stats_all_td3.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_td3_\"+now+'.csv')\n",
    "\n",
    "#   print(\"\\n a2c:\")\n",
    "#   perf_stats_all_a2c = backtest_stats(account_value=df_account_value_a2c)\n",
    "#   perf_stats_all_a2c = pd.DataFrame(perf_stats_all_a2c)\n",
    "#   perf_stats_all_a2c.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_a2c_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oyosyW7_tj1g",
    "outputId": "0e54f2d5-6057-4a14-c94a-5f2af26ad171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Annual return          0.089358\n",
      "Cumulative returns     0.316223\n",
      "Annual volatility      0.146547\n",
      "Sharpe ratio           0.658110\n",
      "Calmar ratio           0.407268\n",
      "Stability              0.108092\n",
      "Max drawdown          -0.219408\n",
      "Omega ratio            1.118655\n",
      "Sortino ratio          0.940026\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.003905\n",
      "Daily value at risk   -0.018081\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = TEST_START_DATE,\n",
    "        end = TEST_END_DATE)\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTest with DJIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2021-01-31</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2024-03-31</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>1</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>185.739%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>17.643%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>84.652%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>10.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-17.072%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-10.103%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.07</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.99</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.20</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.39</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ConversionError",
     "evalue": "Failed to convert value(s) to axis units: (NaT, Timestamp('2024-03-31 00:00:00+0000', tz='UTC'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/matplotlib/axis.py:1769\u001b[0m, in \u001b[0;36mAxis.convert_units\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1769\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pandas/plotting/_matplotlib/converter.py:237\u001b[0m, in \u001b[0;36mPeriodConverter.convert\u001b[0;34m(values, units, axis)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mPeriodConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pandas/plotting/_matplotlib/converter.py:267\u001b[0m, in \u001b[0;36mPeriodConverter._convert_1d\u001b[0;34m(values, units, axis)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, Index)):\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [get_datevalue(x, axis\u001b[38;5;241m.\u001b[39mfreq) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pandas/plotting/_matplotlib/converter.py:267\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, Index)):\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mget_datevalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pandas/plotting/_matplotlib/converter.py:275\u001b[0m, in \u001b[0;36mget_datevalue\u001b[0;34m(date, freq)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(date, (\u001b[38;5;28mstr\u001b[39m, datetime, pydt\u001b[38;5;241m.\u001b[39mdate, pydt\u001b[38;5;241m.\u001b[39mtime, np\u001b[38;5;241m.\u001b[39mdatetime64)):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPeriod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordinal\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    277\u001b[0m     is_integer(date)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_float(date)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(date, (np\u001b[38;5;241m.\u001b[39mndarray, Index)) \u001b[38;5;129;01mand\u001b[39;00m (date\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    280\u001b[0m ):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NaTType' object has no attribute 'ordinal'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConversionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# S&P 500: ^GSPC\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Dow Jones Index: ^DJI\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# NASDAQ 100: ^NDX\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mbacktest_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_account_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbaseline_ticker\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m^DJI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbaseline_start\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTEST_START_DATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbaseline_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTEST_END_DATE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/finrl/plot.py:71\u001b[0m, in \u001b[0;36mbacktest_plot\u001b[0;34m(account_value, baseline_start, baseline_end, baseline_ticker, value_col_name)\u001b[0m\n\u001b[1;32m     68\u001b[0m baseline_returns \u001b[38;5;241m=\u001b[39m get_daily_return(baseline_df, value_col_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pyfolio\u001b[38;5;241m.\u001b[39mplotting\u001b[38;5;241m.\u001b[39mplotting_context(font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mpyfolio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_full_tear_sheet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_returns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbenchmark_rets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_returns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pyfolio/tears.py:180\u001b[0m, in \u001b[0;36mcreate_full_tear_sheet\u001b[0;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[1;32m    174\u001b[0m     returns \u001b[38;5;241m=\u001b[39m txn\u001b[38;5;241m.\u001b[39madjust_returns_for_slippage(returns, positions,\n\u001b[1;32m    175\u001b[0m                                               transactions, slippage)\n\u001b[1;32m    177\u001b[0m positions \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcheck_intraday(estimate_intraday, returns,\n\u001b[1;32m    178\u001b[0m                                  positions, transactions)\n\u001b[0;32m--> 180\u001b[0m \u001b[43mcreate_returns_tear_sheet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_start_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_start_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcone_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcone_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark_rets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark_rets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mturnover_denom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturnover_denom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m create_interesting_times_tear_sheet(returns,\n\u001b[1;32m    193\u001b[0m                                     benchmark_rets\u001b[38;5;241m=\u001b[39mbenchmark_rets,\n\u001b[1;32m    194\u001b[0m                                     set_context\u001b[38;5;241m=\u001b[39mset_context)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m positions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pyfolio/plotting.py:54\u001b[0m, in \u001b[0;36mcustomize.<locals>.call_w_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pyfolio/tears.py:569\u001b[0m, in \u001b[0;36mcreate_returns_tear_sheet\u001b[0;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[1;32m    565\u001b[0m plotting\u001b[38;5;241m.\u001b[39mplot_rolling_sharpe(\n\u001b[1;32m    566\u001b[0m     returns, ax\u001b[38;5;241m=\u001b[39max_rolling_sharpe)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# Drawdowns\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_drawdown_periods\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max_drawdown\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m plotting\u001b[38;5;241m.\u001b[39mplot_drawdown_underwater(\n\u001b[1;32m    573\u001b[0m     returns\u001b[38;5;241m=\u001b[39mreturns, ax\u001b[38;5;241m=\u001b[39max_underwater)\n\u001b[1;32m    575\u001b[0m plotting\u001b[38;5;241m.\u001b[39mplot_monthly_returns_heatmap(returns, ax\u001b[38;5;241m=\u001b[39max_monthly_heatmap)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/pyfolio/plotting.py:442\u001b[0m, in \u001b[0;36mplot_drawdown_periods\u001b[0;34m(returns, top, ax, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(recovery):\n\u001b[1;32m    441\u001b[0m         recovery \u001b[38;5;241m=\u001b[39m returns\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 442\u001b[0m     \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_between\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeak\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecovery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlim\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlim\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m                    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim(lim)\n\u001b[1;32m    448\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m drawdown periods\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m top)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5512\u001b[0m, in \u001b[0;36mAxes.fill_between\u001b[0;34m(self, x, y1, y2, where, interpolate, step, **kwargs)\u001b[0m\n\u001b[1;32m   5510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill_between\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y1, y2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   5511\u001b[0m                  step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill_between_x_or_y\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5513\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5413\u001b[0m, in \u001b[0;36mAxes._fill_between_x_or_y\u001b[0;34m(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs)\u001b[0m\n\u001b[1;32m   5408\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m   5409\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_patches_for_fill\u001b[38;5;241m.\u001b[39mget_next_color()\n\u001b[1;32m   5411\u001b[0m \u001b[38;5;66;03m# Handle united data, such as dates\u001b[39;00m\n\u001b[1;32m   5412\u001b[0m ind, dep1, dep2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m-> 5413\u001b[0m     ma\u001b[38;5;241m.\u001b[39mmasked_invalid, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_unit_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5414\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdep_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdep1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdep_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdep2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, array \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m   5417\u001b[0m         (ind_dir, ind), (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdep_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, dep1), (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdep_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m, dep2)]:\n\u001b[1;32m   5418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/matplotlib/axes/_base.py:2573\u001b[0m, in \u001b[0;36m_AxesBase._process_unit_info\u001b[0;34m(self, datasets, kwargs, convert)\u001b[0m\n\u001b[1;32m   2571\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m dataset_axis_name \u001b[38;5;241m==\u001b[39m axis_name \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2572\u001b[0m                 axis\u001b[38;5;241m.\u001b[39mupdate_units(data)\n\u001b[0;32m-> 2573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [axis_map[axis_name]\u001b[38;5;241m.\u001b[39mconvert_units(data)\n\u001b[1;32m   2574\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data\n\u001b[1;32m   2575\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m axis_name, data \u001b[38;5;129;01min\u001b[39;00m datasets]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/matplotlib/axes/_base.py:2573\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2571\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m dataset_axis_name \u001b[38;5;241m==\u001b[39m axis_name \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2572\u001b[0m                 axis\u001b[38;5;241m.\u001b[39mupdate_units(data)\n\u001b[0;32m-> 2573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43maxis_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2574\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data\n\u001b[1;32m   2575\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m axis_name, data \u001b[38;5;129;01min\u001b[39;00m datasets]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fin_rl_env/lib/python3.10/site-packages/matplotlib/axis.py:1771\u001b[0m, in \u001b[0;36mAxis.convert_units\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1769\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter\u001b[38;5;241m.\u001b[39mconvert(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m munits\u001b[38;5;241m.\u001b[39mConversionError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to convert value(s) to axis \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1772\u001b[0m                                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mConversionError\u001b[0m: Failed to convert value(s) to axis units: (NaT, Timestamp('2024-03-31 00:00:00+0000', tz='UTC'))"
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "\n",
    "backtest_plot(daily_account_value, \n",
    "            baseline_ticker = '^DJI', \n",
    "            baseline_start = TEST_START_DATE,\n",
    "            baseline_end = TEST_END_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Buy&Hold Strategy\n",
    "pass in df_account_value, this information is stored in env class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTest with Buy&Hold Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(DOW_30_TICKER)\n",
    "test_portfolio = DOW_30_TICKER\n",
    "modify_fields = ['open','high','low','close']\n",
    "used_columns = ['date','close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock_test_ = get_baseline(\n",
    "#         ticker='AXP', \n",
    "#         start = TEST_START_DATE,\n",
    "#         end = TEST_END_DATE)\n",
    "# df_stock_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for field in modify_fields:\n",
    "#     df_stock_test_[field] = df_stock_test_[field]/df_stock_test_.iloc[0][field]/len(test_portfolio)\n",
    "# df_stock_test_ = df_stock_test_[used_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "oBQx4bVQFi-a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n",
      "Annual return           0.415405\n",
      "Cumulative returns      0.055238\n",
      "Annual volatility       0.142013\n",
      "Sharpe ratio            2.581802\n",
      "Calmar ratio           10.349352\n",
      "Stability               0.407411\n",
      "Max drawdown           -0.040138\n",
      "Omega ratio             1.575704\n",
      "Sortino ratio           3.763793\n",
      "Skew                         NaN\n",
      "Kurtosis                     NaN\n",
      "Tail ratio              0.848872\n",
      "Daily value at risk    -0.016437\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "shape = daily_account_value.shape\n",
    "df_hold_ = pd.DataFrame(0,index=range(shape[0]), columns=range(shape[1]))\n",
    "df_hold_.columns = used_columns\n",
    "df_hold_['date'] = daily_account_value.date\n",
    "\n",
    "for stock in test_portfolio:\n",
    "    df_stock_ = get_baseline(\n",
    "        ticker=stock, \n",
    "        start = TEST_START_DATE,\n",
    "        end = TEST_END_DATE)\n",
    "    # for field in modify_fields:\n",
    "    if len(df_stock_) < len(df_hold_):\n",
    "        final_row = df_stock_.iloc[-1]\n",
    "        new_rows = pd.DataFrame([final_row] * (len(df_hold_) - len(df_stock_)))\n",
    "        df_stock_ = pd.concat([df_stock_, new_rows], ignore_index=True)\n",
    "        \n",
    "        for i in range(0,len(df_stock_) < len(df_hold_)):\n",
    "            df_stock_.iloc[en(df_stock_)] = df_stock_.iloc[len(df_stock_-1)]\n",
    "    df_stock_['close'] = df_stock_['close']/df_stock_.iloc[0]['close']/len(test_portfolio)\n",
    "    df_hold_['close'] = df_hold_.close + df_stock_.close\n",
    "\n",
    "stats = backtest_stats(df_hold_, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model' calculation encompass the entire timeframe, including non-working days. To address this, we need to determine the most appropriate method to fill up the weekend plots, for example backfilling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hold_.date = pd.to_datetime(df_hold_['date'])\n",
    "# df_hold_ = pd.merge(df_account_value_ppo['date'],df_hold_,how='left')\n",
    "# df_hold_.bfill(inplace=True)\n",
    "# df_hold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_hold:                      hold\n",
      "date                    \n",
      "2021-01-31  1.000000e+06\n",
      "2021-02-28  1.006314e+06\n",
      "2021-03-31  1.021052e+06\n",
      "2021-04-30  1.029017e+06\n",
      "2021-05-31  1.030249e+06\n",
      "2021-06-30  1.029785e+06\n",
      "2021-07-31  1.033666e+06\n",
      "2021-08-31  1.035076e+06\n",
      "2021-09-30  1.035051e+06\n",
      "2021-10-31  1.026937e+06\n",
      "2021-11-30  1.030746e+06\n",
      "2021-12-31  1.039045e+06\n",
      "2022-01-31  1.038597e+06\n",
      "2022-02-28  1.029507e+06\n",
      "2022-03-31  1.028421e+06\n",
      "2022-04-30  1.027227e+06\n",
      "2022-05-31  1.009060e+06\n",
      "2022-06-30  1.018215e+06\n",
      "2022-07-31  9.973398e+05\n",
      "2022-08-31  1.004524e+06\n",
      "2022-09-30  1.018989e+06\n",
      "2022-10-31  1.020445e+06\n",
      "2022-11-30  1.033378e+06\n",
      "2022-12-31  1.038320e+06\n",
      "2023-01-31  1.046430e+06\n",
      "2023-02-28  1.044933e+06\n",
      "2023-03-31  1.047083e+06\n",
      "2023-04-30  1.047593e+06\n",
      "2023-05-31  1.049621e+06\n",
      "2023-06-30  1.051232e+06\n",
      "2023-07-31  1.054914e+06\n",
      "2023-08-31  1.050851e+06\n",
      "2023-09-30  1.052054e+06\n",
      "2023-10-31  1.054023e+06\n",
      "2023-11-30  1.055057e+06\n",
      "2023-12-31  1.069562e+06\n",
      "2024-01-31  1.051501e+06\n",
      "2024-02-29  1.034710e+06\n",
      "2024-03-31  1.055238e+06\n"
     ]
    }
   ],
   "source": [
    "df_hold = pd.DataFrame()\n",
    "df_hold['date'] = daily_account_value['date']\n",
    "df_hold['hold'] = df_hold_['close'] / df_hold_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "# print(\"df_hold: \", df_hold)\n",
    "# df_dji.to_csv(\"df_dji.csv\")\n",
    "df_hold = df_hold.set_index(df_hold.columns[0])\n",
    "print(\"df_hold: \", df_hold)\n",
    "# df_hold.to_csv(\"df_dji+.csv\")\n",
    "\n",
    "# df_account_value.to_csv('df_account_value.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to Buy&Hold===========\n",
      "result:                     stock          hold\n",
      "date                                  \n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "...                  ...           ...\n",
      "2024-02-29  1.349998e+06  1.034710e+06\n",
      "2024-02-29  1.349998e+06  1.034710e+06\n",
      "2024-02-29  1.322213e+06  1.034710e+06\n",
      "2024-02-29  1.317441e+06  1.034710e+06\n",
      "2024-02-29  1.317441e+06  1.034710e+06\n",
      "\n",
      "[1140 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to Buy&Hold===========\")\n",
    "df_result = pd.DataFrame({'date': df_account_value_ppo['date'], 'stock': df_account_value_ppo['account_value']})\n",
    "df_result = df_result.set_index('date')\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result = pd.merge(df_result, df_hold, left_index=True, right_index=True)\n",
    "print(\"result: \", result)\n",
    "# result.to_csv(\"result.csv\")\n",
    "result.columns = ['model', 'buy_and_hold']\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "# 8. Save and load model #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.1'></a>\n",
    "## 8.1 Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./trained_models/main_portfolio_box_ppo_dow30_monthly_2048episode'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"./\"+TRAINED_MODEL_DIR+\"/main_portfolio_box_ppo_dow30_monthly_2048episode\"\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 Save model as ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.onnx\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxableSB3Policy(th.nn.Module):\n",
    "    def __init__(self, policy: BasePolicy):\n",
    "        super().__init__()\n",
    "        self.policy = policy\n",
    "\n",
    "    def forward(self, observation: th.Tensor) -> Tuple[th.Tensor, th.Tensor, th.Tensor]:\n",
    "        # NOTE: Preprocessing is included, but postprocessing\n",
    "        # (clipping/inscaling actions) is not,\n",
    "        # If needed, you also need to transpose the images so that they are channel first\n",
    "        # use deterministic=False if you want to export the stochastic policy\n",
    "        # policy() returns `actions, values, log_prob` for PPO\n",
    "        return self.policy(observation, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_policy = OnnxableSB3Policy(trained_ppo.policy)\n",
    "observation_size = trained_ppo.observation_space.shape\n",
    "dummy_input = th.randn(1, *observation_size)\n",
    "\n",
    "th.onnx.export(\n",
    "    onnx_policy,\n",
    "    dummy_input,\n",
    "    \"sac_model_1200k_sac9.onnx\",\n",
    "    opset_version=17,\n",
    "    input_names=[\"input\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.2'></a>\n",
    "## 8.2 Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.2.1'></a>\n",
    "### 8.2.1 Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/FinRL-Tutorials-master/6-Binhlai_Testing\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./trained_models/main_portfolio_box_ppo_dow30_monthly_1024episode'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"./\"+TRAINED_MODEL_DIR+\"/main_portfolio_box_ppo_dow30_monthly_1024episode\"\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = PPO.load(model_name)\n",
    "trained_model.env = env_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continous training based on the previous model from [**Part6. Train DRL Agents**](#5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Establish the training environment using StockTradingEnv() class\n",
    "# agent = DRLAgent(env = env_train)\n",
    "# trained_model.env = env_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trained_ppo = agent.train_model(model=trained_model, \n",
    "#                              tb_log_name='ppo',\n",
    "#                              total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = StockTradingEnv(df = trade_data, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_step = 1000\n",
    "test_result = []\n",
    "test_env.reset()\n",
    "for i in range(0,test_step):\n",
    "    observation = [test_env.state]\n",
    "    observation = np.array(observation).astype(np.float32)\n",
    "    actions, values, log_prob = ort_sess.run(None, {\"input\": observation})\n",
    "    result = test_env.step(actions)\n",
    "    test_result.append(result[1])\n",
    "    if result[2] == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 Load ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = \"all_in_one_ppo.onnx\"\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# # Check that the predictions are the same\n",
    "# with th.no_grad():\n",
    "#     print(model.policy(th.as_tensor(observation), deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = np.zeros((1, state_space)).astype(np.float32)\n",
    "ort_sess = ort.InferenceSession(onnx_path)\n",
    "actions, values, log_prob = ort_sess.run(None, {\"input\": observation})\n",
    "print(actions, values, log_prob)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
