{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "Below, we will learn to implement and train a policy to play atari-pong, using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JSAnimation in /Users/admin/opt/anaconda3/lib/python3.9/site-packages (0.1)\n",
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# install package for displaying animation\n",
    "!pip install JSAnimation\n",
    "\n",
    "# custom utilies for displaying animation, collecting rollouts and more\n",
    "import pong_utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check which device is being used. \n",
    "# I recommend disabling gpu until you've made sure that the code runs\n",
    "device = pong_utils.device\n",
    "print(\"using device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available actions:  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "# render ai gym environment\n",
    "import gym\n",
    "import time\n",
    "\n",
    "# PongDeterministic does not contain random frameskip\n",
    "# so is faster to train than the vanilla Pong-v4 environment\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "\n",
    "print(\"List of available actions: \", env.unwrapped.get_action_meanings())\n",
    "\n",
    "# we will only use the actions 'RIGHTFIRE' = 4 and 'LEFTFIRE\" = 5\n",
    "# the 'FIRE' part ensures that the game starts again after losing a life\n",
    "# the actions are hard-coded in pong_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show what a preprocessed image looks like\n",
    "env.reset()\n",
    "_, _, _, _, _ = env.step(0)\n",
    "# get a frame after 20 steps\n",
    "for _ in range(20):\n",
    "    frame, _, _, _, _ = env.step(1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "\n",
    "# 80 x 80 black and white image\n",
    "plt.imshow(pong_utils.preprocess_single(frame), cmap='Greys')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    "\n",
    "## Exercise 1: Implement your policy\n",
    " \n",
    "Here, we define our policy. The input is the stack of two different frames (which captures the movement), and the output is a number $P_{\\rm right}$, the probability of moving left. Note that $P_{\\rm left}= 1-P_{\\rm right}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# set up a convolutional neural net\n",
    "# the output is the probability of moving right\n",
    "# P(left) = 1-P(right)\n",
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        \n",
    "        \n",
    "    ########\n",
    "    ## \n",
    "    ## Modify your neural network\n",
    "    ##\n",
    "    ########\n",
    "        # 2 channel from the stacked frame\n",
    "        # After applying the first convolution, the output dimensions become:\n",
    "        # Width: (80 - 4 + 1) / 2 = 39\n",
    "        # Height: (80 - 4 + 1) / 2 = 39\n",
    "        # Channels: 4 (as defined by the layer)\n",
    "        # 80x80 to 39x39: \n",
    "        self.conv1 = nn.Conv2d(2,4,kernel_size=4, stride=2, bias=False)\n",
    "        # 39x39 to 18x18        \n",
    "        self.conv2 = nn.Conv2d(4, 32, kernel_size=5, stride=4,bias=False)\n",
    "        self.size= 32*18*18\n",
    "        \n",
    "        # 1 fully connected layer\n",
    "        self.fc = nn.Linear(self.size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "    ########\n",
    "    ## \n",
    "    ## Modify your neural network\n",
    "    ##\n",
    "    ########\n",
    "    \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # flatten the tensor\n",
    "        x = x.view(-1,self.size)\n",
    "        return self.sig(self.fc(x))\n",
    "\n",
    "\n",
    "# run your own policy!\n",
    "# policy=Policy().to(device)\n",
    "policy=pong_utils.Policy().to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game visualization\n",
    "pong_utils contain a play function given the environment and a policy. An optional preprocess function can be supplied. Here we define a function that plays a game and shows learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "setup() got an unexpected keyword argument 'clear_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yp/xsyhd9vn1bj7xbmj2dyszbh40000gn/T/ipykernel_2047/2170431642.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpong_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# try to add the option \"preprocess=pong_utils.preprocess_single\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# to see what the agent sees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/pong_utils.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(env, policy, time, preprocess, nrand)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0manimate_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/pong_utils.py\u001b[0m in \u001b[0;36manimate_frames\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     47\u001b[0m         lambda x: patch.set_data(frames[x]), frames = len(frames), interval=30)\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfanim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'once'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# play a game and display the animation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[0;34m(anim, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[0;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#with tempfile.NamedTemporaryFile(suffix='.html') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_NameOnlyTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.html'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[0m\u001b[1;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                                  default_mode=default_mode))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# callback a no-op; canvas.manager = None prevents resizing the GUI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;31m# widget (both are likewise done in savefig()).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'savefig.bbox'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m              \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m              cbook._setattr_cm(self._fig.canvas,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# This particular sequence is what contextlib.contextmanager wants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/JSAnimation/html_writer.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, fig, outfile, dpi, frame_dir)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mframe_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         super(HTMLWriter, self).setup(fig, outfile, dpi,\n\u001b[0m\u001b[1;32m    282\u001b[0m                                       frame_prefix, clear_temp=False)\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: setup() got an unexpected keyword argument 'clear_temp'"
     ]
    }
   ],
   "source": [
    "pong_utils.play(env, policy, time=200) \n",
    "# try to add the option \"preprocess=pong_utils.preprocess_single\"\n",
    "# to see what the agent sees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions\n",
    "Here you will define key functions for training. \n",
    "\n",
    "## Exercise 2: write your own function for training\n",
    "(what I call scalar function is the same as policy_loss up to a negative sign)\n",
    "\n",
    "### PPO\n",
    "Later on, you'll implement the PPO algorithm as well, and the scalar function is given by\n",
    "$\\frac{1}{T}\\sum^T_t \\min\\left\\{R_{t}^{\\rm future}\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)},R_{t}^{\\rm future}{\\rm clip}_{\\epsilon}\\!\\left(\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)}\\right)\\right\\}$\n",
    "\n",
    "the ${\\rm clip}_\\epsilon$ function is implemented in pytorch as ```torch.clamp(ratio, 1-epsilon, 1+epsilon)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                      discount = 0.995, epsilon=0.1, beta=0.01):\n",
    "\n",
    "    ########\n",
    "    ## \n",
    "    ## WRITE YOUR OWN CODE HERE\n",
    "    ##\n",
    "    ########\n",
    "    \n",
    "    actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "\n",
    "    # convert states to policy (or probability)\n",
    "    new_probs = pong_utils.states_to_prob(policy, states)\n",
    "    new_probs = torch.where(actions == pong_utils.RIGHT, new_probs, 1.0-new_probs)\n",
    "\n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # prevents policy to become exactly 0 or 1 helps exploration\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    entropy = -(new_probs*torch.log(old_probs+1.e-10)+ \\\n",
    "        (1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "    \n",
    "#     clipped_result = min([entropy*rewards,torch.clamp(entropy, 1-epsilon, 1+epsilon)*rewards])\n",
    "\n",
    "    return torch.mean(beta*entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We are now ready to train our policy!\n",
    "WARNING: make sure to turn on GPU, which also enables multicore processing. It may take up to 45 minutes even with GPU enabled, otherwise it will take much longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: progressbar in /Users/admin/opt/anaconda3/lib/python3.9/site-packages (2.5)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)      | ETA:  --:--:--\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "Process Process-24:\n",
      "Process Process-23:\n",
      "Process Process-21:\n",
      "Process Process-18:\n",
      "Process Process-22:\n",
      "Process Process-19:\n",
      "Process Process-17:\n",
      "Process Process-20:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "Traceback (most recent call last):\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\", line 106, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "ValueError: too many values to unpack (expected 4)\n",
      "ValueError: too many values to unpack (expected 4)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yp/xsyhd9vn1bj7xbmj2dyszbh40000gn/T/ipykernel_2047/8228417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# collect trajectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mold_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mpong_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtotal_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/pong_utils.py\u001b[0m in \u001b[0;36mcollect_trajectories\u001b[0;34m(envs, policy, tmax, nrand)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# start all parallel agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# perform nrand random steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mremote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaiting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GameProjects/DataScience/DeepReinforcementLearning/deep-reinforcement-learning-master/pong/parallelEnv.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mremote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaiting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got end of file during message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from parallelEnv import parallelEnv\n",
    "import numpy as np\n",
    "# keep track of how long training takes\n",
    "# WARNING: running through all 800 episodes will take 30-45 minutes\n",
    "\n",
    "# training loop max iterations\n",
    "episode = 500\n",
    "\n",
    "# widget bar to display progress\n",
    "!pip install progressbar\n",
    "import progressbar as pb\n",
    "widget = ['training loop: ', pb.Percentage(), ' ', \n",
    "          pb.Bar(), ' ', pb.ETA() ]\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "\n",
    "envs = parallelEnv('PongDeterministic-v4', n=8, seed=1234)\n",
    "\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta = .01\n",
    "tmax = 320\n",
    "SGD_epoch = 4\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    old_probs, states, actions, rewards = \\\n",
    "        pong_utils.collect_trajectories(envs, policy, tmax=tmax)\n",
    "        \n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "\n",
    "    # gradient ascent step\n",
    "    for _ in range(SGD_epoch):\n",
    "        \n",
    "        # uncomment to utilize your own clipped function!\n",
    "        # L = -clipped_surrogate(policy, old_probs, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "\n",
    "        L = -pong_utils.clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                                          epsilon=epsilon, beta=beta)\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    timer.update(e+1)\n",
    "    \n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong_utils.play(env, policy, time=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your policy!\n",
    "torch.save(policy, 'PPO.policy')\n",
    "\n",
    "# load policy if needed\n",
    "# policy = torch.load('PPO.policy')\n",
    "\n",
    "# try and test out the solution \n",
    "# make sure GPU is enabled, otherwise loading will fail\n",
    "# (the PPO verion can win more often than not)!\n",
    "#\n",
    "# policy_solution = torch.load('PPO_solution.policy')\n",
    "# pong_utils.play(env, policy_solution, time=2000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
