{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb9q2_QZgdNk"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch\n",
    "## Main_RandomTic_Discrete_AVDataset_Dow30_Daily\n",
    "Network with 128 neutrons and 2 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Check Additional Packages](#1.1)\n",
    "    * [2.2. Import Packages](#1.2)\n",
    "    * [2.3. Create Folders & Relevant Configurations¶](#1.3)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess fundamental data](#3)        \n",
    "    * [4.1. Import the financial data](#3.1)\n",
    "    * [4.2. Specify items needed to calculate financial ratios](#3.2)\n",
    "    * [4.3. Turn the final_ratios to daily basis](#3.3)\n",
    "    * [4.4. Merge stock price data and ratios into one dataframe](#3.4)\n",
    "    * [4.5. Finish data preparation](#3.5)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. Set up the training environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Train DRL Agent](#5)  \n",
    "* [7.Backtest Our Strategy](#6)  \n",
    "    * [7.1. BackTest with DJIA](#6.1)\n",
    "    * [7.2. BackTest with Buy&Hold Strategy](#6.2)\n",
    "* [8.Save & load model](#7)\n",
    "    * [8.1. Save model](#7.1)\n",
    "    * [8.2. Load model](#7.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Alpha Vantage API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If continuing the previous training, jump to [**this point**](#8.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "<a id='1.1'></a>\n",
    "## 2.1. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "import math\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "# from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Create Folders & Relevant Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TEST_END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "TRAIN_START_DATE = '2000-01-01'\n",
    "TRAIN_END_DATE = '2021-01-01'\n",
    "TEST_START_DATE = '2021-01-01'\n",
    "TEST_END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Load price data from csv file\n",
    "# tic_dir = './' + DATA_SAVE_DIR + '/sp500_price_daily.csv'\n",
    "# df = pd.read_csv(tic_dir,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is available locally, we can skip downloading steps and jump directly to part [**4.5.Finish data preparation**](#3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Price Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "0a5b0405-7c4f-4afd-c3e1-1dabd55c81fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download data from YFinance\n",
    "# tic_dir = './' + DATA_SAVE_DIR + '/sp500_ticker.csv'\n",
    "# tic_list = pd.read_csv(tic_dir,index_col=0)\n",
    "# SP_500_TICKER = np.array(tic_list.tic).tolist()\n",
    "# df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "#                      end_date = TEST_END_DATE,\n",
    "#                      ticker_list = SP_500_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GiRuFOTOtj1Y",
    "outputId": "402874c0-b13f-437b-a67f-a83f88de66eb"
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DSw4ZEzVtj1Z",
    "outputId": "94617d16-432c-40eb-f758-16d2fdab09e0"
   },
   "outputs": [],
   "source": [
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "73944c23-5a4e-49f8-b9e5-da382b4fc7f5"
   },
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "87cca0b1-8d3c-4a61-e061-ea0d9989daa1"
   },
   "outputs": [],
   "source": [
    "# df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2vryMsdNL9H",
    "outputId": "6691ba9b-e613-412b-dba5-dee592bb0ff2"
   },
   "outputs": [],
   "source": [
    "# len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcNyXa7RNPrF",
    "outputId": "edb04575-9b82-4d5e-f13a-55c884214725"
   },
   "outputs": [],
   "source": [
    "# df.tic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "<a id='3'></a>\n",
    "# Part 4: Preprocess fundamental data\n",
    "- Import finanical data downloaded from Alpha Vantage\n",
    "- Preprocess the dataset and calculate financial ratios\n",
    "- Turn yearly ratio into daily basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "## 4.1 Import the financial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define configurations of the collecting data & download data via Alpha Vantage API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# api_key = 'GZWRUSYXT18ZTR6C'\n",
    "# features_cols = ['fiscalDateEnding','totalRevenue','costOfRevenue','sellingGeneralAndAdministrative','researchAndDevelopment','depreciation','interestExpense','totalCurrentLiabilities','incomeTaxExpense','netIncome','commonStockSharesOutstanding','cashAndCashEquivalentsAtCarryingValue','cashAndShortTermInvestments','operatingCashflow','totalLiabilities','inventory','currentNetReceivables','propertyPlantEquipment','capitalExpenditures','longTermInvestments','totalShareholderEquity','longTermDebt','retainedEarnings','dividendPayoutCommonStock','paymentsForRepurchaseOfCommonStock','treasuryStock','currentLongTermDebt']\n",
    "# price_cols = ['open','high','low','close','volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download fundamental data from financial reports by ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_fundamental(ticket):\n",
    "#     # Download income statement\n",
    "#     url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_is = r.json()\n",
    "\n",
    "#     # Download balance sheet\n",
    "#     url = f'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_bs = r.json()\n",
    "\n",
    "#     # Download cash flow\n",
    "#     url = f'https://www.alphavantage.co/query?function=CASH_FLOW&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_cf = r.json()\n",
    "\n",
    "#     df_is = pd.json_normalize(data_is['annualReports'])\n",
    "#     df_bs = pd.json_normalize(data_bs['annualReports'])\n",
    "#     df_cf = pd.json_normalize(data_cf['annualReports'])\n",
    "\n",
    "#     merged_df = df_is.merge(df_bs).merge(df_cf)\n",
    "#     merged_df['tic'] = ticket\n",
    "#     merged_df = merged_df[['tic']+features_cols]\n",
    "#     merged_df['fiscalDateEnding'] = pd.to_datetime(merged_df.fiscalDateEnding,format='mixed')\n",
    "\n",
    "#     return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download stock price by ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_price(ticket):\n",
    "#     url = f'https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol={ticket}&apikey={api_key}'\n",
    "#     r = requests.get(url)\n",
    "#     data_monthly_price = r.json()\n",
    "\n",
    "#     price_monthly = pd.DataFrame.from_dict(data_monthly_price['Monthly Time Series'], orient='index')\n",
    "#     price_monthly.columns = price_cols\n",
    "#     price_monthly['fiscalDateEnding'] = pd.to_datetime(price_monthly.index,format='mixed')\n",
    "#     price_monthly.reset_index(inplace=True,drop=True)\n",
    "#     price_monthly = price_monthly[['fiscalDateEnding','open','high','low','close','volume']]\n",
    "#     return price_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to merge monthly stock price into yearly fundamental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_price_to_df(merged_df,price_monthly):\n",
    "#     merged_df['year'] = merged_df.fiscalDateEnding.dt.year\n",
    "#     merged_df['month'] = merged_df.fiscalDateEnding.dt.month\n",
    "#     price_monthly['year'] = price_monthly.fiscalDateEnding.dt.year\n",
    "#     price_monthly['month'] = price_monthly.fiscalDateEnding.dt.month\n",
    "#     merged_final = pd.merge(merged_df,price_monthly,how=\"left\",on=['year','month'])\n",
    "#     merged_final.drop(columns=['year','month','fiscalDateEnding_y'],inplace=True)\n",
    "#     merged_final = df_final.rename(columns={'fiscalDateEnding_x': 'date'})\n",
    "#     merged_final['tic'] = ticket\n",
    "\n",
    "#     merged_columns = [merged_final.columns[-1]]\n",
    "#     for i in range(0,len(merged_final.columns)-1):\n",
    "#         merged_columns.append(merged_final.columns[i])\n",
    "#     merged_final = merged_final[merged_columns]\n",
    "    \n",
    "#     return merged_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_tics = SP_500_TICKER[453:]\n",
    "# print(download_tics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data = pd.DataFrame()\n",
    "\n",
    "# for ticket in download_tics:\n",
    "#     df_fund = collect_fundamental(ticket)\n",
    "#     fund_data = pd.concat([fund_data, df_fund], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data.to_csv('sp500_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dropped tickers which are not available data to download from Alpha Vantage\n",
    "\n",
    "# tics_1 = pd.DataFrame()\n",
    "# tics_2 = pd.DataFrame()\n",
    "# tics_1['tic'] = df.tic.unique()\n",
    "# tics_2['tic'] = fund_data.tic.unique()\n",
    "\n",
    "# merged_df = tics_1.merge(tics_2, how='outer', indicator=True)\n",
    "# unique_in_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "# unique_in_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check reach download limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol=IBM&apikey=GZWRUSYXT18ZTR6C'\n",
    "# r = requests.get(url)\n",
    "# data_is = r.json()\n",
    "# data_is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data = pd.read_csv('./' + DATA_SAVE_DIR + '/sp500_fundamental.csv',index_col=0)\n",
    "# # fund_data = fund_data.rename(columns={'fiscalDateEnding_x':'date'})\n",
    "# fund_data['date'] = pd.to_datetime(fund_data.date,format='mixed')\n",
    "# fund_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select tickers in DJ index only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data = fund_data[fund_data.tic.isin(DOW_30_TICKER)].reset_index(drop=True)\n",
    "# fund_data.tic.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UTIL TOOL: merge yearly fundamental data to daily stock price\n",
    "\n",
    "# start_date = df.iloc[0].date\n",
    "# end_date = df.iloc[-1].date\n",
    "# date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# date_range = pd.DataFrame(date_range)\n",
    "# date_range.columns = ['date']\n",
    "\n",
    "# fund_data = fund_data.rename(columns={'fiscalDateEnding':'date'})\n",
    "# fund_data['date'] = pd.to_datetime(fund_data.date,format='mixed')\n",
    "\n",
    "# fund_data_with_price = pd.DataFrame()\n",
    "# for ticket in fund_data.tic.unique():\n",
    "#     price_by_ticket = df[df.tic == ticket]\n",
    "#     price_by_ticket['date'] = pd.to_datetime(price_by_ticket['date'],format='mixed')\n",
    "#     price_by_ticket = pd.merge(date_range,price_by_ticket,how='left')\n",
    "#     price_by_ticket.bfill(inplace=True)\n",
    "#     price_by_ticket = pd.merge(fund_data.loc[fund_data.tic==ticket],price_by_ticket,how='left',on=['date'])\n",
    "#     price_by_ticket.drop(columns=['tic_y','day'],inplace=True,axis=0)\n",
    "#     price_by_ticket = price_by_ticket.rename(columns={'tic_x':'tic'})\n",
    "#     fund_data_with_price = pd.concat([fund_data_with_price, price_by_ticket], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning ####\n",
    "Refine the data before computing fundamental ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(fund_data.info(),'\\n')\n",
    "# print(fund_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company with zero totalRevenue might cause problems for computing ratios while it is the denominator in some formulars.<br>\n",
    "Deleting all tickers containing this issue is a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_revenue_tics = fund_data[fund_data.totalRevenue == 0].tic.unique()\n",
    "# fund_data = fund_data[~fund_data.tic.isin(zero_revenue_tics)]\n",
    "# fund_data[fund_data.totalRevenue == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While removing zero revenue data was neccessary, other columns with zero values might indicate some potential issues that require further investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_nan = fund_data.eq(0).any()\n",
    "# column_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_data = fund_data.fillna(0)\n",
    "# for i in fund_data.columns:\n",
    "#     print(i,'\\n',fund_data[i].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Compute fundamental ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define support functions before computing fundamental ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to count positive values within a window\n",
    "# def count_positives(window):\n",
    "#   return window[window > 0].count()\n",
    "\n",
    "# def count_positives_window(data,k):\n",
    "#     df = pd.DataFrame(data, columns=['values'])\n",
    "\n",
    "#     # Create a new column with the adjusted positive count (using a shifted window)\n",
    "#     df['positive_count'] = df['values'].rolling(window=k, min_periods=1).apply(count_positives)\n",
    "\n",
    "#     # Set positive_count of the first k rows to positive_count of row k\n",
    "#     df.loc[:k-1,'positive_count'] = df.loc[k-1].positive_count\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to min value within a window\n",
    "# def get_min(window):\n",
    "#   return window.min()\n",
    "\n",
    "# def min_in_window(data,k):\n",
    "#     df = pd.DataFrame(data, columns=['values'])\n",
    "\n",
    "#     # Create a new column with the min in the window (using a shifted window)\n",
    "#     df['min'] = df['values'].rolling(window=k, min_periods=1).apply(get_min)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, data and supporting functions are ready for computing fundamental ratios required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_fund_ratios(df_final):\n",
    "#     pos_count_window = 10  # number of years to look back for count_positive_profit\n",
    "#     min_ebit_window = 4  # number of years to look back for min_ebit\n",
    "    \n",
    "#     gross_income = df_final.totalRevenue - df_final.costOfRevenue\n",
    "#     ebit = gross_income - df_final.sellingGeneralAndAdministrative\n",
    "#     profit = ebit - df_final.interestExpense - df_final.incomeTaxExpense\n",
    "#     market_equity = df_final.commonStockSharesOutstanding * df_final.close\n",
    "#     market_asset = df_final.totalLiabilities + market_equity\n",
    "    \n",
    "#     # Gross profit margin\n",
    "#     gross_profit_margin = (gross_income/df_final.totalRevenue).to_frame('gross_profit_margin')\n",
    "    \n",
    "#     # SGA Expense / Gross Profit\n",
    "#     sga_ratio = (df_final.sellingGeneralAndAdministrative/gross_income).to_frame('sga_ratio')\n",
    "    \n",
    "#     # Depreciation / Gross Profit\n",
    "#     dep_ratio = (df_final.depreciation/gross_income).to_frame('dep_ratio')\n",
    "    \n",
    "#     # EBIT / Bond interest\n",
    "#     ebit_on_int = (ebit/df_final.interestExpense).to_frame('ebit_on_int')\n",
    "    \n",
    "#     # Profit margin\n",
    "#     profit_margin = (profit/df_final.totalRevenue).to_frame('profit_margin')\n",
    "    \n",
    "#     # Amount of positive profit within a window\n",
    "#     count_positive_profit = count_positives_window(profit,pos_count_window)\n",
    "#     count_positive_profit = count_positive_profit['positive_count'].to_frame('count_positive_profit')\n",
    "    \n",
    "#     # Cash And Short Term Investments / Total Liabilities\n",
    "#     csti_on_liabilities = (df_final.cashAndShortTermInvestments/df_final.totalLiabilities).to_frame('csti_on_liabilities')\n",
    "    \n",
    "#     # Inventory / EBIT\n",
    "#     inventory_on_ebit = (df_final.inventory / ebit).to_frame('inventory_on_ebit')\n",
    "    \n",
    "#     # Receivable / Revenue\n",
    "#     receivable_on_rev = (df_final.currentNetReceivables / df_final.totalRevenue).to_frame('receivable_on_rev')\n",
    "    \n",
    "#     # ROA\n",
    "#     roa = (profit / market_asset).to_frame('roa')\n",
    "    \n",
    "#     # ROE\n",
    "#     roe = (profit / market_equity).to_frame('roe')\n",
    "    \n",
    "#     # Long-term debt / minEBIT\n",
    "#     min_ebit = min_in_window(ebit,min_ebit_window)['min']\n",
    "#     debt_on_min_ebit = (df_final.longTermDebt / min_ebit).to_frame('debt_on_min_ebit')\n",
    "    \n",
    "#     # Total Liabilities / Total Equity\n",
    "#     liabilities_on_equity = (df_final.totalLiabilities / market_equity).to_frame('liabilities_on_equity')\n",
    "    \n",
    "#     # Capital Expenditures / EBIT\n",
    "#     capital_cost_on_ebit = (df_final.capitalExpenditures / ebit).to_frame('capital_cost_on_ebit')\n",
    "    \n",
    "#     # EPS / MP\n",
    "#     eps = profit / df_final.commonStockSharesOutstanding\n",
    "#     eps_on_mp = (eps / df_final.close).to_frame('eps_on_mp')\n",
    "    \n",
    "#     # Cash and Stock Dividend & Repurchase Common / MP\n",
    "#     dividend_on_mp = ((df_final.dividendPayoutCommonStock + df_final.paymentsForRepurchaseOfCommonStock) / df_final.close).to_frame('dividend_on_mp')\n",
    "    \n",
    "#     # MP / BV\n",
    "#     mp_on_bv = (df_final.close / (df_final.cashAndShortTermInvestments + df_final.currentNetReceivables*0.8 +df_final.inventory*0.5 + df_final.propertyPlantEquipment*0.2 + df_final.longTermInvestments - df_final.totalLiabilities)).to_frame('mp_on_bv')\n",
    "\n",
    "#     # Create a dataframe that merges all the ratios\n",
    "#     ratios = pd.concat([df_final.date,df_final.tic,gross_profit_margin,sga_ratio,dep_ratio,\n",
    "#                     ebit_on_int,profit_margin,count_positive_profit,csti_on_liabilities,\n",
    "#                     inventory_on_ebit,receivable_on_rev,roa,roe,debt_on_min_ebit,\n",
    "#                    liabilities_on_equity,capital_cost_on_ebit,eps_on_mp,dividend_on_mp,mp_on_bv], axis=1)\n",
    "\n",
    "#     return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios = compute_fund_ratios(fund_data)\n",
    "# ratios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check columns with inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_list = ratios.columns.drop(['date','tic'])\n",
    "# check_ratios = ratios[ratio_list]\n",
    "# inf_cols = check_ratios.columns[~np.isfinite(check_ratios).all()]\n",
    "# inf_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check rows with inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_inf = ratios[((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]\n",
    "# print(len(ratios[((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]))\n",
    "# ratio_inf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ebit_on_int** has infinity values for companies without banking support. We need to address these cases separately: <br>\n",
    " * Replace positive inf with maximum value in ebit_on_int\n",
    " * Replace negative inf with minimum value in ebit_on_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_finite = ratios[~((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]\n",
    "# ratios['ebit_on_int'] = ratios.ebit_on_int.replace(np.inf,ratio_finite.ebit_on_int.max())\n",
    "# ratios['ebit_on_int'] = ratios.ebit_on_int.replace(-np.inf,ratio_finite.ebit_on_int.min())\n",
    "# print(len(ratios[((ratios == np.inf)|(ratios == -np.inf)).any(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "## 4.3 Turn the final_ratios to daily basis¶\n",
    "After our initial inspection, we’ll want to dig deeper to investigate the following:\n",
    "- The data type of each variable.\n",
    "- How discrete/categorical data is coded (and whether we need to make any changes).\n",
    "- How the data are scaled.\n",
    "- Whether there is missing data and how it is coded.\n",
    "- Whether there are outliers.\n",
    "- The distributions of continuous features.\n",
    "- The relationships between pairs of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types\n",
    "It is important to check the data type for each feature. <br>\n",
    "The **date** should be in datetime type <br>\n",
    "The **ratios** should be read in as float64 — and categorical variables should be stored as object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ratios['date'] = pd.to_datetime(ratios['date'],format='mixed')\n",
    "# ratios.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is no missing values from all ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn the final_ratios to daily basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = df.iloc[0].date\n",
    "# end_date = df.iloc[-1].date\n",
    "# date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# date_range = pd.DataFrame(date_range)\n",
    "# date_range.columns = ['date']\n",
    "# date_range.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate missing data in the middle of years for each ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# daily_ratios = pd.DataFrame()\n",
    "# for ticket in ratios.tic.unique():\n",
    "#     # Interpolate data for each ticket\n",
    "#     one_tic_ratios = pd.merge(date_range,ratios[ratios.tic == ticket],how=\"left\",on=['date'])\n",
    "#     one_tic_ratios['tic'] = ticket\n",
    "#     one_tic_ratios = one_tic_ratios.interpolate('linear')\n",
    "#     daily_ratios = pd.concat([daily_ratios, one_tic_ratios], ignore_index=True)\n",
    "\n",
    "#     # Check data by drawing it out\n",
    "#     %matplotlib inline\n",
    "#     plt.figure(figsize=(16, 4)) \n",
    "#     plt.plot(one_tic_ratios.date, one_tic_ratios.gross_profit_margin, color = 'red')\n",
    "#     plt.title(f'Gross profit margin of {ticket}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_ratios.dropna(subset='gross_profit_margin',inplace=True)\n",
    "# daily_ratios.reset_index(inplace=True,drop=True)\n",
    "# daily_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "## 4.4 Merge stock price data and ratios into one dataframe\n",
    "- Merge the price dataframe preprocessed in Part 3 and the ratio dataframe created in this part\n",
    "- Since the prices are daily and ratios are quartely, we have NAs in the ratio columns after merging the two dataframes. We deal with this by backfilling the ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_date = pd.DataFrame(df)[['date','tic','close']]\n",
    "# df_date.columns = ['date','tic','close']\n",
    "# df_date['date'] = pd.to_datetime(df_date.date)\n",
    "# final_ratios = pd.merge(df_date,daily_ratios,how=\"left\",on=['date','tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_ratios.dropna(subset=['gross_profit_margin'],inplace=True,how='any')\n",
    "# final_ratios.reset_index(drop=True,inplace=True)\n",
    "# final_ratios.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_ratios.to_csv('./' + DATA_SAVE_DIR + '/dow30_ready_data_daily.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.5'></a>\n",
    "## 4.5 Finish data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100209 entries, 0 to 100208\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   date                   100209 non-null  datetime64[ns]\n",
      " 1   tic                    100209 non-null  object        \n",
      " 2   close                  100209 non-null  float64       \n",
      " 3   gross_profit_margin    100209 non-null  float64       \n",
      " 4   sga_ratio              100209 non-null  float64       \n",
      " 5   dep_ratio              100209 non-null  float64       \n",
      " 6   ebit_on_int            100209 non-null  float64       \n",
      " 7   profit_margin          100209 non-null  float64       \n",
      " 8   count_positive_profit  100209 non-null  float64       \n",
      " 9   csti_on_liabilities    100209 non-null  float64       \n",
      " 10  inventory_on_ebit      100209 non-null  float64       \n",
      " 11  receivable_on_rev      100209 non-null  float64       \n",
      " 12  roa                    100209 non-null  float64       \n",
      " 13  roe                    100209 non-null  float64       \n",
      " 14  debt_on_min_ebit       100209 non-null  float64       \n",
      " 15  liabilities_on_equity  100209 non-null  float64       \n",
      " 16  capital_cost_on_ebit   100209 non-null  float64       \n",
      " 17  eps_on_mp              100209 non-null  float64       \n",
      " 18  dividend_on_mp         100209 non-null  float64       \n",
      " 19  mp_on_bv               100209 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(18), object(1)\n",
      "memory usage: 16.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# If the data is available in the data storage, load processed_full from readied data\n",
    "processed_full = pd.read_csv('./' + DATA_SAVE_DIR + '/dow30_ready_data_daily.csv',index_col=0)\n",
    "processed_full['date'] = pd.to_datetime(processed_full.date,format='mixed')\n",
    "processed_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'V', 'AMGN', 'AXP', 'BA', 'CAT', 'CVX', 'GS', 'HON', 'IBM',\n",
       "       'INTC', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'TRV', 'UNH', 'VZ',\n",
       "       'CRM', 'HD', 'WMT', 'NKE', 'MSFT', 'PG', 'CSCO', 'JNJ', 'WBA',\n",
       "       'DIS', 'DOW'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full = processed_full[processed_full.tic.isin(DOW_30_TICKER)]\n",
    "processed_full.tic.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset **TRAIN_START_DATE** and **TEST_END_DATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_START_DATE:  2009-09-30 \n",
      "\n",
      "TRAIN_END_DATE:  2021-01-01 \n",
      "\n",
      "TEST_START_DATE:  2021-01-01 \n",
      "\n",
      "TEST_END_DATE:  2024-03-18 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = processed_full.date.min().strftime(\"%Y-%m-%d\")\n",
    "TEST_END_DATE = processed_full.date.max().strftime(\"%Y-%m-%d\")\n",
    "print('TRAIN_START_DATE: ',TRAIN_START_DATE,'\\n')\n",
    "print('TRAIN_END_DATE: ',TRAIN_END_DATE,'\\n')\n",
    "print('TEST_START_DATE: ',TEST_START_DATE,'\\n')\n",
    "print('TEST_END_DATE: ',TEST_END_DATE,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1 Training & Trade Data Split\n",
    "- Training data period: 2009-01-01 to 2020-01-01\n",
    "- Trade data period: 2020-01-01 to 2023-12-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76029\n",
      "24150\n"
     ]
    }
   ],
   "source": [
    "train_data = data_split(processed_full, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "test_data = data_split(processed_full, TEST_START_DATE, TEST_END_DATE)\n",
    "# Check the length of the two datasets\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>gross_profit_margin</th>\n",
       "      <th>sga_ratio</th>\n",
       "      <th>dep_ratio</th>\n",
       "      <th>ebit_on_int</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>count_positive_profit</th>\n",
       "      <th>csti_on_liabilities</th>\n",
       "      <th>inventory_on_ebit</th>\n",
       "      <th>receivable_on_rev</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>debt_on_min_ebit</th>\n",
       "      <th>liabilities_on_equity</th>\n",
       "      <th>capital_cost_on_ebit</th>\n",
       "      <th>eps_on_mp</th>\n",
       "      <th>dividend_on_mp</th>\n",
       "      <th>mp_on_bv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-09-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>5.604187</td>\n",
       "      <td>0.304696</td>\n",
       "      <td>0.317372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.374233</td>\n",
       "      <td>0.111106</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.479352</td>\n",
       "      <td>0.050986</td>\n",
       "      <td>0.078336</td>\n",
       "      <td>0.228046</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.145352</td>\n",
       "      <td>0.128194</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.618375e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-09-30</td>\n",
       "      <td>V</td>\n",
       "      <td>15.578794</td>\n",
       "      <td>0.732890</td>\n",
       "      <td>0.247976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.121739</td>\n",
       "      <td>0.296050</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.670885</td>\n",
       "      <td>0.639013</td>\n",
       "      <td>0.064245</td>\n",
       "      <td>0.091882</td>\n",
       "      <td>0.155239</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.689547</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.155239</td>\n",
       "      <td>1.902586e+08</td>\n",
       "      <td>-1.542455e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-10-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>5.468429</td>\n",
       "      <td>0.304675</td>\n",
       "      <td>0.317283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.543778</td>\n",
       "      <td>0.111186</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.477861</td>\n",
       "      <td>0.051055</td>\n",
       "      <td>0.078353</td>\n",
       "      <td>0.228133</td>\n",
       "      <td>0.945932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.146284</td>\n",
       "      <td>0.128239</td>\n",
       "      <td>0.945932</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.619311e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-10-01</td>\n",
       "      <td>V</td>\n",
       "      <td>15.581048</td>\n",
       "      <td>0.732984</td>\n",
       "      <td>0.247883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.216116</td>\n",
       "      <td>0.296298</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.670978</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.064231</td>\n",
       "      <td>0.091985</td>\n",
       "      <td>0.155358</td>\n",
       "      <td>0.014687</td>\n",
       "      <td>0.689123</td>\n",
       "      <td>0.080252</td>\n",
       "      <td>0.155358</td>\n",
       "      <td>1.899599e+08</td>\n",
       "      <td>-1.552592e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-10-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>5.590579</td>\n",
       "      <td>0.304653</td>\n",
       "      <td>0.317195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.713323</td>\n",
       "      <td>0.111266</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.476371</td>\n",
       "      <td>0.051123</td>\n",
       "      <td>0.078370</td>\n",
       "      <td>0.228219</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.147217</td>\n",
       "      <td>0.128285</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.620246e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76024</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>UNH</td>\n",
       "      <td>335.059784</td>\n",
       "      <td>0.707009</td>\n",
       "      <td>0.229394</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>84.243536</td>\n",
       "      <td>0.519019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.156063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098794</td>\n",
       "      <td>0.300780</td>\n",
       "      <td>0.421057</td>\n",
       "      <td>0.400580</td>\n",
       "      <td>0.399884</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.421057</td>\n",
       "      <td>2.636544e+07</td>\n",
       "      <td>-7.671028e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76025</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>V</td>\n",
       "      <td>213.664169</td>\n",
       "      <td>0.697420</td>\n",
       "      <td>0.133718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.193962</td>\n",
       "      <td>0.441171</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.441947</td>\n",
       "      <td>0.269140</td>\n",
       "      <td>0.080325</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>1.732959</td>\n",
       "      <td>0.115467</td>\n",
       "      <td>0.054096</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>5.456423e+07</td>\n",
       "      <td>-9.743528e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76026</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>VZ</td>\n",
       "      <td>48.816624</td>\n",
       "      <td>0.618534</td>\n",
       "      <td>0.397880</td>\n",
       "      <td>0.179892</td>\n",
       "      <td>11.250294</td>\n",
       "      <td>0.295529</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.078657</td>\n",
       "      <td>0.037589</td>\n",
       "      <td>0.186426</td>\n",
       "      <td>0.078316</td>\n",
       "      <td>0.187464</td>\n",
       "      <td>2.972570</td>\n",
       "      <td>1.393680</td>\n",
       "      <td>0.425241</td>\n",
       "      <td>0.187464</td>\n",
       "      <td>2.096007e+08</td>\n",
       "      <td>-2.217831e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76027</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>WBA</td>\n",
       "      <td>33.866371</td>\n",
       "      <td>-0.009526</td>\n",
       "      <td>-1.021455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.212650</td>\n",
       "      <td>-0.202215</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>-0.305243</td>\n",
       "      <td>0.048514</td>\n",
       "      <td>-0.293656</td>\n",
       "      <td>-0.918168</td>\n",
       "      <td>-0.310980</td>\n",
       "      <td>2.088399</td>\n",
       "      <td>-0.052435</td>\n",
       "      <td>-0.918168</td>\n",
       "      <td>8.263157e+07</td>\n",
       "      <td>-8.529535e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76028</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>WMT</td>\n",
       "      <td>45.710587</td>\n",
       "      <td>0.248178</td>\n",
       "      <td>0.837881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.754111</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>4.084699</td>\n",
       "      <td>0.176538</td>\n",
       "      <td>2.007618</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.109269</td>\n",
       "      <td>2.188798</td>\n",
       "      <td>1.392779</td>\n",
       "      <td>0.460734</td>\n",
       "      <td>0.109269</td>\n",
       "      <td>2.090669e+08</td>\n",
       "      <td>-4.641799e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76029 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic       close  gross_profit_margin  sga_ratio  dep_ratio  \\\n",
       "0     2009-09-30  AAPL    5.604187             0.304696   0.317372   0.000000   \n",
       "1     2009-09-30     V   15.578794             0.732890   0.247976   0.000000   \n",
       "2     2009-10-01  AAPL    5.468429             0.304675   0.317283   0.000000   \n",
       "3     2009-10-01     V   15.581048             0.732984   0.247883   0.000000   \n",
       "4     2009-10-02  AAPL    5.590579             0.304653   0.317195   0.000000   \n",
       "...          ...   ...         ...                  ...        ...        ...   \n",
       "76024 2020-12-31   UNH  335.059784             0.707009   0.229394   0.005501   \n",
       "76025 2020-12-31     V  213.664169             0.697420   0.133718   0.000000   \n",
       "76026 2020-12-31    VZ   48.816624             0.618534   0.397880   0.179892   \n",
       "76027 2020-12-31   WBA   33.866371            -0.009526  -1.021455   0.000000   \n",
       "76028 2020-12-31   WMT   45.710587             0.248178   0.837881   0.000000   \n",
       "\n",
       "       ebit_on_int  profit_margin  count_positive_profit  csti_on_liabilities  \\\n",
       "0        27.374233       0.111106              10.000000             1.479352   \n",
       "1        33.121739       0.296050              10.000000             0.670885   \n",
       "2        27.543778       0.111186              10.000000             1.477861   \n",
       "3        33.216116       0.296298              10.000000             0.670978   \n",
       "4        27.713323       0.111266              10.000000             1.476371   \n",
       "...            ...            ...                    ...                  ...   \n",
       "76024    84.243536       0.519019              10.000000             0.156063   \n",
       "76025    26.193962       0.441171              10.000000             0.441947   \n",
       "76026    11.250294       0.295529              10.000000             0.078657   \n",
       "76027   -39.212650      -0.202215               5.000000             0.012180   \n",
       "76028     9.754111       0.024076               4.084699             0.176538   \n",
       "\n",
       "       inventory_on_ebit  receivable_on_rev       roa       roe  \\\n",
       "0               0.050986           0.078336  0.228046  0.945331   \n",
       "1               0.639013           0.064245  0.091882  0.155239   \n",
       "2               0.051055           0.078353  0.228133  0.945932   \n",
       "3               0.638800           0.064231  0.091985  0.155358   \n",
       "4               0.051123           0.078370  0.228219  0.946533   \n",
       "...                  ...                ...       ...       ...   \n",
       "76024           0.000000           0.098794  0.300780  0.421057   \n",
       "76025           0.269140           0.080325  0.022702  0.025326   \n",
       "76026           0.037589           0.186426  0.078316  0.187464   \n",
       "76027          -0.305243           0.048514 -0.293656 -0.918168   \n",
       "76028           2.007618           0.011682  0.045633  0.109269   \n",
       "\n",
       "       debt_on_min_ebit  liabilities_on_equity  capital_cost_on_ebit  \\\n",
       "0              0.000000               3.145352              0.128194   \n",
       "1              0.014702               0.689547              0.080336   \n",
       "2              0.000000               3.146284              0.128239   \n",
       "3              0.014687               0.689123              0.080252   \n",
       "4              0.000000               3.147217              0.128285   \n",
       "...                 ...                    ...                   ...   \n",
       "76024          0.400580               0.399884              0.014640   \n",
       "76025          1.732959               0.115467              0.054096   \n",
       "76026          2.972570               1.393680              0.425241   \n",
       "76027         -0.310980               2.088399             -0.052435   \n",
       "76028          2.188798               1.392779              0.460734   \n",
       "\n",
       "       eps_on_mp  dividend_on_mp      mp_on_bv  \n",
       "0       0.945331    0.000000e+00  2.618375e-10  \n",
       "1       0.155239    1.902586e+08 -1.542455e-08  \n",
       "2       0.945932    0.000000e+00  2.619311e-10  \n",
       "3       0.155358    1.899599e+08 -1.552592e-08  \n",
       "4       0.946533    0.000000e+00  2.620246e-10  \n",
       "...          ...             ...           ...  \n",
       "76024   0.421057    2.636544e+07 -7.671028e-09  \n",
       "76025   0.025326    5.456423e+07 -9.743528e-09  \n",
       "76026   0.187464    2.096007e+08 -2.217831e-10  \n",
       "76027  -0.918168    8.263157e+07 -8.529535e-10  \n",
       "76028   0.109269    2.090669e+08 -4.641799e-10  \n",
       "\n",
       "[76029 rows x 20 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reset_index(drop=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>gross_profit_margin</th>\n",
       "      <th>sga_ratio</th>\n",
       "      <th>dep_ratio</th>\n",
       "      <th>ebit_on_int</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>count_positive_profit</th>\n",
       "      <th>csti_on_liabilities</th>\n",
       "      <th>inventory_on_ebit</th>\n",
       "      <th>receivable_on_rev</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>debt_on_min_ebit</th>\n",
       "      <th>liabilities_on_equity</th>\n",
       "      <th>capital_cost_on_ebit</th>\n",
       "      <th>eps_on_mp</th>\n",
       "      <th>dividend_on_mp</th>\n",
       "      <th>mp_on_bv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>127.002121</td>\n",
       "      <td>0.315783</td>\n",
       "      <td>0.223707</td>\n",
       "      <td>0.106490</td>\n",
       "      <td>26.533518</td>\n",
       "      <td>0.199342</td>\n",
       "      <td>7.736986</td>\n",
       "      <td>0.316452</td>\n",
       "      <td>0.064367</td>\n",
       "      <td>0.138893</td>\n",
       "      <td>0.025846</td>\n",
       "      <td>0.029237</td>\n",
       "      <td>8.662206</td>\n",
       "      <td>0.131966</td>\n",
       "      <td>0.113972</td>\n",
       "      <td>0.029237</td>\n",
       "      <td>7.508122e+08</td>\n",
       "      <td>-3.869278e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>204.389359</td>\n",
       "      <td>0.711232</td>\n",
       "      <td>0.315051</td>\n",
       "      <td>0.035202</td>\n",
       "      <td>9.963490</td>\n",
       "      <td>0.403834</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.207281</td>\n",
       "      <td>0.313187</td>\n",
       "      <td>0.208373</td>\n",
       "      <td>0.060137</td>\n",
       "      <td>0.087027</td>\n",
       "      <td>25.533623</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>0.087027</td>\n",
       "      <td>3.501339e+07</td>\n",
       "      <td>-5.880832e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>AXP</td>\n",
       "      <td>113.141533</td>\n",
       "      <td>0.168618</td>\n",
       "      <td>1.757511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.305914</td>\n",
       "      <td>-0.212192</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.192420</td>\n",
       "      <td>-13.672682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030969</td>\n",
       "      <td>-0.086809</td>\n",
       "      <td>-9.285692</td>\n",
       "      <td>1.800199</td>\n",
       "      <td>-0.262491</td>\n",
       "      <td>-0.086809</td>\n",
       "      <td>2.198956e+07</td>\n",
       "      <td>-1.552065e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>BA</td>\n",
       "      <td>202.720001</td>\n",
       "      <td>-0.096149</td>\n",
       "      <td>-0.822932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.560140</td>\n",
       "      <td>-0.174822</td>\n",
       "      <td>6.010959</td>\n",
       "      <td>0.149911</td>\n",
       "      <td>-1.191891</td>\n",
       "      <td>0.033712</td>\n",
       "      <td>-0.026293</td>\n",
       "      <td>-0.046943</td>\n",
       "      <td>-6.525702</td>\n",
       "      <td>0.785165</td>\n",
       "      <td>-0.132133</td>\n",
       "      <td>-0.046943</td>\n",
       "      <td>5.351720e+06</td>\n",
       "      <td>-1.598733e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>CAT</td>\n",
       "      <td>170.039978</td>\n",
       "      <td>0.303390</td>\n",
       "      <td>0.366280</td>\n",
       "      <td>0.167152</td>\n",
       "      <td>15.666473</td>\n",
       "      <td>0.155775</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.148474</td>\n",
       "      <td>1.420657</td>\n",
       "      <td>0.401266</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.070241</td>\n",
       "      <td>3.317116</td>\n",
       "      <td>0.678781</td>\n",
       "      <td>0.263380</td>\n",
       "      <td>0.070241</td>\n",
       "      <td>1.991124e+07</td>\n",
       "      <td>-9.147068e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24145</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>UNH</td>\n",
       "      <td>490.820007</td>\n",
       "      <td>0.737986</td>\n",
       "      <td>0.199189</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>67.659889</td>\n",
       "      <td>0.566194</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.169496</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.104865</td>\n",
       "      <td>0.313486</td>\n",
       "      <td>0.423878</td>\n",
       "      <td>16.703334</td>\n",
       "      <td>0.352142</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.423878</td>\n",
       "      <td>2.747652e+07</td>\n",
       "      <td>-8.568411e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24146</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>V</td>\n",
       "      <td>283.040009</td>\n",
       "      <td>0.704715</td>\n",
       "      <td>0.118495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.854037</td>\n",
       "      <td>0.523667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.314608</td>\n",
       "      <td>0.240010</td>\n",
       "      <td>0.078065</td>\n",
       "      <td>0.035065</td>\n",
       "      <td>0.039327</td>\n",
       "      <td>2.099295</td>\n",
       "      <td>0.121541</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>0.039327</td>\n",
       "      <td>6.881727e+07</td>\n",
       "      <td>-8.084724e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24147</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>VZ</td>\n",
       "      <td>39.490002</td>\n",
       "      <td>0.567685</td>\n",
       "      <td>0.430544</td>\n",
       "      <td>0.196397</td>\n",
       "      <td>7.840333</td>\n",
       "      <td>0.245525</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.047495</td>\n",
       "      <td>0.194038</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.204009</td>\n",
       "      <td>74.999502</td>\n",
       "      <td>2.030192</td>\n",
       "      <td>0.567144</td>\n",
       "      <td>0.204009</td>\n",
       "      <td>2.883466e+08</td>\n",
       "      <td>-1.361466e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24148</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>WBA</td>\n",
       "      <td>20.820000</td>\n",
       "      <td>-0.066540</td>\n",
       "      <td>-3.659463</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-75.089655</td>\n",
       "      <td>-0.300945</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.010845</td>\n",
       "      <td>-0.189589</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>-0.473656</td>\n",
       "      <td>-2.002519</td>\n",
       "      <td>-0.208762</td>\n",
       "      <td>3.227792</td>\n",
       "      <td>-0.048609</td>\n",
       "      <td>-2.002519</td>\n",
       "      <td>7.399533e+07</td>\n",
       "      <td>-4.587726e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24149</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>WMT</td>\n",
       "      <td>60.680000</td>\n",
       "      <td>0.243754</td>\n",
       "      <td>0.829020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.449516</td>\n",
       "      <td>0.029082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108676</td>\n",
       "      <td>2.032134</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>-6.715134</td>\n",
       "      <td>0.126712</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>1.624698e+08</td>\n",
       "      <td>-5.866425e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24150 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   tic       close  gross_profit_margin  sga_ratio  dep_ratio  \\\n",
       "0     2021-01-04  AAPL  127.002121             0.315783   0.223707   0.106490   \n",
       "1     2021-01-04  AMGN  204.389359             0.711232   0.315051   0.035202   \n",
       "2     2021-01-04   AXP  113.141533             0.168618   1.757511   0.000000   \n",
       "3     2021-01-04    BA  202.720001            -0.096149  -0.822932   0.000000   \n",
       "4     2021-01-04   CAT  170.039978             0.303390   0.366280   0.167152   \n",
       "...          ...   ...         ...                  ...        ...        ...   \n",
       "24145 2024-03-15   UNH  490.820007             0.737986   0.199189   0.004011   \n",
       "24146 2024-03-15     V  283.040009             0.704715   0.118495   0.000000   \n",
       "24147 2024-03-15    VZ   39.490002             0.567685   0.430544   0.196397   \n",
       "24148 2024-03-15   WBA   20.820000            -0.066540  -3.659463  -0.000000   \n",
       "24149 2024-03-15   WMT   60.680000             0.243754   0.829020   0.000000   \n",
       "\n",
       "       ebit_on_int  profit_margin  count_positive_profit  csti_on_liabilities  \\\n",
       "0        26.533518       0.199342               7.736986             0.316452   \n",
       "1         9.963490       0.403834               9.000000             0.207281   \n",
       "2        -2.305914      -0.212192               3.000000             0.192420   \n",
       "3        -4.560140      -0.174822               6.010959             0.149911   \n",
       "4        15.666473       0.155775              10.000000             0.148474   \n",
       "...            ...            ...                    ...                  ...   \n",
       "24145    67.659889       0.566194              10.000000             0.169496   \n",
       "24146   -30.854037       0.523667               9.000000             0.314608   \n",
       "24147     7.840333       0.245525              10.000000             0.006308   \n",
       "24148   -75.089655      -0.300945               5.000000             0.010845   \n",
       "24149    10.449516       0.029082               1.000000             0.108676   \n",
       "\n",
       "       inventory_on_ebit  receivable_on_rev       roa       roe  \\\n",
       "0               0.064367           0.138893  0.025846  0.029237   \n",
       "1               0.313187           0.208373  0.060137  0.087027   \n",
       "2             -13.672682           0.000000 -0.030969 -0.086809   \n",
       "3              -1.191891           0.033712 -0.026293 -0.046943   \n",
       "4               1.420657           0.401266  0.041842  0.070241   \n",
       "...                  ...                ...       ...       ...   \n",
       "24145           0.012749           0.104865  0.313486  0.423878   \n",
       "24146           0.240010           0.078065  0.035065  0.039327   \n",
       "24147           0.047495           0.194038  0.067325  0.204009   \n",
       "24148          -0.189589           0.038307 -0.473656 -2.002519   \n",
       "24149           2.032134           0.013571  0.012578  0.014171   \n",
       "\n",
       "       debt_on_min_ebit  liabilities_on_equity  capital_cost_on_ebit  \\\n",
       "0              8.662206               0.131966              0.113972   \n",
       "1             25.533623               0.446755              0.048998   \n",
       "2             -9.285692               1.800199             -0.262491   \n",
       "3             -6.525702               0.785165             -0.132133   \n",
       "4              3.317116               0.678781              0.263380   \n",
       "...                 ...                    ...                   ...   \n",
       "24145         16.703334               0.352142              0.015417   \n",
       "24146          2.099295               0.121541              0.053296   \n",
       "24147         74.999502               2.030192              0.567144   \n",
       "24148         -0.208762               3.227792             -0.048609   \n",
       "24149         -6.715134               0.126712              0.762846   \n",
       "\n",
       "       eps_on_mp  dividend_on_mp      mp_on_bv  \n",
       "0       0.029237    7.508122e+08 -3.869278e-09  \n",
       "1       0.087027    3.501339e+07 -5.880832e-09  \n",
       "2      -0.086809    2.198956e+07 -1.552065e-09  \n",
       "3      -0.046943    5.351720e+06 -1.598733e-09  \n",
       "4       0.070241    1.991124e+07 -9.147068e-09  \n",
       "...          ...             ...           ...  \n",
       "24145   0.423878    2.747652e+07 -8.568411e-09  \n",
       "24146   0.039327    6.881727e+07 -8.084724e-09  \n",
       "24147   0.204009    2.883466e+08 -1.361466e-10  \n",
       "24148  -2.002519    7.399533e+07 -4.587726e-10  \n",
       "24149   0.014171    1.624698e+08 -5.866425e-10  \n",
       "\n",
       "[24150 rows x 20 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.reset_index(drop=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2 Set up the training environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the environment: \n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. However, because StableBaseline does not support {-1,0,1} as int for discrete space, we might turn the space to {0,1,2}. For example, \"Buy AAPL with all the current capital\" or \"Sell all available AAPL\" are 2 or 0, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The surplus when selling stocks address reward for each deal and the capital gain at the end of each episode indicate total reward of the trading. To enforce the agent learn something, a punishment is applied at the begining of each step. Additionally, punishments also employ to keep the agent away from deciding unavailable buying and selling.\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# from stable_baselines3.common import logger\n",
    "\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        # stock_dim,\n",
    "        hmax,\n",
    "        initial_amount,\n",
    "        buy_cost_pct,\n",
    "        sell_cost_pct,\n",
    "        reward_scaling,\n",
    "        state_space,\n",
    "        action_space,\n",
    "        tech_indicator_list,\n",
    "        stop_loss,\n",
    "        punishment_rate,\n",
    "        make_plots=False,\n",
    "        print_verbosity=10,\n",
    "        row=0,\n",
    "        initial=True,\n",
    "        previous_state=[],\n",
    "        model_name=\"\",\n",
    "        mode=\"\",\n",
    "        iteration=\"\",\n",
    "    ):\n",
    "        # self.row = row\n",
    "        self.df = df\n",
    "        # self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.buy_cost_pct = buy_cost_pct\n",
    "        self.sell_cost_pct = sell_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        # self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.punishment_rate = punishment_rate\n",
    "        self.stop_loss = stop_loss # the game stops when the asset loses more than stop_loss percent\n",
    "        self.action_space = spaces.Discrete(3, start=0, seed=42)\n",
    "        # self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
    "        )\n",
    "        self.terminal = False\n",
    "        self.make_plots = make_plots\n",
    "        self.print_verbosity = print_verbosity\n",
    "        # self.turbulence_threshold = turbulence_threshold\n",
    "        # self.risk_indicator_col = risk_indicator_col\n",
    "        self.initial = initial\n",
    "        self.previous_state = previous_state\n",
    "        self.model_name = model_name\n",
    "        self.mode = mode\n",
    "        self.iteration = iteration\n",
    "        self.portfolio_columns = ['tic','price','buy_price','amount','weight']\n",
    "        self.tic_list = self.df.tic.unique()\n",
    "        self.original_df = self.df.copy()\n",
    "        self.row = 0\n",
    "        \n",
    "        # initalize state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.episode = 0\n",
    "        \n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        # self.reset()\n",
    "        self._seed()\n",
    "\n",
    "    def _buy_stock(self, action):\n",
    "        def _do_buy():\n",
    "            if self.data.close > 0: # Buy only if the price is > 0 (no missing data in this particular date)\n",
    "                # perform sell action based on the sign of the action\n",
    "                selected_row = self.portfolio[self.portfolio.tic == self.data.tic]\n",
    "\n",
    "                if (selected_row.empty) | (selected_row.amount.any() == 0):\n",
    "                    buy_amount = self.portfolio.loc[0].price * (1 - self.buy_cost_pct)\n",
    "                    buy_num_shares = int(abs(buy_amount/self.data.close))\n",
    "                    \n",
    "                    if selected_row.empty:\n",
    "                        selected_index = len(self.portfolio)\n",
    "                        selected_row = [self.data.tic,0,0,0,0]\n",
    "                    else:\n",
    "                        selected_index = selected_row.index[0]\n",
    "                        selected_row = self.portfolio.loc[selected_index]\n",
    "                        # selected_row[2] = (buy_num_shares*self.data.close + selected_row[2]*selected_row[3]) \\\n",
    "                        #                     /(buy_num_shares + selected_row[3]) # recompute buy_price\n",
    "\n",
    "                    # Update ticker in the portfolio\n",
    "                    selected_row[1] = self.data.close\n",
    "                    selected_row[2] = self.data.close\n",
    "                    selected_row[3] += buy_num_shares\n",
    "                    self.portfolio.loc[selected_index] = selected_row\n",
    "\n",
    "                    # Update remain capital\n",
    "                    capital_row = self.portfolio.loc[0]\n",
    "                    capital_change = buy_num_shares * self.data.close * (1 + self.buy_cost_pct)\n",
    "                    capital_row[1] -= capital_change\n",
    "                    capital_row[2] -= capital_change\n",
    "                    self.portfolio.loc[0] = capital_row\n",
    "                    \n",
    "                    self._compute_weight()\n",
    "                    self.cost += selected_row[1] * buy_num_shares * self.buy_cost_pct\n",
    "                    self.trades += 1\n",
    "\n",
    "                # Close short-sell position\n",
    "                elif selected_row.amount.any() < 0:\n",
    "                    buy_num_shares = abs(selected_row.amount)\n",
    "                    buy_amount = buy_num_shares * self.data.close * (1 + self.buy_cost_pct)\n",
    "                    \n",
    "                    # Update reward\n",
    "                    sell_amout = buy_num_shares * selected_row.buy_price\n",
    "                    self.reward += (sell_amount - buy_amount).values[0].item() * self.reward_scaling\n",
    "                    \n",
    "                    # Update ticker in the portfolio\n",
    "                    selected_index = selected_row.index[0]\n",
    "                    selected_row = self.portfolio.loc[selected_index]\n",
    "                    selected_row[1] = self.data.close\n",
    "                    selected_row[2] = self.data.close\n",
    "                    selected_row[3] = 0\n",
    "                    self.portfolio.loc[selected_index] = selected_row\n",
    "\n",
    "                    # Update remain capital\n",
    "                    capital_row = self.portfolio.loc[0]\n",
    "                    # capital_change = buy_num_shares * self.data.close * (1 + self.buy_cost_pct)\n",
    "                    capital_row[1] -= buy_amount\n",
    "                    capital_row[2] -= capital_change\n",
    "                    self.portfolio.loc[0] = capital_row\n",
    "                    \n",
    "                    self._compute_weight()\n",
    "                    self.cost += selected_row[1] * buy_num_shares * self.buy_cost_pct\n",
    "                    self.trades += 1\n",
    "                \n",
    "                else:           \n",
    "                    buy_num_shares = 0\n",
    "                    \n",
    "                    # Punish a certain amount of money if selling without avaiable stock in the inventory\n",
    "                    self.reward += -10 * self.initial_amount * self.punishment_rate * self.reward_scaling\n",
    "                    \n",
    "                \n",
    "                # buy_amount = self.portfolio.loc[0].price\n",
    "                # buy_num_shares = int(-abs(buy_amount/self.data.close))\n",
    "                # if buy_num_shares > 0:\n",
    "                #     if self.portfolio[self.portfolio.tic == self.data.tic].empty:\n",
    "                #         selected_index = len(self.portfolio)\n",
    "                #         selected_row = [self.data.tic,0,self.data.close,0,0]\n",
    "                #     else:\n",
    "                #         selected_index = self.portfolio[self.portfolio.tic == self.data.tic].index[0]\n",
    "                #         selected_row = self.portfolio.loc[selected_index]\n",
    "                #         selected_row[2] = (buy_num_shares*self.data.close + selected_row[2]*selected_row[3]) \\\n",
    "                #                             /(buy_num_shares + selected_row[3])\n",
    "                    \n",
    "                #     selected_row[1] = self.data.close\n",
    "                #     selected_row[3] += buy_num_shares\n",
    "                #     self.portfolio.loc[selected_index] = selected_row\n",
    "\n",
    "                #     # Update remain capital\n",
    "                #     capital_row = self.portfolio.loc[0]\n",
    "                #     capital_change = buy_num_shares * self.data.close * (1 + self.buy_cost_pct)\n",
    "                #     capital_row[1] -= capital_change\n",
    "                #     capital_row[2] -= capital_change\n",
    "                #     self.portfolio.loc[0] = capital_row\n",
    "                    \n",
    "                #     self._compute_weight()\n",
    "                #     self.cost += selected_row[1] * buy_num_shares * self.buy_cost_pct\n",
    "                #     self.trades += 1\n",
    "                \n",
    "                # else:\n",
    "                #     # Punish a certain amount of money if buying without avaiable capital\n",
    "                #     self.reward += -10 * self.initial_amount * self.punishment_rate * self.reward_scaling\n",
    "                #     # print(f'Set punishment for unavailable buying: {self.reward}')\n",
    "                    \n",
    "            else:\n",
    "                buy_num_shares = 0\n",
    "\n",
    "            return buy_num_shares\n",
    "\n",
    "        buy_num_shares = _do_buy()\n",
    "        return buy_num_shares\n",
    "    \n",
    "    def _sell_stock(self, action):\n",
    "        def _do_sell_normal():\n",
    "            # TODO: Punish a certain amount of money if selling without avaiable stock in the inventory\n",
    "            if self.data.close > 0: # Sell only if the price is > 0 (no missing data in this particular date)\n",
    "                # perform sell action based on the sign of the action\n",
    "                selected_row = self.portfolio[self.portfolio.tic == self.data.tic]\n",
    "                if (selected_row.amount.any() < 0):            \n",
    "                    sell_num_shares = 0\n",
    "                    \n",
    "                    # Punish a certain amount of money if selling without avaiable stock in the inventory\n",
    "                    self.reward += -10 * self.initial_amount * self.punishment_rate * self.reward_scaling\n",
    "\n",
    "                # In the case of short sell\n",
    "                elif (selected_row.empty) | (selected_row.amount.any() == 0):\n",
    "                    if selected_row.empty:\n",
    "                        selected_index = len(self.portfolio)\n",
    "                        selected_row = [self.data.tic,0,0,0,0]\n",
    "                    else:\n",
    "                        selected_index = selected_row.index[0]\n",
    "                        selected_row = self.portfolio.loc[selected_index]\n",
    "                    \n",
    "                    # The agent can sell an amount of stock equaling to the capital\n",
    "                    capital_row = self.portfolio.loc[0]\n",
    "                    sell_num_shares = int(abs(capital_row.price / self.data.close))\n",
    "                    sell_amount = self.data.close * sell_num_shares * (1 - self.sell_cost_pct)\n",
    "                    \n",
    "                    # update stock row in the portfolio\n",
    "                    # selected_index = selected_row.index[0]\n",
    "                    # selected_row = self.portfolio.loc[selected_index]\n",
    "                    selected_row[1] = self.data.close\n",
    "                    selected_row[2] = self.data.close\n",
    "                    selected_row[3] -= sell_num_shares\n",
    "\n",
    "                    # Update remain capital\n",
    "                    capital_row = self.portfolio.loc[0]\n",
    "                    capital_row[1] += sell_amount\n",
    "                    capital_row[2] += sell_amount\n",
    "\n",
    "                    # Update changes to portfolio\n",
    "                    self.portfolio.loc[selected_index] = selected_row\n",
    "                    self.portfolio.loc[0] = capital_row\n",
    "                    self._compute_weight()\n",
    "                    self.cost += selected_row[1] * sell_num_shares * self.sell_cost_pct\n",
    "                    self.trades += 1\n",
    "                \n",
    "                else:\n",
    "                    sell_num_shares = selected_row.iloc[0].amount\n",
    "                    sell_amount = self.data.close * sell_num_shares * (1 - self.sell_cost_pct)\n",
    "\n",
    "                    # Update reward\n",
    "                    buy_amount = selected_row.buy_price * sell_num_shares\n",
    "                    self.reward += (sell_amount - buy_amount).values[0].item() * self.reward_scaling\n",
    "                    \n",
    "                    # update stock row in the portfolio\n",
    "                    selected_index = selected_row.index[0]\n",
    "                    selected_row = self.portfolio.loc[selected_index]\n",
    "                    selected_row[1] = self.data.close\n",
    "                    selected_row[3] -= sell_num_shares\n",
    "\n",
    "                    # Update remain capital\n",
    "                    capital_row = self.portfolio.loc[0]\n",
    "                    capital_row[1] += sell_amount\n",
    "                    capital_row[2] += sell_amount\n",
    "\n",
    "                    # Update changes to portfolio\n",
    "                    self.portfolio.loc[selected_index] = selected_row\n",
    "                    self.portfolio.loc[0] = capital_row\n",
    "                    self._compute_weight()\n",
    "                    self.cost += selected_row[1] * sell_num_shares * self.sell_cost_pct\n",
    "                    self.trades += 1\n",
    "            else:\n",
    "                sell_num_shares = 0\n",
    "\n",
    "            return sell_num_shares\n",
    "\n",
    "        sell_num_shares = _do_sell_normal()\n",
    "        return sell_num_shares\n",
    "\n",
    "    def _compute_weight(self):\n",
    "        nav = sum(self.portfolio.price*self.portfolio.amount)\n",
    "        self.portfolio['weight'] = self.portfolio.apply(lambda x: x.price * x.amount / nav, axis=1)\n",
    "\n",
    "    def step(self, actions):\n",
    "\n",
    "        current_total_asset = sum(self.portfolio.price * self.portfolio.amount)\n",
    "        self.terminal = (self.row >= len(self.df.index.unique()) - 1) | (current_total_asset < self.initial_amount*(1-self.stop_loss))\n",
    "        # print(f'Step {self.row}, action: {actions}, reward: {self.reward}, Trade: {self.trades}')\n",
    "                \n",
    "        # --> IN CASE THE STEP IS THE TERMINATED STEP\n",
    "        if self.terminal: \n",
    "            print(f\"Episode: {self.episode}\")\n",
    "                \n",
    "            # Summary the training performance after an episode\n",
    "            end_total_asset = sum(self.portfolio.price*self.portfolio.amount)\n",
    "            tot_reward = end_total_asset - self.initial_amount\n",
    "\n",
    "            # Print out training results after a certain amount of episodes\n",
    "            if self.episode % self.print_verbosity == 0:\n",
    "                print(f\"Current company: {self.df.tic.unique()}\")\n",
    "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
    "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
    "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
    "                print(f\"total_cost: {self.cost:0.2f}\")\n",
    "                print(f\"total_trades: {self.trades}\")\n",
    "                # if df_total_value[\"daily_return\"].std() != 0:\n",
    "                #     print(f\"Sharpe: {sharpe:0.3f}\")\n",
    "                print(\"=================================\")\n",
    "            \n",
    "            truncated = False  # we do not limit the number of steps here\n",
    "            # Optionally we can pass additional info, we are not using that for now\n",
    "            info = {}\n",
    "\n",
    "\n",
    "            return (\n",
    "                np.array(self.state).astype(np.float32),\n",
    "                self.reward,\n",
    "                self.terminal,\n",
    "                truncated,\n",
    "                info,\n",
    "            )\n",
    "\n",
    "        # --> IN A NORMAL STEP\n",
    "        else: \n",
    "\n",
    "            # begin_total_asset = sum(self.portfolio.price * self.portfolio.amount)\n",
    "\n",
    "            # Set a punishment at each step to push the agent decide an action\n",
    "            self.reward += -1 * self.initial_amount * self.punishment_rate * self.reward_scaling\n",
    "            \n",
    "            action = actions - 1 # Turn from {0,1,2} action space to {-1,0,1}\n",
    "            if action > 0:\n",
    "                self._buy_stock(action)\n",
    "            elif action < 0:\n",
    "                self._sell_stock(action)\n",
    "\n",
    "            self.actions_memory.append(actions)\n",
    "\n",
    "            # Update selected row in the dataset based on state: s -> s+1\n",
    "            self.row += 1\n",
    "            self.data = self.df.loc[self.row]\n",
    "            self.state = self._update_state()\n",
    "    \n",
    "            end_total_asset = sum(self.portfolio.price * self.portfolio.amount)\n",
    "            # print(f'Begin asset: {begin_total_asset}, End asset: {end_total_asset}')\n",
    "\n",
    "            # Update asset memory\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            self.date_memory.append(self._get_date())\n",
    "\n",
    "            # Update reward\n",
    "            # if self.reward == 0:\n",
    "            #     self.reward = end_total_asset - self.initial_amount\n",
    "\n",
    "            if (self.row >= len(self.df.index.unique()) - 1):\n",
    "                self.reward += (end_total_asset - self.initial_amount)  * self.reward_scaling\n",
    "            \n",
    "            self.rewards_memory.append(self.reward)\n",
    "            # self.reward = self.reward * self.reward_scaling\n",
    "\n",
    "        truncated = False  # we do not limit the number of steps here\n",
    "        # Optionally we can pass additional info, we are not using that for now\n",
    "        info = {}\n",
    "        \n",
    "        # return self.state, self.reward, self.terminal, {}\n",
    "    \n",
    "        return (\n",
    "            np.array(self.state).astype(np.float32),\n",
    "            self.reward,\n",
    "            self.terminal,\n",
    "            truncated,\n",
    "            info,\n",
    "        )\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # initiate state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # Reset asset_memory\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "\n",
    "        # if self.initial:\n",
    "        #     self.asset_memory = [self.initial_amount]\n",
    "        # else:\n",
    "        #     previous_total_asset = sum(self.previous_port.price * self.previous_port.amount)\n",
    "        #     self.asset_memory = [previous_total_asset]\n",
    "\n",
    "        # Reset support variables\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        self.episode += 1\n",
    "\n",
    "        return np.array(self.state).astype(np.float32), {}\n",
    "        # return self.state\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return self.state\n",
    "\n",
    "    def _initiate_state(self):\n",
    "        \n",
    "        # Reset portfolio & previous_portfolio\n",
    "        self.portfolio = pd.DataFrame([['cap',self.initial_amount,self.initial_amount,1,1]])\n",
    "        self.portfolio.columns = self.portfolio_columns\n",
    "        \n",
    "        # if self.initial:\n",
    "        #     self.portfolio = pd.DataFrame([['cap',self.initial_amount,self.initial_amount,1,1]])\n",
    "        #     self.portfolio.columns = self.portfolio_columns\n",
    "        #     self.previous_port = self.portfolio.copy()\n",
    "        # else:\n",
    "        #     self.portfolio = self.previous_port.copy()\n",
    "\n",
    "        # Select a random ticker from df\n",
    "        self.df = self.original_df[self.original_df.tic == random.choice(self.tic_list)].reset_index(drop=True)\n",
    "        \n",
    "        # Reset data\n",
    "        self.reward = 0\n",
    "        self.row = 0\n",
    "        self.data = self.df.loc[self.row]\n",
    "        \n",
    "         # Reset state\n",
    "        state = self._update_state()\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def _update_state(self):\n",
    "\n",
    "        # if the stock appear in the portfolio already\n",
    "        if self.portfolio[self.portfolio.tic == self.data.tic].empty:\n",
    "            state = ([0] + [0] + sum([[self.data[tech]] for tech in self.tech_indicator_list], []))\n",
    "            \n",
    "        else:\n",
    "            # Update stock's prices in portfolio before updating state\n",
    "            selected_index = self.portfolio[self.portfolio.tic == self.data.tic].index[0]\n",
    "            selected_row = self.portfolio.loc[selected_index]\n",
    "            selected_row['price'] = self.data.close\n",
    "            self.portfolio.loc[selected_index] = selected_row\n",
    "            self._compute_weight()\n",
    "            selected_row = self.portfolio.loc[selected_index]\n",
    "            # print(\"Update portfolio at \",self.data.tic,\" price: \", self.data.close,\"; with weight: \", selected_row.weight)\n",
    "\n",
    "            if selected_row.amount > 0:\n",
    "                profit_ratio = selected_row.price/selected_row.buy_price-1\n",
    "            elif selected_row.amount < 0:\n",
    "                profit_ratio = 1 - selected_row.price/selected_row.buy_price\n",
    "            else:\n",
    "                profit_ratio = 0\n",
    "            \n",
    "            state = ([selected_row.amount] + [profit_ratio] + sum([[self.data[tech]] for tech in self.tech_indicator_list], []))\n",
    "            \n",
    "            # state = (\n",
    "            #         [self.portfolio.iloc[0].price]\n",
    "            #         + [(selected_row.buy_price/selected_row.price-1)]\n",
    "            #         + [self.data.close]\n",
    "            #         + [selected_row.amount]\n",
    "            #         + [selected_row.weight]\n",
    "            #         + sum([[self.data[tech]] for tech in self.tech_indicator_list], [])\n",
    "            #     )\n",
    "    \n",
    "        return state\n",
    "\n",
    "    def _get_date(self):\n",
    "        # return self.data.date\n",
    "        return self.row\n",
    "\n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        asset_list = self.asset_memory\n",
    "        # print(len(date_list))\n",
    "        # print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame(\n",
    "            {\"date\": date_list, \"account_value\": asset_list}\n",
    "        )\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        \n",
    "        date_list = self.date_memory[:-1]\n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3 Initialize Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State's space include stock_amount, current_return and the indicators decided in ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Dimension: 1, State Space: 19\n"
     ]
    }
   ],
   "source": [
    "ratio_list = train_data.columns.drop(['date','tic','close'])\n",
    "\n",
    "action_dimension = 1 # k float in range (-1,1) to decide sell (k<0) or buy (k>0) decisions\n",
    "state_space = 2 + len(ratio_list)\n",
    "print(f\"Action Dimension: {action_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "# Parameters for the environment\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"tech_indicator_list\": ratio_list, \n",
    "    \"action_space\": action_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"stop_loss\": 0.8,\n",
    "    \"print_verbosity\":4,\n",
    "    \"punishment_rate\": 0.0001\n",
    "}\n",
    "\n",
    "#Establish the training environment using StockTradingEnv() class\n",
    "e_train_gym = StockTradingEnv(df = train_data, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# If the environment don't follow the interface, an error will be thrown\n",
    "check_env(e_train_gym, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN, DDPG\n",
    "\n",
    "# Instantiate the env\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8.1'></a>\n",
    "#### If the training starts from the previous model, the section should **run all cells above** this line and then jump to [**Load trained model**](#7.2.1) to keep the traning going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.0000000e+00,  0.0000000e+00,  3.6317742e-01,  1.2199949e-01,\n",
      "        0.0000000e+00,  4.1426968e+01,  3.3053365e-01,  1.0000000e+01,\n",
      "        3.0619297e-03,  1.8752481e-01,  1.2105499e-01,  1.2626095e-01,\n",
      "        2.2095685e-01,  1.0486100e+00,  7.5133610e-01,  2.9430825e-01,\n",
      "        2.2095685e-01,  1.5422413e+08, -3.1022207e-09], dtype=float32), {})\n"
     ]
    }
   ],
   "source": [
    "# Get samples from train_data\n",
    "test_env_data = test_data\n",
    "# test_env_data = trade_data.iloc[:20]\n",
    "# test_env_data.close = [10,100,15,90,20,80,25,85,18,92,10,100,15,90,20,80,25,85,18,92]\n",
    "\n",
    "# Parameters for the environment\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"tech_indicator_list\": ratio_list, \n",
    "    \"action_space\": action_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"stop_loss\": 0.3,\n",
    "    \"print_verbosity\":4,\n",
    "    \"punishment_rate\": 0.0001\n",
    "}\n",
    "\n",
    "#Establish the training environment using StockTradingEnv() class\n",
    "test_train_gym = StockTradingEnv(df = test_env_data, **env_kwargs)\n",
    "\n",
    "# test reset state\n",
    "print(test_train_gym.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, action: 0, terminated: False, reward: -0.01, Trade: 1\n",
      "Step 2, action: 2, terminated: False, reward: -0.12000000000000001, Trade: 1\n",
      "Step 3, action: 1, terminated: False, reward: -0.13, Trade: 1\n",
      "Step 4, action: 1, terminated: False, reward: -0.14, Trade: 1\n",
      "Step 5, action: 1, terminated: False, reward: -0.15000000000000002, Trade: 1\n",
      "Step 6, action: 2, terminated: False, reward: -0.26, Trade: 1\n",
      "Step 7, action: 0, terminated: False, reward: -10.346805289224232, Trade: 2\n",
      "Step 8, action: 2, terminated: False, reward: -10.356805289224232, Trade: 3\n",
      "Step 9, action: 0, terminated: False, reward: -8.303205532189935, Trade: 4\n",
      "Step 10, action: 0, terminated: False, reward: -8.313205532189935, Trade: 5\n",
      "Step 11, action: 1, terminated: False, reward: -8.323205532189935, Trade: 5\n",
      "Step 12, action: 2, terminated: False, reward: -8.433205532189934, Trade: 5\n",
      "Step 13, action: 2, terminated: False, reward: -8.543205532189933, Trade: 5\n",
      "Step 14, action: 2, terminated: False, reward: -8.653205532189933, Trade: 5\n",
      "Step 15, action: 2, terminated: False, reward: -8.763205532189932, Trade: 5\n",
      "Step 16, action: 2, terminated: False, reward: -8.873205532189932, Trade: 5\n",
      "Step 17, action: 1, terminated: False, reward: -8.883205532189931, Trade: 5\n",
      "Step 18, action: 0, terminated: False, reward: -5.74446835361175, Trade: 6\n",
      "Step 19, action: 2, terminated: False, reward: -5.75446835361175, Trade: 7\n",
      "Step 20, action: 1, terminated: False, reward: -5.76446835361175, Trade: 7\n",
      "Step 21, action: 1, terminated: False, reward: -5.774468353611749, Trade: 7\n",
      "Step 22, action: 1, terminated: False, reward: -5.784468353611749, Trade: 7\n",
      "Step 23, action: 0, terminated: False, reward: -1.6672498463790806, Trade: 8\n",
      "Step 24, action: 2, terminated: False, reward: -1.6772498463790806, Trade: 9\n",
      "Step 25, action: 2, terminated: False, reward: -1.7872498463790807, Trade: 9\n",
      "Step 26, action: 1, terminated: False, reward: -1.7972498463790807, Trade: 9\n",
      "Step 27, action: 1, terminated: False, reward: -1.8072498463790807, Trade: 9\n",
      "Step 28, action: 2, terminated: False, reward: -1.9172498463790808, Trade: 9\n",
      "Step 29, action: 1, terminated: False, reward: -1.9272498463790808, Trade: 9\n",
      "Step 30, action: 1, terminated: False, reward: -1.9372498463790808, Trade: 9\n",
      "Step 31, action: 1, terminated: False, reward: -1.9472498463790808, Trade: 9\n",
      "Step 32, action: 0, terminated: False, reward: 5.7749972477111795, Trade: 10\n",
      "Step 33, action: 0, terminated: False, reward: 5.76499724771118, Trade: 11\n",
      "Step 34, action: 1, terminated: False, reward: 5.75499724771118, Trade: 11\n",
      "Step 35, action: 2, terminated: False, reward: 5.6449972477111805, Trade: 11\n",
      "Step 36, action: 0, terminated: False, reward: -2.600130831147001, Trade: 12\n",
      "Step 37, action: 2, terminated: False, reward: -2.610130831147001, Trade: 13\n",
      "Step 38, action: 2, terminated: False, reward: -2.7201308311470007, Trade: 13\n",
      "Step 39, action: 0, terminated: False, reward: -3.1153912307014493, Trade: 14\n",
      "Step 40, action: 1, terminated: False, reward: -3.125391230701449, Trade: 14\n",
      "Step 41, action: 0, terminated: False, reward: -3.135391230701449, Trade: 15\n",
      "Step 42, action: 2, terminated: False, reward: -3.2453912307014487, Trade: 15\n",
      "Step 43, action: 2, terminated: False, reward: -3.3553912307014486, Trade: 15\n",
      "Step 44, action: 1, terminated: False, reward: -3.3653912307014484, Trade: 15\n",
      "Step 45, action: 0, terminated: False, reward: -8.845381171796427, Trade: 16\n",
      "Step 46, action: 2, terminated: False, reward: -8.855381171796427, Trade: 17\n",
      "Step 47, action: 1, terminated: False, reward: -8.865381171796427, Trade: 17\n",
      "Step 48, action: 2, terminated: False, reward: -8.975381171796426, Trade: 17\n",
      "Step 49, action: 2, terminated: False, reward: -9.085381171796426, Trade: 17\n",
      "Step 50, action: 2, terminated: False, reward: -9.195381171796425, Trade: 17\n",
      "Step 51, action: 2, terminated: False, reward: -9.305381171796425, Trade: 17\n",
      "Step 52, action: 0, terminated: False, reward: -15.39236457118455, Trade: 18\n",
      "Step 53, action: 1, terminated: False, reward: -15.402364571184549, Trade: 18\n",
      "Step 54, action: 1, terminated: False, reward: -15.412364571184549, Trade: 18\n",
      "Step 55, action: 1, terminated: False, reward: -15.422364571184549, Trade: 18\n",
      "Step 56, action: 0, terminated: False, reward: -15.432364571184548, Trade: 19\n",
      "Step 57, action: 1, terminated: False, reward: -15.442364571184548, Trade: 19\n",
      "Step 58, action: 0, terminated: False, reward: -17.646348518225864, Trade: 20\n",
      "Step 59, action: 2, terminated: False, reward: -17.656348518225865, Trade: 21\n",
      "Step 60, action: 2, terminated: False, reward: -17.76634851822587, Trade: 21\n",
      "Step 61, action: 2, terminated: False, reward: -17.87634851822587, Trade: 21\n",
      "Step 62, action: 2, terminated: False, reward: -17.986348518225874, Trade: 21\n",
      "Step 63, action: 1, terminated: False, reward: -17.996348518225876, Trade: 21\n",
      "Step 64, action: 2, terminated: False, reward: -18.10634851822588, Trade: 21\n",
      "Step 65, action: 1, terminated: False, reward: -18.11634851822588, Trade: 21\n",
      "Step 66, action: 0, terminated: False, reward: -21.255947522184012, Trade: 22\n",
      "Step 67, action: 2, terminated: False, reward: -21.265947522184014, Trade: 23\n",
      "Step 68, action: 1, terminated: False, reward: -21.275947522184016, Trade: 23\n",
      "Step 69, action: 0, terminated: False, reward: -21.896886906522404, Trade: 24\n",
      "Step 70, action: 1, terminated: False, reward: -21.906886906522406, Trade: 24\n",
      "Step 71, action: 2, terminated: False, reward: -21.916886906522407, Trade: 25\n",
      "Step 72, action: 0, terminated: False, reward: -22.360674226444285, Trade: 26\n",
      "Step 73, action: 1, terminated: False, reward: -22.370674226444287, Trade: 26\n",
      "Step 74, action: 0, terminated: False, reward: -22.380674226444288, Trade: 27\n",
      "Step 75, action: 2, terminated: False, reward: -22.49067422644429, Trade: 27\n",
      "Step 76, action: 1, terminated: False, reward: -22.500674226444293, Trade: 27\n",
      "Step 77, action: 0, terminated: False, reward: -22.60331896718221, Trade: 28\n",
      "Step 78, action: 0, terminated: False, reward: -22.613318967182213, Trade: 29\n",
      "Step 79, action: 1, terminated: False, reward: -22.623318967182215, Trade: 29\n",
      "Step 80, action: 2, terminated: False, reward: -22.733318967182218, Trade: 29\n",
      "Step 81, action: 2, terminated: False, reward: -22.84331896718222, Trade: 29\n",
      "Step 82, action: 1, terminated: False, reward: -22.853318967182222, Trade: 29\n",
      "Step 83, action: 0, terminated: False, reward: -25.904808440206967, Trade: 30\n",
      "Step 84, action: 2, terminated: False, reward: -25.91480844020697, Trade: 31\n",
      "Step 85, action: 1, terminated: False, reward: -25.92480844020697, Trade: 31\n",
      "Step 86, action: 2, terminated: False, reward: -26.034808440206973, Trade: 31\n",
      "Step 87, action: 0, terminated: False, reward: -23.327274952089002, Trade: 32\n",
      "Step 88, action: 0, terminated: False, reward: -23.337274952089004, Trade: 33\n",
      "Step 89, action: 2, terminated: False, reward: -23.447274952089007, Trade: 33\n",
      "Step 90, action: 2, terminated: False, reward: -23.55727495208901, Trade: 33\n",
      "Step 91, action: 1, terminated: False, reward: -23.56727495208901, Trade: 33\n",
      "Step 92, action: 2, terminated: False, reward: -23.677274952089014, Trade: 33\n",
      "Step 93, action: 2, terminated: False, reward: -23.787274952089017, Trade: 33\n",
      "Step 94, action: 1, terminated: False, reward: -23.79727495208902, Trade: 33\n",
      "Step 95, action: 2, terminated: False, reward: -23.907274952089022, Trade: 33\n",
      "Step 96, action: 0, terminated: False, reward: -20.440116719703767, Trade: 34\n",
      "Step 97, action: 0, terminated: False, reward: -20.450116719703768, Trade: 35\n",
      "Step 98, action: 2, terminated: False, reward: -20.56011671970377, Trade: 35\n",
      "Step 99, action: 1, terminated: False, reward: -20.570116719703773, Trade: 35\n",
      "Step 100, action: 0, terminated: False, reward: -20.49811036485377, Trade: 36\n",
      "Step 101, action: 2, terminated: False, reward: -20.50811036485377, Trade: 37\n",
      "Step 102, action: 0, terminated: False, reward: -19.980309957444092, Trade: 38\n",
      "Step 103, action: 2, terminated: False, reward: -19.990309957444094, Trade: 39\n",
      "Step 104, action: 0, terminated: False, reward: -18.979288673144612, Trade: 40\n",
      "Step 105, action: 2, terminated: False, reward: -18.989288673144614, Trade: 41\n",
      "Step 106, action: 2, terminated: False, reward: -19.099288673144617, Trade: 41\n",
      "Step 107, action: 2, terminated: False, reward: -19.20928867314462, Trade: 41\n",
      "Step 108, action: 1, terminated: False, reward: -19.21928867314462, Trade: 41\n",
      "Step 109, action: 1, terminated: False, reward: -19.229288673144623, Trade: 41\n",
      "Step 110, action: 2, terminated: False, reward: -19.339288673144626, Trade: 41\n",
      "Step 111, action: 0, terminated: False, reward: -19.185060940942485, Trade: 42\n",
      "Step 112, action: 2, terminated: False, reward: -19.195060940942486, Trade: 43\n",
      "Step 113, action: 1, terminated: False, reward: -19.205060940942488, Trade: 43\n",
      "Step 114, action: 1, terminated: False, reward: -19.21506094094249, Trade: 43\n",
      "Step 115, action: 1, terminated: False, reward: -19.22506094094249, Trade: 43\n",
      "Step 116, action: 1, terminated: False, reward: -19.235060940942493, Trade: 43\n",
      "Step 117, action: 0, terminated: False, reward: -20.80992746735698, Trade: 44\n",
      "Step 118, action: 0, terminated: False, reward: -20.819927467356983, Trade: 45\n",
      "Step 119, action: 0, terminated: False, reward: -20.648211474412648, Trade: 46\n",
      "Step 120, action: 0, terminated: False, reward: -20.65821147441265, Trade: 47\n",
      "Step 121, action: 1, terminated: False, reward: -20.66821147441265, Trade: 47\n",
      "Step 122, action: 2, terminated: False, reward: -20.778211474412654, Trade: 47\n",
      "Step 123, action: 1, terminated: False, reward: -20.788211474412655, Trade: 47\n",
      "Step 124, action: 1, terminated: False, reward: -20.798211474412657, Trade: 47\n",
      "Step 125, action: 2, terminated: False, reward: -20.90821147441266, Trade: 47\n",
      "Step 126, action: 1, terminated: False, reward: -20.91821147441266, Trade: 47\n",
      "Step 127, action: 0, terminated: False, reward: -18.43996563494808, Trade: 48\n",
      "Step 128, action: 2, terminated: False, reward: -18.449965634948082, Trade: 49\n",
      "Step 129, action: 1, terminated: False, reward: -18.459965634948084, Trade: 49\n",
      "Step 130, action: 1, terminated: False, reward: -18.469965634948085, Trade: 49\n",
      "Step 131, action: 1, terminated: False, reward: -18.479965634948087, Trade: 49\n",
      "Step 132, action: 1, terminated: False, reward: -18.48996563494809, Trade: 49\n",
      "Step 133, action: 0, terminated: False, reward: -19.369234502657427, Trade: 50\n",
      "Step 134, action: 1, terminated: False, reward: -19.37923450265743, Trade: 50\n",
      "Step 135, action: 2, terminated: False, reward: -19.38923450265743, Trade: 51\n",
      "Step 136, action: 0, terminated: False, reward: -21.727193733634298, Trade: 52\n",
      "Step 137, action: 1, terminated: False, reward: -21.7371937336343, Trade: 52\n",
      "Step 138, action: 0, terminated: False, reward: -21.7471937336343, Trade: 53\n",
      "Step 139, action: 1, terminated: False, reward: -21.757193733634303, Trade: 53\n",
      "Step 140, action: 1, terminated: False, reward: -21.767193733634304, Trade: 53\n",
      "Step 141, action: 2, terminated: False, reward: -21.877193733634307, Trade: 53\n",
      "Step 142, action: 0, terminated: False, reward: -22.446421006302767, Trade: 54\n",
      "Step 143, action: 0, terminated: False, reward: -22.45642100630277, Trade: 55\n",
      "Step 144, action: 1, terminated: False, reward: -22.46642100630277, Trade: 55\n",
      "Step 145, action: 2, terminated: False, reward: -22.576421006302773, Trade: 55\n",
      "Step 146, action: 2, terminated: False, reward: -22.686421006302776, Trade: 55\n",
      "Step 147, action: 0, terminated: False, reward: -23.742399969391766, Trade: 56\n",
      "Step 148, action: 0, terminated: False, reward: -23.752399969391767, Trade: 57\n",
      "Step 149, action: 2, terminated: False, reward: -23.86239996939177, Trade: 57\n",
      "Step 150, action: 0, terminated: False, reward: -25.094841254096366, Trade: 58\n",
      "Step 151, action: 2, terminated: False, reward: -25.104841254096367, Trade: 59\n",
      "Step 152, action: 0, terminated: False, reward: -23.773416278862147, Trade: 60\n",
      "Step 153, action: 2, terminated: False, reward: -23.78341627886215, Trade: 61\n",
      "Step 154, action: 0, terminated: False, reward: -24.033826749963534, Trade: 62\n",
      "Step 155, action: 1, terminated: False, reward: -24.043826749963536, Trade: 62\n",
      "Step 156, action: 1, terminated: False, reward: -24.053826749963537, Trade: 62\n",
      "Step 157, action: 0, terminated: False, reward: -24.06382674996354, Trade: 63\n",
      "Step 158, action: 1, terminated: False, reward: -24.07382674996354, Trade: 63\n",
      "Step 159, action: 1, terminated: False, reward: -24.083826749963542, Trade: 63\n",
      "Step 160, action: 2, terminated: False, reward: -24.193826749963545, Trade: 63\n",
      "Step 161, action: 2, terminated: False, reward: -24.303826749963548, Trade: 63\n",
      "Step 162, action: 1, terminated: False, reward: -24.31382674996355, Trade: 63\n",
      "Step 163, action: 1, terminated: False, reward: -24.32382674996355, Trade: 63\n",
      "Step 164, action: 1, terminated: False, reward: -24.333826749963553, Trade: 63\n",
      "Step 165, action: 1, terminated: False, reward: -24.343826749963554, Trade: 63\n",
      "Step 166, action: 2, terminated: False, reward: -24.453826749963557, Trade: 63\n",
      "Step 167, action: 0, terminated: False, reward: -22.308535288263137, Trade: 64\n",
      "Step 168, action: 0, terminated: False, reward: -22.31853528826314, Trade: 65\n",
      "Step 169, action: 1, terminated: False, reward: -22.32853528826314, Trade: 65\n",
      "Step 170, action: 0, terminated: False, reward: -23.761164288537802, Trade: 66\n",
      "Step 171, action: 0, terminated: False, reward: -23.771164288537804, Trade: 67\n",
      "Step 172, action: 0, terminated: False, reward: -23.15403158092672, Trade: 68\n",
      "Step 173, action: 2, terminated: False, reward: -23.16403158092672, Trade: 69\n",
      "Step 174, action: 2, terminated: False, reward: -23.274031580926724, Trade: 69\n",
      "Step 175, action: 2, terminated: False, reward: -23.384031580926727, Trade: 69\n",
      "Step 176, action: 1, terminated: False, reward: -23.39403158092673, Trade: 69\n",
      "Step 177, action: 2, terminated: False, reward: -23.504031580926732, Trade: 69\n",
      "Step 178, action: 0, terminated: False, reward: -22.496519698330143, Trade: 70\n",
      "Step 179, action: 2, terminated: False, reward: -22.506519698330145, Trade: 71\n",
      "Step 180, action: 1, terminated: False, reward: -22.516519698330146, Trade: 71\n",
      "Step 181, action: 2, terminated: False, reward: -22.62651969833015, Trade: 71\n",
      "Step 182, action: 0, terminated: False, reward: -21.983030109280623, Trade: 72\n",
      "Step 183, action: 1, terminated: False, reward: -21.993030109280625, Trade: 72\n",
      "Step 184, action: 2, terminated: False, reward: -22.003030109280626, Trade: 73\n",
      "Step 185, action: 1, terminated: False, reward: -22.013030109280628, Trade: 73\n",
      "Step 186, action: 1, terminated: False, reward: -22.02303010928063, Trade: 73\n",
      "Step 187, action: 0, terminated: False, reward: -19.90769205610757, Trade: 74\n",
      "Step 188, action: 1, terminated: False, reward: -19.917692056107573, Trade: 74\n",
      "Step 189, action: 0, terminated: False, reward: -19.927692056107574, Trade: 75\n",
      "Step 190, action: 0, terminated: False, reward: -20.166083156380694, Trade: 76\n",
      "Step 191, action: 2, terminated: False, reward: -20.176083156380695, Trade: 77\n",
      "Step 192, action: 1, terminated: False, reward: -20.186083156380697, Trade: 77\n",
      "Step 193, action: 1, terminated: False, reward: -20.1960831563807, Trade: 77\n",
      "Step 194, action: 1, terminated: False, reward: -20.2060831563807, Trade: 77\n",
      "Step 195, action: 2, terminated: False, reward: -20.316083156380703, Trade: 77\n",
      "Step 196, action: 0, terminated: False, reward: -19.3972631100947, Trade: 78\n",
      "Step 197, action: 1, terminated: False, reward: -19.4072631100947, Trade: 78\n",
      "Step 198, action: 0, terminated: False, reward: -19.4172631100947, Trade: 79\n",
      "Step 199, action: 1, terminated: False, reward: -19.427263110094703, Trade: 79\n",
      "Step 200, action: 2, terminated: False, reward: -19.537263110094706, Trade: 79\n",
      "Step 201, action: 1, terminated: False, reward: -19.547263110094708, Trade: 79\n",
      "Step 202, action: 2, terminated: False, reward: -19.65726311009471, Trade: 79\n",
      "Step 203, action: 1, terminated: False, reward: -19.667263110094712, Trade: 79\n",
      "Step 204, action: 2, terminated: False, reward: -19.777263110094715, Trade: 79\n",
      "Step 205, action: 1, terminated: False, reward: -19.787263110094717, Trade: 79\n",
      "Step 206, action: 0, terminated: False, reward: -23.79580939602611, Trade: 80\n",
      "Step 207, action: 2, terminated: False, reward: -23.805809396026113, Trade: 81\n",
      "Step 208, action: 2, terminated: False, reward: -23.915809396026116, Trade: 81\n",
      "Step 209, action: 0, terminated: False, reward: -22.28231190181685, Trade: 82\n",
      "Step 210, action: 2, terminated: False, reward: -22.292311901816852, Trade: 83\n",
      "Step 211, action: 0, terminated: False, reward: -22.88112637114136, Trade: 84\n",
      "Step 212, action: 2, terminated: False, reward: -22.89112637114136, Trade: 85\n",
      "Step 213, action: 2, terminated: False, reward: -23.001126371141364, Trade: 85\n",
      "Step 214, action: 1, terminated: False, reward: -23.011126371141366, Trade: 85\n",
      "Step 215, action: 2, terminated: False, reward: -23.12112637114137, Trade: 85\n",
      "Step 216, action: 0, terminated: False, reward: -21.076370915672623, Trade: 86\n",
      "Step 217, action: 0, terminated: False, reward: -21.086370915672624, Trade: 87\n",
      "Step 218, action: 0, terminated: False, reward: -21.020764066466086, Trade: 88\n",
      "Step 219, action: 1, terminated: False, reward: -21.030764066466087, Trade: 88\n",
      "Step 220, action: 2, terminated: False, reward: -21.04076406646609, Trade: 89\n",
      "Step 221, action: 0, terminated: False, reward: -20.807973576201203, Trade: 90\n",
      "Step 222, action: 1, terminated: False, reward: -20.817973576201204, Trade: 90\n",
      "Step 223, action: 2, terminated: False, reward: -20.827973576201206, Trade: 91\n",
      "Step 224, action: 0, terminated: False, reward: -22.759277301820717, Trade: 92\n",
      "Step 225, action: 2, terminated: False, reward: -22.76927730182072, Trade: 93\n",
      "Step 226, action: 0, terminated: False, reward: -21.164156862990144, Trade: 94\n",
      "Step 227, action: 2, terminated: False, reward: -21.174156862990145, Trade: 95\n",
      "Step 228, action: 1, terminated: False, reward: -21.184156862990147, Trade: 95\n",
      "Step 229, action: 1, terminated: False, reward: -21.19415686299015, Trade: 95\n",
      "Step 230, action: 0, terminated: False, reward: -24.3228939442615, Trade: 96\n",
      "Step 231, action: 1, terminated: False, reward: -24.332893944261503, Trade: 96\n",
      "Step 232, action: 2, terminated: False, reward: -24.342893944261505, Trade: 97\n",
      "Step 233, action: 0, terminated: False, reward: -24.934090971461814, Trade: 98\n",
      "Step 234, action: 2, terminated: False, reward: -24.944090971461815, Trade: 99\n",
      "Step 235, action: 1, terminated: False, reward: -24.954090971461817, Trade: 99\n",
      "Step 236, action: 2, terminated: False, reward: -25.06409097146182, Trade: 99\n",
      "Step 237, action: 1, terminated: False, reward: -25.07409097146182, Trade: 99\n",
      "Step 238, action: 1, terminated: False, reward: -25.084090971461823, Trade: 99\n",
      "Step 239, action: 0, terminated: False, reward: -25.388897934309707, Trade: 100\n",
      "Step 240, action: 1, terminated: False, reward: -25.39889793430971, Trade: 100\n",
      "Step 241, action: 0, terminated: False, reward: -25.40889793430971, Trade: 101\n",
      "Step 242, action: 1, terminated: False, reward: -25.41889793430971, Trade: 101\n",
      "Step 243, action: 0, terminated: False, reward: -24.023919359556892, Trade: 102\n",
      "Step 244, action: 1, terminated: False, reward: -24.033919359556894, Trade: 102\n",
      "Step 245, action: 1, terminated: False, reward: -24.043919359556895, Trade: 102\n",
      "Step 246, action: 0, terminated: False, reward: -24.053919359556897, Trade: 103\n",
      "Step 247, action: 2, terminated: False, reward: -24.1639193595569, Trade: 103\n",
      "Step 248, action: 1, terminated: False, reward: -24.1739193595569, Trade: 103\n",
      "Step 249, action: 2, terminated: False, reward: -24.283919359556904, Trade: 103\n",
      "Step 250, action: 0, terminated: False, reward: -25.460911149783648, Trade: 104\n",
      "Step 251, action: 0, terminated: False, reward: -25.47091114978365, Trade: 105\n",
      "Step 252, action: 1, terminated: False, reward: -25.48091114978365, Trade: 105\n",
      "Step 253, action: 0, terminated: False, reward: -26.632729652877373, Trade: 106\n",
      "Step 254, action: 0, terminated: False, reward: -26.642729652877374, Trade: 107\n",
      "Step 255, action: 1, terminated: False, reward: -26.652729652877376, Trade: 107\n",
      "Step 256, action: 0, terminated: False, reward: -27.747165876897768, Trade: 108\n",
      "Step 257, action: 2, terminated: False, reward: -27.75716587689777, Trade: 109\n",
      "Step 258, action: 0, terminated: False, reward: -27.79454775069308, Trade: 110\n",
      "Step 259, action: 0, terminated: False, reward: -27.804547750693082, Trade: 111\n",
      "Step 260, action: 1, terminated: False, reward: -27.814547750693084, Trade: 111\n",
      "Step 261, action: 2, terminated: False, reward: -27.924547750693087, Trade: 111\n",
      "Step 262, action: 0, terminated: False, reward: -28.445167656519665, Trade: 112\n",
      "Step 263, action: 0, terminated: False, reward: -28.455167656519667, Trade: 113\n",
      "Step 264, action: 2, terminated: False, reward: -28.56516765651967, Trade: 113\n",
      "Step 265, action: 2, terminated: False, reward: -28.675167656519672, Trade: 113\n",
      "Step 266, action: 1, terminated: False, reward: -28.685167656519674, Trade: 113\n",
      "Step 267, action: 1, terminated: False, reward: -28.695167656519676, Trade: 113\n",
      "Step 268, action: 1, terminated: False, reward: -28.705167656519677, Trade: 113\n",
      "Step 269, action: 1, terminated: False, reward: -28.71516765651968, Trade: 113\n",
      "Step 270, action: 1, terminated: False, reward: -28.72516765651968, Trade: 113\n",
      "Step 271, action: 0, terminated: False, reward: -29.375130301441565, Trade: 114\n",
      "Step 272, action: 0, terminated: False, reward: -29.385130301441567, Trade: 115\n",
      "Step 273, action: 0, terminated: False, reward: -31.28367436395376, Trade: 116\n",
      "Step 274, action: 2, terminated: False, reward: -31.293674363953762, Trade: 117\n",
      "Step 275, action: 1, terminated: False, reward: -31.303674363953764, Trade: 117\n",
      "Step 276, action: 1, terminated: False, reward: -31.313674363953766, Trade: 117\n",
      "Step 277, action: 1, terminated: False, reward: -31.323674363953767, Trade: 117\n",
      "Step 278, action: 2, terminated: False, reward: -31.43367436395377, Trade: 117\n",
      "Step 279, action: 0, terminated: False, reward: -30.24231655807608, Trade: 118\n",
      "Step 280, action: 0, terminated: False, reward: -30.25231655807608, Trade: 119\n",
      "Step 281, action: 0, terminated: False, reward: -31.688780862660582, Trade: 120\n",
      "Step 282, action: 1, terminated: False, reward: -31.698780862660584, Trade: 120\n",
      "Step 283, action: 2, terminated: False, reward: -31.708780862660586, Trade: 121\n",
      "Step 284, action: 1, terminated: False, reward: -31.718780862660587, Trade: 121\n",
      "Step 285, action: 1, terminated: False, reward: -31.72878086266059, Trade: 121\n",
      "Step 286, action: 2, terminated: False, reward: -31.83878086266059, Trade: 121\n",
      "Step 287, action: 0, terminated: False, reward: -32.91991927563589, Trade: 122\n",
      "Step 288, action: 1, terminated: False, reward: -32.92991927563589, Trade: 122\n",
      "Step 289, action: 1, terminated: False, reward: -32.93991927563589, Trade: 122\n",
      "Step 290, action: 1, terminated: False, reward: -32.949919275635885, Trade: 122\n",
      "Step 291, action: 2, terminated: False, reward: -32.95991927563588, Trade: 123\n",
      "Step 292, action: 0, terminated: False, reward: -30.22193453193165, Trade: 124\n",
      "Step 293, action: 2, terminated: False, reward: -30.231934531931653, Trade: 125\n",
      "Step 294, action: 0, terminated: False, reward: -29.321988576021923, Trade: 126\n",
      "Step 295, action: 1, terminated: False, reward: -29.331988576021924, Trade: 126\n",
      "Step 296, action: 1, terminated: False, reward: -29.341988576021926, Trade: 126\n",
      "Step 297, action: 2, terminated: False, reward: -29.351988576021927, Trade: 127\n",
      "Step 298, action: 1, terminated: False, reward: -29.36198857602193, Trade: 127\n",
      "Step 299, action: 0, terminated: False, reward: -29.31986828206136, Trade: 128\n",
      "Step 300, action: 0, terminated: False, reward: -29.329868282061362, Trade: 129\n",
      "Step 301, action: 1, terminated: False, reward: -29.339868282061364, Trade: 129\n",
      "Step 302, action: 2, terminated: False, reward: -29.449868282061367, Trade: 129\n",
      "Step 303, action: 0, terminated: False, reward: -23.632168099836335, Trade: 130\n",
      "Step 304, action: 2, terminated: False, reward: -23.642168099836336, Trade: 131\n",
      "Step 305, action: 1, terminated: False, reward: -23.652168099836338, Trade: 131\n",
      "Step 306, action: 0, terminated: False, reward: -21.642923789106355, Trade: 132\n",
      "Step 307, action: 0, terminated: False, reward: -21.652923789106357, Trade: 133\n",
      "Step 308, action: 1, terminated: False, reward: -21.662923789106358, Trade: 133\n",
      "Step 309, action: 0, terminated: False, reward: -22.698032375548923, Trade: 134\n",
      "Step 310, action: 0, terminated: False, reward: -22.708032375548925, Trade: 135\n",
      "Step 311, action: 1, terminated: False, reward: -22.718032375548926, Trade: 135\n",
      "Step 312, action: 2, terminated: False, reward: -22.82803237554893, Trade: 135\n",
      "Step 313, action: 0, terminated: False, reward: -20.921845121444317, Trade: 136\n",
      "Step 314, action: 0, terminated: False, reward: -20.93184512144432, Trade: 137\n",
      "Step 315, action: 0, terminated: False, reward: -21.566929394512556, Trade: 138\n",
      "Step 316, action: 1, terminated: False, reward: -21.576929394512558, Trade: 138\n",
      "Step 317, action: 2, terminated: False, reward: -21.58692939451256, Trade: 139\n",
      "Step 318, action: 2, terminated: False, reward: -21.696929394512562, Trade: 139\n",
      "Step 319, action: 2, terminated: False, reward: -21.806929394512565, Trade: 139\n",
      "Step 320, action: 2, terminated: False, reward: -21.916929394512568, Trade: 139\n",
      "Step 321, action: 0, terminated: False, reward: -20.902701321000308, Trade: 140\n",
      "Step 322, action: 0, terminated: False, reward: -20.91270132100031, Trade: 141\n",
      "Step 323, action: 1, terminated: False, reward: -20.92270132100031, Trade: 141\n",
      "Step 324, action: 2, terminated: False, reward: -21.032701321000314, Trade: 141\n",
      "Step 325, action: 2, terminated: False, reward: -21.142701321000317, Trade: 141\n",
      "Step 326, action: 0, terminated: False, reward: -22.45741454929469, Trade: 142\n",
      "Step 327, action: 0, terminated: False, reward: -22.46741454929469, Trade: 143\n",
      "Step 328, action: 0, terminated: False, reward: -18.62640043326686, Trade: 144\n",
      "Step 329, action: 0, terminated: False, reward: -18.63640043326686, Trade: 145\n",
      "Step 330, action: 1, terminated: False, reward: -18.646400433266862, Trade: 145\n",
      "Step 331, action: 1, terminated: False, reward: -18.656400433266864, Trade: 145\n",
      "Step 332, action: 1, terminated: False, reward: -18.666400433266865, Trade: 145\n",
      "Step 333, action: 0, terminated: False, reward: -19.037296462868916, Trade: 146\n",
      "Step 334, action: 2, terminated: False, reward: -19.047296462868918, Trade: 147\n",
      "Step 335, action: 1, terminated: False, reward: -19.05729646286892, Trade: 147\n",
      "Step 336, action: 2, terminated: False, reward: -19.167296462868922, Trade: 147\n",
      "Step 337, action: 2, terminated: False, reward: -19.277296462868925, Trade: 147\n",
      "Step 338, action: 0, terminated: False, reward: -14.167586093545196, Trade: 148\n",
      "Step 339, action: 0, terminated: False, reward: -14.177586093545196, Trade: 149\n",
      "Step 340, action: 2, terminated: False, reward: -14.287586093545196, Trade: 149\n",
      "Step 341, action: 1, terminated: False, reward: -14.297586093545195, Trade: 149\n",
      "Step 342, action: 0, terminated: False, reward: -10.240916427770655, Trade: 150\n",
      "Step 343, action: 1, terminated: False, reward: -10.250916427770655, Trade: 150\n",
      "Step 344, action: 1, terminated: False, reward: -10.260916427770654, Trade: 150\n",
      "Step 345, action: 2, terminated: False, reward: -10.270916427770654, Trade: 151\n",
      "Step 346, action: 0, terminated: False, reward: -9.82068221588711, Trade: 152\n",
      "Step 347, action: 2, terminated: False, reward: -9.83068221588711, Trade: 153\n",
      "Step 348, action: 2, terminated: False, reward: -9.94068221588711, Trade: 153\n",
      "Step 349, action: 0, terminated: False, reward: -10.179924351568264, Trade: 154\n",
      "Step 350, action: 0, terminated: False, reward: -10.189924351568264, Trade: 155\n",
      "Step 351, action: 1, terminated: False, reward: -10.199924351568264, Trade: 155\n",
      "Step 352, action: 0, terminated: False, reward: -12.138953436529205, Trade: 156\n",
      "Step 353, action: 0, terminated: False, reward: -12.148953436529204, Trade: 157\n",
      "Step 354, action: 1, terminated: False, reward: -12.158953436529204, Trade: 157\n",
      "Step 355, action: 2, terminated: False, reward: -12.268953436529204, Trade: 157\n",
      "Step 356, action: 2, terminated: False, reward: -12.378953436529203, Trade: 157\n",
      "Step 357, action: 0, terminated: False, reward: -11.988886168218658, Trade: 158\n",
      "Step 358, action: 2, terminated: False, reward: -11.998886168218657, Trade: 159\n",
      "Step 359, action: 0, terminated: False, reward: -12.50171066709866, Trade: 160\n",
      "Step 360, action: 2, terminated: False, reward: -12.51171066709866, Trade: 161\n",
      "Step 361, action: 2, terminated: False, reward: -12.62171066709866, Trade: 161\n",
      "Step 362, action: 2, terminated: False, reward: -12.731710667098659, Trade: 161\n",
      "Step 363, action: 0, terminated: False, reward: -15.277880915392721, Trade: 162\n",
      "Step 364, action: 2, terminated: False, reward: -15.287880915392721, Trade: 163\n",
      "Step 365, action: 0, terminated: False, reward: -15.269908896422999, Trade: 164\n",
      "Step 366, action: 1, terminated: False, reward: -15.279908896422999, Trade: 164\n",
      "Step 367, action: 1, terminated: False, reward: -15.289908896422999, Trade: 164\n",
      "Step 368, action: 0, terminated: False, reward: -15.299908896422998, Trade: 165\n",
      "Step 369, action: 0, terminated: False, reward: -18.952626210067404, Trade: 166\n",
      "Step 370, action: 2, terminated: False, reward: -18.962626210067405, Trade: 167\n",
      "Step 371, action: 1, terminated: False, reward: -18.972626210067407, Trade: 167\n",
      "Step 372, action: 1, terminated: False, reward: -18.98262621006741, Trade: 167\n",
      "Step 373, action: 1, terminated: False, reward: -18.99262621006741, Trade: 167\n",
      "Step 374, action: 1, terminated: False, reward: -19.00262621006741, Trade: 167\n",
      "Step 375, action: 2, terminated: False, reward: -19.112626210067415, Trade: 167\n",
      "Step 376, action: 0, terminated: False, reward: -20.991962875481843, Trade: 168\n",
      "Step 377, action: 2, terminated: False, reward: -21.001962875481844, Trade: 169\n",
      "Step 378, action: 2, terminated: False, reward: -21.111962875481847, Trade: 169\n",
      "Step 379, action: 1, terminated: False, reward: -21.12196287548185, Trade: 169\n",
      "Step 380, action: 0, terminated: False, reward: -22.917854041819442, Trade: 170\n",
      "Step 381, action: 0, terminated: False, reward: -22.927854041819444, Trade: 171\n",
      "Step 382, action: 2, terminated: False, reward: -23.037854041819447, Trade: 171\n",
      "Step 383, action: 2, terminated: False, reward: -23.14785404181945, Trade: 171\n",
      "Step 384, action: 0, terminated: False, reward: -20.34344632197082, Trade: 172\n",
      "Step 385, action: 0, terminated: False, reward: -20.35344632197082, Trade: 173\n",
      "Step 386, action: 0, terminated: False, reward: -21.34007155344055, Trade: 174\n",
      "Step 387, action: 0, terminated: False, reward: -21.35007155344055, Trade: 175\n",
      "Step 388, action: 2, terminated: False, reward: -21.460071553440553, Trade: 175\n",
      "Step 389, action: 2, terminated: False, reward: -21.570071553440556, Trade: 175\n",
      "Step 390, action: 0, terminated: False, reward: -24.969817040372934, Trade: 176\n",
      "Step 391, action: 2, terminated: False, reward: -24.979817040372936, Trade: 177\n",
      "Step 392, action: 0, terminated: False, reward: -22.696897038663952, Trade: 178\n",
      "Step 393, action: 1, terminated: False, reward: -22.706897038663953, Trade: 178\n",
      "Step 394, action: 1, terminated: False, reward: -22.716897038663955, Trade: 178\n",
      "Step 395, action: 2, terminated: False, reward: -22.726897038663957, Trade: 179\n",
      "Step 396, action: 2, terminated: False, reward: -22.83689703866396, Trade: 179\n",
      "Step 397, action: 0, terminated: False, reward: -17.413995634391497, Trade: 180\n",
      "Step 398, action: 0, terminated: False, reward: -17.4239956343915, Trade: 181\n",
      "Step 399, action: 0, terminated: False, reward: -15.271051898038962, Trade: 182\n",
      "Step 400, action: 0, terminated: False, reward: -15.281051898038962, Trade: 183\n",
      "Step 401, action: 2, terminated: False, reward: -15.391051898038961, Trade: 183\n",
      "Step 402, action: 2, terminated: False, reward: -15.50105189803896, Trade: 183\n",
      "Step 403, action: 0, terminated: False, reward: -17.948896905317405, Trade: 184\n",
      "Step 404, action: 2, terminated: False, reward: -17.958896905317406, Trade: 185\n",
      "Step 405, action: 1, terminated: False, reward: -17.968896905317408, Trade: 185\n",
      "Step 406, action: 1, terminated: False, reward: -17.97889690531741, Trade: 185\n",
      "Step 407, action: 1, terminated: False, reward: -17.98889690531741, Trade: 185\n",
      "Step 408, action: 0, terminated: False, reward: -17.75702136936771, Trade: 186\n",
      "Step 409, action: 2, terminated: False, reward: -17.76702136936771, Trade: 187\n",
      "Step 410, action: 0, terminated: False, reward: -16.338762814527627, Trade: 188\n",
      "Step 411, action: 0, terminated: False, reward: -16.34876281452763, Trade: 189\n",
      "Step 412, action: 0, terminated: False, reward: -15.827162830677532, Trade: 190\n",
      "Step 413, action: 0, terminated: False, reward: -15.837162830677531, Trade: 191\n",
      "Step 414, action: 0, terminated: False, reward: -16.416610795979047, Trade: 192\n",
      "Step 415, action: 0, terminated: False, reward: -16.426610795979048, Trade: 193\n",
      "Step 416, action: 2, terminated: False, reward: -16.53661079597905, Trade: 193\n",
      "Step 417, action: 2, terminated: False, reward: -16.646610795979054, Trade: 193\n",
      "Step 418, action: 0, terminated: False, reward: -14.424529202595265, Trade: 194\n",
      "Step 419, action: 0, terminated: False, reward: -14.434529202595265, Trade: 195\n",
      "Step 420, action: 1, terminated: False, reward: -14.444529202595264, Trade: 195\n",
      "Step 421, action: 2, terminated: False, reward: -14.554529202595264, Trade: 195\n",
      "Step 422, action: 2, terminated: False, reward: -14.664529202595263, Trade: 195\n",
      "Step 423, action: 2, terminated: False, reward: -14.774529202595263, Trade: 195\n",
      "Step 424, action: 1, terminated: False, reward: -14.784529202595262, Trade: 195\n",
      "Step 425, action: 1, terminated: False, reward: -14.794529202595262, Trade: 195\n",
      "Step 426, action: 0, terminated: False, reward: -17.252420563453416, Trade: 196\n",
      "Step 427, action: 2, terminated: False, reward: -17.262420563453418, Trade: 197\n",
      "Step 428, action: 2, terminated: False, reward: -17.37242056345342, Trade: 197\n",
      "Step 429, action: 0, terminated: False, reward: -16.80429353265966, Trade: 198\n",
      "Step 430, action: 2, terminated: False, reward: -16.81429353265966, Trade: 199\n",
      "Step 431, action: 0, terminated: False, reward: -16.65882558283514, Trade: 200\n",
      "Step 432, action: 2, terminated: False, reward: -16.66882558283514, Trade: 201\n",
      "Step 433, action: 2, terminated: False, reward: -16.778825582835143, Trade: 201\n",
      "Step 434, action: 0, terminated: False, reward: -17.66258896746039, Trade: 202\n",
      "Step 435, action: 1, terminated: False, reward: -17.672588967460392, Trade: 202\n",
      "Step 436, action: 0, terminated: False, reward: -17.682588967460394, Trade: 203\n",
      "Step 437, action: 1, terminated: False, reward: -17.692588967460395, Trade: 203\n",
      "Step 438, action: 2, terminated: False, reward: -17.802588967460398, Trade: 203\n",
      "Step 439, action: 0, terminated: False, reward: -20.088380000983964, Trade: 204\n",
      "Step 440, action: 1, terminated: False, reward: -20.098380000983965, Trade: 204\n",
      "Step 441, action: 2, terminated: False, reward: -20.108380000983967, Trade: 205\n",
      "Step 442, action: 0, terminated: False, reward: -16.89886922818123, Trade: 206\n",
      "Step 443, action: 0, terminated: False, reward: -16.90886922818123, Trade: 207\n",
      "Step 444, action: 1, terminated: False, reward: -16.918869228181233, Trade: 207\n",
      "Step 445, action: 1, terminated: False, reward: -16.928869228181235, Trade: 207\n",
      "Step 446, action: 1, terminated: False, reward: -16.938869228181236, Trade: 207\n",
      "Step 447, action: 0, terminated: False, reward: -16.103833060354397, Trade: 208\n",
      "Step 448, action: 2, terminated: False, reward: -16.1138330603544, Trade: 209\n",
      "Step 449, action: 1, terminated: False, reward: -16.1238330603544, Trade: 209\n",
      "Step 450, action: 0, terminated: False, reward: -14.81335852532785, Trade: 210\n",
      "Step 451, action: 2, terminated: False, reward: -14.82335852532785, Trade: 211\n",
      "Step 452, action: 2, terminated: False, reward: -14.933358525327849, Trade: 211\n",
      "Step 453, action: 1, terminated: False, reward: -14.943358525327849, Trade: 211\n",
      "Step 454, action: 0, terminated: False, reward: -10.770339071470428, Trade: 212\n",
      "Step 455, action: 1, terminated: False, reward: -10.780339071470427, Trade: 212\n",
      "Step 456, action: 1, terminated: False, reward: -10.790339071470427, Trade: 212\n",
      "Step 457, action: 0, terminated: False, reward: -10.800339071470427, Trade: 213\n",
      "Step 458, action: 1, terminated: False, reward: -10.810339071470427, Trade: 213\n",
      "Step 459, action: 2, terminated: False, reward: -10.920339071470426, Trade: 213\n",
      "Step 460, action: 0, terminated: False, reward: -13.557726878623743, Trade: 214\n",
      "Step 461, action: 2, terminated: False, reward: -13.567726878623743, Trade: 215\n",
      "Step 462, action: 0, terminated: False, reward: -13.001834057305691, Trade: 216\n",
      "Step 463, action: 2, terminated: False, reward: -13.011834057305691, Trade: 217\n",
      "Step 464, action: 1, terminated: False, reward: -13.021834057305691, Trade: 217\n",
      "Step 465, action: 0, terminated: False, reward: -10.589632074551176, Trade: 218\n",
      "Step 466, action: 2, terminated: False, reward: -10.599632074551176, Trade: 219\n",
      "Step 467, action: 0, terminated: False, reward: -10.841192241042872, Trade: 220\n",
      "Step 468, action: 1, terminated: False, reward: -10.851192241042872, Trade: 220\n",
      "Step 469, action: 0, terminated: False, reward: -10.861192241042872, Trade: 221\n",
      "Step 470, action: 2, terminated: False, reward: -10.971192241042871, Trade: 221\n",
      "Step 471, action: 2, terminated: False, reward: -11.08119224104287, Trade: 221\n",
      "Step 472, action: 2, terminated: False, reward: -11.19119224104287, Trade: 221\n",
      "Step 473, action: 1, terminated: False, reward: -11.20119224104287, Trade: 221\n",
      "Step 474, action: 1, terminated: False, reward: -11.21119224104287, Trade: 221\n",
      "Step 475, action: 1, terminated: False, reward: -11.22119224104287, Trade: 221\n",
      "Step 476, action: 2, terminated: False, reward: -11.331192241042869, Trade: 221\n",
      "Step 477, action: 2, terminated: False, reward: -11.441192241042868, Trade: 221\n",
      "Step 478, action: 0, terminated: False, reward: -13.621957455540244, Trade: 222\n",
      "Step 479, action: 1, terminated: False, reward: -13.631957455540244, Trade: 222\n",
      "Step 480, action: 0, terminated: False, reward: -13.641957455540243, Trade: 223\n",
      "Step 481, action: 0, terminated: False, reward: -14.934305225152364, Trade: 224\n",
      "Step 482, action: 2, terminated: False, reward: -14.944305225152364, Trade: 225\n",
      "Step 483, action: 0, terminated: False, reward: -15.448850159101648, Trade: 226\n",
      "Step 484, action: 2, terminated: False, reward: -15.458850159101647, Trade: 227\n",
      "Step 485, action: 1, terminated: False, reward: -15.468850159101647, Trade: 227\n",
      "Step 486, action: 0, terminated: False, reward: -20.040587741349572, Trade: 228\n",
      "Step 487, action: 1, terminated: False, reward: -20.050587741349574, Trade: 228\n",
      "Step 488, action: 1, terminated: False, reward: -20.060587741349575, Trade: 228\n",
      "Step 489, action: 2, terminated: False, reward: -20.070587741349577, Trade: 229\n",
      "Step 490, action: 1, terminated: False, reward: -20.08058774134958, Trade: 229\n",
      "Step 491, action: 2, terminated: False, reward: -20.19058774134958, Trade: 229\n",
      "Step 492, action: 2, terminated: False, reward: -20.300587741349585, Trade: 229\n",
      "Step 493, action: 2, terminated: False, reward: -20.410587741349588, Trade: 229\n",
      "Step 494, action: 1, terminated: False, reward: -20.42058774134959, Trade: 229\n",
      "Step 495, action: 0, terminated: False, reward: -19.563330297257796, Trade: 230\n",
      "Step 496, action: 1, terminated: False, reward: -19.573330297257797, Trade: 230\n",
      "Step 497, action: 0, terminated: False, reward: -19.5833302972578, Trade: 231\n",
      "Step 498, action: 1, terminated: False, reward: -19.5933302972578, Trade: 231\n",
      "Step 499, action: 2, terminated: False, reward: -19.703330297257803, Trade: 231\n",
      "Step 500, action: 1, terminated: False, reward: -19.713330297257805, Trade: 231\n",
      "Step 501, action: 0, terminated: False, reward: -20.759386363871577, Trade: 232\n",
      "Step 502, action: 1, terminated: False, reward: -20.76938636387158, Trade: 232\n",
      "Step 503, action: 2, terminated: False, reward: -20.77938636387158, Trade: 233\n",
      "Step 504, action: 2, terminated: False, reward: -20.889386363871584, Trade: 233\n",
      "Step 505, action: 0, terminated: False, reward: -24.455583606355106, Trade: 234\n",
      "Step 506, action: 1, terminated: False, reward: -24.465583606355107, Trade: 234\n",
      "Step 507, action: 1, terminated: False, reward: -24.47558360635511, Trade: 234\n",
      "Step 508, action: 0, terminated: False, reward: -24.48558360635511, Trade: 235\n",
      "Step 509, action: 0, terminated: False, reward: -24.813019308717173, Trade: 236\n",
      "Step 510, action: 0, terminated: False, reward: -24.823019308717175, Trade: 237\n",
      "Step 511, action: 2, terminated: False, reward: -24.933019308717178, Trade: 237\n",
      "Step 512, action: 2, terminated: False, reward: -25.04301930871718, Trade: 237\n",
      "Step 513, action: 2, terminated: False, reward: -25.153019308717184, Trade: 237\n",
      "Step 514, action: 2, terminated: False, reward: -25.263019308717187, Trade: 237\n",
      "Step 515, action: 2, terminated: False, reward: -25.37301930871719, Trade: 237\n",
      "Step 516, action: 0, terminated: False, reward: -27.93183606956314, Trade: 238\n",
      "Step 517, action: 2, terminated: False, reward: -27.94183606956314, Trade: 239\n",
      "Step 518, action: 0, terminated: False, reward: -27.956524636012112, Trade: 240\n",
      "Step 519, action: 1, terminated: False, reward: -27.966524636012114, Trade: 240\n",
      "Step 520, action: 1, terminated: False, reward: -27.976524636012115, Trade: 240\n",
      "Step 521, action: 1, terminated: False, reward: -27.986524636012117, Trade: 240\n",
      "Step 522, action: 0, terminated: False, reward: -27.99652463601212, Trade: 241\n",
      "Step 523, action: 0, terminated: False, reward: -27.84761457029557, Trade: 242\n",
      "Step 524, action: 2, terminated: False, reward: -27.85761457029557, Trade: 243\n",
      "Step 525, action: 0, terminated: False, reward: -29.017041159730386, Trade: 244\n",
      "Step 526, action: 0, terminated: False, reward: -29.027041159730388, Trade: 245\n",
      "Step 527, action: 2, terminated: False, reward: -29.13704115973039, Trade: 245\n",
      "Step 528, action: 0, terminated: False, reward: -31.17759170656572, Trade: 246\n",
      "Step 529, action: 2, terminated: False, reward: -31.187591706565723, Trade: 247\n",
      "Step 530, action: 2, terminated: False, reward: -31.297591706565726, Trade: 247\n",
      "Step 531, action: 1, terminated: False, reward: -31.307591706565727, Trade: 247\n",
      "Step 532, action: 0, terminated: False, reward: -30.94810958861224, Trade: 248\n",
      "Step 533, action: 0, terminated: False, reward: -30.958109588612242, Trade: 249\n",
      "Step 534, action: 0, terminated: False, reward: -30.100840306600833, Trade: 250\n",
      "Step 535, action: 1, terminated: False, reward: -30.110840306600835, Trade: 250\n",
      "Step 536, action: 0, terminated: False, reward: -30.120840306600837, Trade: 251\n",
      "Step 537, action: 1, terminated: False, reward: -30.130840306600838, Trade: 251\n",
      "Step 538, action: 0, terminated: False, reward: -28.898835136154066, Trade: 252\n",
      "Step 539, action: 1, terminated: False, reward: -28.908835136154067, Trade: 252\n",
      "Step 540, action: 0, terminated: False, reward: -28.91883513615407, Trade: 253\n",
      "Step 541, action: 2, terminated: False, reward: -29.028835136154072, Trade: 253\n",
      "Step 542, action: 0, terminated: False, reward: -28.182909310729883, Trade: 254\n",
      "Step 543, action: 0, terminated: False, reward: -28.192909310729885, Trade: 255\n",
      "Step 544, action: 0, terminated: False, reward: -28.370079531060696, Trade: 256\n",
      "Step 545, action: 2, terminated: False, reward: -28.380079531060698, Trade: 257\n",
      "Step 546, action: 0, terminated: False, reward: -27.898757096029566, Trade: 258\n",
      "Step 547, action: 1, terminated: False, reward: -27.908757096029568, Trade: 258\n",
      "Step 548, action: 1, terminated: False, reward: -27.91875709602957, Trade: 258\n",
      "Step 549, action: 1, terminated: False, reward: -27.92875709602957, Trade: 258\n",
      "Step 550, action: 2, terminated: False, reward: -27.938757096029573, Trade: 259\n",
      "Step 551, action: 2, terminated: False, reward: -28.048757096029576, Trade: 259\n",
      "Step 552, action: 1, terminated: False, reward: -28.058757096029577, Trade: 259\n",
      "Step 553, action: 2, terminated: False, reward: -28.16875709602958, Trade: 259\n",
      "Step 554, action: 0, terminated: False, reward: -30.884192458181687, Trade: 260\n",
      "Step 555, action: 2, terminated: False, reward: -30.89419245818169, Trade: 261\n",
      "Step 556, action: 1, terminated: False, reward: -30.90419245818169, Trade: 261\n",
      "Step 557, action: 2, terminated: False, reward: -31.014192458181693, Trade: 261\n",
      "Step 558, action: 2, terminated: False, reward: -31.124192458181696, Trade: 261\n",
      "Step 559, action: 2, terminated: False, reward: -31.2341924581817, Trade: 261\n",
      "Step 560, action: 2, terminated: False, reward: -31.344192458181702, Trade: 261\n",
      "Step 561, action: 1, terminated: False, reward: -31.354192458181704, Trade: 261\n",
      "Step 562, action: 0, terminated: False, reward: -27.90995544266657, Trade: 262\n",
      "Step 563, action: 1, terminated: False, reward: -27.91995544266657, Trade: 262\n",
      "Step 564, action: 0, terminated: False, reward: -27.92995544266657, Trade: 263\n",
      "Step 565, action: 2, terminated: False, reward: -28.039955442666574, Trade: 263\n",
      "Step 566, action: 0, terminated: False, reward: -31.63277001833491, Trade: 264\n",
      "Step 567, action: 0, terminated: False, reward: -31.64277001833491, Trade: 265\n",
      "Step 568, action: 0, terminated: False, reward: -31.95038296732478, Trade: 266\n",
      "Step 569, action: 1, terminated: False, reward: -31.960382967324783, Trade: 266\n",
      "Step 570, action: 1, terminated: False, reward: -31.970382967324785, Trade: 266\n",
      "Step 571, action: 2, terminated: False, reward: -31.980382967324786, Trade: 267\n",
      "Step 572, action: 1, terminated: False, reward: -31.990382967324788, Trade: 267\n",
      "Step 573, action: 0, terminated: False, reward: -30.81077973180233, Trade: 268\n",
      "Step 574, action: 0, terminated: False, reward: -30.820779731802332, Trade: 269\n",
      "Step 575, action: 0, terminated: False, reward: -30.087308121835296, Trade: 270\n",
      "Step 576, action: 1, terminated: False, reward: -30.097308121835297, Trade: 270\n",
      "Step 577, action: 2, terminated: False, reward: -30.1073081218353, Trade: 271\n",
      "Step 578, action: 1, terminated: False, reward: -30.1173081218353, Trade: 271\n",
      "Step 579, action: 2, terminated: False, reward: -30.227308121835303, Trade: 271\n",
      "Step 580, action: 0, terminated: False, reward: -29.95594267826841, Trade: 272\n",
      "Step 581, action: 0, terminated: False, reward: -29.965942678268412, Trade: 273\n",
      "Step 582, action: 2, terminated: False, reward: -30.075942678268415, Trade: 273\n",
      "Step 583, action: 0, terminated: False, reward: -29.084422230426014, Trade: 274\n",
      "Step 584, action: 0, terminated: False, reward: -29.094422230426016, Trade: 275\n",
      "Step 585, action: 1, terminated: False, reward: -29.104422230426017, Trade: 275\n",
      "Step 586, action: 2, terminated: False, reward: -29.21442223042602, Trade: 275\n",
      "Step 587, action: 2, terminated: False, reward: -29.324422230426023, Trade: 275\n",
      "Step 588, action: 0, terminated: False, reward: -23.572823715966802, Trade: 276\n",
      "Step 589, action: 2, terminated: False, reward: -23.582823715966803, Trade: 277\n",
      "Step 590, action: 2, terminated: False, reward: -23.692823715966806, Trade: 277\n",
      "Step 591, action: 2, terminated: False, reward: -23.80282371596681, Trade: 277\n",
      "Step 592, action: 2, terminated: False, reward: -23.912823715966812, Trade: 277\n",
      "Step 593, action: 0, terminated: False, reward: -26.076303250491353, Trade: 278\n",
      "Step 594, action: 2, terminated: False, reward: -26.086303250491355, Trade: 279\n",
      "Step 595, action: 0, terminated: False, reward: -25.877729930166648, Trade: 280\n",
      "Step 596, action: 2, terminated: False, reward: -25.88772993016665, Trade: 281\n",
      "Step 597, action: 1, terminated: False, reward: -25.89772993016665, Trade: 281\n",
      "Step 598, action: 2, terminated: False, reward: -26.007729930166654, Trade: 281\n",
      "Step 599, action: 1, terminated: False, reward: -26.017729930166656, Trade: 281\n",
      "Step 600, action: 1, terminated: False, reward: -26.027729930166657, Trade: 281\n",
      "Step 601, action: 1, terminated: False, reward: -26.03772993016666, Trade: 281\n",
      "Step 602, action: 2, terminated: False, reward: -26.147729930166662, Trade: 281\n",
      "Step 603, action: 2, terminated: False, reward: -26.257729930166665, Trade: 281\n",
      "Step 604, action: 0, terminated: False, reward: -25.251469123463483, Trade: 282\n",
      "Step 605, action: 2, terminated: False, reward: -25.261469123463485, Trade: 283\n",
      "Step 606, action: 1, terminated: False, reward: -25.271469123463486, Trade: 283\n",
      "Step 607, action: 0, terminated: False, reward: -25.877376475517316, Trade: 284\n",
      "Step 608, action: 1, terminated: False, reward: -25.887376475517318, Trade: 284\n",
      "Step 609, action: 2, terminated: False, reward: -25.89737647551732, Trade: 285\n",
      "Step 610, action: 2, terminated: False, reward: -26.007376475517322, Trade: 285\n",
      "Step 611, action: 2, terminated: False, reward: -26.117376475517325, Trade: 285\n",
      "Step 612, action: 1, terminated: False, reward: -26.127376475517327, Trade: 285\n",
      "Step 613, action: 2, terminated: False, reward: -26.23737647551733, Trade: 285\n",
      "Step 614, action: 1, terminated: False, reward: -26.24737647551733, Trade: 285\n",
      "Step 615, action: 2, terminated: False, reward: -26.357376475517334, Trade: 285\n",
      "Step 616, action: 1, terminated: False, reward: -26.367376475517336, Trade: 285\n",
      "Step 617, action: 0, terminated: False, reward: -25.01089615591285, Trade: 286\n",
      "Step 618, action: 0, terminated: False, reward: -25.02089615591285, Trade: 287\n",
      "Step 619, action: 0, terminated: False, reward: -23.066532352766494, Trade: 288\n",
      "Step 620, action: 0, terminated: False, reward: -23.076532352766495, Trade: 289\n",
      "Step 621, action: 1, terminated: False, reward: -23.086532352766497, Trade: 289\n",
      "Step 622, action: 1, terminated: False, reward: -23.0965323527665, Trade: 289\n",
      "Step 623, action: 0, terminated: False, reward: -22.547016602835164, Trade: 290\n",
      "Step 624, action: 1, terminated: False, reward: -22.557016602835166, Trade: 290\n",
      "Step 625, action: 1, terminated: False, reward: -22.567016602835167, Trade: 290\n",
      "Step 626, action: 0, terminated: False, reward: -22.57701660283517, Trade: 291\n",
      "Step 627, action: 1, terminated: False, reward: -22.58701660283517, Trade: 291\n",
      "Step 628, action: 1, terminated: False, reward: -22.597016602835172, Trade: 291\n",
      "Step 629, action: 1, terminated: False, reward: -22.607016602835174, Trade: 291\n",
      "Step 630, action: 1, terminated: False, reward: -22.617016602835175, Trade: 291\n",
      "Step 631, action: 2, terminated: False, reward: -22.727016602835178, Trade: 291\n",
      "Step 632, action: 0, terminated: False, reward: -22.113268517242528, Trade: 292\n",
      "Step 633, action: 1, terminated: False, reward: -22.12326851724253, Trade: 292\n",
      "Step 634, action: 1, terminated: False, reward: -22.13326851724253, Trade: 292\n",
      "Step 635, action: 0, terminated: False, reward: -22.143268517242532, Trade: 293\n",
      "Step 636, action: 2, terminated: False, reward: -22.253268517242535, Trade: 293\n",
      "Step 637, action: 0, terminated: False, reward: -19.967112311744796, Trade: 294\n",
      "Step 638, action: 0, terminated: False, reward: -19.977112311744797, Trade: 295\n",
      "Step 639, action: 2, terminated: False, reward: -20.0871123117448, Trade: 295\n",
      "Step 640, action: 2, terminated: False, reward: -20.197112311744803, Trade: 295\n",
      "Step 641, action: 2, terminated: False, reward: -20.307112311744806, Trade: 295\n",
      "Step 642, action: 2, terminated: False, reward: -20.41711231174481, Trade: 295\n",
      "Step 643, action: 2, terminated: False, reward: -20.527112311744812, Trade: 295\n",
      "Step 644, action: 1, terminated: False, reward: -20.537112311744814, Trade: 295\n",
      "Step 645, action: 2, terminated: False, reward: -20.647112311744817, Trade: 295\n",
      "Step 646, action: 0, terminated: False, reward: -23.49141949748701, Trade: 296\n",
      "Step 647, action: 1, terminated: False, reward: -23.50141949748701, Trade: 296\n",
      "Step 648, action: 1, terminated: False, reward: -23.51141949748701, Trade: 296\n",
      "Step 649, action: 2, terminated: False, reward: -23.521419497487013, Trade: 297\n",
      "Step 650, action: 2, terminated: False, reward: -23.631419497487016, Trade: 297\n",
      "Step 651, action: 1, terminated: False, reward: -23.641419497487018, Trade: 297\n",
      "Step 652, action: 1, terminated: False, reward: -23.65141949748702, Trade: 297\n",
      "Step 653, action: 0, terminated: False, reward: -23.788706949446247, Trade: 298\n",
      "Step 654, action: 2, terminated: False, reward: -23.79870694944625, Trade: 299\n",
      "Step 655, action: 1, terminated: False, reward: -23.80870694944625, Trade: 299\n",
      "Step 656, action: 1, terminated: False, reward: -23.818706949446252, Trade: 299\n",
      "Step 657, action: 2, terminated: False, reward: -23.928706949446255, Trade: 299\n",
      "Step 658, action: 1, terminated: False, reward: -23.938706949446257, Trade: 299\n",
      "Step 659, action: 0, terminated: False, reward: -24.68372783041855, Trade: 300\n",
      "Step 660, action: 0, terminated: False, reward: -24.693727830418553, Trade: 301\n",
      "Step 661, action: 0, terminated: False, reward: -25.22310574902817, Trade: 302\n",
      "Step 662, action: 2, terminated: False, reward: -25.233105749028173, Trade: 303\n",
      "Step 663, action: 0, terminated: False, reward: -26.01049929639145, Trade: 304\n",
      "Step 664, action: 0, terminated: False, reward: -26.020499296391453, Trade: 305\n",
      "Step 665, action: 1, terminated: False, reward: -26.030499296391454, Trade: 305\n",
      "Step 666, action: 2, terminated: False, reward: -26.140499296391457, Trade: 305\n",
      "Step 667, action: 1, terminated: False, reward: -26.15049929639146, Trade: 305\n",
      "Step 668, action: 2, terminated: False, reward: -26.260499296391462, Trade: 305\n",
      "Step 669, action: 2, terminated: False, reward: -26.370499296391465, Trade: 305\n",
      "Step 670, action: 0, terminated: False, reward: -27.254786801677106, Trade: 306\n",
      "Step 671, action: 2, terminated: False, reward: -27.264786801677108, Trade: 307\n",
      "Step 672, action: 1, terminated: False, reward: -27.27478680167711, Trade: 307\n",
      "Step 673, action: 1, terminated: False, reward: -27.28478680167711, Trade: 307\n",
      "Step 674, action: 0, terminated: False, reward: -26.21800354254015, Trade: 308\n",
      "Step 675, action: 1, terminated: False, reward: -26.22800354254015, Trade: 308\n",
      "Step 676, action: 2, terminated: False, reward: -26.238003542540152, Trade: 309\n",
      "Step 677, action: 1, terminated: False, reward: -26.248003542540154, Trade: 309\n",
      "Step 678, action: 0, terminated: False, reward: -25.114100401178156, Trade: 310\n",
      "Step 679, action: 1, terminated: False, reward: -25.124100401178158, Trade: 310\n",
      "Step 680, action: 2, terminated: False, reward: -25.13410040117816, Trade: 311\n",
      "Step 681, action: 2, terminated: False, reward: -25.244100401178162, Trade: 311\n",
      "Step 682, action: 0, terminated: False, reward: -24.98705273711566, Trade: 312\n",
      "Step 683, action: 2, terminated: False, reward: -24.997052737115663, Trade: 313\n",
      "Step 684, action: 2, terminated: False, reward: -25.107052737115666, Trade: 313\n",
      "Step 685, action: 0, terminated: False, reward: -25.406185403703496, Trade: 314\n",
      "Step 686, action: 2, terminated: False, reward: -25.416185403703498, Trade: 315\n",
      "Step 687, action: 1, terminated: False, reward: -25.4261854037035, Trade: 315\n",
      "Step 688, action: 1, terminated: False, reward: -25.4361854037035, Trade: 315\n",
      "Step 689, action: 1, terminated: False, reward: -25.446185403703502, Trade: 315\n",
      "Step 690, action: 2, terminated: False, reward: -25.556185403703505, Trade: 315\n",
      "Step 691, action: 2, terminated: False, reward: -25.66618540370351, Trade: 315\n",
      "Step 692, action: 2, terminated: False, reward: -25.77618540370351, Trade: 315\n",
      "Step 693, action: 2, terminated: False, reward: -25.886185403703514, Trade: 315\n",
      "Step 694, action: 2, terminated: False, reward: -25.996185403703517, Trade: 315\n",
      "Step 695, action: 0, terminated: False, reward: -29.284035679525967, Trade: 316\n",
      "Step 696, action: 0, terminated: False, reward: -29.29403567952597, Trade: 317\n",
      "Step 697, action: 2, terminated: False, reward: -29.404035679525972, Trade: 317\n",
      "Step 698, action: 1, terminated: False, reward: -29.414035679525973, Trade: 317\n",
      "Step 699, action: 0, terminated: False, reward: -26.712684807963786, Trade: 318\n",
      "Step 700, action: 0, terminated: False, reward: -26.722684807963788, Trade: 319\n",
      "Step 701, action: 1, terminated: False, reward: -26.73268480796379, Trade: 319\n",
      "Step 702, action: 1, terminated: False, reward: -26.74268480796379, Trade: 319\n",
      "Step 703, action: 0, terminated: False, reward: -29.114962202726975, Trade: 320\n",
      "Step 704, action: 0, terminated: False, reward: -29.124962202726977, Trade: 321\n",
      "Step 705, action: 0, terminated: False, reward: -27.979656919030994, Trade: 322\n",
      "Step 706, action: 1, terminated: False, reward: -27.989656919030995, Trade: 322\n",
      "Step 707, action: 0, terminated: False, reward: -27.999656919030997, Trade: 323\n",
      "Step 708, action: 1, terminated: False, reward: -28.009656919031, Trade: 323\n",
      "Step 709, action: 1, terminated: False, reward: -28.019656919031, Trade: 323\n",
      "Step 710, action: 1, terminated: False, reward: -28.029656919031, Trade: 323\n",
      "Step 711, action: 2, terminated: False, reward: -28.139656919031005, Trade: 323\n",
      "Step 712, action: 1, terminated: False, reward: -28.149656919031006, Trade: 323\n",
      "Step 713, action: 2, terminated: False, reward: -28.25965691903101, Trade: 323\n",
      "Step 714, action: 2, terminated: False, reward: -28.369656919031012, Trade: 323\n",
      "Step 715, action: 2, terminated: False, reward: -28.479656919031015, Trade: 323\n",
      "Step 716, action: 2, terminated: False, reward: -28.589656919031018, Trade: 323\n",
      "Step 717, action: 1, terminated: False, reward: -28.59965691903102, Trade: 323\n",
      "Step 718, action: 1, terminated: False, reward: -28.60965691903102, Trade: 323\n",
      "Step 719, action: 0, terminated: False, reward: -20.91678629499538, Trade: 324\n",
      "Step 720, action: 1, terminated: False, reward: -20.92678629499538, Trade: 324\n",
      "Step 721, action: 0, terminated: False, reward: -20.936786294995382, Trade: 325\n",
      "Step 722, action: 2, terminated: False, reward: -21.046786294995385, Trade: 325\n",
      "Step 723, action: 2, terminated: False, reward: -21.15678629499539, Trade: 325\n",
      "Step 724, action: 0, terminated: False, reward: -20.619305672729762, Trade: 326\n",
      "Step 725, action: 2, terminated: False, reward: -20.629305672729764, Trade: 327\n",
      "Step 726, action: 0, terminated: False, reward: -20.777925252395907, Trade: 328\n",
      "Step 727, action: 2, terminated: False, reward: -20.787925252395908, Trade: 329\n",
      "Step 728, action: 0, terminated: False, reward: -20.70790074542417, Trade: 330\n",
      "Step 729, action: 1, terminated: False, reward: -20.71790074542417, Trade: 330\n",
      "Step 730, action: 1, terminated: False, reward: -20.727900745424172, Trade: 330\n",
      "Step 731, action: 2, terminated: False, reward: -20.737900745424174, Trade: 331\n",
      "Step 732, action: 1, terminated: False, reward: -20.747900745424175, Trade: 331\n",
      "Step 733, action: 2, terminated: False, reward: -20.85790074542418, Trade: 331\n",
      "Step 734, action: 2, terminated: False, reward: -20.96790074542418, Trade: 331\n",
      "Step 735, action: 0, terminated: False, reward: -21.458022444154658, Trade: 332\n",
      "Step 736, action: 2, terminated: False, reward: -21.46802244415466, Trade: 333\n",
      "Step 737, action: 2, terminated: False, reward: -21.578022444154662, Trade: 333\n",
      "Step 738, action: 1, terminated: False, reward: -21.588022444154664, Trade: 333\n",
      "Step 739, action: 2, terminated: False, reward: -21.698022444154667, Trade: 333\n",
      "Step 740, action: 2, terminated: False, reward: -21.80802244415467, Trade: 333\n",
      "Step 741, action: 2, terminated: False, reward: -21.918022444154673, Trade: 333\n",
      "Step 742, action: 2, terminated: False, reward: -22.028022444154676, Trade: 333\n",
      "Step 743, action: 1, terminated: False, reward: -22.038022444154677, Trade: 333\n",
      "Step 744, action: 0, terminated: False, reward: -18.12287063365968, Trade: 334\n",
      "Step 745, action: 2, terminated: False, reward: -18.13287063365968, Trade: 335\n",
      "Step 746, action: 1, terminated: False, reward: -18.142870633659683, Trade: 335\n",
      "Step 747, action: 1, terminated: False, reward: -18.152870633659685, Trade: 335\n",
      "Step 748, action: 0, terminated: False, reward: -17.620797321647963, Trade: 336\n",
      "Step 749, action: 0, terminated: False, reward: -17.630797321647965, Trade: 337\n",
      "Step 750, action: 0, terminated: False, reward: -18.3828559826343, Trade: 338\n",
      "Step 751, action: 2, terminated: False, reward: -18.392855982634302, Trade: 339\n",
      "Step 752, action: 0, terminated: False, reward: -19.787934656668426, Trade: 340\n",
      "Step 753, action: 0, terminated: False, reward: -19.797934656668428, Trade: 341\n",
      "Step 754, action: 2, terminated: False, reward: -19.90793465666843, Trade: 341\n",
      "Step 755, action: 1, terminated: False, reward: -19.917934656668432, Trade: 341\n",
      "Step 756, action: 1, terminated: False, reward: -19.927934656668434, Trade: 341\n",
      "Step 757, action: 2, terminated: False, reward: -20.037934656668437, Trade: 341\n",
      "Step 758, action: 1, terminated: False, reward: -20.04793465666844, Trade: 341\n",
      "Step 759, action: 0, terminated: False, reward: -17.87007148718602, Trade: 342\n",
      "Step 760, action: 2, terminated: False, reward: -17.880071487186022, Trade: 343\n",
      "Step 761, action: 0, terminated: False, reward: -17.48370798254735, Trade: 344\n",
      "Step 762, action: 1, terminated: False, reward: -17.493707982547352, Trade: 344\n",
      "Step 763, action: 2, terminated: False, reward: -17.503707982547354, Trade: 345\n",
      "Step 764, action: 2, terminated: False, reward: -17.613707982547357, Trade: 345\n",
      "Step 765, action: 1, terminated: False, reward: -17.62370798254736, Trade: 345\n",
      "Step 766, action: 2, terminated: False, reward: -17.73370798254736, Trade: 345\n",
      "Step 767, action: 1, terminated: False, reward: -17.743707982547363, Trade: 345\n",
      "Step 768, action: 1, terminated: False, reward: -17.753707982547365, Trade: 345\n",
      "Step 769, action: 0, terminated: False, reward: -17.062800733600227, Trade: 346\n",
      "Step 770, action: 1, terminated: False, reward: -17.07280073360023, Trade: 346\n",
      "Step 771, action: 1, terminated: False, reward: -17.08280073360023, Trade: 346\n",
      "Step 772, action: 2, terminated: False, reward: -17.09280073360023, Trade: 347\n",
      "Step 773, action: 0, terminated: False, reward: -16.54506596113929, Trade: 348\n",
      "Step 774, action: 2, terminated: False, reward: -16.55506596113929, Trade: 349\n",
      "Step 775, action: 2, terminated: False, reward: -16.665065961139295, Trade: 349\n",
      "Step 776, action: 2, terminated: False, reward: -16.775065961139298, Trade: 349\n",
      "Step 777, action: 1, terminated: False, reward: -16.7850659611393, Trade: 349\n",
      "Step 778, action: 0, terminated: False, reward: -13.758781521203998, Trade: 350\n",
      "Step 779, action: 0, terminated: False, reward: -13.768781521203998, Trade: 351\n",
      "Step 780, action: 2, terminated: False, reward: -13.878781521203997, Trade: 351\n",
      "Step 781, action: 2, terminated: False, reward: -13.988781521203997, Trade: 351\n",
      "Step 782, action: 1, terminated: False, reward: -13.998781521203997, Trade: 351\n",
      "Step 783, action: 0, terminated: False, reward: -12.937988976788718, Trade: 352\n",
      "Step 784, action: 0, terminated: False, reward: -12.947988976788718, Trade: 353\n",
      "Step 785, action: 1, terminated: False, reward: -12.957988976788718, Trade: 353\n",
      "Step 786, action: 1, terminated: False, reward: -12.967988976788718, Trade: 353\n",
      "Step 787, action: 0, terminated: False, reward: -15.905012177203757, Trade: 354\n",
      "Step 788, action: 2, terminated: False, reward: -15.915012177203756, Trade: 355\n",
      "Step 789, action: 1, terminated: False, reward: -15.925012177203756, Trade: 355\n",
      "Step 790, action: 0, terminated: False, reward: -16.50496710305215, Trade: 356\n",
      "Step 791, action: 0, terminated: False, reward: -16.51496710305215, Trade: 357\n",
      "Step 792, action: 1, terminated: False, reward: -16.524967103052152, Trade: 357\n",
      "Step 793, action: 2, terminated: False, reward: -16.634967103052155, Trade: 357\n",
      "Step 794, action: 2, terminated: False, reward: -16.744967103052158, Trade: 357\n",
      "Step 795, action: 1, terminated: False, reward: -16.75496710305216, Trade: 357\n",
      "Step 796, action: 0, terminated: False, reward: -13.276455140161536, Trade: 358\n",
      "Step 797, action: 2, terminated: False, reward: -13.286455140161536, Trade: 359\n",
      "Step 798, action: 1, terminated: False, reward: -13.296455140161536, Trade: 359\n",
      "Step 799, action: 0, terminated: False, reward: -13.547248235754795, Trade: 360\n",
      "Step 800, action: 1, terminated: False, reward: -13.557248235754795, Trade: 360\n",
      "Step 801, action: 0, terminated: False, reward: -13.567248235754795, Trade: 361\n",
      "Step 802, action: 0, terminated: False, reward: -13.4096644345814, Trade: 362\n",
      "Step 803, action: 1, terminated: False, reward: -13.4196644345814, Trade: 362\n",
      "Step 804, action: 2, terminated: False, reward: -16.2715376599192, Trade: 363\n",
      "Episode: 1\n",
      "Step 0, action: 2, terminated: True, reward: 0, Trade: 0\n",
      "Step 1, action: 2, terminated: False, reward: -0.01, Trade: 1\n",
      "Step 2, action: 1, terminated: False, reward: -0.02, Trade: 1\n",
      "Step 3, action: 0, terminated: False, reward: 3.960361316720583, Trade: 2\n",
      "Step 4, action: 1, terminated: False, reward: 3.950361316720583, Trade: 2\n",
      "Step 5, action: 2, terminated: False, reward: 3.9403613167205833, Trade: 3\n",
      "Step 6, action: 0, terminated: False, reward: 2.2905400422820947, Trade: 4\n",
      "Step 7, action: 2, terminated: False, reward: 2.280540042282095, Trade: 5\n",
      "Step 8, action: 2, terminated: False, reward: 2.170540042282095, Trade: 5\n",
      "Step 9, action: 0, terminated: False, reward: 2.792168104489126, Trade: 6\n",
      "Step 10, action: 2, terminated: False, reward: 2.782168104489126, Trade: 7\n",
      "Step 11, action: 2, terminated: False, reward: 2.6721681044891263, Trade: 7\n",
      "Step 12, action: 0, terminated: False, reward: 6.135274997280867, Trade: 8\n",
      "Step 13, action: 0, terminated: False, reward: 6.125274997280867, Trade: 9\n",
      "Step 14, action: 1, terminated: False, reward: 6.115274997280867, Trade: 9\n",
      "Step 15, action: 2, terminated: False, reward: 6.005274997280868, Trade: 9\n",
      "Step 16, action: 0, terminated: False, reward: 8.833491188149985, Trade: 10\n",
      "Step 17, action: 1, terminated: False, reward: 8.823491188149985, Trade: 10\n",
      "Step 18, action: 0, terminated: False, reward: 8.813491188149985, Trade: 11\n",
      "Step 19, action: 1, terminated: False, reward: 8.803491188149986, Trade: 11\n",
      "Step 20, action: 1, terminated: False, reward: 8.793491188149986, Trade: 11\n",
      "Step 21, action: 0, terminated: False, reward: 6.84824089679864, Trade: 12\n",
      "Step 22, action: 2, terminated: False, reward: 6.8382408967986406, Trade: 13\n",
      "Step 23, action: 2, terminated: False, reward: 6.728240896798641, Trade: 13\n",
      "Step 24, action: 2, terminated: False, reward: 6.618240896798642, Trade: 13\n",
      "Step 25, action: 0, terminated: False, reward: 8.843572148240609, Trade: 14\n",
      "Step 26, action: 0, terminated: False, reward: 8.83357214824061, Trade: 15\n",
      "Step 27, action: 0, terminated: False, reward: 10.550002123124637, Trade: 16\n",
      "Step 28, action: 1, terminated: False, reward: 10.540002123124637, Trade: 16\n",
      "Step 29, action: 0, terminated: False, reward: 10.530002123124637, Trade: 17\n",
      "Step 30, action: 2, terminated: False, reward: 10.420002123124638, Trade: 17\n",
      "Step 31, action: 2, terminated: False, reward: 10.310002123124638, Trade: 17\n",
      "Step 32, action: 2, terminated: False, reward: 10.200002123124639, Trade: 17\n",
      "Step 33, action: 0, terminated: False, reward: 6.905702539543084, Trade: 18\n",
      "Step 34, action: 0, terminated: False, reward: 6.895702539543084, Trade: 19\n",
      "Step 35, action: 2, terminated: False, reward: 6.7857025395430846, Trade: 19\n",
      "Step 36, action: 0, terminated: False, reward: -1.388315144203279, Trade: 20\n",
      "Step 37, action: 1, terminated: False, reward: -1.398315144203279, Trade: 20\n",
      "Step 38, action: 2, terminated: False, reward: -1.408315144203279, Trade: 21\n",
      "Step 39, action: 0, terminated: False, reward: 4.2413391455183715, Trade: 22\n",
      "Step 40, action: 0, terminated: False, reward: 4.231339145518372, Trade: 23\n",
      "Step 41, action: 0, terminated: False, reward: 1.7933035127608319, Trade: 24\n",
      "Step 42, action: 0, terminated: False, reward: 1.7833035127608319, Trade: 25\n",
      "Step 43, action: 0, terminated: False, reward: 2.5497373068160125, Trade: 26\n",
      "Step 44, action: 2, terminated: False, reward: 2.5397373068160127, Trade: 27\n",
      "Step 45, action: 1, terminated: False, reward: 2.529737306816013, Trade: 27\n",
      "Step 46, action: 2, terminated: False, reward: 2.419737306816013, Trade: 27\n",
      "Step 47, action: 2, terminated: False, reward: 2.309737306816013, Trade: 27\n",
      "Step 48, action: 2, terminated: False, reward: 2.1997373068160133, Trade: 27\n",
      "Step 49, action: 0, terminated: False, reward: 21.08368062150108, Trade: 28\n",
      "Step 50, action: 0, terminated: False, reward: 21.07368062150108, Trade: 29\n",
      "Step 51, action: 2, terminated: False, reward: 20.963680621501076, Trade: 29\n",
      "Step 52, action: 0, terminated: False, reward: 20.671385289842164, Trade: 30\n",
      "Step 53, action: 0, terminated: False, reward: 20.661385289842162, Trade: 31\n",
      "Step 54, action: 2, terminated: False, reward: 20.55138528984216, Trade: 31\n",
      "Step 55, action: 2, terminated: False, reward: 20.441385289842156, Trade: 31\n",
      "Step 56, action: 2, terminated: False, reward: 20.331385289842153, Trade: 31\n",
      "Step 57, action: 2, terminated: False, reward: 20.22138528984215, Trade: 31\n",
      "Step 58, action: 0, terminated: False, reward: 25.502086618577504, Trade: 32\n",
      "Step 59, action: 2, terminated: False, reward: 25.492086618577503, Trade: 33\n",
      "Step 60, action: 2, terminated: False, reward: 25.3820866185775, Trade: 33\n",
      "Step 61, action: 2, terminated: False, reward: 25.272086618577497, Trade: 33\n",
      "Step 62, action: 2, terminated: False, reward: 25.162086618577494, Trade: 33\n",
      "Step 63, action: 2, terminated: False, reward: 25.05208661857749, Trade: 33\n",
      "Step 64, action: 1, terminated: False, reward: 25.04208661857749, Trade: 33\n",
      "Step 65, action: 0, terminated: False, reward: 25.940675424362123, Trade: 34\n",
      "Step 66, action: 1, terminated: False, reward: 25.93067542436212, Trade: 34\n",
      "Step 67, action: 0, terminated: False, reward: 25.92067542436212, Trade: 35\n",
      "Step 68, action: 0, terminated: False, reward: 27.463466337933326, Trade: 36\n",
      "Step 69, action: 0, terminated: False, reward: 27.453466337933325, Trade: 37\n",
      "Step 70, action: 2, terminated: False, reward: 27.34346633793332, Trade: 37\n",
      "Step 71, action: 1, terminated: False, reward: 27.33346633793332, Trade: 37\n",
      "Step 72, action: 1, terminated: False, reward: 27.32346633793332, Trade: 37\n",
      "Step 73, action: 2, terminated: False, reward: 27.213466337933315, Trade: 37\n",
      "Step 74, action: 1, terminated: False, reward: 27.203466337933314, Trade: 37\n",
      "Step 75, action: 1, terminated: False, reward: 27.193466337933312, Trade: 37\n",
      "Step 76, action: 0, terminated: False, reward: 36.89526572043299, Trade: 38\n",
      "Step 77, action: 2, terminated: False, reward: 36.88526572043299, Trade: 39\n",
      "Step 78, action: 1, terminated: False, reward: 36.87526572043299, Trade: 39\n",
      "Step 79, action: 0, terminated: False, reward: 39.0879816851272, Trade: 40\n",
      "Step 80, action: 2, terminated: False, reward: 39.0779816851272, Trade: 41\n",
      "Step 81, action: 2, terminated: False, reward: 38.9679816851272, Trade: 41\n",
      "Step 82, action: 0, terminated: False, reward: 38.13611140409079, Trade: 42\n",
      "Step 83, action: 0, terminated: False, reward: 38.12611140409079, Trade: 43\n",
      "Step 84, action: 0, terminated: False, reward: 39.17596593134908, Trade: 44\n",
      "Step 85, action: 0, terminated: False, reward: 39.165965931349085, Trade: 45\n",
      "Step 86, action: 0, terminated: False, reward: 38.29750644719994, Trade: 46\n",
      "Step 87, action: 2, terminated: False, reward: 38.287506447199945, Trade: 47\n",
      "Step 88, action: 1, terminated: False, reward: 38.27750644719995, Trade: 47\n",
      "Step 89, action: 2, terminated: False, reward: 38.16750644719995, Trade: 47\n",
      "Step 90, action: 2, terminated: False, reward: 38.05750644719995, Trade: 47\n",
      "Step 91, action: 1, terminated: False, reward: 38.04750644719995, Trade: 47\n",
      "Step 92, action: 1, terminated: False, reward: 38.03750644719995, Trade: 47\n",
      "Step 93, action: 0, terminated: False, reward: 33.47929759859612, Trade: 48\n",
      "Step 94, action: 0, terminated: False, reward: 33.46929759859612, Trade: 49\n",
      "Step 95, action: 1, terminated: False, reward: 33.45929759859612, Trade: 49\n",
      "Step 96, action: 0, terminated: False, reward: 33.52459096477653, Trade: 50\n",
      "Step 97, action: 0, terminated: False, reward: 33.51459096477653, Trade: 51\n",
      "Step 98, action: 0, terminated: False, reward: 32.143437227722096, Trade: 52\n",
      "Step 99, action: 2, terminated: False, reward: 32.1334372277221, Trade: 53\n",
      "Step 100, action: 1, terminated: False, reward: 32.1234372277221, Trade: 53\n",
      "Step 101, action: 2, terminated: False, reward: 32.0134372277221, Trade: 53\n",
      "Step 102, action: 1, terminated: False, reward: 32.0034372277221, Trade: 53\n",
      "Step 103, action: 0, terminated: False, reward: 39.55469798909748, Trade: 54\n",
      "Step 104, action: 1, terminated: False, reward: 39.54469798909748, Trade: 54\n",
      "Step 105, action: 0, terminated: False, reward: 39.53469798909748, Trade: 55\n",
      "Step 106, action: 2, terminated: False, reward: 39.42469798909748, Trade: 55\n",
      "Step 107, action: 0, terminated: False, reward: 38.24662457646326, Trade: 56\n",
      "Step 108, action: 1, terminated: False, reward: 38.236624576463264, Trade: 56\n",
      "Step 109, action: 2, terminated: False, reward: 38.226624576463266, Trade: 57\n",
      "Step 110, action: 1, terminated: False, reward: 38.21662457646327, Trade: 57\n",
      "Step 111, action: 1, terminated: False, reward: 38.20662457646327, Trade: 57\n",
      "Step 112, action: 1, terminated: False, reward: 38.19662457646327, Trade: 57\n",
      "Step 113, action: 2, terminated: False, reward: 38.08662457646327, Trade: 57\n",
      "Step 114, action: 0, terminated: False, reward: 34.70519262345576, Trade: 58\n",
      "Step 115, action: 1, terminated: False, reward: 34.69519262345576, Trade: 58\n",
      "Step 116, action: 2, terminated: False, reward: 34.68519262345576, Trade: 59\n",
      "Step 117, action: 1, terminated: False, reward: 34.675192623455764, Trade: 59\n",
      "Step 118, action: 1, terminated: False, reward: 34.665192623455766, Trade: 59\n",
      "Step 119, action: 0, terminated: False, reward: 38.058172556353746, Trade: 60\n",
      "Step 120, action: 0, terminated: False, reward: 38.04817255635375, Trade: 61\n",
      "Step 121, action: 2, terminated: False, reward: 37.93817255635375, Trade: 61\n",
      "Step 122, action: 1, terminated: False, reward: 37.92817255635375, Trade: 61\n",
      "Step 123, action: 0, terminated: False, reward: 46.23698034404751, Trade: 62\n",
      "Step 124, action: 1, terminated: False, reward: 46.22698034404751, Trade: 62\n",
      "Step 125, action: 1, terminated: False, reward: 46.21698034404751, Trade: 62\n",
      "Step 126, action: 1, terminated: False, reward: 46.206980344047516, Trade: 62\n",
      "Step 127, action: 2, terminated: False, reward: 46.19698034404752, Trade: 63\n",
      "Step 128, action: 0, terminated: False, reward: 43.336862119959996, Trade: 64\n",
      "Step 129, action: 1, terminated: False, reward: 43.32686211996, Trade: 64\n",
      "Step 130, action: 1, terminated: False, reward: 43.31686211996, Trade: 64\n",
      "Step 131, action: 2, terminated: False, reward: 43.30686211996, Trade: 65\n",
      "Step 132, action: 0, terminated: False, reward: 37.080148828219585, Trade: 66\n",
      "Step 133, action: 0, terminated: False, reward: 37.07014882821959, Trade: 67\n",
      "Step 134, action: 1, terminated: False, reward: 37.06014882821959, Trade: 67\n",
      "Step 135, action: 1, terminated: False, reward: 37.05014882821959, Trade: 67\n",
      "Step 136, action: 2, terminated: False, reward: 36.94014882821959, Trade: 67\n",
      "Step 137, action: 1, terminated: False, reward: 36.93014882821959, Trade: 67\n",
      "Step 138, action: 2, terminated: False, reward: 36.820148828219594, Trade: 67\n",
      "Step 139, action: 1, terminated: False, reward: 36.810148828219596, Trade: 67\n",
      "Step 140, action: 0, terminated: False, reward: 38.72887458841249, Trade: 68\n",
      "Step 141, action: 0, terminated: False, reward: 38.71887458841249, Trade: 69\n",
      "Step 142, action: 2, terminated: False, reward: 38.60887458841249, Trade: 69\n",
      "Step 143, action: 0, terminated: False, reward: 35.217452117849724, Trade: 70\n",
      "Step 144, action: 2, terminated: False, reward: 35.207452117849726, Trade: 71\n",
      "Step 145, action: 0, terminated: False, reward: 32.05220596451413, Trade: 72\n",
      "Step 146, action: 0, terminated: False, reward: 32.04220596451413, Trade: 73\n",
      "Step 147, action: 0, terminated: False, reward: 29.964023428363014, Trade: 74\n",
      "Step 148, action: 1, terminated: False, reward: 29.954023428363012, Trade: 74\n",
      "Step 149, action: 1, terminated: False, reward: 29.94402342836301, Trade: 74\n",
      "Step 150, action: 2, terminated: False, reward: 29.93402342836301, Trade: 75\n",
      "Step 151, action: 1, terminated: False, reward: 29.924023428363007, Trade: 75\n",
      "Step 152, action: 1, terminated: False, reward: 29.914023428363006, Trade: 75\n",
      "Step 153, action: 1, terminated: False, reward: 29.904023428363004, Trade: 75\n",
      "Step 154, action: 2, terminated: False, reward: 29.794023428363, Trade: 75\n",
      "Step 155, action: 1, terminated: False, reward: 29.784023428363, Trade: 75\n",
      "Step 156, action: 0, terminated: False, reward: 28.36929940218499, Trade: 76\n",
      "Step 157, action: 1, terminated: False, reward: 28.359299402184988, Trade: 76\n",
      "Step 158, action: 2, terminated: False, reward: 28.349299402184986, Trade: 77\n",
      "Step 159, action: 0, terminated: False, reward: 24.20179927659595, Trade: 78\n",
      "Step 160, action: 2, terminated: False, reward: 24.191799276595948, Trade: 79\n",
      "Step 161, action: 1, terminated: False, reward: 24.181799276595946, Trade: 79\n",
      "Step 162, action: 1, terminated: False, reward: 24.171799276595944, Trade: 79\n",
      "Step 163, action: 0, terminated: False, reward: 28.915772010815314, Trade: 80\n",
      "Step 164, action: 2, terminated: False, reward: 28.905772010815312, Trade: 81\n",
      "Step 165, action: 0, terminated: False, reward: 31.888586410815318, Trade: 82\n",
      "Step 166, action: 0, terminated: False, reward: 31.878586410815316, Trade: 83\n",
      "Step 167, action: 1, terminated: False, reward: 31.868586410815315, Trade: 83\n",
      "Step 168, action: 1, terminated: False, reward: 31.858586410815313, Trade: 83\n",
      "Step 169, action: 1, terminated: False, reward: 31.84858641081531, Trade: 83\n",
      "Step 170, action: 0, terminated: False, reward: 31.66182830591567, Trade: 84\n",
      "Step 171, action: 0, terminated: False, reward: 31.651828305915668, Trade: 85\n",
      "Step 172, action: 0, terminated: False, reward: 33.5276560036696, Trade: 86\n",
      "Step 173, action: 1, terminated: False, reward: 33.5176560036696, Trade: 86\n",
      "Step 174, action: 1, terminated: False, reward: 33.5076560036696, Trade: 86\n",
      "Step 175, action: 1, terminated: False, reward: 33.497656003669604, Trade: 86\n",
      "Step 176, action: 1, terminated: False, reward: 33.487656003669606, Trade: 86\n",
      "Step 177, action: 2, terminated: False, reward: 33.47765600366961, Trade: 87\n",
      "Step 178, action: 1, terminated: False, reward: 33.46765600366961, Trade: 87\n",
      "Step 179, action: 1, terminated: False, reward: 33.45765600366961, Trade: 87\n",
      "Step 180, action: 1, terminated: False, reward: 33.447656003669614, Trade: 87\n",
      "Step 181, action: 1, terminated: False, reward: 33.437656003669616, Trade: 87\n",
      "Step 182, action: 1, terminated: False, reward: 33.42765600366962, Trade: 87\n",
      "Step 183, action: 0, terminated: False, reward: 37.5568312750319, Trade: 88\n",
      "Step 184, action: 0, terminated: False, reward: 37.5468312750319, Trade: 89\n",
      "Step 185, action: 2, terminated: False, reward: 37.4368312750319, Trade: 89\n",
      "Step 186, action: 1, terminated: False, reward: 37.4268312750319, Trade: 89\n",
      "Step 187, action: 1, terminated: False, reward: 37.4168312750319, Trade: 89\n",
      "Step 188, action: 0, terminated: False, reward: 38.44252617184588, Trade: 90\n",
      "Step 189, action: 1, terminated: False, reward: 38.43252617184588, Trade: 90\n",
      "Step 190, action: 1, terminated: False, reward: 38.42252617184588, Trade: 90\n",
      "Step 191, action: 1, terminated: False, reward: 38.41252617184588, Trade: 90\n",
      "Step 192, action: 1, terminated: False, reward: 38.402526171845885, Trade: 90\n",
      "Step 193, action: 1, terminated: False, reward: 38.39252617184589, Trade: 90\n",
      "Step 194, action: 2, terminated: False, reward: 38.38252617184589, Trade: 91\n",
      "Step 195, action: 1, terminated: False, reward: 38.37252617184589, Trade: 91\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,1000):\n",
    "    action = test_train_gym.action_space.sample()\n",
    "    # print(test_train_gym.data)\n",
    "    state,reward,terminal,truncated,info = test_train_gym.step(action)\n",
    "    if terminal:\n",
    "        test_train_gym.reset()\n",
    "    print(f'Step {test_train_gym.row}, action: {action}, terminated: {terminal}, reward: {test_train_gym.reward}, Trade: {test_train_gym.trades}')\n",
    "    # print(f'State:\\n{test_train_gym.state}')\n",
    "    # print(test_train_gym.portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Train DRL Agents\n",
    "* The DRL algorithms are from **Stable Baselines 3**.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define callback function for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional values in tensorboard.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        try:\n",
    "            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n",
    "\n",
    "        except BaseException as error:\n",
    "            try:\n",
    "                self.logger.record(key=\"train/reward\", value=self.locals[\"reward\"][0])\n",
    "\n",
    "            except BaseException as inner_error:\n",
    "                # Handle the case where neither \"rewards\" nor \"reward\" is found\n",
    "                self.logger.record(key=\"train/reward\", value=None)\n",
    "                # Print the original error and the inner error for debugging\n",
    "                print(\"Original Error:\", error)\n",
    "                print(\"Inner Error:\", inner_error)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_kwargs = dict(net_arch=dict(pi=[256, 256], vf=[256, 256]))\n",
    "total_training_step = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for keeping training\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  trained_model\n",
    "except NameError:\n",
    "    print('No any model')\n",
    "else:\n",
    "    print('Ready for keeping training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/test_ppo/ppo_17\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 291        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 3          |\n",
      "|    total_timesteps | 1024       |\n",
      "| train/             |            |\n",
      "|    reward          | -35.431583 |\n",
      "-----------------------------------\n",
      "Episode: 5\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8776162e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.78e+04      |\n",
      "|    n_updates            | 25240         |\n",
      "|    policy_gradient_loss | -6.23e-05     |\n",
      "|    reward               | -0.511473     |\n",
      "|    value_loss           | 5.62e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.672325e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.57e+04     |\n",
      "|    n_updates            | 25250        |\n",
      "|    policy_gradient_loss | -0.00023     |\n",
      "|    reward               | -7.619667    |\n",
      "|    value_loss           | 1.34e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5824568e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.66e+04      |\n",
      "|    n_updates            | 25260         |\n",
      "|    policy_gradient_loss | -5.07e-05     |\n",
      "|    reward               | -61.800602    |\n",
      "|    value_loss           | 1.35e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 6\n",
      "Episode: 7\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 5120          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024624664 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.44e+04      |\n",
      "|    n_updates            | 25270         |\n",
      "|    policy_gradient_loss | -0.000175     |\n",
      "|    reward               | -19.146032    |\n",
      "|    value_loss           | 4.88e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002767747 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.9e+04      |\n",
      "|    n_updates            | 25280        |\n",
      "|    policy_gradient_loss | 0.000166     |\n",
      "|    reward               | -22.302565   |\n",
      "|    value_loss           | 1.18e+05     |\n",
      "------------------------------------------\n",
      "Episode: 8\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 593960.31\n",
      "total_reward: -406039.69\n",
      "total_cost: 1025848.39\n",
      "total_trades: 777\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.165544e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.01e+04     |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -7.47e-05    |\n",
      "|    reward               | -12.351575   |\n",
      "|    value_loss           | 2.02e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.291942e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.68e+05     |\n",
      "|    n_updates            | 25300        |\n",
      "|    policy_gradient_loss | -0.000137    |\n",
      "|    reward               | 31.298805    |\n",
      "|    value_loss           | 5.36e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 9216          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1626515e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+05      |\n",
      "|    n_updates            | 25310         |\n",
      "|    policy_gradient_loss | -6.3e-05      |\n",
      "|    reward               | -32.847458    |\n",
      "|    value_loss           | 2.88e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 9\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 277          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.705066e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.9e+04      |\n",
      "|    n_updates            | 25320        |\n",
      "|    policy_gradient_loss | -0.000121    |\n",
      "|    reward               | -11.7923155  |\n",
      "|    value_loss           | 7.8e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.718479e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.33e+05     |\n",
      "|    n_updates            | 25330        |\n",
      "|    policy_gradient_loss | -0.000169    |\n",
      "|    reward               | -22.947567   |\n",
      "|    value_loss           | 2.66e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 274          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.047728e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.15e+04     |\n",
      "|    n_updates            | 25340        |\n",
      "|    policy_gradient_loss | -1.25e-05    |\n",
      "|    reward               | -58.533875   |\n",
      "|    value_loss           | 4.31e+04     |\n",
      "------------------------------------------\n",
      "Episode: 10\n",
      "Episode: 11\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 273           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 48            |\n",
      "|    total_timesteps      | 13312         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1468226e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.19e+04      |\n",
      "|    n_updates            | 25350         |\n",
      "|    policy_gradient_loss | -3.1e-07      |\n",
      "|    reward               | -24.91046     |\n",
      "|    value_loss           | 1.84e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 271           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 52            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0218937e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0.00265       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.14e+04      |\n",
      "|    n_updates            | 25360         |\n",
      "|    policy_gradient_loss | -1.36e-05     |\n",
      "|    reward               | 7.6189213     |\n",
      "|    value_loss           | 1.43e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 15360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.782023e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.95e+04     |\n",
      "|    n_updates            | 25370        |\n",
      "|    policy_gradient_loss | -3.35e-05    |\n",
      "|    reward               | -27.008196   |\n",
      "|    value_loss           | 1.39e+05     |\n",
      "------------------------------------------\n",
      "Episode: 12\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 660722.74\n",
      "total_reward: -339277.26\n",
      "total_cost: 949789.81\n",
      "total_trades: 711\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 60            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8999285e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.75e+04      |\n",
      "|    n_updates            | 25380         |\n",
      "|    policy_gradient_loss | -0.000112     |\n",
      "|    reward               | -10.344642    |\n",
      "|    value_loss           | 7.5e+04       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.747688e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.95e+04     |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -9.54e-05    |\n",
      "|    reward               | -45.722496   |\n",
      "|    value_loss           | 3.91e+04     |\n",
      "------------------------------------------\n",
      "Episode: 13\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.902843e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.07e+05     |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -5.7e-05     |\n",
      "|    reward               | -33.662003   |\n",
      "|    value_loss           | 2.14e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 19456         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3444689e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.32e+05      |\n",
      "|    n_updates            | 25410         |\n",
      "|    policy_gradient_loss | -7.26e-05     |\n",
      "|    reward               | -41.585518    |\n",
      "|    value_loss           | 4.64e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 271           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 75            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7247235e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.24e+05      |\n",
      "|    n_updates            | 25420         |\n",
      "|    policy_gradient_loss | -4.69e-05     |\n",
      "|    reward               | -70.76926     |\n",
      "|    value_loss           | 2.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 14\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 270            |\n",
      "|    iterations           | 21             |\n",
      "|    time_elapsed         | 79             |\n",
      "|    total_timesteps      | 21504          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.04845385e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.06          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.84e+05       |\n",
      "|    n_updates            | 25430          |\n",
      "|    policy_gradient_loss | -0.000178      |\n",
      "|    reward               | 58.250996      |\n",
      "|    value_loss           | 3.69e+05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.131952e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.24e+05     |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -1.19e-05    |\n",
      "|    reward               | 200.52882    |\n",
      "|    value_loss           | 2.48e+05     |\n",
      "------------------------------------------\n",
      "Episode: 15\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.294255e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.27e+06     |\n",
      "|    n_updates            | 25450        |\n",
      "|    policy_gradient_loss | -3.26e-05    |\n",
      "|    reward               | -1.7219547   |\n",
      "|    value_loss           | 8.55e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 92            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9703446e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.62e+06      |\n",
      "|    n_updates            | 25460         |\n",
      "|    policy_gradient_loss | 6.25e-06      |\n",
      "|    reward               | -27.389044    |\n",
      "|    value_loss           | 1.32e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.471396e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.87e+04     |\n",
      "|    n_updates            | 25470        |\n",
      "|    policy_gradient_loss | -3.7e-05     |\n",
      "|    reward               | -55.405514   |\n",
      "|    value_loss           | 1.17e+05     |\n",
      "------------------------------------------\n",
      "Episode: 16\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1713756.96\n",
      "total_reward: 713756.96\n",
      "total_cost: 715782.82\n",
      "total_trades: 710\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 102           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5615445e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.16e+05      |\n",
      "|    n_updates            | 25480         |\n",
      "|    policy_gradient_loss | 3.23e-05      |\n",
      "|    reward               | 25.0712       |\n",
      "|    value_loss           | 6.33e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 106           |\n",
      "|    total_timesteps      | 27648         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016954564 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.42e+05      |\n",
      "|    n_updates            | 25490         |\n",
      "|    policy_gradient_loss | -0.000242     |\n",
      "|    reward               | -62.565254    |\n",
      "|    value_loss           | 4.84e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 17\n",
      "Episode: 18\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001471666 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.02e+05     |\n",
      "|    n_updates            | 25500        |\n",
      "|    policy_gradient_loss | 0.000378     |\n",
      "|    reward               | -17.03576    |\n",
      "|    value_loss           | 2.05e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 114           |\n",
      "|    total_timesteps      | 29696         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048766384 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.62e+04      |\n",
      "|    n_updates            | 25510         |\n",
      "|    policy_gradient_loss | -0.000387     |\n",
      "|    reward               | -19.150316    |\n",
      "|    value_loss           | 5.25e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006558438 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.42e+04     |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.000795    |\n",
      "|    reward               | -59.037773   |\n",
      "|    value_loss           | 1.09e+05     |\n",
      "------------------------------------------\n",
      "Episode: 19\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.404901e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.02e+05     |\n",
      "|    n_updates            | 25530        |\n",
      "|    policy_gradient_loss | 0.000165     |\n",
      "|    reward               | -23.450119   |\n",
      "|    value_loss           | 2.05e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 125           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3632234e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.37e+04      |\n",
      "|    n_updates            | 25540         |\n",
      "|    policy_gradient_loss | 2.97e-05      |\n",
      "|    reward               | -45.159435    |\n",
      "|    value_loss           | 1.08e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 20\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 795306.57\n",
      "total_reward: -204693.43\n",
      "total_cost: 800574.79\n",
      "total_trades: 781\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 128           |\n",
      "|    total_timesteps      | 33792         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1418243e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.16e+05      |\n",
      "|    n_updates            | 25550         |\n",
      "|    policy_gradient_loss | 1.22e-06      |\n",
      "|    reward               | -5.2860584    |\n",
      "|    value_loss           | 2.33e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 132           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4752226e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.68e+05      |\n",
      "|    n_updates            | 25560         |\n",
      "|    policy_gradient_loss | -2.01e-05     |\n",
      "|    reward               | -39.761566    |\n",
      "|    value_loss           | 1.14e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.936739e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.04e+04     |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.000107    |\n",
      "|    reward               | 27.20861     |\n",
      "|    value_loss           | 8.2e+04      |\n",
      "------------------------------------------\n",
      "Episode: 21\n",
      "Episode: 22\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7779176e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.38e+04      |\n",
      "|    n_updates            | 25580         |\n",
      "|    policy_gradient_loss | 1.85e-05      |\n",
      "|    reward               | 1.8659197     |\n",
      "|    value_loss           | 6.76e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 143           |\n",
      "|    total_timesteps      | 37888         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0444326e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.01e+04      |\n",
      "|    n_updates            | 25590         |\n",
      "|    policy_gradient_loss | -0.000382     |\n",
      "|    reward               | -44.082474    |\n",
      "|    value_loss           | 1.6e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 23\n",
      "Episode: 24\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699924.50\n",
      "total_reward: -300075.50\n",
      "total_cost: 87224.02\n",
      "total_trades: 97\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 146           |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026393915 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.43e+04      |\n",
      "|    n_updates            | 25600         |\n",
      "|    policy_gradient_loss | -0.000395     |\n",
      "|    reward               | -16.670094    |\n",
      "|    value_loss           | 6.86e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 25\n",
      "Episode: 26\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001730618 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.04e+05     |\n",
      "|    n_updates            | 25610        |\n",
      "|    policy_gradient_loss | -0.000105    |\n",
      "|    reward               | -23.799475   |\n",
      "|    value_loss           | 2.09e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 265           |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032059057 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.27e+04      |\n",
      "|    n_updates            | 25620         |\n",
      "|    policy_gradient_loss | -0.000418     |\n",
      "|    reward               | -75.3387      |\n",
      "|    value_loss           | 2.54e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 265           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 158           |\n",
      "|    total_timesteps      | 41984         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031947723 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.94e+05      |\n",
      "|    n_updates            | 25630         |\n",
      "|    policy_gradient_loss | -0.000367     |\n",
      "|    reward               | -18.005028    |\n",
      "|    value_loss           | 5.9e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 27\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 265           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 161           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8160477e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.3e+05       |\n",
      "|    n_updates            | 25640         |\n",
      "|    policy_gradient_loss | 0.000129      |\n",
      "|    reward               | 21.368439     |\n",
      "|    value_loss           | 8.65e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 166           |\n",
      "|    total_timesteps      | 44032         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020969426 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+04      |\n",
      "|    n_updates            | 25650         |\n",
      "|    policy_gradient_loss | -0.000434     |\n",
      "|    reward               | -4.352722     |\n",
      "|    value_loss           | 4.91e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 28\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1824538.65\n",
      "total_reward: 824538.65\n",
      "total_cost: 1096180.94\n",
      "total_trades: 696\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 170           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030062976 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.88e+05      |\n",
      "|    n_updates            | 25660         |\n",
      "|    policy_gradient_loss | -0.000313     |\n",
      "|    reward               | -7.0751867    |\n",
      "|    value_loss           | 5.77e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 174           |\n",
      "|    total_timesteps      | 46080         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6811944e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.95e+04      |\n",
      "|    n_updates            | 25670         |\n",
      "|    policy_gradient_loss | 8.93e-05      |\n",
      "|    reward               | 17.07206      |\n",
      "|    value_loss           | 7.92e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 264            |\n",
      "|    iterations           | 46             |\n",
      "|    time_elapsed         | 178            |\n",
      "|    total_timesteps      | 47104          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.50901615e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.04          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 2.54e+04       |\n",
      "|    n_updates            | 25680          |\n",
      "|    policy_gradient_loss | -3.64e-05      |\n",
      "|    reward               | 32.384727      |\n",
      "|    value_loss           | 5.09e+04       |\n",
      "--------------------------------------------\n",
      "Episode: 29\n",
      "Episode: 30\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 181           |\n",
      "|    total_timesteps      | 48128         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9983577e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.96e+05      |\n",
      "|    n_updates            | 25690         |\n",
      "|    policy_gradient_loss | 2.09e-05      |\n",
      "|    reward               | 8.011548      |\n",
      "|    value_loss           | 9.92e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 264           |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 185           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4790947e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.534         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.56e+05      |\n",
      "|    n_updates            | 25700         |\n",
      "|    policy_gradient_loss | -8.58e-05     |\n",
      "|    reward               | 57.200905     |\n",
      "|    value_loss           | 3.13e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 265           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 189           |\n",
      "|    total_timesteps      | 50176         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7795363e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -0.186        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.54e+05      |\n",
      "|    n_updates            | 25710         |\n",
      "|    policy_gradient_loss | -9.28e-05     |\n",
      "|    reward               | 110.37984     |\n",
      "|    value_loss           | 9.07e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 31\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 265           |\n",
      "|    iterations           | 50            |\n",
      "|    time_elapsed         | 192           |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0614624e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.86e+05      |\n",
      "|    n_updates            | 25720         |\n",
      "|    policy_gradient_loss | -7.4e-05      |\n",
      "|    reward               | 68.616776     |\n",
      "|    value_loss           | 9.72e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 265           |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 196           |\n",
      "|    total_timesteps      | 52224         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7294154e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.87e+06      |\n",
      "|    n_updates            | 25730         |\n",
      "|    policy_gradient_loss | -1.7e-05      |\n",
      "|    reward               | -8.83446      |\n",
      "|    value_loss           | 3.74e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 200           |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9379153e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.55e+05      |\n",
      "|    n_updates            | 25740         |\n",
      "|    policy_gradient_loss | -3.23e-05     |\n",
      "|    reward               | -69.73131     |\n",
      "|    value_loss           | 3.1e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 32\n",
      "Current company: ['IBM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1086174.25\n",
      "total_reward: 86174.25\n",
      "total_cost: 974633.89\n",
      "total_trades: 730\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.611021e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.39e+05     |\n",
      "|    n_updates            | 25750        |\n",
      "|    policy_gradient_loss | -9.4e-06     |\n",
      "|    reward               | -42.074577   |\n",
      "|    value_loss           | 6.79e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.183974e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.1e+04      |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -1.8e-06     |\n",
      "|    reward               | -43.644524   |\n",
      "|    value_loss           | 1.22e+05     |\n",
      "------------------------------------------\n",
      "Episode: 33\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 267           |\n",
      "|    iterations           | 55            |\n",
      "|    time_elapsed         | 210           |\n",
      "|    total_timesteps      | 56320         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3317913e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.74e+05      |\n",
      "|    n_updates            | 25770         |\n",
      "|    policy_gradient_loss | -1.18e-05     |\n",
      "|    reward               | 5.8810797     |\n",
      "|    value_loss           | 3.48e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.943569e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.27e+05     |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -8.8e-06     |\n",
      "|    reward               | 33.905563    |\n",
      "|    value_loss           | 6.54e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.269699e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51e+05     |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -5.08e-05    |\n",
      "|    reward               | -14.006212   |\n",
      "|    value_loss           | 3.03e+05     |\n",
      "------------------------------------------\n",
      "Episode: 34\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.745997e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.07e+04     |\n",
      "|    n_updates            | 25800        |\n",
      "|    policy_gradient_loss | -0.000126    |\n",
      "|    reward               | -0.16480725  |\n",
      "|    value_loss           | 1.01e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 269           |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 224           |\n",
      "|    total_timesteps      | 60416         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5129716e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.51e+05      |\n",
      "|    n_updates            | 25810         |\n",
      "|    policy_gradient_loss | 8.62e-05      |\n",
      "|    reward               | -36.87923     |\n",
      "|    value_loss           | 1.9e+06       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 269           |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 227           |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4522305e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.99e+04      |\n",
      "|    n_updates            | 25820         |\n",
      "|    policy_gradient_loss | -1.12e-05     |\n",
      "|    reward               | -62.41749     |\n",
      "|    value_loss           | 9.97e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 35\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 231           |\n",
      "|    total_timesteps      | 62464         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9712177e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.45e+05      |\n",
      "|    n_updates            | 25830         |\n",
      "|    policy_gradient_loss | -6.1e-05      |\n",
      "|    reward               | 29.926527     |\n",
      "|    value_loss           | 6.9e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 62            |\n",
      "|    time_elapsed         | 234           |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0089134e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.48e+05      |\n",
      "|    n_updates            | 25840         |\n",
      "|    policy_gradient_loss | 9.96e-06      |\n",
      "|    reward               | 117.883484    |\n",
      "|    value_loss           | 6.96e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 36\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4575104.69\n",
      "total_reward: 3575104.69\n",
      "total_cost: 1614986.66\n",
      "total_trades: 717\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 271           |\n",
      "|    iterations           | 63            |\n",
      "|    time_elapsed         | 238           |\n",
      "|    total_timesteps      | 64512         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0850136e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.89e+05      |\n",
      "|    n_updates            | 25850         |\n",
      "|    policy_gradient_loss | -1.48e-05     |\n",
      "|    reward               | -14.277957    |\n",
      "|    value_loss           | 1.78e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 271           |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 241           |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5832484e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.19e+06      |\n",
      "|    n_updates            | 25860         |\n",
      "|    policy_gradient_loss | 6.12e-06      |\n",
      "|    reward               | -37.206707    |\n",
      "|    value_loss           | 8.37e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 66560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.569686e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.38e+04     |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -1.98e-05    |\n",
      "|    reward               | -16.119438   |\n",
      "|    value_loss           | 1.28e+05     |\n",
      "------------------------------------------\n",
      "Episode: 37\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 272           |\n",
      "|    iterations           | 66            |\n",
      "|    time_elapsed         | 248           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7577702e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.35e+04      |\n",
      "|    n_updates            | 25880         |\n",
      "|    policy_gradient_loss | -3.55e-05     |\n",
      "|    reward               | -19.819588    |\n",
      "|    value_loss           | 1.27e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 272           |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 251           |\n",
      "|    total_timesteps      | 68608         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3339194e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.87e+04      |\n",
      "|    n_updates            | 25890         |\n",
      "|    policy_gradient_loss | -0.000105     |\n",
      "|    reward               | -22.00243     |\n",
      "|    value_loss           | 5.74e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 272           |\n",
      "|    iterations           | 68            |\n",
      "|    time_elapsed         | 255           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3712346e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.33e+04      |\n",
      "|    n_updates            | 25900         |\n",
      "|    policy_gradient_loss | 0.000105      |\n",
      "|    reward               | 8.922945      |\n",
      "|    value_loss           | 1.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 38\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.886969e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.24e+04     |\n",
      "|    n_updates            | 25910        |\n",
      "|    policy_gradient_loss | -0.000277    |\n",
      "|    reward               | -21.824472   |\n",
      "|    value_loss           | 8.48e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 273           |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 262           |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8155914e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.59e+04      |\n",
      "|    n_updates            | 25920         |\n",
      "|    policy_gradient_loss | 3.75e-05      |\n",
      "|    reward               | -23.413246    |\n",
      "|    value_loss           | 9.19e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 39\n",
      "Episode: 40\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 690279.63\n",
      "total_reward: -309720.37\n",
      "total_cost: 50664.17\n",
      "total_trades: 59\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 273           |\n",
      "|    iterations           | 71            |\n",
      "|    time_elapsed         | 265           |\n",
      "|    total_timesteps      | 72704         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3761455e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.31e+04      |\n",
      "|    n_updates            | 25930         |\n",
      "|    policy_gradient_loss | 1.11e-05      |\n",
      "|    reward               | -14.785527    |\n",
      "|    value_loss           | 1.86e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.310882e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.06e+04     |\n",
      "|    n_updates            | 25940        |\n",
      "|    policy_gradient_loss | -7.88e-06    |\n",
      "|    reward               | 2.666421     |\n",
      "|    value_loss           | 1.81e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 274           |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 272           |\n",
      "|    total_timesteps      | 74752         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040714716 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75e+04      |\n",
      "|    n_updates            | 25950         |\n",
      "|    policy_gradient_loss | -0.000798     |\n",
      "|    reward               | -70.63901     |\n",
      "|    value_loss           | 3.51e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 41\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 274           |\n",
      "|    iterations           | 74            |\n",
      "|    time_elapsed         | 276           |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043299975 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+05      |\n",
      "|    n_updates            | 25960         |\n",
      "|    policy_gradient_loss | 0.000463      |\n",
      "|    reward               | 2.7995481     |\n",
      "|    value_loss           | 2.77e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 274          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.157414e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.84e+05     |\n",
      "|    n_updates            | 25970        |\n",
      "|    policy_gradient_loss | -2.03e-05    |\n",
      "|    reward               | 60.13232     |\n",
      "|    value_loss           | 7.68e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 274           |\n",
      "|    iterations           | 76            |\n",
      "|    time_elapsed         | 283           |\n",
      "|    total_timesteps      | 77824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8405262e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01e+05      |\n",
      "|    n_updates            | 25980         |\n",
      "|    policy_gradient_loss | 3.27e-05      |\n",
      "|    reward               | 41.683994     |\n",
      "|    value_loss           | 2.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 42\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 274           |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 287           |\n",
      "|    total_timesteps      | 78848         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4086635e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.88e+05      |\n",
      "|    n_updates            | 25990         |\n",
      "|    policy_gradient_loss | 2.1e-07       |\n",
      "|    reward               | 3.9313648     |\n",
      "|    value_loss           | 1.18e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 43\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 274           |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 290           |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6313355e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.73e+05      |\n",
      "|    n_updates            | 26000         |\n",
      "|    policy_gradient_loss | -4.21e-05     |\n",
      "|    reward               | -18.277676    |\n",
      "|    value_loss           | 3.45e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 275           |\n",
      "|    iterations           | 79            |\n",
      "|    time_elapsed         | 294           |\n",
      "|    total_timesteps      | 80896         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025888404 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.31e+04      |\n",
      "|    n_updates            | 26010         |\n",
      "|    policy_gradient_loss | -0.000277     |\n",
      "|    reward               | 41.733223     |\n",
      "|    value_loss           | 1.06e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 297          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005638015 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.89e+04     |\n",
      "|    n_updates            | 26020        |\n",
      "|    policy_gradient_loss | -0.000432    |\n",
      "|    reward               | -56.30911    |\n",
      "|    value_loss           | 1.18e+05     |\n",
      "------------------------------------------\n",
      "Episode: 44\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1078358.31\n",
      "total_reward: 78358.31\n",
      "total_cost: 1030964.07\n",
      "total_trades: 801\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 275           |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 301           |\n",
      "|    total_timesteps      | 82944         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061357184 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.96e+04      |\n",
      "|    n_updates            | 26030         |\n",
      "|    policy_gradient_loss | 0.00053       |\n",
      "|    reward               | -5.21814      |\n",
      "|    value_loss           | 1.39e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 275           |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 304           |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5745128e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+05      |\n",
      "|    n_updates            | 26040         |\n",
      "|    policy_gradient_loss | -0.000206     |\n",
      "|    reward               | -55.812843    |\n",
      "|    value_loss           | 3.23e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 45\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 308          |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.693947e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.37e+05     |\n",
      "|    n_updates            | 26050        |\n",
      "|    policy_gradient_loss | 8.79e-05     |\n",
      "|    reward               | 3.130029     |\n",
      "|    value_loss           | 2.73e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.113391e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.1e+05      |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.000124    |\n",
      "|    reward               | -9.2221575   |\n",
      "|    value_loss           | 6.21e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 87040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.785348e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.74e+04     |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -4.42e-05    |\n",
      "|    reward               | 26.389305    |\n",
      "|    value_loss           | 7.48e+04     |\n",
      "------------------------------------------\n",
      "Episode: 46\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 275           |\n",
      "|    iterations           | 86            |\n",
      "|    time_elapsed         | 319           |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012495043 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.57e+04      |\n",
      "|    n_updates            | 26080         |\n",
      "|    policy_gradient_loss | -0.000107     |\n",
      "|    reward               | -11.523029    |\n",
      "|    value_loss           | 5.15e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 322          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.168634e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.44e+04     |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -1.55e-05    |\n",
      "|    reward               | -51.56881    |\n",
      "|    value_loss           | 1.09e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 326           |\n",
      "|    total_timesteps      | 90112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0041654e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.52e+04      |\n",
      "|    n_updates            | 26100         |\n",
      "|    policy_gradient_loss | -7.39e-06     |\n",
      "|    reward               | -51.91415     |\n",
      "|    value_loss           | 9.05e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 47\n",
      "Episode: 48\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694844.76\n",
      "total_reward: -305155.24\n",
      "total_cost: 43909.65\n",
      "total_trades: 49\n",
      "=================================\n",
      "Episode: 49\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 89            |\n",
      "|    time_elapsed         | 329           |\n",
      "|    total_timesteps      | 91136         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4133783e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.43e+05      |\n",
      "|    n_updates            | 26110         |\n",
      "|    policy_gradient_loss | -6.39e-05     |\n",
      "|    reward               | -0.02893041   |\n",
      "|    value_loss           | 4.87e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 333          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.462083e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.31e+04     |\n",
      "|    n_updates            | 26120        |\n",
      "|    policy_gradient_loss | -3.15e-05    |\n",
      "|    reward               | -18.62788    |\n",
      "|    value_loss           | 1.26e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 91            |\n",
      "|    time_elapsed         | 336           |\n",
      "|    total_timesteps      | 93184         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7422892e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.07e+04      |\n",
      "|    n_updates            | 26130         |\n",
      "|    policy_gradient_loss | -5.2e-05      |\n",
      "|    reward               | -52.16317     |\n",
      "|    value_loss           | 4.15e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 50\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 92            |\n",
      "|    time_elapsed         | 340           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.8907975e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+05      |\n",
      "|    n_updates            | 26140         |\n",
      "|    policy_gradient_loss | -1.75e-06     |\n",
      "|    reward               | 10.576039     |\n",
      "|    value_loss           | 3.24e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 93            |\n",
      "|    time_elapsed         | 343           |\n",
      "|    total_timesteps      | 95232         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5807163e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 26150         |\n",
      "|    policy_gradient_loss | -9.29e-05     |\n",
      "|    reward               | 119.78289     |\n",
      "|    value_loss           | 2.46e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 94            |\n",
      "|    time_elapsed         | 347           |\n",
      "|    total_timesteps      | 96256         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5035621e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.12e+05      |\n",
      "|    n_updates            | 26160         |\n",
      "|    policy_gradient_loss | -1.97e-05     |\n",
      "|    reward               | 109.19585     |\n",
      "|    value_loss           | 1.62e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 51\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 352           |\n",
      "|    total_timesteps      | 97280         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1441374e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.84e+06      |\n",
      "|    n_updates            | 26170         |\n",
      "|    policy_gradient_loss | 1.05e-05      |\n",
      "|    reward               | -29.7328      |\n",
      "|    value_loss           | 5.67e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 355          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.469774e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.99e+05     |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -5.08e-05    |\n",
      "|    reward               | -55.10549    |\n",
      "|    value_loss           | 7.98e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 97            |\n",
      "|    time_elapsed         | 359           |\n",
      "|    total_timesteps      | 99328         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6379434e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.06e+05      |\n",
      "|    n_updates            | 26190         |\n",
      "|    policy_gradient_loss | -2.08e-05     |\n",
      "|    reward               | -113.87187    |\n",
      "|    value_loss           | 6.12e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 52\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 794542.68\n",
      "total_reward: -205457.32\n",
      "total_cost: 727002.87\n",
      "total_trades: 735\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 362          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.685173e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.45e+05     |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | 3.99e-06     |\n",
      "|    reward               | 67.81854     |\n",
      "|    value_loss           | 8.91e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 99            |\n",
      "|    time_elapsed         | 366           |\n",
      "|    total_timesteps      | 101376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0617077e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.42e+05      |\n",
      "|    n_updates            | 26210         |\n",
      "|    policy_gradient_loss | -6.52e-06     |\n",
      "|    reward               | 90.27439      |\n",
      "|    value_loss           | 2.84e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 53\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 100           |\n",
      "|    time_elapsed         | 369           |\n",
      "|    total_timesteps      | 102400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1775486e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.47e+05      |\n",
      "|    n_updates            | 26220         |\n",
      "|    policy_gradient_loss | 1.23e-06      |\n",
      "|    reward               | 1.9978406     |\n",
      "|    value_loss           | 8.95e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 103424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.02797e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.17       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.74e+05    |\n",
      "|    n_updates            | 26230       |\n",
      "|    policy_gradient_loss | -3.51e-05   |\n",
      "|    reward               | 11.756641   |\n",
      "|    value_loss           | 1.95e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 277          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.856579e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.11e+04     |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -6.97e-05    |\n",
      "|    reward               | -55.33182    |\n",
      "|    value_loss           | 6.24e+04     |\n",
      "------------------------------------------\n",
      "Episode: 54\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 105472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.28188e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42e+05    |\n",
      "|    n_updates            | 26250       |\n",
      "|    policy_gradient_loss | -0.000139   |\n",
      "|    reward               | -27.031506  |\n",
      "|    value_loss           | 2.83e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 104           |\n",
      "|    time_elapsed         | 383           |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038645673 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.5e+05       |\n",
      "|    n_updates            | 26260         |\n",
      "|    policy_gradient_loss | -0.000588     |\n",
      "|    reward               | -54.379787    |\n",
      "|    value_loss           | 5e+05         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 105           |\n",
      "|    time_elapsed         | 387           |\n",
      "|    total_timesteps      | 107520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033312407 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.51e+05      |\n",
      "|    n_updates            | 26270         |\n",
      "|    policy_gradient_loss | -5.1e-05      |\n",
      "|    reward               | -17.234093    |\n",
      "|    value_loss           | 3.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 55\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 277          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 391          |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.691803e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.09e+04     |\n",
      "|    n_updates            | 26280        |\n",
      "|    policy_gradient_loss | -0.000247    |\n",
      "|    reward               | 96.63054     |\n",
      "|    value_loss           | 1.02e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 277          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 394          |\n",
      "|    total_timesteps      | 109568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.962285e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.072       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.01e+05     |\n",
      "|    n_updates            | 26290        |\n",
      "|    policy_gradient_loss | 1.15e-05     |\n",
      "|    reward               | 32.71455     |\n",
      "|    value_loss           | 8.02e+05     |\n",
      "------------------------------------------\n",
      "Episode: 56\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4231775.65\n",
      "total_reward: 3231775.65\n",
      "total_cost: 1568017.20\n",
      "total_trades: 861\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 108           |\n",
      "|    time_elapsed         | 398           |\n",
      "|    total_timesteps      | 110592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9269006e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.66e+05      |\n",
      "|    n_updates            | 26300         |\n",
      "|    policy_gradient_loss | -0.000273     |\n",
      "|    reward               | -0.43215075   |\n",
      "|    value_loss           | 1.13e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 109           |\n",
      "|    time_elapsed         | 402           |\n",
      "|    total_timesteps      | 111616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0444259e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -0.00484      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.31e+06      |\n",
      "|    n_updates            | 26310         |\n",
      "|    policy_gradient_loss | -8.28e-05     |\n",
      "|    reward               | 50.715546     |\n",
      "|    value_loss           | 2.63e+06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.69541e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.44e+04    |\n",
      "|    n_updates            | 26320       |\n",
      "|    policy_gradient_loss | -0.000131   |\n",
      "|    reward               | 90.76635    |\n",
      "|    value_loss           | 1.29e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 57\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 111           |\n",
      "|    time_elapsed         | 409           |\n",
      "|    total_timesteps      | 113664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3729383e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.075        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.31e+05      |\n",
      "|    n_updates            | 26330         |\n",
      "|    policy_gradient_loss | -3.52e-06     |\n",
      "|    reward               | -28.198997    |\n",
      "|    value_loss           | 1.47e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 58\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 112           |\n",
      "|    time_elapsed         | 412           |\n",
      "|    total_timesteps      | 114688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1394808e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 0.505         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.82e+05      |\n",
      "|    n_updates            | 26340         |\n",
      "|    policy_gradient_loss | -3.11e-05     |\n",
      "|    reward               | 20.450308     |\n",
      "|    value_loss           | 1.97e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 113           |\n",
      "|    time_elapsed         | 416           |\n",
      "|    total_timesteps      | 115712        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3847137e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.13e+04      |\n",
      "|    n_updates            | 26350         |\n",
      "|    policy_gradient_loss | -6.98e-05     |\n",
      "|    reward               | 40.990875     |\n",
      "|    value_loss           | 1.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 59\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 114           |\n",
      "|    time_elapsed         | 419           |\n",
      "|    total_timesteps      | 116736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1590193e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.55e+04      |\n",
      "|    n_updates            | 26360         |\n",
      "|    policy_gradient_loss | 1.83e-05      |\n",
      "|    reward               | -18.328424    |\n",
      "|    value_loss           | 1.71e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 115           |\n",
      "|    time_elapsed         | 423           |\n",
      "|    total_timesteps      | 117760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7778594e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.66e+05      |\n",
      "|    n_updates            | 26370         |\n",
      "|    policy_gradient_loss | -6.9e-05      |\n",
      "|    reward               | -35.69945     |\n",
      "|    value_loss           | 5.35e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 116           |\n",
      "|    time_elapsed         | 427           |\n",
      "|    total_timesteps      | 118784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3922413e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.86e+04      |\n",
      "|    n_updates            | 26380         |\n",
      "|    policy_gradient_loss | -1.23e-05     |\n",
      "|    reward               | -90.350555    |\n",
      "|    value_loss           | 5.72e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 60\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999898.01\n",
      "total_reward: -101.99\n",
      "total_cost: 744832.27\n",
      "total_trades: 767\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 117           |\n",
      "|    time_elapsed         | 430           |\n",
      "|    total_timesteps      | 119808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1601369e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.24e+05      |\n",
      "|    n_updates            | 26390         |\n",
      "|    policy_gradient_loss | 4.17e-06      |\n",
      "|    reward               | -2.202041     |\n",
      "|    value_loss           | 8.49e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 118           |\n",
      "|    time_elapsed         | 434           |\n",
      "|    total_timesteps      | 120832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3624085e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.87e+05      |\n",
      "|    n_updates            | 26400         |\n",
      "|    policy_gradient_loss | -1.98e-05     |\n",
      "|    reward               | -31.672295    |\n",
      "|    value_loss           | 9.74e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 119           |\n",
      "|    time_elapsed         | 438           |\n",
      "|    total_timesteps      | 121856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015965651 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.16e+04      |\n",
      "|    n_updates            | 26410         |\n",
      "|    policy_gradient_loss | -0.000108     |\n",
      "|    reward               | -29.818361    |\n",
      "|    value_loss           | 2.33e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 61\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 120           |\n",
      "|    time_elapsed         | 441           |\n",
      "|    total_timesteps      | 122880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012746238 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.79e+04      |\n",
      "|    n_updates            | 26420         |\n",
      "|    policy_gradient_loss | 0.000294      |\n",
      "|    reward               | -4.184551     |\n",
      "|    value_loss           | 1.56e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 62\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 121           |\n",
      "|    time_elapsed         | 445           |\n",
      "|    total_timesteps      | 123904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6559104e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.45e+04      |\n",
      "|    n_updates            | 26430         |\n",
      "|    policy_gradient_loss | -0.000149     |\n",
      "|    reward               | -6.2863593    |\n",
      "|    value_loss           | 1.89e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 278            |\n",
      "|    iterations           | 122            |\n",
      "|    time_elapsed         | 448            |\n",
      "|    total_timesteps      | 124928         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000110461144 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.07          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 5.18e+04       |\n",
      "|    n_updates            | 26440          |\n",
      "|    policy_gradient_loss | -0.000252      |\n",
      "|    reward               | -32.349915     |\n",
      "|    value_loss           | 1.04e+05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 452          |\n",
      "|    total_timesteps      | 125952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.254161e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.32e+04     |\n",
      "|    n_updates            | 26450        |\n",
      "|    policy_gradient_loss | -0.000111    |\n",
      "|    reward               | -87.78622    |\n",
      "|    value_loss           | 6.65e+04     |\n",
      "------------------------------------------\n",
      "Episode: 63\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 124           |\n",
      "|    time_elapsed         | 456           |\n",
      "|    total_timesteps      | 126976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7668779e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5e+05         |\n",
      "|    n_updates            | 26460         |\n",
      "|    policy_gradient_loss | -0.000116     |\n",
      "|    reward               | -15.710709    |\n",
      "|    value_loss           | 1e+06         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 125           |\n",
      "|    time_elapsed         | 459           |\n",
      "|    total_timesteps      | 128000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4471463e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.27e+05      |\n",
      "|    n_updates            | 26470         |\n",
      "|    policy_gradient_loss | -4.82e-05     |\n",
      "|    reward               | -26.255127    |\n",
      "|    value_loss           | 6.54e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 126           |\n",
      "|    time_elapsed         | 463           |\n",
      "|    total_timesteps      | 129024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.3344487e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.28e+04      |\n",
      "|    n_updates            | 26480         |\n",
      "|    policy_gradient_loss | -1.18e-05     |\n",
      "|    reward               | -82.8792      |\n",
      "|    value_loss           | 8.58e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 64\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1072139.36\n",
      "total_reward: 72139.36\n",
      "total_cost: 852394.93\n",
      "total_trades: 797\n",
      "=================================\n",
      "Episode: 65\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 127           |\n",
      "|    time_elapsed         | 466           |\n",
      "|    total_timesteps      | 130048        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8952414e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+05      |\n",
      "|    n_updates            | 26490         |\n",
      "|    policy_gradient_loss | 2.02e-05      |\n",
      "|    reward               | -23.509504    |\n",
      "|    value_loss           | 4.46e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 470          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.674287e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.35e+04     |\n",
      "|    n_updates            | 26500        |\n",
      "|    policy_gradient_loss | -0.000107    |\n",
      "|    reward               | -52.55291    |\n",
      "|    value_loss           | 1.87e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 129           |\n",
      "|    time_elapsed         | 474           |\n",
      "|    total_timesteps      | 132096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8779305e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 26510         |\n",
      "|    policy_gradient_loss | -7.45e-06     |\n",
      "|    reward               | -46.96489     |\n",
      "|    value_loss           | 2.47e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 66\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 130           |\n",
      "|    time_elapsed         | 478           |\n",
      "|    total_timesteps      | 133120        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9597736e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.75e+05      |\n",
      "|    n_updates            | 26520         |\n",
      "|    policy_gradient_loss | -7.5e-05      |\n",
      "|    reward               | -3.312793     |\n",
      "|    value_loss           | 5.51e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 131           |\n",
      "|    time_elapsed         | 483           |\n",
      "|    total_timesteps      | 134144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9220246e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.22e+04      |\n",
      "|    n_updates            | 26530         |\n",
      "|    policy_gradient_loss | 3.39e-06      |\n",
      "|    reward               | 17.794954     |\n",
      "|    value_loss           | 1.85e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 67\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 132           |\n",
      "|    time_elapsed         | 487           |\n",
      "|    total_timesteps      | 135168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3690093e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.22e+05      |\n",
      "|    n_updates            | 26540         |\n",
      "|    policy_gradient_loss | -0.000113     |\n",
      "|    reward               | 13.979295     |\n",
      "|    value_loss           | 2.44e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 68\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1693418.08\n",
      "total_reward: 693418.08\n",
      "total_cost: 83456.71\n",
      "total_trades: 73\n",
      "=================================\n",
      "Episode: 69\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 277          |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 491          |\n",
      "|    total_timesteps      | 136192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.391659e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.01e+05     |\n",
      "|    n_updates            | 26550        |\n",
      "|    policy_gradient_loss | -1.16e-05    |\n",
      "|    reward               | -4.4898696   |\n",
      "|    value_loss           | 2.03e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003992959 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21e+04    |\n",
      "|    n_updates            | 26560       |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    reward               | -35.397602  |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 70\n",
      "Episode: 71\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 135           |\n",
      "|    time_elapsed         | 498           |\n",
      "|    total_timesteps      | 138240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024191238 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.28e+04      |\n",
      "|    n_updates            | 26570         |\n",
      "|    policy_gradient_loss | 0.000574      |\n",
      "|    reward               | -10.867725    |\n",
      "|    value_loss           | 8.56e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 136           |\n",
      "|    time_elapsed         | 501           |\n",
      "|    total_timesteps      | 139264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3802505e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+05      |\n",
      "|    n_updates            | 26580         |\n",
      "|    policy_gradient_loss | 1.82e-05      |\n",
      "|    reward               | 137.43895     |\n",
      "|    value_loss           | 2.98e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 137           |\n",
      "|    time_elapsed         | 505           |\n",
      "|    total_timesteps      | 140288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7451897e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.18e+06      |\n",
      "|    n_updates            | 26590         |\n",
      "|    policy_gradient_loss | -3.17e-05     |\n",
      "|    reward               | 151.97821     |\n",
      "|    value_loss           | 2.36e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 72\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2747298.86\n",
      "total_reward: 1747298.86\n",
      "total_cost: 1742623.75\n",
      "total_trades: 748\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 138           |\n",
      "|    time_elapsed         | 509           |\n",
      "|    total_timesteps      | 141312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8508872e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.24e+06      |\n",
      "|    n_updates            | 26600         |\n",
      "|    policy_gradient_loss | -4.73e-05     |\n",
      "|    reward               | -17.170614    |\n",
      "|    value_loss           | 8.48e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 73\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 139           |\n",
      "|    time_elapsed         | 512           |\n",
      "|    total_timesteps      | 142336        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6019053e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.11e+06      |\n",
      "|    n_updates            | 26610         |\n",
      "|    policy_gradient_loss | -1.36e-05     |\n",
      "|    reward               | 6.545459      |\n",
      "|    value_loss           | 2.21e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 140           |\n",
      "|    time_elapsed         | 516           |\n",
      "|    total_timesteps      | 143360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037433393 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.54e+04      |\n",
      "|    n_updates            | 26620         |\n",
      "|    policy_gradient_loss | -0.000295     |\n",
      "|    reward               | 37.248016     |\n",
      "|    value_loss           | 5.08e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 74\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 141           |\n",
      "|    time_elapsed         | 519           |\n",
      "|    total_timesteps      | 144384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037671183 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.74e+05      |\n",
      "|    n_updates            | 26630         |\n",
      "|    policy_gradient_loss | 7.4e-05       |\n",
      "|    reward               | -13.839767    |\n",
      "|    value_loss           | 3.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 75\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 277           |\n",
      "|    iterations           | 142           |\n",
      "|    time_elapsed         | 523           |\n",
      "|    total_timesteps      | 145408        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1009043e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.7e+05       |\n",
      "|    n_updates            | 26640         |\n",
      "|    policy_gradient_loss | -2.32e-05     |\n",
      "|    reward               | -14.957789    |\n",
      "|    value_loss           | 1.34e+06      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 278            |\n",
      "|    iterations           | 143            |\n",
      "|    time_elapsed         | 526            |\n",
      "|    total_timesteps      | 146432         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.14871655e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.05          |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 7.04e+04       |\n",
      "|    n_updates            | 26650          |\n",
      "|    policy_gradient_loss | -4.11e-05      |\n",
      "|    reward               | 40.569225      |\n",
      "|    value_loss           | 1.41e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 144           |\n",
      "|    time_elapsed         | 529           |\n",
      "|    total_timesteps      | 147456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5745477e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.4e+04       |\n",
      "|    n_updates            | 26660         |\n",
      "|    policy_gradient_loss | -0.000186     |\n",
      "|    reward               | -15.009943    |\n",
      "|    value_loss           | 6.81e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 76\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1697897.33\n",
      "total_reward: 697897.33\n",
      "total_cost: 946819.64\n",
      "total_trades: 698\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 145           |\n",
      "|    time_elapsed         | 533           |\n",
      "|    total_timesteps      | 148480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4084987e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.5e+04       |\n",
      "|    n_updates            | 26670         |\n",
      "|    policy_gradient_loss | -6.32e-05     |\n",
      "|    reward               | -0.69332963   |\n",
      "|    value_loss           | 1.3e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 536          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.397976e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.37e+04     |\n",
      "|    n_updates            | 26680        |\n",
      "|    policy_gradient_loss | -1.24e-05    |\n",
      "|    reward               | 67.20542     |\n",
      "|    value_loss           | 1.08e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 147           |\n",
      "|    time_elapsed         | 540           |\n",
      "|    total_timesteps      | 150528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0860793e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.8e+05       |\n",
      "|    n_updates            | 26690         |\n",
      "|    policy_gradient_loss | -3.47e-05     |\n",
      "|    reward               | 80.63717      |\n",
      "|    value_loss           | 7.6e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 77\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 148           |\n",
      "|    time_elapsed         | 543           |\n",
      "|    total_timesteps      | 151552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2485037e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.08e+05      |\n",
      "|    n_updates            | 26700         |\n",
      "|    policy_gradient_loss | -1.45e-05     |\n",
      "|    reward               | -35.385403    |\n",
      "|    value_loss           | 1.82e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 149           |\n",
      "|    time_elapsed         | 547           |\n",
      "|    total_timesteps      | 152576        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7631915e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.27e+05      |\n",
      "|    n_updates            | 26710         |\n",
      "|    policy_gradient_loss | -8.08e-05     |\n",
      "|    reward               | -8.6856365    |\n",
      "|    value_loss           | 4.55e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 78\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 150           |\n",
      "|    time_elapsed         | 550           |\n",
      "|    total_timesteps      | 153600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4661458e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.86e+04      |\n",
      "|    n_updates            | 26720         |\n",
      "|    policy_gradient_loss | -0.000121     |\n",
      "|    reward               | 7.3879185     |\n",
      "|    value_loss           | 5.72e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 151           |\n",
      "|    time_elapsed         | 554           |\n",
      "|    total_timesteps      | 154624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9964256e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -0.0237       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.43e+05      |\n",
      "|    n_updates            | 26730         |\n",
      "|    policy_gradient_loss | 1.37e-05      |\n",
      "|    reward               | 42.857025     |\n",
      "|    value_loss           | 2.86e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 557          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.602872e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.29e+05     |\n",
      "|    n_updates            | 26740        |\n",
      "|    policy_gradient_loss | -4.3e-05     |\n",
      "|    reward               | 100.56386    |\n",
      "|    value_loss           | 6.78e+05     |\n",
      "------------------------------------------\n",
      "Episode: 79\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 153           |\n",
      "|    time_elapsed         | 561           |\n",
      "|    total_timesteps      | 156672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6589183e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.441        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.17e+05      |\n",
      "|    n_updates            | 26750         |\n",
      "|    policy_gradient_loss | -1.54e-05     |\n",
      "|    reward               | -23.01952     |\n",
      "|    value_loss           | 6.74e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 154           |\n",
      "|    time_elapsed         | 564           |\n",
      "|    total_timesteps      | 157696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7695129e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.494         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.76e+05      |\n",
      "|    n_updates            | 26760         |\n",
      "|    policy_gradient_loss | -9.32e-06     |\n",
      "|    reward               | -51.61569     |\n",
      "|    value_loss           | 1.96e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 155           |\n",
      "|    time_elapsed         | 568           |\n",
      "|    total_timesteps      | 158720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5490805e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+05      |\n",
      "|    n_updates            | 26770         |\n",
      "|    policy_gradient_loss | -2.01e-05     |\n",
      "|    reward               | -40.33371     |\n",
      "|    value_loss           | 2.42e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 80\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1409014.91\n",
      "total_reward: 409014.91\n",
      "total_cost: 680570.28\n",
      "total_trades: 681\n",
      "=================================\n",
      "Episode: 81\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 279          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 571          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.703179e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.81e+05     |\n",
      "|    n_updates            | 26780        |\n",
      "|    policy_gradient_loss | 1.72e-05     |\n",
      "|    reward               | -13.392267   |\n",
      "|    value_loss           | 5.62e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 279          |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 575          |\n",
      "|    total_timesteps      | 160768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.900184e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.89e+04     |\n",
      "|    n_updates            | 26790        |\n",
      "|    policy_gradient_loss | -7.75e-05    |\n",
      "|    reward               | -4.079973    |\n",
      "|    value_loss           | 1.58e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 279          |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 579          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.027135e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.15e+03     |\n",
      "|    n_updates            | 26800        |\n",
      "|    policy_gradient_loss | -0.000159    |\n",
      "|    reward               | -73.609665   |\n",
      "|    value_loss           | 8.29e+03     |\n",
      "------------------------------------------\n",
      "Episode: 82\n",
      "Episode: 83\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 159           |\n",
      "|    time_elapsed         | 582           |\n",
      "|    total_timesteps      | 162816        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016729062 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.24e+05      |\n",
      "|    n_updates            | 26810         |\n",
      "|    policy_gradient_loss | -0.000211     |\n",
      "|    reward               | -25.41848     |\n",
      "|    value_loss           | 4.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 84\n",
      "Current company: ['CVX']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 680402.16\n",
      "total_reward: -319597.84\n",
      "total_cost: 312906.45\n",
      "total_trades: 333\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 160           |\n",
      "|    time_elapsed         | 586           |\n",
      "|    total_timesteps      | 163840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013527728 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.42e+04      |\n",
      "|    n_updates            | 26820         |\n",
      "|    policy_gradient_loss | -0.000212     |\n",
      "|    reward               | -17.779232    |\n",
      "|    value_loss           | 4.84e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 85\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 591          |\n",
      "|    total_timesteps      | 164864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.567279e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.37e+04     |\n",
      "|    n_updates            | 26830        |\n",
      "|    policy_gradient_loss | -0.000148    |\n",
      "|    reward               | -3.046718    |\n",
      "|    value_loss           | 1.28e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 162          |\n",
      "|    time_elapsed         | 594          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018997523 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.28e+03     |\n",
      "|    n_updates            | 26840        |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    reward               | 12.585536    |\n",
      "|    value_loss           | 1.86e+04     |\n",
      "------------------------------------------\n",
      "Episode: 86\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 163           |\n",
      "|    time_elapsed         | 598           |\n",
      "|    total_timesteps      | 166912        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036109082 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.93e+04      |\n",
      "|    n_updates            | 26850         |\n",
      "|    policy_gradient_loss | 0.000444      |\n",
      "|    reward               | -6.201412     |\n",
      "|    value_loss           | 7.86e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 164           |\n",
      "|    time_elapsed         | 601           |\n",
      "|    total_timesteps      | 167936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7759641e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.88e+05      |\n",
      "|    n_updates            | 26860         |\n",
      "|    policy_gradient_loss | -0.000111     |\n",
      "|    reward               | -35.42726     |\n",
      "|    value_loss           | 1.98e+06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 168960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.63047e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.59e+04    |\n",
      "|    n_updates            | 26870       |\n",
      "|    policy_gradient_loss | -6.63e-06   |\n",
      "|    reward               | -65.305176  |\n",
      "|    value_loss           | 9.19e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 87\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 166           |\n",
      "|    time_elapsed         | 608           |\n",
      "|    total_timesteps      | 169984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0623073e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.66e+05      |\n",
      "|    n_updates            | 26880         |\n",
      "|    policy_gradient_loss | -0.000119     |\n",
      "|    reward               | 7.2745285     |\n",
      "|    value_loss           | 5.32e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 167           |\n",
      "|    time_elapsed         | 612           |\n",
      "|    total_timesteps      | 171008        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1702803e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.69          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.73e+05      |\n",
      "|    n_updates            | 26890         |\n",
      "|    policy_gradient_loss | -8.69e-05     |\n",
      "|    reward               | 42.10049      |\n",
      "|    value_loss           | 7.49e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 279          |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 615          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.010632e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.18e+05     |\n",
      "|    n_updates            | 26900        |\n",
      "|    policy_gradient_loss | -4.66e-05    |\n",
      "|    reward               | 250.75633    |\n",
      "|    value_loss           | 2.37e+05     |\n",
      "------------------------------------------\n",
      "Episode: 88\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5487089.12\n",
      "total_reward: 4487089.12\n",
      "total_cost: 1498903.13\n",
      "total_trades: 731\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 169           |\n",
      "|    time_elapsed         | 619           |\n",
      "|    total_timesteps      | 173056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3594274e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.96e+06      |\n",
      "|    n_updates            | 26910         |\n",
      "|    policy_gradient_loss | 0.0001        |\n",
      "|    reward               | 4.075289      |\n",
      "|    value_loss           | 9.92e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 170           |\n",
      "|    time_elapsed         | 623           |\n",
      "|    total_timesteps      | 174080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3191602e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+06      |\n",
      "|    n_updates            | 26920         |\n",
      "|    policy_gradient_loss | -1.59e-05     |\n",
      "|    reward               | -42.611088    |\n",
      "|    value_loss           | 4.46e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 89\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 171           |\n",
      "|    time_elapsed         | 626           |\n",
      "|    total_timesteps      | 175104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0985102e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.84e+04      |\n",
      "|    n_updates            | 26930         |\n",
      "|    policy_gradient_loss | -2.41e-05     |\n",
      "|    reward               | -13.557441    |\n",
      "|    value_loss           | 1.97e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 172           |\n",
      "|    time_elapsed         | 630           |\n",
      "|    total_timesteps      | 176128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7087383e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.37e+05      |\n",
      "|    n_updates            | 26940         |\n",
      "|    policy_gradient_loss | -0.00017      |\n",
      "|    reward               | -36.141453    |\n",
      "|    value_loss           | 4.75e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 279          |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 177152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.419186e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.01e+04     |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -6.13e-05    |\n",
      "|    reward               | -69.030594   |\n",
      "|    value_loss           | 6.03e+04     |\n",
      "------------------------------------------\n",
      "Episode: 90\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 174           |\n",
      "|    time_elapsed         | 637           |\n",
      "|    total_timesteps      | 178176        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3990852e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.61e+05      |\n",
      "|    n_updates            | 26960         |\n",
      "|    policy_gradient_loss | -3.37e-05     |\n",
      "|    reward               | -0.83963746   |\n",
      "|    value_loss           | 7.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 175           |\n",
      "|    time_elapsed         | 640           |\n",
      "|    total_timesteps      | 179200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7377373e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.28e+05      |\n",
      "|    n_updates            | 26970         |\n",
      "|    policy_gradient_loss | -0.000144     |\n",
      "|    reward               | -63.42155     |\n",
      "|    value_loss           | 6.57e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 91\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 176           |\n",
      "|    time_elapsed         | 644           |\n",
      "|    total_timesteps      | 180224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0254287e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.26e+04      |\n",
      "|    n_updates            | 26980         |\n",
      "|    policy_gradient_loss | -4.26e-05     |\n",
      "|    reward               | 20.812105     |\n",
      "|    value_loss           | 1.25e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 177           |\n",
      "|    time_elapsed         | 647           |\n",
      "|    total_timesteps      | 181248        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020164438 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.42e+04      |\n",
      "|    n_updates            | 26990         |\n",
      "|    policy_gradient_loss | -0.000105     |\n",
      "|    reward               | 2.2004902     |\n",
      "|    value_loss           | 4.83e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 92\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 595052.85\n",
      "total_reward: -404947.15\n",
      "total_cost: 794631.21\n",
      "total_trades: 661\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 178           |\n",
      "|    time_elapsed         | 651           |\n",
      "|    total_timesteps      | 182272        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012340554 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.86e+04      |\n",
      "|    n_updates            | 27000         |\n",
      "|    policy_gradient_loss | 0.000213      |\n",
      "|    reward               | 27.229397     |\n",
      "|    value_loss           | 1.77e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 279           |\n",
      "|    iterations           | 179           |\n",
      "|    time_elapsed         | 654           |\n",
      "|    total_timesteps      | 183296        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6512116e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.85e+04      |\n",
      "|    n_updates            | 27010         |\n",
      "|    policy_gradient_loss | -0.000108     |\n",
      "|    reward               | 146.23149     |\n",
      "|    value_loss           | 1.17e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 280          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 658          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.188569e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.92e+06     |\n",
      "|    n_updates            | 27020        |\n",
      "|    policy_gradient_loss | 8.65e-05     |\n",
      "|    reward               | 303.50613    |\n",
      "|    value_loss           | 3.84e+06     |\n",
      "------------------------------------------\n",
      "Episode: 93\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 280           |\n",
      "|    iterations           | 181           |\n",
      "|    time_elapsed         | 661           |\n",
      "|    total_timesteps      | 185344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3530017e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.05e+06      |\n",
      "|    n_updates            | 27030         |\n",
      "|    policy_gradient_loss | -7.04e-05     |\n",
      "|    reward               | -32.074013    |\n",
      "|    value_loss           | 1.01e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 280           |\n",
      "|    iterations           | 182           |\n",
      "|    time_elapsed         | 665           |\n",
      "|    total_timesteps      | 186368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4792022e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+06      |\n",
      "|    n_updates            | 27040         |\n",
      "|    policy_gradient_loss | -0.000133     |\n",
      "|    reward               | -54.039444    |\n",
      "|    value_loss           | 2.45e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 94\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 280            |\n",
      "|    iterations           | 183            |\n",
      "|    time_elapsed         | 668            |\n",
      "|    total_timesteps      | 187392         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.10313995e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.04          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.21e+05       |\n",
      "|    n_updates            | 27050          |\n",
      "|    policy_gradient_loss | 8.73e-08       |\n",
      "|    reward               | -11.668509     |\n",
      "|    value_loss           | 2.42e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 280           |\n",
      "|    iterations           | 184           |\n",
      "|    time_elapsed         | 672           |\n",
      "|    total_timesteps      | 188416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8757647e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.57e+05      |\n",
      "|    n_updates            | 27060         |\n",
      "|    policy_gradient_loss | -3.86e-05     |\n",
      "|    reward               | -42.130333    |\n",
      "|    value_loss           | 7.14e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 280          |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 675          |\n",
      "|    total_timesteps      | 189440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.246788e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.36e+04     |\n",
      "|    n_updates            | 27070        |\n",
      "|    policy_gradient_loss | -0.00023     |\n",
      "|    reward               | 19.651041    |\n",
      "|    value_loss           | 4.73e+04     |\n",
      "------------------------------------------\n",
      "Episode: 95\n",
      "Episode: 96\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699463.99\n",
      "total_reward: -300536.01\n",
      "total_cost: 112346.52\n",
      "total_trades: 129\n",
      "=================================\n",
      "Episode: 97\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 280          |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 679          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.992906e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.6e+04      |\n",
      "|    n_updates            | 27080        |\n",
      "|    policy_gradient_loss | 2.91e-05     |\n",
      "|    reward               | -2.56025     |\n",
      "|    value_loss           | 1.92e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 280           |\n",
      "|    iterations           | 187           |\n",
      "|    time_elapsed         | 682           |\n",
      "|    total_timesteps      | 191488        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0771502e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+05      |\n",
      "|    n_updates            | 27090         |\n",
      "|    policy_gradient_loss | -1.16e-05     |\n",
      "|    reward               | -5.105778     |\n",
      "|    value_loss           | 2.42e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 280          |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 686          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006221271 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 27100        |\n",
      "|    policy_gradient_loss | 0.00144      |\n",
      "|    reward               | -66.80114    |\n",
      "|    value_loss           | 3.63e+03     |\n",
      "------------------------------------------\n",
      "Episode: 98\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 689         |\n",
      "|    total_timesteps      | 193536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040312525 |\n",
      "|    clip_fraction        | 0.608       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.62e+05    |\n",
      "|    n_updates            | 27110       |\n",
      "|    policy_gradient_loss | 0.0276      |\n",
      "|    reward               | -10.497172  |\n",
      "|    value_loss           | 3.25e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 190        |\n",
      "|    time_elapsed         | 692        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0033736  |\n",
      "|    clip_fraction        | 0.0981     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.913     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.51e+05   |\n",
      "|    n_updates            | 27120      |\n",
      "|    policy_gradient_loss | 0.00125    |\n",
      "|    reward               | -17.399225 |\n",
      "|    value_loss           | 5.02e+05   |\n",
      "----------------------------------------\n",
      "Episode: 99\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 695          |\n",
      "|    total_timesteps      | 195584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003637786 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.887       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.07e+04     |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.000233    |\n",
      "|    reward               | -0.5699838   |\n",
      "|    value_loss           | 2.14e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 699          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.539988e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.62e+04     |\n",
      "|    n_updates            | 27140        |\n",
      "|    policy_gradient_loss | 1.06e-05     |\n",
      "|    reward               | 166.61131    |\n",
      "|    value_loss           | 1.52e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 702          |\n",
      "|    total_timesteps      | 197632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.882241e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.873       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.19e+06     |\n",
      "|    n_updates            | 27150        |\n",
      "|    policy_gradient_loss | -8.84e-05    |\n",
      "|    reward               | 180.35887    |\n",
      "|    value_loss           | 2.38e+06     |\n",
      "------------------------------------------\n",
      "Episode: 100\n",
      "Current company: ['V']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3815330.64\n",
      "total_reward: 2815330.64\n",
      "total_cost: 1224040.53\n",
      "total_trades: 461\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 705          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.133364e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.872       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.4e+06      |\n",
      "|    n_updates            | 27160        |\n",
      "|    policy_gradient_loss | -2.11e-05    |\n",
      "|    reward               | -26.378912   |\n",
      "|    value_loss           | 8.8e+06      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 281           |\n",
      "|    iterations           | 195           |\n",
      "|    time_elapsed         | 709           |\n",
      "|    total_timesteps      | 199680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7584534e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.871        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.28e+06      |\n",
      "|    n_updates            | 27170         |\n",
      "|    policy_gradient_loss | -2.86e-06     |\n",
      "|    reward               | -25.902412    |\n",
      "|    value_loss           | 1.66e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 712          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.220855e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.871       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.17e+04     |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -3.45e-05    |\n",
      "|    reward               | 24.15999     |\n",
      "|    value_loss           | 4.34e+04     |\n",
      "------------------------------------------\n",
      "Episode: 101\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 715          |\n",
      "|    total_timesteps      | 201728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.083275e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.873       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.27e+04     |\n",
      "|    n_updates            | 27190        |\n",
      "|    policy_gradient_loss | -1.98e-05    |\n",
      "|    reward               | -34.209312   |\n",
      "|    value_loss           | 6.54e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 198           |\n",
      "|    time_elapsed         | 718           |\n",
      "|    total_timesteps      | 202752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5163476e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.875        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.95e+05      |\n",
      "|    n_updates            | 27200         |\n",
      "|    policy_gradient_loss | 6.44e-06      |\n",
      "|    reward               | -41.597267    |\n",
      "|    value_loss           | 3.91e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 199           |\n",
      "|    time_elapsed         | 722           |\n",
      "|    total_timesteps      | 203776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7078585e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.874        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.38e+04      |\n",
      "|    n_updates            | 27210         |\n",
      "|    policy_gradient_loss | -2.83e-06     |\n",
      "|    reward               | -19.910923    |\n",
      "|    value_loss           | 1.28e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 102\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 725          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.585592e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.874       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.15e+05     |\n",
      "|    n_updates            | 27220        |\n",
      "|    policy_gradient_loss | 2.75e-06     |\n",
      "|    reward               | -4.692677    |\n",
      "|    value_loss           | 2.3e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 201          |\n",
      "|    time_elapsed         | 728          |\n",
      "|    total_timesteps      | 205824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.898111e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.875       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.32e+04     |\n",
      "|    n_updates            | 27230        |\n",
      "|    policy_gradient_loss | -4.5e-05     |\n",
      "|    reward               | 44.25011     |\n",
      "|    value_loss           | 4.63e+04     |\n",
      "------------------------------------------\n",
      "Episode: 103\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 202           |\n",
      "|    time_elapsed         | 732           |\n",
      "|    total_timesteps      | 206848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3100176e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.19e+05      |\n",
      "|    n_updates            | 27240         |\n",
      "|    policy_gradient_loss | -6.49e-06     |\n",
      "|    reward               | 7.8629217     |\n",
      "|    value_loss           | 2.37e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 735          |\n",
      "|    total_timesteps      | 207872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.000496e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.881       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.54e+05     |\n",
      "|    n_updates            | 27250        |\n",
      "|    policy_gradient_loss | -3.84e-05    |\n",
      "|    reward               | 25.550964    |\n",
      "|    value_loss           | 1.11e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 204           |\n",
      "|    time_elapsed         | 738           |\n",
      "|    total_timesteps      | 208896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6182312e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.883        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.23e+04      |\n",
      "|    n_updates            | 27260         |\n",
      "|    policy_gradient_loss | -3.34e-05     |\n",
      "|    reward               | 64.1327       |\n",
      "|    value_loss           | 6.46e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 104\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3733953.08\n",
      "total_reward: 2733953.08\n",
      "total_cost: 791506.28\n",
      "total_trades: 467\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 205           |\n",
      "|    time_elapsed         | 741           |\n",
      "|    total_timesteps      | 209920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7001876e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.17e+05      |\n",
      "|    n_updates            | 27270         |\n",
      "|    policy_gradient_loss | -4.98e-05     |\n",
      "|    reward               | 9.693866      |\n",
      "|    value_loss           | 6.35e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 283           |\n",
      "|    iterations           | 206           |\n",
      "|    time_elapsed         | 745           |\n",
      "|    total_timesteps      | 210944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2392563e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.02e+06      |\n",
      "|    n_updates            | 27280         |\n",
      "|    policy_gradient_loss | 1.05e-05      |\n",
      "|    reward               | 76.076836     |\n",
      "|    value_loss           | 4.05e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 283           |\n",
      "|    iterations           | 207           |\n",
      "|    time_elapsed         | 748           |\n",
      "|    total_timesteps      | 211968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3114186e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.67e+05      |\n",
      "|    n_updates            | 27290         |\n",
      "|    policy_gradient_loss | -8.35e-06     |\n",
      "|    reward               | 109.26882     |\n",
      "|    value_loss           | 7.34e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 105\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 283           |\n",
      "|    iterations           | 208           |\n",
      "|    time_elapsed         | 751           |\n",
      "|    total_timesteps      | 212992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5506521e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.48e+06      |\n",
      "|    n_updates            | 27300         |\n",
      "|    policy_gradient_loss | -2.79e-07     |\n",
      "|    reward               | -20.427034    |\n",
      "|    value_loss           | 2.96e+06      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 283       |\n",
      "|    iterations           | 209       |\n",
      "|    time_elapsed         | 755       |\n",
      "|    total_timesteps      | 214016    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.885    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 6.55e+05  |\n",
      "|    n_updates            | 27310     |\n",
      "|    policy_gradient_loss | 3.7e-07   |\n",
      "|    reward               | 27.781292 |\n",
      "|    value_loss           | 1.31e+06  |\n",
      "---------------------------------------\n",
      "Episode: 106\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 758          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.502393e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.23e+04     |\n",
      "|    n_updates            | 27320        |\n",
      "|    policy_gradient_loss | -0.000248    |\n",
      "|    reward               | -15.743434   |\n",
      "|    value_loss           | 4.45e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 761          |\n",
      "|    total_timesteps      | 216064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.933871e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.888       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.15e+05     |\n",
      "|    n_updates            | 27330        |\n",
      "|    policy_gradient_loss | -0.00019     |\n",
      "|    reward               | 10.953366    |\n",
      "|    value_loss           | 1.63e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 283           |\n",
      "|    iterations           | 212           |\n",
      "|    time_elapsed         | 765           |\n",
      "|    total_timesteps      | 217088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1977041e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.889        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.38e+05      |\n",
      "|    n_updates            | 27340         |\n",
      "|    policy_gradient_loss | -2.4e-05      |\n",
      "|    reward               | 35.842525     |\n",
      "|    value_loss           | 4.76e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 107\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 283           |\n",
      "|    iterations           | 213           |\n",
      "|    time_elapsed         | 768           |\n",
      "|    total_timesteps      | 218112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9231887e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.89         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.48e+04      |\n",
      "|    n_updates            | 27350         |\n",
      "|    policy_gradient_loss | -3.83e-05     |\n",
      "|    reward               | -7.5985937    |\n",
      "|    value_loss           | 1.7e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 771          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.993142e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.891       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.81e+04     |\n",
      "|    n_updates            | 27360        |\n",
      "|    policy_gradient_loss | -4.49e-05    |\n",
      "|    reward               | -46.6405     |\n",
      "|    value_loss           | 7.62e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 215           |\n",
      "|    time_elapsed         | 774           |\n",
      "|    total_timesteps      | 220160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9078448e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.07e+04      |\n",
      "|    n_updates            | 27370         |\n",
      "|    policy_gradient_loss | 4.87e-05      |\n",
      "|    reward               | -66.426765    |\n",
      "|    value_loss           | 1.21e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 108\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 685535.11\n",
      "total_reward: -314464.89\n",
      "total_cost: 421248.93\n",
      "total_trades: 469\n",
      "=================================\n",
      "Episode: 109\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 778          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.294422e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.7e+05      |\n",
      "|    n_updates            | 27380        |\n",
      "|    policy_gradient_loss | -1.83e-05    |\n",
      "|    reward               | 1.8872355    |\n",
      "|    value_loss           | 5.41e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 222208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.171191e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.895       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.58e+04     |\n",
      "|    n_updates            | 27390        |\n",
      "|    policy_gradient_loss | -4.09e-05    |\n",
      "|    reward               | 14.5798025   |\n",
      "|    value_loss           | 1.52e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 218          |\n",
      "|    time_elapsed         | 784          |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.118258e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.13e+05     |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | 6.62e-05     |\n",
      "|    reward               | 45.164253    |\n",
      "|    value_loss           | 2.26e+05     |\n",
      "------------------------------------------\n",
      "Episode: 110\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 219           |\n",
      "|    time_elapsed         | 788           |\n",
      "|    total_timesteps      | 224256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2960536e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.899        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.86e+04      |\n",
      "|    n_updates            | 27410         |\n",
      "|    policy_gradient_loss | -0.000127     |\n",
      "|    reward               | -26.284292    |\n",
      "|    value_loss           | 5.73e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 220           |\n",
      "|    time_elapsed         | 791           |\n",
      "|    total_timesteps      | 225280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4045074e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.905        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.13e+04      |\n",
      "|    n_updates            | 27420         |\n",
      "|    policy_gradient_loss | -0.000395     |\n",
      "|    reward               | -39.04711     |\n",
      "|    value_loss           | 8.27e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 111\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 221           |\n",
      "|    time_elapsed         | 794           |\n",
      "|    total_timesteps      | 226304        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5069032e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.909        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.16e+05      |\n",
      "|    n_updates            | 27430         |\n",
      "|    policy_gradient_loss | 0.000167      |\n",
      "|    reward               | -20.091703    |\n",
      "|    value_loss           | 2.32e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 112\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 686004.97\n",
      "total_reward: -313995.03\n",
      "total_cost: 71822.69\n",
      "total_trades: 89\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 222           |\n",
      "|    time_elapsed         | 798           |\n",
      "|    total_timesteps      | 227328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5658165e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.91         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.43e+05      |\n",
      "|    n_updates            | 27440         |\n",
      "|    policy_gradient_loss | 2.11e-05      |\n",
      "|    reward               | 19.813122     |\n",
      "|    value_loss           | 4.86e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 223           |\n",
      "|    time_elapsed         | 801           |\n",
      "|    total_timesteps      | 228352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8240535e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.909        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.55e+04      |\n",
      "|    n_updates            | 27450         |\n",
      "|    policy_gradient_loss | -2.8e-05      |\n",
      "|    reward               | -19.709427    |\n",
      "|    value_loss           | 1.31e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 113\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 284           |\n",
      "|    iterations           | 224           |\n",
      "|    time_elapsed         | 804           |\n",
      "|    total_timesteps      | 229376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6315607e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.907        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.86e+04      |\n",
      "|    n_updates            | 27460         |\n",
      "|    policy_gradient_loss | -1.1e-05      |\n",
      "|    reward               | 0.17307818    |\n",
      "|    value_loss           | 1.17e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 285            |\n",
      "|    iterations           | 225            |\n",
      "|    time_elapsed         | 808            |\n",
      "|    total_timesteps      | 230400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.17579475e-08 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.907         |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.15e+05       |\n",
      "|    n_updates            | 27470          |\n",
      "|    policy_gradient_loss | 5.48e-06       |\n",
      "|    reward               | -22.420448     |\n",
      "|    value_loss           | 2.31e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 285           |\n",
      "|    iterations           | 226           |\n",
      "|    time_elapsed         | 811           |\n",
      "|    total_timesteps      | 231424        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029736437 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.904        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.84e+03      |\n",
      "|    n_updates            | 27480         |\n",
      "|    policy_gradient_loss | -0.000441     |\n",
      "|    reward               | -23.726318    |\n",
      "|    value_loss           | 1.77e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 114\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 814          |\n",
      "|    total_timesteps      | 232448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003177321 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.892       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.15e+04     |\n",
      "|    n_updates            | 27490        |\n",
      "|    policy_gradient_loss | -0.000259    |\n",
      "|    reward               | 6.042696     |\n",
      "|    value_loss           | 6.3e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 228          |\n",
      "|    time_elapsed         | 818          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.729877e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.77e+04     |\n",
      "|    n_updates            | 27500        |\n",
      "|    policy_gradient_loss | 2.55e-06     |\n",
      "|    reward               | -8.248276    |\n",
      "|    value_loss           | 1.16e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 285           |\n",
      "|    iterations           | 229           |\n",
      "|    time_elapsed         | 821           |\n",
      "|    total_timesteps      | 234496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5235855e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.47e+04      |\n",
      "|    n_updates            | 27510         |\n",
      "|    policy_gradient_loss | 1.06e-05      |\n",
      "|    reward               | -14.008897    |\n",
      "|    value_loss           | 6.93e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 115\n",
      "Episode: 116\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694361.24\n",
      "total_reward: -305638.76\n",
      "total_cost: 86952.32\n",
      "total_trades: 93\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 285           |\n",
      "|    iterations           | 230           |\n",
      "|    time_elapsed         | 824           |\n",
      "|    total_timesteps      | 235520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4627585e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.38e+04      |\n",
      "|    n_updates            | 27520         |\n",
      "|    policy_gradient_loss | 1.31e-05      |\n",
      "|    reward               | -3.2280946    |\n",
      "|    value_loss           | 2.75e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 117\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 828          |\n",
      "|    total_timesteps      | 236544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.213101e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.68e+04     |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -1.83e-07    |\n",
      "|    reward               | -9.426619    |\n",
      "|    value_loss           | 7.36e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 285           |\n",
      "|    iterations           | 232           |\n",
      "|    time_elapsed         | 831           |\n",
      "|    total_timesteps      | 237568        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.7398803e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.33e+04      |\n",
      "|    n_updates            | 27540         |\n",
      "|    policy_gradient_loss | -6.59e-06     |\n",
      "|    reward               | -0.51149243   |\n",
      "|    value_loss           | 6.67e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 834          |\n",
      "|    total_timesteps      | 238592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.512716e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.64e+04     |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -4.88e-05    |\n",
      "|    reward               | 5.160735     |\n",
      "|    value_loss           | 1.13e+05     |\n",
      "------------------------------------------\n",
      "Episode: 118\n",
      "Episode: 119\n",
      "Episode: 120\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696685.24\n",
      "total_reward: -303314.76\n",
      "total_cost: 93118.08\n",
      "total_trades: 111\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 838          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.377216e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.887       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.7e+04      |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | 1.36e-05     |\n",
      "|    reward               | 11.008364    |\n",
      "|    value_loss           | 5.41e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 235          |\n",
      "|    time_elapsed         | 841          |\n",
      "|    total_timesteps      | 240640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.338946e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.56e+04     |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -7.16e-05    |\n",
      "|    reward               | 50.802223    |\n",
      "|    value_loss           | 7.13e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 844          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.964306e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.13e+05     |\n",
      "|    n_updates            | 27580        |\n",
      "|    policy_gradient_loss | -5.73e-05    |\n",
      "|    reward               | 204.42944    |\n",
      "|    value_loss           | 4.26e+05     |\n",
      "------------------------------------------\n",
      "Episode: 121\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 237          |\n",
      "|    time_elapsed         | 848          |\n",
      "|    total_timesteps      | 242688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.500647e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81e+06     |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | 2.37e-05     |\n",
      "|    reward               | 15.747076    |\n",
      "|    value_loss           | 3.62e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.11411e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.7e+06     |\n",
      "|    n_updates            | 27600       |\n",
      "|    policy_gradient_loss | -2.89e-07   |\n",
      "|    reward               | 22.618483   |\n",
      "|    value_loss           | 5.41e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 854          |\n",
      "|    total_timesteps      | 244736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.032657e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.62e+04     |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -1.78e-06    |\n",
      "|    reward               | 112.95017    |\n",
      "|    value_loss           | 1.12e+05     |\n",
      "------------------------------------------\n",
      "Episode: 122\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 286           |\n",
      "|    iterations           | 240           |\n",
      "|    time_elapsed         | 858           |\n",
      "|    total_timesteps      | 245760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.5460564e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.56e+05      |\n",
      "|    n_updates            | 27620         |\n",
      "|    policy_gradient_loss | 2.13e-06      |\n",
      "|    reward               | -4.04603      |\n",
      "|    value_loss           | 1.91e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 861          |\n",
      "|    total_timesteps      | 246784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.131572e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.31e+06     |\n",
      "|    n_updates            | 27630        |\n",
      "|    policy_gradient_loss | -5.98e-06    |\n",
      "|    reward               | -9.136122    |\n",
      "|    value_loss           | 4.61e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 286           |\n",
      "|    iterations           | 242           |\n",
      "|    time_elapsed         | 864           |\n",
      "|    total_timesteps      | 247808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3187528e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+04      |\n",
      "|    n_updates            | 27640         |\n",
      "|    policy_gradient_loss | -9.96e-05     |\n",
      "|    reward               | -0.30228025   |\n",
      "|    value_loss           | 2.04e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 123\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 868          |\n",
      "|    total_timesteps      | 248832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.795853e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4e+04        |\n",
      "|    n_updates            | 27650        |\n",
      "|    policy_gradient_loss | 4.29e-05     |\n",
      "|    reward               | 81.299965    |\n",
      "|    value_loss           | 7.99e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 286           |\n",
      "|    iterations           | 244           |\n",
      "|    time_elapsed         | 871           |\n",
      "|    total_timesteps      | 249856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2642856e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.982        |\n",
      "|    explained_variance   | -1.21         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.42e+05      |\n",
      "|    n_updates            | 27660         |\n",
      "|    policy_gradient_loss | 3.51e-05      |\n",
      "|    reward               | 96.61134      |\n",
      "|    value_loss           | 1.09e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 124\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3282237.66\n",
      "total_reward: 2282237.66\n",
      "total_cost: 1070967.51\n",
      "total_trades: 563\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 286           |\n",
      "|    iterations           | 245           |\n",
      "|    time_elapsed         | 874           |\n",
      "|    total_timesteps      | 250880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9697853e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.93e+05      |\n",
      "|    n_updates            | 27670         |\n",
      "|    policy_gradient_loss | -6.67e-06     |\n",
      "|    reward               | 3.0042534     |\n",
      "|    value_loss           | 1.99e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 286           |\n",
      "|    iterations           | 246           |\n",
      "|    time_elapsed         | 878           |\n",
      "|    total_timesteps      | 251904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7299774e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.877        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.91e+06      |\n",
      "|    n_updates            | 27680         |\n",
      "|    policy_gradient_loss | -3.45e-06     |\n",
      "|    reward               | -26.348063    |\n",
      "|    value_loss           | 3.82e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 286           |\n",
      "|    iterations           | 247           |\n",
      "|    time_elapsed         | 881           |\n",
      "|    total_timesteps      | 252928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5161233e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.31e+03      |\n",
      "|    n_updates            | 27690         |\n",
      "|    policy_gradient_loss | -0.000138     |\n",
      "|    reward               | -26.339018    |\n",
      "|    value_loss           | 1.94e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 125\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 248           |\n",
      "|    time_elapsed         | 884           |\n",
      "|    total_timesteps      | 253952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.6148426e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+04      |\n",
      "|    n_updates            | 27700         |\n",
      "|    policy_gradient_loss | 3.68e-05      |\n",
      "|    reward               | -19.986816    |\n",
      "|    value_loss           | 2.49e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 126\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 249           |\n",
      "|    time_elapsed         | 888           |\n",
      "|    total_timesteps      | 254976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010170764 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+04      |\n",
      "|    n_updates            | 27710         |\n",
      "|    policy_gradient_loss | -0.000334     |\n",
      "|    reward               | 9.212919      |\n",
      "|    value_loss           | 2.89e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 287            |\n",
      "|    iterations           | 250            |\n",
      "|    time_elapsed         | 891            |\n",
      "|    total_timesteps      | 256000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000110630644 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.877         |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 8.68e+04       |\n",
      "|    n_updates            | 27720          |\n",
      "|    policy_gradient_loss | -0.000253      |\n",
      "|    reward               | 5.9106483      |\n",
      "|    value_loss           | 1.74e+05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 894          |\n",
      "|    total_timesteps      | 257024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.969444e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.21e+04     |\n",
      "|    n_updates            | 27730        |\n",
      "|    policy_gradient_loss | 6.71e-05     |\n",
      "|    reward               | -13.894889   |\n",
      "|    value_loss           | 6.43e+04     |\n",
      "------------------------------------------\n",
      "Episode: 127\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 897          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.822528e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.73e+03     |\n",
      "|    n_updates            | 27740        |\n",
      "|    policy_gradient_loss | -4.99e-05    |\n",
      "|    reward               | -16.646694   |\n",
      "|    value_loss           | 1.55e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 253           |\n",
      "|    time_elapsed         | 901           |\n",
      "|    total_timesteps      | 259072        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0990072e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.8e+04       |\n",
      "|    n_updates            | 27750         |\n",
      "|    policy_gradient_loss | -6.97e-05     |\n",
      "|    reward               | 3.350327      |\n",
      "|    value_loss           | 5.6e+04       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 254           |\n",
      "|    time_elapsed         | 904           |\n",
      "|    total_timesteps      | 260096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6896753e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.3e+03       |\n",
      "|    n_updates            | 27760         |\n",
      "|    policy_gradient_loss | -8e-05        |\n",
      "|    reward               | -2.1867433    |\n",
      "|    value_loss           | 1.66e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 128\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1435662.26\n",
      "total_reward: 435662.26\n",
      "total_cost: 536977.40\n",
      "total_trades: 447\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 255           |\n",
      "|    time_elapsed         | 907           |\n",
      "|    total_timesteps      | 261120        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0340434e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.56e+04      |\n",
      "|    n_updates            | 27770         |\n",
      "|    policy_gradient_loss | -7.37e-05     |\n",
      "|    reward               | -23.582918    |\n",
      "|    value_loss           | 7.12e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 256           |\n",
      "|    time_elapsed         | 910           |\n",
      "|    total_timesteps      | 262144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5917467e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.33e+04      |\n",
      "|    n_updates            | 27780         |\n",
      "|    policy_gradient_loss | 3.8e-05       |\n",
      "|    reward               | -6.7761946    |\n",
      "|    value_loss           | 1.07e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 129\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 257           |\n",
      "|    time_elapsed         | 914           |\n",
      "|    total_timesteps      | 263168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8085273e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.09e+04      |\n",
      "|    n_updates            | 27790         |\n",
      "|    policy_gradient_loss | -1.22e-05     |\n",
      "|    reward               | 2.1071904     |\n",
      "|    value_loss           | 1.42e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 258           |\n",
      "|    time_elapsed         | 917           |\n",
      "|    total_timesteps      | 264192        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0300504e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.9e+04       |\n",
      "|    n_updates            | 27800         |\n",
      "|    policy_gradient_loss | -1.39e-05     |\n",
      "|    reward               | -19.498041    |\n",
      "|    value_loss           | 1.18e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 259          |\n",
      "|    time_elapsed         | 920          |\n",
      "|    total_timesteps      | 265216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007392881 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.892       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.79e+03     |\n",
      "|    n_updates            | 27810        |\n",
      "|    policy_gradient_loss | -0.000228    |\n",
      "|    reward               | -54.00291    |\n",
      "|    value_loss           | 5.57e+03     |\n",
      "------------------------------------------\n",
      "Episode: 130\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 260           |\n",
      "|    time_elapsed         | 924           |\n",
      "|    total_timesteps      | 266240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093889574 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.916        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.52e+05      |\n",
      "|    n_updates            | 27820         |\n",
      "|    policy_gradient_loss | 0.00037       |\n",
      "|    reward               | 5.149445      |\n",
      "|    value_loss           | 3.05e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 928          |\n",
      "|    total_timesteps      | 267264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001613723 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.929       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.1e+05      |\n",
      "|    n_updates            | 27830        |\n",
      "|    policy_gradient_loss | -2.83e-05    |\n",
      "|    reward               | 5.2306757    |\n",
      "|    value_loss           | 2.2e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 262          |\n",
      "|    time_elapsed         | 931          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.024835e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.21e+04     |\n",
      "|    n_updates            | 27840        |\n",
      "|    policy_gradient_loss | 3.67e-06     |\n",
      "|    reward               | 1.1096202    |\n",
      "|    value_loss           | 2.41e+04     |\n",
      "------------------------------------------\n",
      "Episode: 131\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 263           |\n",
      "|    time_elapsed         | 935           |\n",
      "|    total_timesteps      | 269312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2757485e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.77e+04      |\n",
      "|    n_updates            | 27850         |\n",
      "|    policy_gradient_loss | -3.81e-05     |\n",
      "|    reward               | -6.9714985    |\n",
      "|    value_loss           | 1.95e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 264           |\n",
      "|    time_elapsed         | 938           |\n",
      "|    total_timesteps      | 270336        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4803426e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.08e+03      |\n",
      "|    n_updates            | 27860         |\n",
      "|    policy_gradient_loss | -0.000144     |\n",
      "|    reward               | -23.799557    |\n",
      "|    value_loss           | 1.42e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 132\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1001395.30\n",
      "total_reward: 1395.30\n",
      "total_cost: 541373.61\n",
      "total_trades: 504\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 265           |\n",
      "|    time_elapsed         | 941           |\n",
      "|    total_timesteps      | 271360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010361412 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.937        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.07e+04      |\n",
      "|    n_updates            | 27870         |\n",
      "|    policy_gradient_loss | -0.000279     |\n",
      "|    reward               | -26.269613    |\n",
      "|    value_loss           | 6.14e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 266           |\n",
      "|    time_elapsed         | 945           |\n",
      "|    total_timesteps      | 272384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9456958e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.942        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.57e+05      |\n",
      "|    n_updates            | 27880         |\n",
      "|    policy_gradient_loss | -1.66e-05     |\n",
      "|    reward               | -25.239697    |\n",
      "|    value_loss           | 3.15e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 267           |\n",
      "|    time_elapsed         | 948           |\n",
      "|    total_timesteps      | 273408        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4334295e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.944        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.91e+04      |\n",
      "|    n_updates            | 27890         |\n",
      "|    policy_gradient_loss | 1.16e-05      |\n",
      "|    reward               | -44.47804     |\n",
      "|    value_loss           | 9.83e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 133\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 268           |\n",
      "|    time_elapsed         | 951           |\n",
      "|    total_timesteps      | 274432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4540654e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.944        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.56e+05      |\n",
      "|    n_updates            | 27900         |\n",
      "|    policy_gradient_loss | -1.42e-05     |\n",
      "|    reward               | 33.13414      |\n",
      "|    value_loss           | 5.12e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 269           |\n",
      "|    time_elapsed         | 955           |\n",
      "|    total_timesteps      | 275456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3224933e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.65e+05      |\n",
      "|    n_updates            | 27910         |\n",
      "|    policy_gradient_loss | 5.71e-07      |\n",
      "|    reward               | 47.46747      |\n",
      "|    value_loss           | 3.29e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 134\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 270           |\n",
      "|    time_elapsed         | 958           |\n",
      "|    total_timesteps      | 276480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8288847e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.39e+05      |\n",
      "|    n_updates            | 27920         |\n",
      "|    policy_gradient_loss | -4.13e-06     |\n",
      "|    reward               | 1.5392922     |\n",
      "|    value_loss           | 4.79e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 961          |\n",
      "|    total_timesteps      | 277504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.611188e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.945       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.33e+06     |\n",
      "|    n_updates            | 27930        |\n",
      "|    policy_gradient_loss | -1.19e-05    |\n",
      "|    reward               | -47.844257   |\n",
      "|    value_loss           | 2.66e+06     |\n",
      "------------------------------------------\n",
      "Episode: 135\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 272           |\n",
      "|    time_elapsed         | 965           |\n",
      "|    total_timesteps      | 278528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6635902e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.88e+04      |\n",
      "|    n_updates            | 27940         |\n",
      "|    policy_gradient_loss | -7.34e-06     |\n",
      "|    reward               | -8.56726      |\n",
      "|    value_loss           | 1.58e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 136\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695581.49\n",
      "total_reward: -304418.51\n",
      "total_cost: 37412.99\n",
      "total_trades: 39\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 273           |\n",
      "|    time_elapsed         | 968           |\n",
      "|    total_timesteps      | 279552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0722003e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.52e+05      |\n",
      "|    n_updates            | 27950         |\n",
      "|    policy_gradient_loss | 8.2e-06       |\n",
      "|    reward               | -4.860392     |\n",
      "|    value_loss           | 5.05e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 274          |\n",
      "|    time_elapsed         | 971          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.158464e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.945       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.86e+04     |\n",
      "|    n_updates            | 27960        |\n",
      "|    policy_gradient_loss | -4.88e-05    |\n",
      "|    reward               | -47.61515    |\n",
      "|    value_loss           | 3.72e+04     |\n",
      "------------------------------------------\n",
      "Episode: 137\n",
      "Episode: 138\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 275           |\n",
      "|    time_elapsed         | 975           |\n",
      "|    total_timesteps      | 281600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0835002e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.944        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.69e+04      |\n",
      "|    n_updates            | 27970         |\n",
      "|    policy_gradient_loss | -2.7e-05      |\n",
      "|    reward               | -2.732207     |\n",
      "|    value_loss           | 1.54e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 276           |\n",
      "|    time_elapsed         | 978           |\n",
      "|    total_timesteps      | 282624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0454477e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.943        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.36e+05      |\n",
      "|    n_updates            | 27980         |\n",
      "|    policy_gradient_loss | -3.33e-07     |\n",
      "|    reward               | 112.29035     |\n",
      "|    value_loss           | 4.72e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 277           |\n",
      "|    time_elapsed         | 982           |\n",
      "|    total_timesteps      | 283648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4726767e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.943        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.47e+05      |\n",
      "|    n_updates            | 27990         |\n",
      "|    policy_gradient_loss | -1.11e-05     |\n",
      "|    reward               | 366.42813     |\n",
      "|    value_loss           | 8.94e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 139\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 985          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.498855e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.944       |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.26e+06     |\n",
      "|    n_updates            | 28000        |\n",
      "|    policy_gradient_loss | -1.71e-06    |\n",
      "|    reward               | -17.985336   |\n",
      "|    value_loss           | 1.85e+07     |\n",
      "------------------------------------------\n",
      "Episode: 140\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697397.65\n",
      "total_reward: -302602.35\n",
      "total_cost: 109544.23\n",
      "total_trades: 125\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 279       |\n",
      "|    time_elapsed         | 988       |\n",
      "|    total_timesteps      | 285696    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.944    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.03e+07  |\n",
      "|    n_updates            | 28010     |\n",
      "|    policy_gradient_loss | 4.96e-06  |\n",
      "|    reward               | 10.833251 |\n",
      "|    value_loss           | 2.06e+07  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 288           |\n",
      "|    iterations           | 280           |\n",
      "|    time_elapsed         | 992           |\n",
      "|    total_timesteps      | 286720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6898924e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.944        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.11e+05      |\n",
      "|    n_updates            | 28020         |\n",
      "|    policy_gradient_loss | -3.74e-05     |\n",
      "|    reward               | 54.511307     |\n",
      "|    value_loss           | 2.22e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 281          |\n",
      "|    time_elapsed         | 995          |\n",
      "|    total_timesteps      | 287744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.915986e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.946       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.23e+05     |\n",
      "|    n_updates            | 28030        |\n",
      "|    policy_gradient_loss | -5.31e-05    |\n",
      "|    reward               | 378.38522    |\n",
      "|    value_loss           | 6.46e+05     |\n",
      "------------------------------------------\n",
      "Episode: 141\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 282           |\n",
      "|    time_elapsed         | 999           |\n",
      "|    total_timesteps      | 288768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0415097e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.948        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.99e+06      |\n",
      "|    n_updates            | 28040         |\n",
      "|    policy_gradient_loss | 3.32e-05      |\n",
      "|    reward               | 51.347713     |\n",
      "|    value_loss           | 9.98e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 1002         |\n",
      "|    total_timesteps      | 289792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.667121e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.948       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.66e+05     |\n",
      "|    n_updates            | 28050        |\n",
      "|    policy_gradient_loss | -5.64e-06    |\n",
      "|    reward               | 43.51124     |\n",
      "|    value_loss           | 1.13e+06     |\n",
      "------------------------------------------\n",
      "Episode: 142\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 284          |\n",
      "|    time_elapsed         | 1005         |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.346366e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.948       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.63e+05     |\n",
      "|    n_updates            | 28060        |\n",
      "|    policy_gradient_loss | -1.78e-05    |\n",
      "|    reward               | 18.279184    |\n",
      "|    value_loss           | 5.26e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 285           |\n",
      "|    time_elapsed         | 1009          |\n",
      "|    total_timesteps      | 291840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1443626e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.948        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.46e+04      |\n",
      "|    n_updates            | 28070         |\n",
      "|    policy_gradient_loss | 2.31e-07      |\n",
      "|    reward               | 35.805157     |\n",
      "|    value_loss           | 1.7e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 286           |\n",
      "|    time_elapsed         | 1012          |\n",
      "|    total_timesteps      | 292864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4158431e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.948        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.18e+04      |\n",
      "|    n_updates            | 28080         |\n",
      "|    policy_gradient_loss | -3.51e-05     |\n",
      "|    reward               | 58.34192      |\n",
      "|    value_loss           | 1.84e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 143\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 287           |\n",
      "|    time_elapsed         | 1015          |\n",
      "|    total_timesteps      | 293888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0236552e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.81e+05      |\n",
      "|    n_updates            | 28090         |\n",
      "|    policy_gradient_loss | -4.22e-05     |\n",
      "|    reward               | -19.168793    |\n",
      "|    value_loss           | 7.62e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 1019         |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.301569e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.95        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.29e+05     |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -7.78e-06    |\n",
      "|    reward               | -46.880455   |\n",
      "|    value_loss           | 2.58e+05     |\n",
      "------------------------------------------\n",
      "Episode: 144\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 690819.99\n",
      "total_reward: -309180.01\n",
      "total_cost: 363140.75\n",
      "total_trades: 395\n",
      "=================================\n",
      "Episode: 145\n",
      "Episode: 146\n",
      "Episode: 147\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 289           |\n",
      "|    time_elapsed         | 1022          |\n",
      "|    total_timesteps      | 295936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3544923e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.31e+05      |\n",
      "|    n_updates            | 28110         |\n",
      "|    policy_gradient_loss | -1.88e-05     |\n",
      "|    reward               | -10.71253     |\n",
      "|    value_loss           | 2.62e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 289            |\n",
      "|    iterations           | 290            |\n",
      "|    time_elapsed         | 1025           |\n",
      "|    total_timesteps      | 296960         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.18860044e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.95          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 9.52e+04       |\n",
      "|    n_updates            | 28120          |\n",
      "|    policy_gradient_loss | 8.6e-07        |\n",
      "|    reward               | -2.3718998     |\n",
      "|    value_loss           | 1.91e+05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 1029         |\n",
      "|    total_timesteps      | 297984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.902882e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.62e+04     |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -2.33e-05    |\n",
      "|    reward               | 17.225538    |\n",
      "|    value_loss           | 3.24e+04     |\n",
      "------------------------------------------\n",
      "Episode: 148\n",
      "Current company: ['CVX']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1814743.83\n",
      "total_reward: 814743.83\n",
      "total_cost: 690800.81\n",
      "total_trades: 528\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 292           |\n",
      "|    time_elapsed         | 1032          |\n",
      "|    total_timesteps      | 299008        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8958311e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.952        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.53e+04      |\n",
      "|    n_updates            | 28140         |\n",
      "|    policy_gradient_loss | -4.34e-06     |\n",
      "|    reward               | 38.219486     |\n",
      "|    value_loss           | 5.06e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 293          |\n",
      "|    time_elapsed         | 1036         |\n",
      "|    total_timesteps      | 300032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.257331e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.954       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.55e+04     |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -8.88e-05    |\n",
      "|    reward               | 44.494564    |\n",
      "|    value_loss           | 1.51e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 294           |\n",
      "|    time_elapsed         | 1039          |\n",
      "|    total_timesteps      | 301056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5043492e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.956        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+05      |\n",
      "|    n_updates            | 28160         |\n",
      "|    policy_gradient_loss | -1.83e-05     |\n",
      "|    reward               | 101.479515    |\n",
      "|    value_loss           | 4.9e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 149\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 1042        |\n",
      "|    total_timesteps      | 302080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 1.38022e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71e+05    |\n",
      "|    n_updates            | 28170       |\n",
      "|    policy_gradient_loss | -2.85e-05   |\n",
      "|    reward               | 71.555405   |\n",
      "|    value_loss           | 1.54e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 296           |\n",
      "|    time_elapsed         | 1046          |\n",
      "|    total_timesteps      | 303104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1082815e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.994        |\n",
      "|    explained_variance   | 0.395         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.91e+05      |\n",
      "|    n_updates            | 28180         |\n",
      "|    policy_gradient_loss | 4.21e-06      |\n",
      "|    reward               | 87.61122      |\n",
      "|    value_loss           | 1.42e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 150\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 297           |\n",
      "|    time_elapsed         | 1050          |\n",
      "|    total_timesteps      | 304128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0559022e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0.0509        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.18e+06      |\n",
      "|    n_updates            | 28190         |\n",
      "|    policy_gradient_loss | -8.7e-06      |\n",
      "|    reward               | 1.4876082     |\n",
      "|    value_loss           | 2.43e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 298        |\n",
      "|    time_elapsed         | 1053       |\n",
      "|    total_timesteps      | 305152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0.318      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.45e+05   |\n",
      "|    n_updates            | 28200      |\n",
      "|    policy_gradient_loss | 1.51e-06   |\n",
      "|    reward               | -7.3705335 |\n",
      "|    value_loss           | 1.92e+06   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 1056         |\n",
      "|    total_timesteps      | 306176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.288114e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.79e+03     |\n",
      "|    n_updates            | 28210        |\n",
      "|    policy_gradient_loss | -0.000168    |\n",
      "|    reward               | -9.344434    |\n",
      "|    value_loss           | 7.99e+03     |\n",
      "------------------------------------------\n",
      "Episode: 151\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 1060         |\n",
      "|    total_timesteps      | 307200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.305475e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84e+04     |\n",
      "|    n_updates            | 28220        |\n",
      "|    policy_gradient_loss | -9.23e-05    |\n",
      "|    reward               | 37.11512     |\n",
      "|    value_loss           | 3.71e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 301          |\n",
      "|    time_elapsed         | 1063         |\n",
      "|    total_timesteps      | 308224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.466254e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.84e+04     |\n",
      "|    n_updates            | 28230        |\n",
      "|    policy_gradient_loss | -3.83e-05    |\n",
      "|    reward               | 9.844923     |\n",
      "|    value_loss           | 9.71e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 302           |\n",
      "|    time_elapsed         | 1067          |\n",
      "|    total_timesteps      | 309248        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.6822547e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.78e+05      |\n",
      "|    n_updates            | 28240         |\n",
      "|    policy_gradient_loss | 1.51e-05      |\n",
      "|    reward               | 57.875645     |\n",
      "|    value_loss           | 5.57e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 152\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2097327.42\n",
      "total_reward: 1097327.42\n",
      "total_cost: 834911.09\n",
      "total_trades: 533\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 303           |\n",
      "|    time_elapsed         | 1071          |\n",
      "|    total_timesteps      | 310272        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6554335e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.76e+05      |\n",
      "|    n_updates            | 28250         |\n",
      "|    policy_gradient_loss | -3.94e-06     |\n",
      "|    reward               | 7.0240316     |\n",
      "|    value_loss           | 5.52e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 1074         |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.197385e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.945       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.38e+05     |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -1.79e-05    |\n",
      "|    reward               | 15.392125    |\n",
      "|    value_loss           | 2.77e+05     |\n",
      "------------------------------------------\n",
      "Episode: 153\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 1078         |\n",
      "|    total_timesteps      | 312320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.847557e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.944       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.38e+04     |\n",
      "|    n_updates            | 28270        |\n",
      "|    policy_gradient_loss | -1.17e-05    |\n",
      "|    reward               | -15.065801   |\n",
      "|    value_loss           | 1.1e+05      |\n",
      "------------------------------------------\n",
      "Episode: 154\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 289           |\n",
      "|    iterations           | 306           |\n",
      "|    time_elapsed         | 1081          |\n",
      "|    total_timesteps      | 313344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0963413e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.944        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.97e+04      |\n",
      "|    n_updates            | 28280         |\n",
      "|    policy_gradient_loss | -8.54e-06     |\n",
      "|    reward               | 20.601797     |\n",
      "|    value_loss           | 1.6e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 307           |\n",
      "|    time_elapsed         | 1113          |\n",
      "|    total_timesteps      | 314368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0073064e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.943        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.86e+04      |\n",
      "|    n_updates            | 28290         |\n",
      "|    policy_gradient_loss | -4.14e-05     |\n",
      "|    reward               | 15.355305     |\n",
      "|    value_loss           | 1.18e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 155\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 1117         |\n",
      "|    total_timesteps      | 315392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.350448e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.51e+05     |\n",
      "|    n_updates            | 28300        |\n",
      "|    policy_gradient_loss | 2.19e-05     |\n",
      "|    reward               | 4.7540383    |\n",
      "|    value_loss           | 5.06e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 1120         |\n",
      "|    total_timesteps      | 316416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.961636e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.7e+05      |\n",
      "|    n_updates            | 28310        |\n",
      "|    policy_gradient_loss | -6.67e-06    |\n",
      "|    reward               | -18.855318   |\n",
      "|    value_loss           | 7.49e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 310           |\n",
      "|    time_elapsed         | 1124          |\n",
      "|    total_timesteps      | 317440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7830171e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.942        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.32e+04      |\n",
      "|    n_updates            | 28320         |\n",
      "|    policy_gradient_loss | -3.3e-05      |\n",
      "|    reward               | 11.127506     |\n",
      "|    value_loss           | 2.79e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 156\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1416324.08\n",
      "total_reward: 416324.08\n",
      "total_cost: 673532.63\n",
      "total_trades: 533\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 311          |\n",
      "|    time_elapsed         | 1127         |\n",
      "|    total_timesteps      | 318464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.783303e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.943       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.98e+04     |\n",
      "|    n_updates            | 28330        |\n",
      "|    policy_gradient_loss | -6.19e-05    |\n",
      "|    reward               | -6.7105446   |\n",
      "|    value_loss           | 4e+04        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 312           |\n",
      "|    time_elapsed         | 1131          |\n",
      "|    total_timesteps      | 319488        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5500118e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -0.439        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.3e+05       |\n",
      "|    n_updates            | 28340         |\n",
      "|    policy_gradient_loss | 9e-05         |\n",
      "|    reward               | -9.611276     |\n",
      "|    value_loss           | 2.62e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 313          |\n",
      "|    time_elapsed         | 1134         |\n",
      "|    total_timesteps      | 320512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.392373e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.961       |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.29e+04     |\n",
      "|    n_updates            | 28350        |\n",
      "|    policy_gradient_loss | -8.02e-07    |\n",
      "|    reward               | 58.997154    |\n",
      "|    value_loss           | 1.06e+05     |\n",
      "------------------------------------------\n",
      "Episode: 157\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 314           |\n",
      "|    time_elapsed         | 1138          |\n",
      "|    total_timesteps      | 321536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7386704e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.69e+05      |\n",
      "|    n_updates            | 28360         |\n",
      "|    policy_gradient_loss | 3.26e-06      |\n",
      "|    reward               | 28.801165     |\n",
      "|    value_loss           | 1.14e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 315           |\n",
      "|    time_elapsed         | 1142          |\n",
      "|    total_timesteps      | 322560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5169145e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+06      |\n",
      "|    n_updates            | 28370         |\n",
      "|    policy_gradient_loss | -4e-07        |\n",
      "|    reward               | 136.92415     |\n",
      "|    value_loss           | 2.99e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 1145         |\n",
      "|    total_timesteps      | 323584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.837095e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.946       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.6e+05      |\n",
      "|    n_updates            | 28380        |\n",
      "|    policy_gradient_loss | -2.02e-06    |\n",
      "|    reward               | 138.33336    |\n",
      "|    value_loss           | 1.93e+06     |\n",
      "------------------------------------------\n",
      "Episode: 158\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 317           |\n",
      "|    time_elapsed         | 1149          |\n",
      "|    total_timesteps      | 324608        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4354238e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.48e+06      |\n",
      "|    n_updates            | 28390         |\n",
      "|    policy_gradient_loss | -2.2e-06      |\n",
      "|    reward               | -0.31039083   |\n",
      "|    value_loss           | 9e+06         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 318           |\n",
      "|    time_elapsed         | 1152          |\n",
      "|    total_timesteps      | 325632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4201505e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.29e+05      |\n",
      "|    n_updates            | 28400         |\n",
      "|    policy_gradient_loss | -3.49e-05     |\n",
      "|    reward               | 41.95468      |\n",
      "|    value_loss           | 4.59e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 159\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 319           |\n",
      "|    time_elapsed         | 1156          |\n",
      "|    total_timesteps      | 326656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2478205e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.82e+04      |\n",
      "|    n_updates            | 28410         |\n",
      "|    policy_gradient_loss | -6.33e-05     |\n",
      "|    reward               | -13.719516    |\n",
      "|    value_loss           | 1.17e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 320           |\n",
      "|    time_elapsed         | 1159          |\n",
      "|    total_timesteps      | 327680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7025817e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.44e+05      |\n",
      "|    n_updates            | 28420         |\n",
      "|    policy_gradient_loss | -9.71e-06     |\n",
      "|    reward               | -50.001076    |\n",
      "|    value_loss           | 4.95e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 1163         |\n",
      "|    total_timesteps      | 328704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.308554e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.09e+04     |\n",
      "|    n_updates            | 28430        |\n",
      "|    policy_gradient_loss | -2.36e-05    |\n",
      "|    reward               | -62.06296    |\n",
      "|    value_loss           | 1.83e+05     |\n",
      "------------------------------------------\n",
      "Episode: 160\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 961472.40\n",
      "total_reward: -38527.60\n",
      "total_cost: 482701.77\n",
      "total_trades: 537\n",
      "=================================\n",
      "Episode: 161\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 322           |\n",
      "|    time_elapsed         | 1166          |\n",
      "|    total_timesteps      | 329728        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6303966e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.947        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.34e+05      |\n",
      "|    n_updates            | 28440         |\n",
      "|    policy_gradient_loss | -4.33e-05     |\n",
      "|    reward               | 22.08187      |\n",
      "|    value_loss           | 6.68e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 323          |\n",
      "|    time_elapsed         | 1170         |\n",
      "|    total_timesteps      | 330752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.875241e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.75e+05     |\n",
      "|    n_updates            | 28450        |\n",
      "|    policy_gradient_loss | -6.43e-05    |\n",
      "|    reward               | 12.326667    |\n",
      "|    value_loss           | 5.5e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 324          |\n",
      "|    time_elapsed         | 1173         |\n",
      "|    total_timesteps      | 331776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.889894e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.95        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.83e+05     |\n",
      "|    n_updates            | 28460        |\n",
      "|    policy_gradient_loss | 1.62e-05     |\n",
      "|    reward               | 98.64303     |\n",
      "|    value_loss           | 5.66e+05     |\n",
      "------------------------------------------\n",
      "Episode: 162\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 325          |\n",
      "|    time_elapsed         | 1177         |\n",
      "|    total_timesteps      | 332800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.587361e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.94e+05     |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -9.83e-06    |\n",
      "|    reward               | -32.99978    |\n",
      "|    value_loss           | 1.19e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 1180         |\n",
      "|    total_timesteps      | 333824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.961636e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.952       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.11e+05     |\n",
      "|    n_updates            | 28480        |\n",
      "|    policy_gradient_loss | -1.74e-05    |\n",
      "|    reward               | -8.083317    |\n",
      "|    value_loss           | 1.22e+06     |\n",
      "------------------------------------------\n",
      "Episode: 163\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 327           |\n",
      "|    time_elapsed         | 1184          |\n",
      "|    total_timesteps      | 334848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.5714855e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.951        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.09e+04      |\n",
      "|    n_updates            | 28490         |\n",
      "|    policy_gradient_loss | -5.09e-05     |\n",
      "|    reward               | -0.13         |\n",
      "|    value_loss           | 2.18e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 328          |\n",
      "|    time_elapsed         | 1187         |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011059982 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.958       |\n",
      "|    explained_variance   | 0.000247     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.96e+04     |\n",
      "|    n_updates            | 28500        |\n",
      "|    policy_gradient_loss | -0.00064     |\n",
      "|    reward               | 105.2337     |\n",
      "|    value_loss           | 3.93e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 1191         |\n",
      "|    total_timesteps      | 336896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006432441 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.32e+05     |\n",
      "|    n_updates            | 28510        |\n",
      "|    policy_gradient_loss | 0.00118      |\n",
      "|    reward               | 59.187614    |\n",
      "|    value_loss           | 1.48e+06     |\n",
      "------------------------------------------\n",
      "Episode: 164\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3504993.60\n",
      "total_reward: 2504993.60\n",
      "total_cost: 1499829.48\n",
      "total_trades: 760\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 330          |\n",
      "|    time_elapsed         | 1195         |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.806214e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.38e+05     |\n",
      "|    n_updates            | 28520        |\n",
      "|    policy_gradient_loss | 3.4e-05      |\n",
      "|    reward               | -13.853024   |\n",
      "|    value_loss           | 1.1e+06      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 331           |\n",
      "|    time_elapsed         | 1198          |\n",
      "|    total_timesteps      | 338944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2330004e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.325         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.33e+06      |\n",
      "|    n_updates            | 28530         |\n",
      "|    policy_gradient_loss | -5.6e-05      |\n",
      "|    reward               | -6.0093074    |\n",
      "|    value_loss           | 2.67e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 1202         |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006888333 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 28540        |\n",
      "|    policy_gradient_loss | -0.000174    |\n",
      "|    reward               | 10.5649805   |\n",
      "|    value_loss           | 3.63e+03     |\n",
      "------------------------------------------\n",
      "Episode: 165\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 333          |\n",
      "|    time_elapsed         | 1206         |\n",
      "|    total_timesteps      | 340992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006611504 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.2e+04      |\n",
      "|    n_updates            | 28550        |\n",
      "|    policy_gradient_loss | -1.77e-05    |\n",
      "|    reward               | 2.6157491    |\n",
      "|    value_loss           | 4.41e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 1210         |\n",
      "|    total_timesteps      | 342016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002103115 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.1e+04      |\n",
      "|    n_updates            | 28560        |\n",
      "|    policy_gradient_loss | -0.000494    |\n",
      "|    reward               | 10.27406     |\n",
      "|    value_loss           | 6.21e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 1214         |\n",
      "|    total_timesteps      | 343040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.241506e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.07e+04     |\n",
      "|    n_updates            | 28570        |\n",
      "|    policy_gradient_loss | 1.01e-05     |\n",
      "|    reward               | -23.824776   |\n",
      "|    value_loss           | 6.15e+04     |\n",
      "------------------------------------------\n",
      "Episode: 166\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 336           |\n",
      "|    time_elapsed         | 1217          |\n",
      "|    total_timesteps      | 344064        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8268703e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.73e+04      |\n",
      "|    n_updates            | 28580         |\n",
      "|    policy_gradient_loss | 9.4e-05       |\n",
      "|    reward               | -6.1826158    |\n",
      "|    value_loss           | 1.35e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 337           |\n",
      "|    time_elapsed         | 1221          |\n",
      "|    total_timesteps      | 345088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018628733 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.33e+03      |\n",
      "|    n_updates            | 28590         |\n",
      "|    policy_gradient_loss | -0.000563     |\n",
      "|    reward               | 20.928139     |\n",
      "|    value_loss           | 1.87e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 167\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 338           |\n",
      "|    time_elapsed         | 1225          |\n",
      "|    total_timesteps      | 346112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013112975 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.14e+04      |\n",
      "|    n_updates            | 28600         |\n",
      "|    policy_gradient_loss | 0.000376      |\n",
      "|    reward               | -8.029901     |\n",
      "|    value_loss           | 4.29e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 339          |\n",
      "|    time_elapsed         | 1228         |\n",
      "|    total_timesteps      | 347136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.293668e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.62e+05     |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -9.92e-06    |\n",
      "|    reward               | -14.389246   |\n",
      "|    value_loss           | 7.25e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 340           |\n",
      "|    time_elapsed         | 1232          |\n",
      "|    total_timesteps      | 348160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2111501e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.13e+03      |\n",
      "|    n_updates            | 28620         |\n",
      "|    policy_gradient_loss | -9.77e-05     |\n",
      "|    reward               | -1.3980047    |\n",
      "|    value_loss           | 1.04e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 168\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1780059.09\n",
      "total_reward: 780059.09\n",
      "total_cost: 848980.66\n",
      "total_trades: 728\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 341           |\n",
      "|    time_elapsed         | 1236          |\n",
      "|    total_timesteps      | 349184        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7117709e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.07e+05      |\n",
      "|    n_updates            | 28630         |\n",
      "|    policy_gradient_loss | 0.00011       |\n",
      "|    reward               | 5.3493986     |\n",
      "|    value_loss           | 2.14e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 342           |\n",
      "|    time_elapsed         | 1239          |\n",
      "|    total_timesteps      | 350208        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3318217e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.13e+04      |\n",
      "|    n_updates            | 28640         |\n",
      "|    policy_gradient_loss | -5.77e-05     |\n",
      "|    reward               | -16.267488    |\n",
      "|    value_loss           | 6.25e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 343          |\n",
      "|    time_elapsed         | 1244         |\n",
      "|    total_timesteps      | 351232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.502044e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.86e+04     |\n",
      "|    n_updates            | 28650        |\n",
      "|    policy_gradient_loss | -4.96e-05    |\n",
      "|    reward               | -32.145336   |\n",
      "|    value_loss           | 3.72e+04     |\n",
      "------------------------------------------\n",
      "Episode: 169\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 344           |\n",
      "|    time_elapsed         | 1248          |\n",
      "|    total_timesteps      | 352256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1733926e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.93e+04      |\n",
      "|    n_updates            | 28660         |\n",
      "|    policy_gradient_loss | 4.39e-06      |\n",
      "|    reward               | -26.720959    |\n",
      "|    value_loss           | 1.39e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 1251         |\n",
      "|    total_timesteps      | 353280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.203008e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.76e+04     |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -1.77e-05    |\n",
      "|    reward               | -60.2916     |\n",
      "|    value_loss           | 7.52e+04     |\n",
      "------------------------------------------\n",
      "Episode: 170\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 1255         |\n",
      "|    total_timesteps      | 354304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.705806e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.41e+05     |\n",
      "|    n_updates            | 28680        |\n",
      "|    policy_gradient_loss | -0.000127    |\n",
      "|    reward               | 6.5481353    |\n",
      "|    value_loss           | 4.83e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 347           |\n",
      "|    time_elapsed         | 1259          |\n",
      "|    total_timesteps      | 355328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5777845e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.67e+05      |\n",
      "|    n_updates            | 28690         |\n",
      "|    policy_gradient_loss | 5.81e-06      |\n",
      "|    reward               | 12.581722     |\n",
      "|    value_loss           | 7.34e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 1262         |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.430228e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.16e+04     |\n",
      "|    n_updates            | 28700        |\n",
      "|    policy_gradient_loss | -5.13e-05    |\n",
      "|    reward               | 42.19423     |\n",
      "|    value_loss           | 1.63e+05     |\n",
      "------------------------------------------\n",
      "Episode: 171\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 349          |\n",
      "|    time_elapsed         | 1266         |\n",
      "|    total_timesteps      | 357376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.900541e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.49e+05     |\n",
      "|    n_updates            | 28710        |\n",
      "|    policy_gradient_loss | 2.9e-05      |\n",
      "|    reward               | 23.334852    |\n",
      "|    value_loss           | 4.98e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 350          |\n",
      "|    time_elapsed         | 1269         |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.215376e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.7e+05      |\n",
      "|    n_updates            | 28720        |\n",
      "|    policy_gradient_loss | -6.64e-06    |\n",
      "|    reward               | 21.691378    |\n",
      "|    value_loss           | 1.54e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 1273        |\n",
      "|    total_timesteps      | 359424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.60889e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63e+05    |\n",
      "|    n_updates            | 28730       |\n",
      "|    policy_gradient_loss | -1.26e-05   |\n",
      "|    reward               | -62.54744   |\n",
      "|    value_loss           | 3.26e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 172\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 889653.33\n",
      "total_reward: -110346.67\n",
      "total_cost: 860664.84\n",
      "total_trades: 693\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 352           |\n",
      "|    time_elapsed         | 1277          |\n",
      "|    total_timesteps      | 360448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5322813e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.18e+05      |\n",
      "|    n_updates            | 28740         |\n",
      "|    policy_gradient_loss | -4.58e-05     |\n",
      "|    reward               | -12.873585    |\n",
      "|    value_loss           | 2.37e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 353          |\n",
      "|    time_elapsed         | 1280         |\n",
      "|    total_timesteps      | 361472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.773028e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79e+04     |\n",
      "|    n_updates            | 28750        |\n",
      "|    policy_gradient_loss | -2.65e-05    |\n",
      "|    reward               | -37.622177   |\n",
      "|    value_loss           | 1.76e+05     |\n",
      "------------------------------------------\n",
      "Episode: 173\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 1284         |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.544214e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.73e+04     |\n",
      "|    n_updates            | 28760        |\n",
      "|    policy_gradient_loss | -4.07e-05    |\n",
      "|    reward               | -7.191384    |\n",
      "|    value_loss           | 9.47e+04     |\n",
      "------------------------------------------\n",
      "Episode: 174\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 1288         |\n",
      "|    total_timesteps      | 363520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.926734e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.05e+05     |\n",
      "|    n_updates            | 28770        |\n",
      "|    policy_gradient_loss | 2.28e-05     |\n",
      "|    reward               | -24.790854   |\n",
      "|    value_loss           | 4.11e+05     |\n",
      "------------------------------------------\n",
      "Episode: 175\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 356           |\n",
      "|    time_elapsed         | 1291          |\n",
      "|    total_timesteps      | 364544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1352567e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.86e+03      |\n",
      "|    n_updates            | 28780         |\n",
      "|    policy_gradient_loss | -7.24e-05     |\n",
      "|    reward               | -27.03895     |\n",
      "|    value_loss           | 1.98e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 176\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 692608.96\n",
      "total_reward: -307391.04\n",
      "total_cost: 134251.55\n",
      "total_trades: 155\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 357           |\n",
      "|    time_elapsed         | 1295          |\n",
      "|    total_timesteps      | 365568        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6970905e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.74e+05      |\n",
      "|    n_updates            | 28790         |\n",
      "|    policy_gradient_loss | -0.000237     |\n",
      "|    reward               | -3.8210871    |\n",
      "|    value_loss           | 3.48e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 358           |\n",
      "|    time_elapsed         | 1298          |\n",
      "|    total_timesteps      | 366592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7599494e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.3e+04       |\n",
      "|    n_updates            | 28800         |\n",
      "|    policy_gradient_loss | -3.75e-05     |\n",
      "|    reward               | -8.330606     |\n",
      "|    value_loss           | 6.61e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 359           |\n",
      "|    time_elapsed         | 1302          |\n",
      "|    total_timesteps      | 367616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010244758 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.17e+03      |\n",
      "|    n_updates            | 28810         |\n",
      "|    policy_gradient_loss | -0.000365     |\n",
      "|    reward               | -56.013195    |\n",
      "|    value_loss           | 1.24e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 177\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 360           |\n",
      "|    time_elapsed         | 1306          |\n",
      "|    total_timesteps      | 368640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012268336 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.99e+04      |\n",
      "|    n_updates            | 28820         |\n",
      "|    policy_gradient_loss | 7.16e-05      |\n",
      "|    reward               | 4.9740562     |\n",
      "|    value_loss           | 1.4e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 361           |\n",
      "|    time_elapsed         | 1309          |\n",
      "|    total_timesteps      | 369664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060584466 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.57e+04      |\n",
      "|    n_updates            | 28830         |\n",
      "|    policy_gradient_loss | -0.000747     |\n",
      "|    reward               | -8.437254     |\n",
      "|    value_loss           | 3.14e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 178\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 362          |\n",
      "|    time_elapsed         | 1313         |\n",
      "|    total_timesteps      | 370688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006702617 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.5e+04      |\n",
      "|    n_updates            | 28840        |\n",
      "|    policy_gradient_loss | -0.000737    |\n",
      "|    reward               | 6.5873604    |\n",
      "|    value_loss           | 4.99e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 363           |\n",
      "|    time_elapsed         | 1316          |\n",
      "|    total_timesteps      | 371712        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015961722 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.82e+05      |\n",
      "|    n_updates            | 28850         |\n",
      "|    policy_gradient_loss | -4.98e-05     |\n",
      "|    reward               | 17.009108     |\n",
      "|    value_loss           | 3.64e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 364           |\n",
      "|    time_elapsed         | 1320          |\n",
      "|    total_timesteps      | 372736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8529303e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.93e+04      |\n",
      "|    n_updates            | 28860         |\n",
      "|    policy_gradient_loss | 1.35e-05      |\n",
      "|    reward               | 117.51905     |\n",
      "|    value_loss           | 1.99e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 179\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 1323         |\n",
      "|    total_timesteps      | 373760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.112356e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.77e+05     |\n",
      "|    n_updates            | 28870        |\n",
      "|    policy_gradient_loss | -1.61e-05    |\n",
      "|    reward               | 16.242138    |\n",
      "|    value_loss           | 9.54e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 1327         |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.825453e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -1.3         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.69e+05     |\n",
      "|    n_updates            | 28880        |\n",
      "|    policy_gradient_loss | 4.98e-06     |\n",
      "|    reward               | -10.409989   |\n",
      "|    value_loss           | 1.74e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 367           |\n",
      "|    time_elapsed         | 1331          |\n",
      "|    total_timesteps      | 375808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0558946e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.64e+04      |\n",
      "|    n_updates            | 28890         |\n",
      "|    policy_gradient_loss | -1.46e-05     |\n",
      "|    reward               | 10.114047     |\n",
      "|    value_loss           | 1.33e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 180\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2166461.11\n",
      "total_reward: 1166461.11\n",
      "total_cost: 1001153.82\n",
      "total_trades: 723\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 368          |\n",
      "|    time_elapsed         | 1334         |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.369715e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.77e+04     |\n",
      "|    n_updates            | 28900        |\n",
      "|    policy_gradient_loss | -3.14e-05    |\n",
      "|    reward               | -19.088238   |\n",
      "|    value_loss           | 9.54e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 369           |\n",
      "|    time_elapsed         | 1338          |\n",
      "|    total_timesteps      | 377856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6077108e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+05      |\n",
      "|    n_updates            | 28910         |\n",
      "|    policy_gradient_loss | 1.81e-05      |\n",
      "|    reward               | -11.73435     |\n",
      "|    value_loss           | 2.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 181\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 1341         |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.387433e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.16e+04     |\n",
      "|    n_updates            | 28920        |\n",
      "|    policy_gradient_loss | -5.41e-05    |\n",
      "|    reward               | -4.6539817   |\n",
      "|    value_loss           | 2.32e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 1345         |\n",
      "|    total_timesteps      | 379904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.744805e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.71e+05     |\n",
      "|    n_updates            | 28930        |\n",
      "|    policy_gradient_loss | 0.000174     |\n",
      "|    reward               | -21.035328   |\n",
      "|    value_loss           | 3.42e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 372           |\n",
      "|    time_elapsed         | 1348          |\n",
      "|    total_timesteps      | 380928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3306853e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.9e+04       |\n",
      "|    n_updates            | 28940         |\n",
      "|    policy_gradient_loss | -2.55e-06     |\n",
      "|    reward               | -43.238045    |\n",
      "|    value_loss           | 5.82e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 182\n",
      "Episode: 183\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 373           |\n",
      "|    time_elapsed         | 1352          |\n",
      "|    total_timesteps      | 381952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1250377e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.12e+05      |\n",
      "|    n_updates            | 28950         |\n",
      "|    policy_gradient_loss | -2.25e-05     |\n",
      "|    reward               | 25.928802     |\n",
      "|    value_loss           | 4.24e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 374           |\n",
      "|    time_elapsed         | 1355          |\n",
      "|    total_timesteps      | 382976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0468066e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.39e+04      |\n",
      "|    n_updates            | 28960         |\n",
      "|    policy_gradient_loss | -0.000104     |\n",
      "|    reward               | 36.227207     |\n",
      "|    value_loss           | 1.48e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 375          |\n",
      "|    time_elapsed         | 1359         |\n",
      "|    total_timesteps      | 384000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.175375e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.998       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.47e+05     |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | 3.81e-05     |\n",
      "|    reward               | 83.02656     |\n",
      "|    value_loss           | 2.95e+05     |\n",
      "------------------------------------------\n",
      "Episode: 184\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1964077.95\n",
      "total_reward: 964077.95\n",
      "total_cost: 1065047.16\n",
      "total_trades: 640\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 376           |\n",
      "|    time_elapsed         | 1362          |\n",
      "|    total_timesteps      | 385024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1366792e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.997        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.6e+05       |\n",
      "|    n_updates            | 28980         |\n",
      "|    policy_gradient_loss | 1.31e-05      |\n",
      "|    reward               | 1.5469085     |\n",
      "|    value_loss           | 1.52e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 377          |\n",
      "|    time_elapsed         | 1366         |\n",
      "|    total_timesteps      | 386048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.849893e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.997       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.63e+05     |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -2.65e-05    |\n",
      "|    reward               | -5.345933    |\n",
      "|    value_loss           | 5.27e+05     |\n",
      "------------------------------------------\n",
      "Episode: 185\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 1369         |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016138642 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.997       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.97e+03     |\n",
      "|    n_updates            | 29000        |\n",
      "|    policy_gradient_loss | -0.000207    |\n",
      "|    reward               | -0.4038917   |\n",
      "|    value_loss           | 1.19e+04     |\n",
      "------------------------------------------\n",
      "Episode: 186\n",
      "Episode: 187\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 379          |\n",
      "|    time_elapsed         | 1373         |\n",
      "|    total_timesteps      | 388096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018210398 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.995       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.23e+04     |\n",
      "|    n_updates            | 29010        |\n",
      "|    policy_gradient_loss | -4.06e-05    |\n",
      "|    reward               | -18.5666     |\n",
      "|    value_loss           | 8.45e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 380          |\n",
      "|    time_elapsed         | 1376         |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.071074e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.996       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.37e+04     |\n",
      "|    n_updates            | 29020        |\n",
      "|    policy_gradient_loss | 0.000164     |\n",
      "|    reward               | 31.107338    |\n",
      "|    value_loss           | 6.74e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 381          |\n",
      "|    time_elapsed         | 1380         |\n",
      "|    total_timesteps      | 390144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.643232e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.994       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.26e+04     |\n",
      "|    n_updates            | 29030        |\n",
      "|    policy_gradient_loss | -9.63e-05    |\n",
      "|    reward               | 26.917694    |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n",
      "Episode: 188\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1704112.35\n",
      "total_reward: 704112.35\n",
      "total_cost: 894917.84\n",
      "total_trades: 636\n",
      "=================================\n",
      "Episode: 189\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 382           |\n",
      "|    time_elapsed         | 1384          |\n",
      "|    total_timesteps      | 391168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1352939e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.993        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.11e+05      |\n",
      "|    n_updates            | 29040         |\n",
      "|    policy_gradient_loss | 7.12e-06      |\n",
      "|    reward               | 3.6720743     |\n",
      "|    value_loss           | 4.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 383           |\n",
      "|    time_elapsed         | 1387          |\n",
      "|    total_timesteps      | 392192        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4781835e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.993        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.93e+04      |\n",
      "|    n_updates            | 29050         |\n",
      "|    policy_gradient_loss | -6.64e-07     |\n",
      "|    reward               | -20.768232    |\n",
      "|    value_loss           | 1.59e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 384          |\n",
      "|    time_elapsed         | 1391         |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011323587 |\n",
      "|    clip_fraction        | 0.084        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.979       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51e+04     |\n",
      "|    n_updates            | 29060        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -56.104946   |\n",
      "|    value_loss           | 3.02e+04     |\n",
      "------------------------------------------\n",
      "Episode: 190\n",
      "Episode: 191\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 1395         |\n",
      "|    total_timesteps      | 394240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012454075 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.993       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.16e+05     |\n",
      "|    n_updates            | 29070        |\n",
      "|    policy_gradient_loss | -0.000841    |\n",
      "|    reward               | -8.08972     |\n",
      "|    value_loss           | 4.32e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 386          |\n",
      "|    time_elapsed         | 1460         |\n",
      "|    total_timesteps      | 395264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001529472 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.01e+05     |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -2.3e-05     |\n",
      "|    reward               | -54.258442   |\n",
      "|    value_loss           | 2.01e+05     |\n",
      "------------------------------------------\n",
      "Episode: 192\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697962.08\n",
      "total_reward: -302037.92\n",
      "total_cost: 268641.73\n",
      "total_trades: 287\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 1465         |\n",
      "|    total_timesteps      | 396288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.216606e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.62e+04     |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | 1.98e-05     |\n",
      "|    reward               | -18.004484   |\n",
      "|    value_loss           | 1.53e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 388          |\n",
      "|    time_elapsed         | 1468         |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.525972e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.08e+04     |\n",
      "|    n_updates            | 29100        |\n",
      "|    policy_gradient_loss | 7.26e-06     |\n",
      "|    reward               | -40.965363   |\n",
      "|    value_loss           | 1.22e+05     |\n",
      "------------------------------------------\n",
      "Episode: 193\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 389          |\n",
      "|    time_elapsed         | 1472         |\n",
      "|    total_timesteps      | 398336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.924376e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.41e+05     |\n",
      "|    n_updates            | 29110        |\n",
      "|    policy_gradient_loss | -1.37e-05    |\n",
      "|    reward               | -19.421291   |\n",
      "|    value_loss           | 4.83e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 390          |\n",
      "|    time_elapsed         | 1475         |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.641494e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.34e+05     |\n",
      "|    n_updates            | 29120        |\n",
      "|    policy_gradient_loss | -1.43e-05    |\n",
      "|    reward               | -22.491634   |\n",
      "|    value_loss           | 2.69e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 391           |\n",
      "|    time_elapsed         | 1479          |\n",
      "|    total_timesteps      | 400384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1302334e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.33e+04      |\n",
      "|    n_updates            | 29130         |\n",
      "|    policy_gradient_loss | -4.11e-05     |\n",
      "|    reward               | -1.3350217    |\n",
      "|    value_loss           | 1.07e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 194\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 392           |\n",
      "|    time_elapsed         | 1482          |\n",
      "|    total_timesteps      | 401408        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4237263e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.96e+03      |\n",
      "|    n_updates            | 29140         |\n",
      "|    policy_gradient_loss | -0.000152     |\n",
      "|    reward               | -3.1252377    |\n",
      "|    value_loss           | 2e+04         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 393          |\n",
      "|    time_elapsed         | 1486         |\n",
      "|    total_timesteps      | 402432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.018832e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.61e+03     |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | 9.22e-06     |\n",
      "|    reward               | -21.459808   |\n",
      "|    value_loss           | 1.92e+04     |\n",
      "------------------------------------------\n",
      "Episode: 195\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 394           |\n",
      "|    time_elapsed         | 1490          |\n",
      "|    total_timesteps      | 403456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5830621e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.9e+04       |\n",
      "|    n_updates            | 29160         |\n",
      "|    policy_gradient_loss | 0.00012       |\n",
      "|    reward               | -25.088968    |\n",
      "|    value_loss           | 3.81e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 395           |\n",
      "|    time_elapsed         | 1493          |\n",
      "|    total_timesteps      | 404480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2967328e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.57e+04      |\n",
      "|    n_updates            | 29170         |\n",
      "|    policy_gradient_loss | -9.11e-05     |\n",
      "|    reward               | -26.819468    |\n",
      "|    value_loss           | 7.15e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 396           |\n",
      "|    time_elapsed         | 1497          |\n",
      "|    total_timesteps      | 405504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5680714e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.83e+04      |\n",
      "|    n_updates            | 29180         |\n",
      "|    policy_gradient_loss | -0.000199     |\n",
      "|    reward               | -66.332756    |\n",
      "|    value_loss           | 5.68e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 196\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 639348.94\n",
      "total_reward: -360651.06\n",
      "total_cost: 533058.61\n",
      "total_trades: 575\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 397           |\n",
      "|    time_elapsed         | 1500          |\n",
      "|    total_timesteps      | 406528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3427343e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.52e+05      |\n",
      "|    n_updates            | 29190         |\n",
      "|    policy_gradient_loss | 1.93e-05      |\n",
      "|    reward               | -27.613113    |\n",
      "|    value_loss           | 5.06e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 398           |\n",
      "|    time_elapsed         | 1504          |\n",
      "|    total_timesteps      | 407552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1327287e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.82e+05      |\n",
      "|    n_updates            | 29200         |\n",
      "|    policy_gradient_loss | -4.18e-05     |\n",
      "|    reward               | -0.7922652    |\n",
      "|    value_loss           | 3.8e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 399           |\n",
      "|    time_elapsed         | 1508          |\n",
      "|    total_timesteps      | 408576        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5796623e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.22e+04      |\n",
      "|    n_updates            | 29210         |\n",
      "|    policy_gradient_loss | -3.67e-05     |\n",
      "|    reward               | 10.488394     |\n",
      "|    value_loss           | 2.51e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 197\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 1511         |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.048497e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.94e+04     |\n",
      "|    n_updates            | 29220        |\n",
      "|    policy_gradient_loss | -9.45e-05    |\n",
      "|    reward               | 40.065983    |\n",
      "|    value_loss           | 1.59e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 401           |\n",
      "|    time_elapsed         | 1515          |\n",
      "|    total_timesteps      | 410624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6008347e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.999        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.52e+05      |\n",
      "|    n_updates            | 29230         |\n",
      "|    policy_gradient_loss | 1.19e-05      |\n",
      "|    reward               | 69.83072      |\n",
      "|    value_loss           | 3.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 198\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 402           |\n",
      "|    time_elapsed         | 1519          |\n",
      "|    total_timesteps      | 411648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6007335e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.999        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.99e+05      |\n",
      "|    n_updates            | 29240         |\n",
      "|    policy_gradient_loss | -1.11e-05     |\n",
      "|    reward               | -19.833464    |\n",
      "|    value_loss           | 7.98e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 403           |\n",
      "|    time_elapsed         | 1522          |\n",
      "|    total_timesteps      | 412672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0454248e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.999        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.21e+05      |\n",
      "|    n_updates            | 29250         |\n",
      "|    policy_gradient_loss | -1.08e-05     |\n",
      "|    reward               | -0.37519297   |\n",
      "|    value_loss           | 1.04e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 404           |\n",
      "|    time_elapsed         | 1526          |\n",
      "|    total_timesteps      | 413696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8560247e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.999        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.75e+04      |\n",
      "|    n_updates            | 29260         |\n",
      "|    policy_gradient_loss | -4.99e-05     |\n",
      "|    reward               | -0.5852964    |\n",
      "|    value_loss           | 9.49e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 199\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 405           |\n",
      "|    time_elapsed         | 1530          |\n",
      "|    total_timesteps      | 414720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089320244 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.89e+03      |\n",
      "|    n_updates            | 29270         |\n",
      "|    policy_gradient_loss | -0.000335     |\n",
      "|    reward               | 17.466564     |\n",
      "|    value_loss           | 1.58e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 406          |\n",
      "|    time_elapsed         | 1534         |\n",
      "|    total_timesteps      | 415744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010067833 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.00453      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42e+05     |\n",
      "|    n_updates            | 29280        |\n",
      "|    policy_gradient_loss | -9.61e-05    |\n",
      "|    reward               | 59.027527    |\n",
      "|    value_loss           | 2.85e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 271           |\n",
      "|    iterations           | 407           |\n",
      "|    time_elapsed         | 1537          |\n",
      "|    total_timesteps      | 416768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0632211e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.274        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.81e+05      |\n",
      "|    n_updates            | 29290         |\n",
      "|    policy_gradient_loss | 5.62e-06      |\n",
      "|    reward               | 50.43692      |\n",
      "|    value_loss           | 1.59e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 200\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1811007.99\n",
      "total_reward: 811007.99\n",
      "total_cost: 1466076.81\n",
      "total_trades: 750\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 1541         |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.450581e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -1.25        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1e+06        |\n",
      "|    n_updates            | 29300        |\n",
      "|    policy_gradient_loss | 4.16e-06     |\n",
      "|    reward               | -6.0088344   |\n",
      "|    value_loss           | 2.01e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 409           |\n",
      "|    time_elapsed         | 1545          |\n",
      "|    total_timesteps      | 418816        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0487427e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0.697         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.05e+04      |\n",
      "|    n_updates            | 29310         |\n",
      "|    policy_gradient_loss | -7.7e-05      |\n",
      "|    reward               | -39.97618     |\n",
      "|    value_loss           | 1.64e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 201\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 410           |\n",
      "|    time_elapsed         | 1550          |\n",
      "|    total_timesteps      | 419840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9616286e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.59e+04      |\n",
      "|    n_updates            | 29320         |\n",
      "|    policy_gradient_loss | -1.01e-05     |\n",
      "|    reward               | 14.478861     |\n",
      "|    value_loss           | 1.92e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 411           |\n",
      "|    time_elapsed         | 1554          |\n",
      "|    total_timesteps      | 420864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2047974e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.84e+05      |\n",
      "|    n_updates            | 29330         |\n",
      "|    policy_gradient_loss | -6.22e-05     |\n",
      "|    reward               | 7.962805      |\n",
      "|    value_loss           | 3.72e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 412          |\n",
      "|    time_elapsed         | 1557         |\n",
      "|    total_timesteps      | 421888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.406844e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.42e+04     |\n",
      "|    n_updates            | 29340        |\n",
      "|    policy_gradient_loss | -6.44e-05    |\n",
      "|    reward               | 92.9737      |\n",
      "|    value_loss           | 8.91e+04     |\n",
      "------------------------------------------\n",
      "Episode: 202\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 413           |\n",
      "|    time_elapsed         | 1561          |\n",
      "|    total_timesteps      | 422912        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3762695e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.62e+05      |\n",
      "|    n_updates            | 29350         |\n",
      "|    policy_gradient_loss | -3.02e-05     |\n",
      "|    reward               | -0.34016278   |\n",
      "|    value_loss           | 5.25e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 414           |\n",
      "|    time_elapsed         | 1565          |\n",
      "|    total_timesteps      | 423936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7500791e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.84e+05      |\n",
      "|    n_updates            | 29360         |\n",
      "|    policy_gradient_loss | -7.52e-05     |\n",
      "|    reward               | 12.17761      |\n",
      "|    value_loss           | 1.77e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 415           |\n",
      "|    time_elapsed         | 1568          |\n",
      "|    total_timesteps      | 424960        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3565295e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.53e+04      |\n",
      "|    n_updates            | 29370         |\n",
      "|    policy_gradient_loss | -4.76e-06     |\n",
      "|    reward               | -15.48317     |\n",
      "|    value_loss           | 9.08e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 203\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 416          |\n",
      "|    time_elapsed         | 1572         |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.729008e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.9e+04      |\n",
      "|    n_updates            | 29380        |\n",
      "|    policy_gradient_loss | -3.9e-05     |\n",
      "|    reward               | -17.038816   |\n",
      "|    value_loss           | 1.38e+05     |\n",
      "------------------------------------------\n",
      "Episode: 204\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 687711.75\n",
      "total_reward: -312288.25\n",
      "total_cost: 300648.36\n",
      "total_trades: 339\n",
      "=================================\n",
      "Episode: 205\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 417           |\n",
      "|    time_elapsed         | 1576          |\n",
      "|    total_timesteps      | 427008        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4107666e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.79e+04      |\n",
      "|    n_updates            | 29390         |\n",
      "|    policy_gradient_loss | -5.46e-05     |\n",
      "|    reward               | 55.220497     |\n",
      "|    value_loss           | 1.56e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 418           |\n",
      "|    time_elapsed         | 1580          |\n",
      "|    total_timesteps      | 428032        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0808227e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0.00436       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+05      |\n",
      "|    n_updates            | 29400         |\n",
      "|    policy_gradient_loss | 5.62e-06      |\n",
      "|    reward               | 164.10715     |\n",
      "|    value_loss           | 2.89e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 419          |\n",
      "|    time_elapsed         | 1584         |\n",
      "|    total_timesteps      | 429056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.043104e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.76e+06     |\n",
      "|    n_updates            | 29410        |\n",
      "|    policy_gradient_loss | -1.27e-05    |\n",
      "|    reward               | 343.58597    |\n",
      "|    value_loss           | 5.54e+06     |\n",
      "------------------------------------------\n",
      "Episode: 206\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 420           |\n",
      "|    time_elapsed         | 1589          |\n",
      "|    total_timesteps      | 430080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0995427e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.455        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.88e+06      |\n",
      "|    n_updates            | 29420         |\n",
      "|    policy_gradient_loss | 9.76e-07      |\n",
      "|    reward               | -32.95746     |\n",
      "|    value_loss           | 1.38e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 421           |\n",
      "|    time_elapsed         | 1593          |\n",
      "|    total_timesteps      | 431104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0314474e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.125         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.41e+07      |\n",
      "|    n_updates            | 29430         |\n",
      "|    policy_gradient_loss | -3.35e-06     |\n",
      "|    reward               | -34.23836     |\n",
      "|    value_loss           | 6.82e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 422           |\n",
      "|    time_elapsed         | 1597          |\n",
      "|    total_timesteps      | 432128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9592699e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.87e+04      |\n",
      "|    n_updates            | 29440         |\n",
      "|    policy_gradient_loss | -5.24e-06     |\n",
      "|    reward               | 19.863865     |\n",
      "|    value_loss           | 7.98e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 207\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 423           |\n",
      "|    time_elapsed         | 1601          |\n",
      "|    total_timesteps      | 433152        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0820804e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.56e+04      |\n",
      "|    n_updates            | 29450         |\n",
      "|    policy_gradient_loss | -2.15e-05     |\n",
      "|    reward               | -7.763436     |\n",
      "|    value_loss           | 1.12e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 424           |\n",
      "|    time_elapsed         | 1604          |\n",
      "|    total_timesteps      | 434176        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3452525e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.76e+04      |\n",
      "|    n_updates            | 29460         |\n",
      "|    policy_gradient_loss | -2.53e-05     |\n",
      "|    reward               | -26.051683    |\n",
      "|    value_loss           | 7.53e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 208\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1550415.64\n",
      "total_reward: 550415.64\n",
      "total_cost: 731384.08\n",
      "total_trades: 654\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 425           |\n",
      "|    time_elapsed         | 1608          |\n",
      "|    total_timesteps      | 435200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8370566e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.08e+04      |\n",
      "|    n_updates            | 29470         |\n",
      "|    policy_gradient_loss | 1.67e-06      |\n",
      "|    reward               | -8.184635     |\n",
      "|    value_loss           | 1.22e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 209\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 426           |\n",
      "|    time_elapsed         | 1612          |\n",
      "|    total_timesteps      | 436224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9527506e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.06e+04      |\n",
      "|    n_updates            | 29480         |\n",
      "|    policy_gradient_loss | -1.92e-05     |\n",
      "|    reward               | 10.603859     |\n",
      "|    value_loss           | 1.01e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 1616         |\n",
      "|    total_timesteps      | 437248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.748328e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.43e+04     |\n",
      "|    n_updates            | 29490        |\n",
      "|    policy_gradient_loss | -2.53e-05    |\n",
      "|    reward               | 57.7218      |\n",
      "|    value_loss           | 8.86e+04     |\n",
      "------------------------------------------\n",
      "Episode: 210\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 428           |\n",
      "|    time_elapsed         | 1620          |\n",
      "|    total_timesteps      | 438272        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.3144835e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.58e+05      |\n",
      "|    n_updates            | 29500         |\n",
      "|    policy_gradient_loss | -3.75e-05     |\n",
      "|    reward               | -3.5533564    |\n",
      "|    value_loss           | 7.16e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 429           |\n",
      "|    time_elapsed         | 1623          |\n",
      "|    total_timesteps      | 439296        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6648278e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -0.00783      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.2e+05       |\n",
      "|    n_updates            | 29510         |\n",
      "|    policy_gradient_loss | -7.64e-05     |\n",
      "|    reward               | -53.67426     |\n",
      "|    value_loss           | 4.41e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 430           |\n",
      "|    time_elapsed         | 1627          |\n",
      "|    total_timesteps      | 440320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3048993e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -3.62         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.98e+05      |\n",
      "|    n_updates            | 29520         |\n",
      "|    policy_gradient_loss | -1.32e-05     |\n",
      "|    reward               | -18.372082    |\n",
      "|    value_loss           | 5.98e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 211\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 431           |\n",
      "|    time_elapsed         | 1631          |\n",
      "|    total_timesteps      | 441344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4884156e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -3.64         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.21e+05      |\n",
      "|    n_updates            | 29530         |\n",
      "|    policy_gradient_loss | -3.77e-05     |\n",
      "|    reward               | -14.027428    |\n",
      "|    value_loss           | 4.44e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 432          |\n",
      "|    time_elapsed         | 1635         |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.247785e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.3         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 29540        |\n",
      "|    policy_gradient_loss | -0.000137    |\n",
      "|    reward               | -41.312527   |\n",
      "|    value_loss           | 2.83e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 433           |\n",
      "|    time_elapsed         | 1639          |\n",
      "|    total_timesteps      | 443392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9781524e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.11e+05      |\n",
      "|    n_updates            | 29550         |\n",
      "|    policy_gradient_loss | -0.000221     |\n",
      "|    reward               | -21.307331    |\n",
      "|    value_loss           | 2.22e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 212\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1335360.43\n",
      "total_reward: 335360.43\n",
      "total_cost: 668247.54\n",
      "total_trades: 668\n",
      "=================================\n",
      "Episode: 213\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 434           |\n",
      "|    time_elapsed         | 1642          |\n",
      "|    total_timesteps      | 444416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7454615e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.37e+05      |\n",
      "|    n_updates            | 29560         |\n",
      "|    policy_gradient_loss | -9.87e-05     |\n",
      "|    reward               | 4.939664      |\n",
      "|    value_loss           | 4.73e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 270            |\n",
      "|    iterations           | 435            |\n",
      "|    time_elapsed         | 1646           |\n",
      "|    total_timesteps      | 445440         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.36510935e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.03          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 3.93e+04       |\n",
      "|    n_updates            | 29570          |\n",
      "|    policy_gradient_loss | -4.63e-05      |\n",
      "|    reward               | -13.309426     |\n",
      "|    value_loss           | 7.87e+04       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 436          |\n",
      "|    time_elapsed         | 1650         |\n",
      "|    total_timesteps      | 446464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020701706 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.05e+04     |\n",
      "|    n_updates            | 29580        |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    reward               | -48.46807    |\n",
      "|    value_loss           | 6.1e+04      |\n",
      "------------------------------------------\n",
      "Episode: 214\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 1653        |\n",
      "|    total_timesteps      | 447488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002199803 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.21e+05    |\n",
      "|    n_updates            | 29590       |\n",
      "|    policy_gradient_loss | 0.000627    |\n",
      "|    reward               | -24.400576  |\n",
      "|    value_loss           | 4.42e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 438           |\n",
      "|    time_elapsed         | 1657          |\n",
      "|    total_timesteps      | 448512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025587913 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.46e+05      |\n",
      "|    n_updates            | 29600         |\n",
      "|    policy_gradient_loss | 0.000347      |\n",
      "|    reward               | -34.531433    |\n",
      "|    value_loss           | 2.91e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 439           |\n",
      "|    time_elapsed         | 1661          |\n",
      "|    total_timesteps      | 449536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0076131e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.29e+04      |\n",
      "|    n_updates            | 29610         |\n",
      "|    policy_gradient_loss | -6.44e-05     |\n",
      "|    reward               | -58.95195     |\n",
      "|    value_loss           | 1.26e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 215\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 440          |\n",
      "|    time_elapsed         | 1665         |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.169321e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.01e+05     |\n",
      "|    n_updates            | 29620        |\n",
      "|    policy_gradient_loss | 7.79e-05     |\n",
      "|    reward               | 32.354095    |\n",
      "|    value_loss           | 8.02e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 1669         |\n",
      "|    total_timesteps      | 451584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.479654e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.1e+05      |\n",
      "|    n_updates            | 29630        |\n",
      "|    policy_gradient_loss | -2.34e-06    |\n",
      "|    reward               | -37.2853     |\n",
      "|    value_loss           | 2.21e+05     |\n",
      "------------------------------------------\n",
      "Episode: 216\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885361.69\n",
      "total_reward: -114638.31\n",
      "total_cost: 898761.12\n",
      "total_trades: 739\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 442           |\n",
      "|    time_elapsed         | 1672          |\n",
      "|    total_timesteps      | 452608        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7589496e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.64e+04      |\n",
      "|    n_updates            | 29640         |\n",
      "|    policy_gradient_loss | -2.48e-05     |\n",
      "|    reward               | -16.236526    |\n",
      "|    value_loss           | 1.33e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 443           |\n",
      "|    time_elapsed         | 1676          |\n",
      "|    total_timesteps      | 453632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1558524e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.18e+05      |\n",
      "|    n_updates            | 29650         |\n",
      "|    policy_gradient_loss | 5.39e-05      |\n",
      "|    reward               | -27.794716    |\n",
      "|    value_loss           | 6.36e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 444           |\n",
      "|    time_elapsed         | 1680          |\n",
      "|    total_timesteps      | 454656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9208174e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.01e+04      |\n",
      "|    n_updates            | 29660         |\n",
      "|    policy_gradient_loss | -3.39e-05     |\n",
      "|    reward               | -66.456955    |\n",
      "|    value_loss           | 4.02e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 217\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 445          |\n",
      "|    time_elapsed         | 1684         |\n",
      "|    total_timesteps      | 455680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.558599e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.43e+05     |\n",
      "|    n_updates            | 29670        |\n",
      "|    policy_gradient_loss | -6.99e-06    |\n",
      "|    reward               | -18.141834   |\n",
      "|    value_loss           | 4.87e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 446           |\n",
      "|    time_elapsed         | 1687          |\n",
      "|    total_timesteps      | 456704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0476443e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.98e+05      |\n",
      "|    n_updates            | 29680         |\n",
      "|    policy_gradient_loss | -6.83e-05     |\n",
      "|    reward               | 2.0265071     |\n",
      "|    value_loss           | 3.96e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 447           |\n",
      "|    time_elapsed         | 1691          |\n",
      "|    total_timesteps      | 457728        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015594956 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.55e+04      |\n",
      "|    n_updates            | 29690         |\n",
      "|    policy_gradient_loss | -0.000372     |\n",
      "|    reward               | 128.35233     |\n",
      "|    value_loss           | 3.1e+04       |\n",
      "-------------------------------------------\n",
      "Episode: 218\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 448           |\n",
      "|    time_elapsed         | 1695          |\n",
      "|    total_timesteps      | 458752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014528411 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.05e+05      |\n",
      "|    n_updates            | 29700         |\n",
      "|    policy_gradient_loss | -0.000142     |\n",
      "|    reward               | 24.177986     |\n",
      "|    value_loss           | 1.61e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 449           |\n",
      "|    time_elapsed         | 1698          |\n",
      "|    total_timesteps      | 459776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2631873e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.96e+05      |\n",
      "|    n_updates            | 29710         |\n",
      "|    policy_gradient_loss | 0.00013       |\n",
      "|    reward               | 143.89285     |\n",
      "|    value_loss           | 3.92e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 219\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 450          |\n",
      "|    time_elapsed         | 1702         |\n",
      "|    total_timesteps      | 460800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.041459e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.38e+06     |\n",
      "|    n_updates            | 29720        |\n",
      "|    policy_gradient_loss | 3.27e-05     |\n",
      "|    reward               | 18.34872     |\n",
      "|    value_loss           | 2.77e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 451          |\n",
      "|    time_elapsed         | 1706         |\n",
      "|    total_timesteps      | 461824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.328329e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.37e+06     |\n",
      "|    n_updates            | 29730        |\n",
      "|    policy_gradient_loss | -3.73e-05    |\n",
      "|    reward               | -5.7784915   |\n",
      "|    value_loss           | 1.07e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 452           |\n",
      "|    time_elapsed         | 1710          |\n",
      "|    total_timesteps      | 462848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4983816e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.08e+05      |\n",
      "|    n_updates            | 29740         |\n",
      "|    policy_gradient_loss | -3.17e-05     |\n",
      "|    reward               | -52.603786    |\n",
      "|    value_loss           | 2.17e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 220\n",
      "Current company: ['CVX']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 679985.92\n",
      "total_reward: -320014.08\n",
      "total_cost: 817414.93\n",
      "total_trades: 675\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 453           |\n",
      "|    time_elapsed         | 1713          |\n",
      "|    total_timesteps      | 463872        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0049275e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.79e+04      |\n",
      "|    n_updates            | 29750         |\n",
      "|    policy_gradient_loss | -3.1e-05      |\n",
      "|    reward               | -31.933563    |\n",
      "|    value_loss           | 1.96e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 221\n",
      "Episode: 222\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 454          |\n",
      "|    time_elapsed         | 1717         |\n",
      "|    total_timesteps      | 464896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.849389e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48e+04     |\n",
      "|    n_updates            | 29760        |\n",
      "|    policy_gradient_loss | -3.11e-05    |\n",
      "|    reward               | -13.023827   |\n",
      "|    value_loss           | 1.9e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 455          |\n",
      "|    time_elapsed         | 1721         |\n",
      "|    total_timesteps      | 465920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.828581e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.09e+05     |\n",
      "|    n_updates            | 29770        |\n",
      "|    policy_gradient_loss | -4.9e-05     |\n",
      "|    reward               | 51.844578    |\n",
      "|    value_loss           | 2.18e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 456          |\n",
      "|    time_elapsed         | 1725         |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.880444e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.25e+05     |\n",
      "|    n_updates            | 29780        |\n",
      "|    policy_gradient_loss | -5.7e-05     |\n",
      "|    reward               | 60.090164    |\n",
      "|    value_loss           | 2.5e+05      |\n",
      "------------------------------------------\n",
      "Episode: 223\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 457           |\n",
      "|    time_elapsed         | 1729          |\n",
      "|    total_timesteps      | 467968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.5725915e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.45e+05      |\n",
      "|    n_updates            | 29790         |\n",
      "|    policy_gradient_loss | -0.000197     |\n",
      "|    reward               | -27.338953    |\n",
      "|    value_loss           | 1.29e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 458          |\n",
      "|    time_elapsed         | 1733         |\n",
      "|    total_timesteps      | 468992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.016367e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.68e+05     |\n",
      "|    n_updates            | 29800        |\n",
      "|    policy_gradient_loss | -0.000107    |\n",
      "|    reward               | -66.32184    |\n",
      "|    value_loss           | 1.34e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 459           |\n",
      "|    time_elapsed         | 1737          |\n",
      "|    total_timesteps      | 470016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4580204e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.08e+05      |\n",
      "|    n_updates            | 29810         |\n",
      "|    policy_gradient_loss | -0.000149     |\n",
      "|    reward               | -86.42488     |\n",
      "|    value_loss           | 2.16e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 224\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1350994.85\n",
      "total_reward: 350994.85\n",
      "total_cost: 739079.70\n",
      "total_trades: 704\n",
      "=================================\n",
      "Episode: 225\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 460           |\n",
      "|    time_elapsed         | 1741          |\n",
      "|    total_timesteps      | 471040        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1615997e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.71e+05      |\n",
      "|    n_updates            | 29820         |\n",
      "|    policy_gradient_loss | 9.1e-05       |\n",
      "|    reward               | 7.238487      |\n",
      "|    value_loss           | 5.41e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 461           |\n",
      "|    time_elapsed         | 1744          |\n",
      "|    total_timesteps      | 472064        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086236134 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.12e+05      |\n",
      "|    n_updates            | 29830         |\n",
      "|    policy_gradient_loss | -0.000502     |\n",
      "|    reward               | 10.475462     |\n",
      "|    value_loss           | 2.24e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 462          |\n",
      "|    time_elapsed         | 1748         |\n",
      "|    total_timesteps      | 473088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011603667 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.5e+04      |\n",
      "|    n_updates            | 29840        |\n",
      "|    policy_gradient_loss | -0.000394    |\n",
      "|    reward               | 4.5039487    |\n",
      "|    value_loss           | 7e+04        |\n",
      "------------------------------------------\n",
      "Episode: 226\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 1752         |\n",
      "|    total_timesteps      | 474112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002456985 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.86e+04     |\n",
      "|    n_updates            | 29850        |\n",
      "|    policy_gradient_loss | -0.000801    |\n",
      "|    reward               | -28.600739   |\n",
      "|    value_loss           | 1.37e+05     |\n",
      "------------------------------------------\n",
      "Episode: 227\n",
      "Episode: 228\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695511.88\n",
      "total_reward: -304488.12\n",
      "total_cost: 35418.00\n",
      "total_trades: 41\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 464          |\n",
      "|    time_elapsed         | 1756         |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.240106e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.22e+04     |\n",
      "|    n_updates            | 29860        |\n",
      "|    policy_gradient_loss | 0.000128     |\n",
      "|    reward               | -20.147375   |\n",
      "|    value_loss           | 6.44e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 465           |\n",
      "|    time_elapsed         | 1760          |\n",
      "|    total_timesteps      | 476160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3374876e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.41e+04      |\n",
      "|    n_updates            | 29870         |\n",
      "|    policy_gradient_loss | -0.000288     |\n",
      "|    reward               | 35.18678      |\n",
      "|    value_loss           | 1.88e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 466           |\n",
      "|    time_elapsed         | 1763          |\n",
      "|    total_timesteps      | 477184        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7011655e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.51e+04      |\n",
      "|    n_updates            | 29880         |\n",
      "|    policy_gradient_loss | 1.59e-05      |\n",
      "|    reward               | 138.85466     |\n",
      "|    value_loss           | 1.1e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 229\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 467          |\n",
      "|    time_elapsed         | 1767         |\n",
      "|    total_timesteps      | 478208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.308073e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.79e+05     |\n",
      "|    n_updates            | 29890        |\n",
      "|    policy_gradient_loss | -5.41e-05    |\n",
      "|    reward               | -32.47413    |\n",
      "|    value_loss           | 1.36e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 468           |\n",
      "|    time_elapsed         | 1771          |\n",
      "|    total_timesteps      | 479232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8556907e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.63e+05      |\n",
      "|    n_updates            | 29900         |\n",
      "|    policy_gradient_loss | -4e-06        |\n",
      "|    reward               | 6.5889707     |\n",
      "|    value_loss           | 1.13e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 230\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 469           |\n",
      "|    time_elapsed         | 1775          |\n",
      "|    total_timesteps      | 480256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7317008e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.16e+04      |\n",
      "|    n_updates            | 29910         |\n",
      "|    policy_gradient_loss | -1.96e-05     |\n",
      "|    reward               | -0.05         |\n",
      "|    value_loss           | 1.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 470           |\n",
      "|    time_elapsed         | 1779          |\n",
      "|    total_timesteps      | 481280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2158416e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.08e+04      |\n",
      "|    n_updates            | 29920         |\n",
      "|    policy_gradient_loss | -5.66e-07     |\n",
      "|    reward               | 47.758415     |\n",
      "|    value_loss           | 8.18e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 471           |\n",
      "|    time_elapsed         | 1782          |\n",
      "|    total_timesteps      | 482304        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2933895e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.63e+04      |\n",
      "|    n_updates            | 29930         |\n",
      "|    policy_gradient_loss | 1.43e-05      |\n",
      "|    reward               | 119.606514    |\n",
      "|    value_loss           | 1.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 231\n",
      "Episode: 232\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 689235.14\n",
      "total_reward: -310764.86\n",
      "total_cost: 61835.60\n",
      "total_trades: 73\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 472           |\n",
      "|    time_elapsed         | 1786          |\n",
      "|    total_timesteps      | 483328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8179999e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.7e+05       |\n",
      "|    n_updates            | 29940         |\n",
      "|    policy_gradient_loss | -4.44e-05     |\n",
      "|    reward               | -15.016263    |\n",
      "|    value_loss           | 1.54e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 473           |\n",
      "|    time_elapsed         | 1790          |\n",
      "|    total_timesteps      | 484352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9620132e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.35e+05      |\n",
      "|    n_updates            | 29950         |\n",
      "|    policy_gradient_loss | -6.14e-05     |\n",
      "|    reward               | -22.666393    |\n",
      "|    value_loss           | 1.67e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 474          |\n",
      "|    time_elapsed         | 1793         |\n",
      "|    total_timesteps      | 485376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.662907e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.38e+04     |\n",
      "|    n_updates            | 29960        |\n",
      "|    policy_gradient_loss | -5.07e-05    |\n",
      "|    reward               | -42.160507   |\n",
      "|    value_loss           | 4.75e+04     |\n",
      "------------------------------------------\n",
      "Episode: 233\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 475          |\n",
      "|    time_elapsed         | 1797         |\n",
      "|    total_timesteps      | 486400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.023995e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.79e+04     |\n",
      "|    n_updates            | 29970        |\n",
      "|    policy_gradient_loss | -1.31e-05    |\n",
      "|    reward               | -16.641111   |\n",
      "|    value_loss           | 9.6e+04      |\n",
      "------------------------------------------\n",
      "Episode: 234\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 476          |\n",
      "|    time_elapsed         | 1801         |\n",
      "|    total_timesteps      | 487424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.081964e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.12e+05     |\n",
      "|    n_updates            | 29980        |\n",
      "|    policy_gradient_loss | 1.03e-05     |\n",
      "|    reward               | -14.174751   |\n",
      "|    value_loss           | 6.24e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 477           |\n",
      "|    time_elapsed         | 1805          |\n",
      "|    total_timesteps      | 488448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2017728e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+04      |\n",
      "|    n_updates            | 29990         |\n",
      "|    policy_gradient_loss | -7.05e-05     |\n",
      "|    reward               | -11.132891    |\n",
      "|    value_loss           | 4.91e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 270            |\n",
      "|    iterations           | 478            |\n",
      "|    time_elapsed         | 1809           |\n",
      "|    total_timesteps      | 489472         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000111107714 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.06          |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.1e+04        |\n",
      "|    n_updates            | 30000          |\n",
      "|    policy_gradient_loss | -0.000347      |\n",
      "|    reward               | -0.15007515    |\n",
      "|    value_loss           | 2.2e+04        |\n",
      "--------------------------------------------\n",
      "Episode: 235\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 479          |\n",
      "|    time_elapsed         | 1813         |\n",
      "|    total_timesteps      | 490496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.635885e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.22e+04     |\n",
      "|    n_updates            | 30010        |\n",
      "|    policy_gradient_loss | 4.58e-06     |\n",
      "|    reward               | 22.191442    |\n",
      "|    value_loss           | 2.45e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 480           |\n",
      "|    time_elapsed         | 1817          |\n",
      "|    total_timesteps      | 491520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7256163e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+04      |\n",
      "|    n_updates            | 30020         |\n",
      "|    policy_gradient_loss | -3.5e-05      |\n",
      "|    reward               | -29.73363     |\n",
      "|    value_loss           | 2.79e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 236\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1054627.16\n",
      "total_reward: 54627.16\n",
      "total_cost: 815258.74\n",
      "total_trades: 689\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 481           |\n",
      "|    time_elapsed         | 1821          |\n",
      "|    total_timesteps      | 492544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064323057 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.09e+04      |\n",
      "|    n_updates            | 30030         |\n",
      "|    policy_gradient_loss | -0.000572     |\n",
      "|    reward               | -1.8846459    |\n",
      "|    value_loss           | 1.42e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 1824         |\n",
      "|    total_timesteps      | 493568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004823422 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.54e+05     |\n",
      "|    n_updates            | 30040        |\n",
      "|    policy_gradient_loss | 0.000264     |\n",
      "|    reward               | -44.424423   |\n",
      "|    value_loss           | 3.07e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 483           |\n",
      "|    time_elapsed         | 1828          |\n",
      "|    total_timesteps      | 494592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9102433e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.96e+04      |\n",
      "|    n_updates            | 30050         |\n",
      "|    policy_gradient_loss | 0.000115      |\n",
      "|    reward               | -44.81796     |\n",
      "|    value_loss           | 1.19e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 237\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 484           |\n",
      "|    time_elapsed         | 1832          |\n",
      "|    total_timesteps      | 495616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7537968e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.82e+05      |\n",
      "|    n_updates            | 30060         |\n",
      "|    policy_gradient_loss | 8.09e-07      |\n",
      "|    reward               | -21.30094     |\n",
      "|    value_loss           | 5.64e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 485           |\n",
      "|    time_elapsed         | 1835          |\n",
      "|    total_timesteps      | 496640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3864093e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.54e+04      |\n",
      "|    n_updates            | 30070         |\n",
      "|    policy_gradient_loss | -0.000173     |\n",
      "|    reward               | -28.781939    |\n",
      "|    value_loss           | 1.91e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 486           |\n",
      "|    time_elapsed         | 1839          |\n",
      "|    total_timesteps      | 497664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5323203e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.62e+04      |\n",
      "|    n_updates            | 30080         |\n",
      "|    policy_gradient_loss | -5.9e-05      |\n",
      "|    reward               | -74.98129     |\n",
      "|    value_loss           | 7.25e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 238\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 487           |\n",
      "|    time_elapsed         | 1843          |\n",
      "|    total_timesteps      | 498688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9478106e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.32e+05      |\n",
      "|    n_updates            | 30090         |\n",
      "|    policy_gradient_loss | 6.23e-05      |\n",
      "|    reward               | -20.904976    |\n",
      "|    value_loss           | 6.65e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 488           |\n",
      "|    time_elapsed         | 1847          |\n",
      "|    total_timesteps      | 499712        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1371019e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.67e+04      |\n",
      "|    n_updates            | 30100         |\n",
      "|    policy_gradient_loss | -2.86e-05     |\n",
      "|    reward               | -40.434982    |\n",
      "|    value_loss           | 1.14e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 239\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 489           |\n",
      "|    time_elapsed         | 1850          |\n",
      "|    total_timesteps      | 500736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4912879e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+05      |\n",
      "|    n_updates            | 30110         |\n",
      "|    policy_gradient_loss | 2.55e-05      |\n",
      "|    reward               | -12.27958     |\n",
      "|    value_loss           | 2.13e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 490           |\n",
      "|    time_elapsed         | 1854          |\n",
      "|    total_timesteps      | 501760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6488484e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.08e+05      |\n",
      "|    n_updates            | 30120         |\n",
      "|    policy_gradient_loss | -2.9e-06      |\n",
      "|    reward               | -7.7552457    |\n",
      "|    value_loss           | 4.17e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 491          |\n",
      "|    time_elapsed         | 1858         |\n",
      "|    total_timesteps      | 502784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019581853 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.77e+03     |\n",
      "|    n_updates            | 30130        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | -40.594032   |\n",
      "|    value_loss           | 7.53e+03     |\n",
      "------------------------------------------\n",
      "Episode: 240\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1540750.16\n",
      "total_reward: 540750.16\n",
      "total_cost: 724811.34\n",
      "total_trades: 605\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 492          |\n",
      "|    time_elapsed         | 1862         |\n",
      "|    total_timesteps      | 503808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012482826 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.86e+04     |\n",
      "|    n_updates            | 30140        |\n",
      "|    policy_gradient_loss | 0.000674     |\n",
      "|    reward               | 9.596928     |\n",
      "|    value_loss           | 5.75e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 493           |\n",
      "|    time_elapsed         | 1865          |\n",
      "|    total_timesteps      | 504832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013480743 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.65e+04      |\n",
      "|    n_updates            | 30150         |\n",
      "|    policy_gradient_loss | 2.94e-05      |\n",
      "|    reward               | 54.259853     |\n",
      "|    value_loss           | 1.73e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 241\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 494           |\n",
      "|    time_elapsed         | 1869          |\n",
      "|    total_timesteps      | 505856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3902027e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.89e+05      |\n",
      "|    n_updates            | 30160         |\n",
      "|    policy_gradient_loss | -5.34e-05     |\n",
      "|    reward               | 2.191067      |\n",
      "|    value_loss           | 7.78e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 242\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 495           |\n",
      "|    time_elapsed         | 1873          |\n",
      "|    total_timesteps      | 506880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4695764e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.43e+06      |\n",
      "|    n_updates            | 30170         |\n",
      "|    policy_gradient_loss | -2.82e-05     |\n",
      "|    reward               | 32.8861       |\n",
      "|    value_loss           | 2.87e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 496           |\n",
      "|    time_elapsed         | 1877          |\n",
      "|    total_timesteps      | 507904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7557526e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.43e+04      |\n",
      "|    n_updates            | 30180         |\n",
      "|    policy_gradient_loss | -0.00021      |\n",
      "|    reward               | 18.574125     |\n",
      "|    value_loss           | 1.69e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 243\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 497           |\n",
      "|    time_elapsed         | 1880          |\n",
      "|    total_timesteps      | 508928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8359354e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.12e+04      |\n",
      "|    n_updates            | 30190         |\n",
      "|    policy_gradient_loss | -8.61e-05     |\n",
      "|    reward               | -3.2451165    |\n",
      "|    value_loss           | 1.63e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 267           |\n",
      "|    iterations           | 498           |\n",
      "|    time_elapsed         | 1905          |\n",
      "|    total_timesteps      | 509952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4545163e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.07e+05      |\n",
      "|    n_updates            | 30200         |\n",
      "|    policy_gradient_loss | -0.00012      |\n",
      "|    reward               | -25.030655    |\n",
      "|    value_loss           | 4.14e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 499          |\n",
      "|    time_elapsed         | 1911         |\n",
      "|    total_timesteps      | 510976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.904907e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.98e+04     |\n",
      "|    n_updates            | 30210        |\n",
      "|    policy_gradient_loss | -0.000103    |\n",
      "|    reward               | -54.881855   |\n",
      "|    value_loss           | 5.96e+04     |\n",
      "------------------------------------------\n",
      "Episode: 244\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1518224.03\n",
      "total_reward: 518224.03\n",
      "total_cost: 688146.88\n",
      "total_trades: 628\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 267           |\n",
      "|    iterations           | 500           |\n",
      "|    time_elapsed         | 1916          |\n",
      "|    total_timesteps      | 512000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2361794e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.46e+05      |\n",
      "|    n_updates            | 30220         |\n",
      "|    policy_gradient_loss | 9.36e-05      |\n",
      "|    reward               | 6.90947       |\n",
      "|    value_loss           | 2.93e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 267           |\n",
      "|    iterations           | 501           |\n",
      "|    time_elapsed         | 1920          |\n",
      "|    total_timesteps      | 513024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1088559e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+05      |\n",
      "|    n_updates            | 30230         |\n",
      "|    policy_gradient_loss | -1.8e-05      |\n",
      "|    reward               | -46.400543    |\n",
      "|    value_loss           | 2.77e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 245\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 502          |\n",
      "|    time_elapsed         | 1924         |\n",
      "|    total_timesteps      | 514048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014926989 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.78e+04     |\n",
      "|    n_updates            | 30240        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | -31.113401   |\n",
      "|    value_loss           | 1.16e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 503          |\n",
      "|    time_elapsed         | 1928         |\n",
      "|    total_timesteps      | 515072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016854071 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.19e+04     |\n",
      "|    n_updates            | 30250        |\n",
      "|    policy_gradient_loss | -0.000524    |\n",
      "|    reward               | -45.22214    |\n",
      "|    value_loss           | 1.44e+05     |\n",
      "------------------------------------------\n",
      "Episode: 246\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 267           |\n",
      "|    iterations           | 504           |\n",
      "|    time_elapsed         | 1932          |\n",
      "|    total_timesteps      | 516096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027611008 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.993        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.5e+05       |\n",
      "|    n_updates            | 30260         |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    reward               | 7.0156784     |\n",
      "|    value_loss           | 3e+05         |\n",
      "-------------------------------------------\n",
      "Episode: 247\n",
      "Episode: 248\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699125.46\n",
      "total_reward: -300874.54\n",
      "total_cost: 139073.30\n",
      "total_trades: 151\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 1937         |\n",
      "|    total_timesteps      | 517120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.427135e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.988       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84e+05     |\n",
      "|    n_updates            | 30270        |\n",
      "|    policy_gradient_loss | 5.47e-05     |\n",
      "|    reward               | -12.041504   |\n",
      "|    value_loss           | 3.67e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 506          |\n",
      "|    time_elapsed         | 1942         |\n",
      "|    total_timesteps      | 518144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.667183e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.987       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.23e+04     |\n",
      "|    n_updates            | 30280        |\n",
      "|    policy_gradient_loss | -0.000269    |\n",
      "|    reward               | -31.830845   |\n",
      "|    value_loss           | 6.46e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 507           |\n",
      "|    time_elapsed         | 1946          |\n",
      "|    total_timesteps      | 519168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013090984 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.989        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.61e+04      |\n",
      "|    n_updates            | 30290         |\n",
      "|    policy_gradient_loss | -0.000153     |\n",
      "|    reward               | -72.670364    |\n",
      "|    value_loss           | 1.32e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 249\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 508           |\n",
      "|    time_elapsed         | 1949          |\n",
      "|    total_timesteps      | 520192        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4645764e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.992        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.12e+05      |\n",
      "|    n_updates            | 30300         |\n",
      "|    policy_gradient_loss | -9e-06        |\n",
      "|    reward               | -46.534237    |\n",
      "|    value_loss           | 4.25e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 250\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 509           |\n",
      "|    time_elapsed         | 1953          |\n",
      "|    total_timesteps      | 521216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4753896e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.994        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.65e+05      |\n",
      "|    n_updates            | 30310         |\n",
      "|    policy_gradient_loss | 3.73e-05      |\n",
      "|    reward               | 12.866758     |\n",
      "|    value_loss           | 3.3e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 510           |\n",
      "|    time_elapsed         | 1957          |\n",
      "|    total_timesteps      | 522240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1496671e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.994        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.21e+04      |\n",
      "|    n_updates            | 30320         |\n",
      "|    policy_gradient_loss | -2.82e-05     |\n",
      "|    reward               | 76.91352      |\n",
      "|    value_loss           | 1.24e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 251\n",
      "Episode: 252\n",
      "Current company: ['DOW']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 586242.82\n",
      "total_reward: -413757.18\n",
      "total_cost: 9931.61\n",
      "total_trades: 11\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 511          |\n",
      "|    time_elapsed         | 1961         |\n",
      "|    total_timesteps      | 523264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.720125e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.995       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.59e+05     |\n",
      "|    n_updates            | 30330        |\n",
      "|    policy_gradient_loss | -3.28e-05    |\n",
      "|    reward               | -12.761777   |\n",
      "|    value_loss           | 5.19e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 512           |\n",
      "|    time_elapsed         | 1966          |\n",
      "|    total_timesteps      | 524288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0322623e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.995        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.34e+05      |\n",
      "|    n_updates            | 30340         |\n",
      "|    policy_gradient_loss | -2.36e-05     |\n",
      "|    reward               | 27.420776     |\n",
      "|    value_loss           | 1.47e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 513          |\n",
      "|    time_elapsed         | 1970         |\n",
      "|    total_timesteps      | 525312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.134847e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.996       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.04e+04     |\n",
      "|    n_updates            | 30350        |\n",
      "|    policy_gradient_loss | -2.62e-05    |\n",
      "|    reward               | -15.944199   |\n",
      "|    value_loss           | 1.21e+05     |\n",
      "------------------------------------------\n",
      "Episode: 253\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 1996         |\n",
      "|    total_timesteps      | 526336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063658278 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.979       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.3e+04      |\n",
      "|    n_updates            | 30360        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | 0.76258      |\n",
      "|    value_loss           | 4.61e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 515          |\n",
      "|    time_elapsed         | 2001         |\n",
      "|    total_timesteps      | 527360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009500575 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.961       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.57e+05     |\n",
      "|    n_updates            | 30370        |\n",
      "|    policy_gradient_loss | -2.61e-05    |\n",
      "|    reward               | 51.501736    |\n",
      "|    value_loss           | 3.14e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 516           |\n",
      "|    time_elapsed         | 2006          |\n",
      "|    total_timesteps      | 528384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014576642 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.972        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.17e+05      |\n",
      "|    n_updates            | 30380         |\n",
      "|    policy_gradient_loss | -9.21e-05     |\n",
      "|    reward               | 30.375618     |\n",
      "|    value_loss           | 8.34e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 254\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 517           |\n",
      "|    time_elapsed         | 2011          |\n",
      "|    total_timesteps      | 529408        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0467443e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+06      |\n",
      "|    n_updates            | 30390         |\n",
      "|    policy_gradient_loss | -0.000101     |\n",
      "|    reward               | 78.67427      |\n",
      "|    value_loss           | 4.45e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 518           |\n",
      "|    time_elapsed         | 2016          |\n",
      "|    total_timesteps      | 530432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7962025e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.977        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.5e+05       |\n",
      "|    n_updates            | 30400         |\n",
      "|    policy_gradient_loss | -5.52e-05     |\n",
      "|    reward               | 165.91924     |\n",
      "|    value_loss           | 2.99e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 255\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 519           |\n",
      "|    time_elapsed         | 2020          |\n",
      "|    total_timesteps      | 531456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4077523e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.77e+06      |\n",
      "|    n_updates            | 30410         |\n",
      "|    policy_gradient_loss | 5.06e-05      |\n",
      "|    reward               | 19.94041      |\n",
      "|    value_loss           | 3.54e+06      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 263            |\n",
      "|    iterations           | 520            |\n",
      "|    time_elapsed         | 2023           |\n",
      "|    total_timesteps      | 532480         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.06636435e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.978         |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 7.22e+06       |\n",
      "|    n_updates            | 30420          |\n",
      "|    policy_gradient_loss | -5.51e-06      |\n",
      "|    reward               | -23.347975     |\n",
      "|    value_loss           | 1.44e+07       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 521          |\n",
      "|    time_elapsed         | 2027         |\n",
      "|    total_timesteps      | 533504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.747351e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.978       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.92e+04     |\n",
      "|    n_updates            | 30430        |\n",
      "|    policy_gradient_loss | -1.89e-05    |\n",
      "|    reward               | -36.83838    |\n",
      "|    value_loss           | 7.83e+04     |\n",
      "------------------------------------------\n",
      "Episode: 256\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2597947.18\n",
      "total_reward: 1597947.18\n",
      "total_cost: 628972.00\n",
      "total_trades: 537\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 522           |\n",
      "|    time_elapsed         | 2032          |\n",
      "|    total_timesteps      | 534528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9910512e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.979        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.88e+05      |\n",
      "|    n_updates            | 30440         |\n",
      "|    policy_gradient_loss | 2.35e-05      |\n",
      "|    reward               | -4.833503     |\n",
      "|    value_loss           | 3.76e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 523           |\n",
      "|    time_elapsed         | 2036          |\n",
      "|    total_timesteps      | 535552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3838755e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.98         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.75e+04      |\n",
      "|    n_updates            | 30450         |\n",
      "|    policy_gradient_loss | -8.42e-05     |\n",
      "|    reward               | -7.2325115    |\n",
      "|    value_loss           | 1.35e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 2039         |\n",
      "|    total_timesteps      | 536576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.582216e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.982       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.32e+04     |\n",
      "|    n_updates            | 30460        |\n",
      "|    policy_gradient_loss | -0.000107    |\n",
      "|    reward               | -23.336788   |\n",
      "|    value_loss           | 8.65e+04     |\n",
      "------------------------------------------\n",
      "Episode: 257\n",
      "Episode: 258\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 525           |\n",
      "|    time_elapsed         | 2043          |\n",
      "|    total_timesteps      | 537600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1409458e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.984        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.29e+04      |\n",
      "|    n_updates            | 30470         |\n",
      "|    policy_gradient_loss | 1.58e-05      |\n",
      "|    reward               | -10.632846    |\n",
      "|    value_loss           | 6.59e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 263           |\n",
      "|    iterations           | 526           |\n",
      "|    time_elapsed         | 2047          |\n",
      "|    total_timesteps      | 538624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6371926e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.986        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.7e+04       |\n",
      "|    n_updates            | 30480         |\n",
      "|    policy_gradient_loss | -0.000449     |\n",
      "|    reward               | 60.492905     |\n",
      "|    value_loss           | 9.39e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 527          |\n",
      "|    time_elapsed         | 2051         |\n",
      "|    total_timesteps      | 539648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.566424e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.992       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81e+05     |\n",
      "|    n_updates            | 30490        |\n",
      "|    policy_gradient_loss | -5.48e-06    |\n",
      "|    reward               | 57.421505    |\n",
      "|    value_loss           | 3.62e+05     |\n",
      "------------------------------------------\n",
      "Episode: 259\n",
      "Episode: 260\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696646.29\n",
      "total_reward: -303353.71\n",
      "total_cost: 64276.73\n",
      "total_trades: 73\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 528           |\n",
      "|    time_elapsed         | 2056          |\n",
      "|    total_timesteps      | 540672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2260338e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.995        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.18e+05      |\n",
      "|    n_updates            | 30500         |\n",
      "|    policy_gradient_loss | -5.52e-05     |\n",
      "|    reward               | -10.262531    |\n",
      "|    value_loss           | 1.24e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 529           |\n",
      "|    time_elapsed         | 2059          |\n",
      "|    total_timesteps      | 541696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2759195e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.995        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.5e+05       |\n",
      "|    n_updates            | 30510         |\n",
      "|    policy_gradient_loss | 8.29e-06      |\n",
      "|    reward               | -10.904943    |\n",
      "|    value_loss           | 7e+05         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 530          |\n",
      "|    time_elapsed         | 2063         |\n",
      "|    total_timesteps      | 542720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.048199e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.996       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.08e+04     |\n",
      "|    n_updates            | 30520        |\n",
      "|    policy_gradient_loss | -5.15e-05    |\n",
      "|    reward               | -52.841576   |\n",
      "|    value_loss           | 2.16e+04     |\n",
      "------------------------------------------\n",
      "Episode: 261\n",
      "Episode: 262\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 531           |\n",
      "|    time_elapsed         | 2067          |\n",
      "|    total_timesteps      | 543744        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0052996e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.997        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.23e+04      |\n",
      "|    n_updates            | 30530         |\n",
      "|    policy_gradient_loss | 3.96e-05      |\n",
      "|    reward               | -4.903477     |\n",
      "|    value_loss           | 1.25e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 532           |\n",
      "|    time_elapsed         | 2071          |\n",
      "|    total_timesteps      | 544768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3087254e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.997        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.08e+04      |\n",
      "|    n_updates            | 30540         |\n",
      "|    policy_gradient_loss | -0.000196     |\n",
      "|    reward               | -16.847448    |\n",
      "|    value_loss           | 1.22e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 263\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 533           |\n",
      "|    time_elapsed         | 2075          |\n",
      "|    total_timesteps      | 545792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1496958e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.996        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+04      |\n",
      "|    n_updates            | 30550         |\n",
      "|    policy_gradient_loss | -0.000214     |\n",
      "|    reward               | 20.849428     |\n",
      "|    value_loss           | 4.45e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 2079         |\n",
      "|    total_timesteps      | 546816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022716718 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.14e+04     |\n",
      "|    n_updates            | 30560        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | 48.132717    |\n",
      "|    value_loss           | 1.03e+05     |\n",
      "------------------------------------------\n",
      "Episode: 264\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2010243.98\n",
      "total_reward: 1010243.98\n",
      "total_cost: 887323.56\n",
      "total_trades: 555\n",
      "=================================\n",
      "Episode: 265\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 535          |\n",
      "|    time_elapsed         | 2083         |\n",
      "|    total_timesteps      | 547840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008692981 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.88e+05     |\n",
      "|    n_updates            | 30570        |\n",
      "|    policy_gradient_loss | 7.09e-05     |\n",
      "|    reward               | 1.215307     |\n",
      "|    value_loss           | 5.76e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 536           |\n",
      "|    time_elapsed         | 2088          |\n",
      "|    total_timesteps      | 548864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010597147 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.98e+05      |\n",
      "|    n_updates            | 30580         |\n",
      "|    policy_gradient_loss | 9.07e-05      |\n",
      "|    reward               | 46.09547      |\n",
      "|    value_loss           | 7.97e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 537           |\n",
      "|    time_elapsed         | 2092          |\n",
      "|    total_timesteps      | 549888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0785647e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.04e+05      |\n",
      "|    n_updates            | 30590         |\n",
      "|    policy_gradient_loss | 3.83e-05      |\n",
      "|    reward               | -4.1309376    |\n",
      "|    value_loss           | 4.08e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 266\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 538           |\n",
      "|    time_elapsed         | 2096          |\n",
      "|    total_timesteps      | 550912        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8503051e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.73e+05      |\n",
      "|    n_updates            | 30600         |\n",
      "|    policy_gradient_loss | -4.96e-07     |\n",
      "|    reward               | -14.281781    |\n",
      "|    value_loss           | 3.47e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 539           |\n",
      "|    time_elapsed         | 2100          |\n",
      "|    total_timesteps      | 551936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8132036e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.59e+04      |\n",
      "|    n_updates            | 30610         |\n",
      "|    policy_gradient_loss | -4.86e-05     |\n",
      "|    reward               | -21.723156    |\n",
      "|    value_loss           | 7.18e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 267\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 540          |\n",
      "|    time_elapsed         | 2104         |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021202136 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.93e+03     |\n",
      "|    n_updates            | 30620        |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    reward               | -0.5441768   |\n",
      "|    value_loss           | 1.99e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 541          |\n",
      "|    time_elapsed         | 2108         |\n",
      "|    total_timesteps      | 553984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019111703 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.45e+04     |\n",
      "|    n_updates            | 30630        |\n",
      "|    policy_gradient_loss | 0.000428     |\n",
      "|    reward               | -11.677812   |\n",
      "|    value_loss           | 1.29e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 542           |\n",
      "|    time_elapsed         | 2112          |\n",
      "|    total_timesteps      | 555008        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030739757 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.78e+04      |\n",
      "|    n_updates            | 30640         |\n",
      "|    policy_gradient_loss | -0.000279     |\n",
      "|    reward               | -14.653859    |\n",
      "|    value_loss           | 5.55e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 268\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1373885.18\n",
      "total_reward: 373885.18\n",
      "total_cost: 1010668.90\n",
      "total_trades: 743\n",
      "=================================\n",
      "Episode: 269\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 543           |\n",
      "|    time_elapsed         | 2116          |\n",
      "|    total_timesteps      | 556032        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014607108 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.69e+04      |\n",
      "|    n_updates            | 30650         |\n",
      "|    policy_gradient_loss | -0.000303     |\n",
      "|    reward               | -3.5921636    |\n",
      "|    value_loss           | 9.39e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 544           |\n",
      "|    time_elapsed         | 2120          |\n",
      "|    total_timesteps      | 557056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020675955 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.92e+04      |\n",
      "|    n_updates            | 30660         |\n",
      "|    policy_gradient_loss | -0.000441     |\n",
      "|    reward               | -21.35029     |\n",
      "|    value_loss           | 3.84e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 545           |\n",
      "|    time_elapsed         | 2125          |\n",
      "|    total_timesteps      | 558080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045755273 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+04      |\n",
      "|    n_updates            | 30670         |\n",
      "|    policy_gradient_loss | -0.000375     |\n",
      "|    reward               | -74.29187     |\n",
      "|    value_loss           | 2.04e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 270\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 546           |\n",
      "|    time_elapsed         | 2129          |\n",
      "|    total_timesteps      | 559104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026670308 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.03e+05      |\n",
      "|    n_updates            | 30680         |\n",
      "|    policy_gradient_loss | -0.000393     |\n",
      "|    reward               | -29.358564    |\n",
      "|    value_loss           | 6.07e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 547           |\n",
      "|    time_elapsed         | 2133          |\n",
      "|    total_timesteps      | 560128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8544571e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.73e+05      |\n",
      "|    n_updates            | 30690         |\n",
      "|    policy_gradient_loss | 6.28e-05      |\n",
      "|    reward               | -37.23009     |\n",
      "|    value_loss           | 5.46e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 271\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 548           |\n",
      "|    time_elapsed         | 2137          |\n",
      "|    total_timesteps      | 561152        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0957086e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.51e+04      |\n",
      "|    n_updates            | 30700         |\n",
      "|    policy_gradient_loss | 6.43e-06      |\n",
      "|    reward               | -9.183497     |\n",
      "|    value_loss           | 1.5e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 549           |\n",
      "|    time_elapsed         | 2141          |\n",
      "|    total_timesteps      | 562176        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2584572e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.69e+05      |\n",
      "|    n_updates            | 30710         |\n",
      "|    policy_gradient_loss | 1.99e-06      |\n",
      "|    reward               | -58.116       |\n",
      "|    value_loss           | 3.39e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 550          |\n",
      "|    time_elapsed         | 2145         |\n",
      "|    total_timesteps      | 563200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.857705e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12e+05     |\n",
      "|    n_updates            | 30720        |\n",
      "|    policy_gradient_loss | -6.13e-05    |\n",
      "|    reward               | -102.06419   |\n",
      "|    value_loss           | 2.24e+05     |\n",
      "------------------------------------------\n",
      "Episode: 272\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 979192.60\n",
      "total_reward: -20807.40\n",
      "total_cost: 651103.77\n",
      "total_trades: 718\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 2149         |\n",
      "|    total_timesteps      | 564224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.560097e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.97e+05     |\n",
      "|    n_updates            | 30730        |\n",
      "|    policy_gradient_loss | 3.98e-06     |\n",
      "|    reward               | -8.28334     |\n",
      "|    value_loss           | 1.59e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 552           |\n",
      "|    time_elapsed         | 2154          |\n",
      "|    total_timesteps      | 565248        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6763806e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.49e+05      |\n",
      "|    n_updates            | 30740         |\n",
      "|    policy_gradient_loss | -7.78e-07     |\n",
      "|    reward               | -69.24428     |\n",
      "|    value_loss           | 1.1e+06       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 2158        |\n",
      "|    total_timesteps      | 566272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.07338e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.27e+05    |\n",
      "|    n_updates            | 30750       |\n",
      "|    policy_gradient_loss | 5.38e-06    |\n",
      "|    reward               | -66.65045   |\n",
      "|    value_loss           | 4.55e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 273\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 554           |\n",
      "|    time_elapsed         | 2162          |\n",
      "|    total_timesteps      | 567296        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4680048e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.73e+05      |\n",
      "|    n_updates            | 30760         |\n",
      "|    policy_gradient_loss | 1.66e-06      |\n",
      "|    reward               | -50.76421     |\n",
      "|    value_loss           | 9.46e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 555          |\n",
      "|    time_elapsed         | 2166         |\n",
      "|    total_timesteps      | 568320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.991687e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.89e+04     |\n",
      "|    n_updates            | 30770        |\n",
      "|    policy_gradient_loss | -6.62e-05    |\n",
      "|    reward               | -61.10268    |\n",
      "|    value_loss           | 1.58e+05     |\n",
      "------------------------------------------\n",
      "Episode: 274\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 556          |\n",
      "|    time_elapsed         | 2171         |\n",
      "|    total_timesteps      | 569344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.733237e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.45e+05     |\n",
      "|    n_updates            | 30780        |\n",
      "|    policy_gradient_loss | -4.68e-06    |\n",
      "|    reward               | -26.328985   |\n",
      "|    value_loss           | 4.9e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 557           |\n",
      "|    time_elapsed         | 2175          |\n",
      "|    total_timesteps      | 570368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9552334e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.04e+05      |\n",
      "|    n_updates            | 30790         |\n",
      "|    policy_gradient_loss | 2.64e-05      |\n",
      "|    reward               | -64.60507     |\n",
      "|    value_loss           | 8.08e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 558           |\n",
      "|    time_elapsed         | 2179          |\n",
      "|    total_timesteps      | 571392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3746321e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.04e+05      |\n",
      "|    n_updates            | 30800         |\n",
      "|    policy_gradient_loss | -2.52e-05     |\n",
      "|    reward               | -81.81728     |\n",
      "|    value_loss           | 2.08e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 275\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 559           |\n",
      "|    time_elapsed         | 2183          |\n",
      "|    total_timesteps      | 572416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8930878e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.98e+05      |\n",
      "|    n_updates            | 30810         |\n",
      "|    policy_gradient_loss | -7.94e-07     |\n",
      "|    reward               | -32.827164    |\n",
      "|    value_loss           | 1.2e+06       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 560           |\n",
      "|    time_elapsed         | 2187          |\n",
      "|    total_timesteps      | 573440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9082876e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.67e+05      |\n",
      "|    n_updates            | 30820         |\n",
      "|    policy_gradient_loss | -5.09e-05     |\n",
      "|    reward               | -68.94369     |\n",
      "|    value_loss           | 5.34e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 276\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1225016.95\n",
      "total_reward: 225016.95\n",
      "total_cost: 703924.65\n",
      "total_trades: 755\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 561          |\n",
      "|    time_elapsed         | 2192         |\n",
      "|    total_timesteps      | 574464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.619694e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.45e+05     |\n",
      "|    n_updates            | 30830        |\n",
      "|    policy_gradient_loss | -1.73e-05    |\n",
      "|    reward               | -12.541053   |\n",
      "|    value_loss           | 6.9e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 562           |\n",
      "|    time_elapsed         | 2196          |\n",
      "|    total_timesteps      | 575488        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5501005e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.85e+05      |\n",
      "|    n_updates            | 30840         |\n",
      "|    policy_gradient_loss | 9.94e-06      |\n",
      "|    reward               | -26.317863    |\n",
      "|    value_loss           | 1.37e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 563           |\n",
      "|    time_elapsed         | 2200          |\n",
      "|    total_timesteps      | 576512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1972685e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.11e+04      |\n",
      "|    n_updates            | 30850         |\n",
      "|    policy_gradient_loss | -6.19e-05     |\n",
      "|    reward               | -37.472572    |\n",
      "|    value_loss           | 6.22e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 277\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 564           |\n",
      "|    time_elapsed         | 2204          |\n",
      "|    total_timesteps      | 577536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5908852e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.62e+04      |\n",
      "|    n_updates            | 30860         |\n",
      "|    policy_gradient_loss | -8.55e-05     |\n",
      "|    reward               | 17.184366     |\n",
      "|    value_loss           | 1.53e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 2209         |\n",
      "|    total_timesteps      | 578560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.657749e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.00304      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.46e+05     |\n",
      "|    n_updates            | 30870        |\n",
      "|    policy_gradient_loss | 3.42e-05     |\n",
      "|    reward               | -33.247147   |\n",
      "|    value_loss           | 2.97e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 566          |\n",
      "|    time_elapsed         | 2214         |\n",
      "|    total_timesteps      | 579584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.270615e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.338       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.98e+05     |\n",
      "|    n_updates            | 30880        |\n",
      "|    policy_gradient_loss | -6.02e-05    |\n",
      "|    reward               | 4.0424194    |\n",
      "|    value_loss           | 3.98e+05     |\n",
      "------------------------------------------\n",
      "Episode: 278\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 567           |\n",
      "|    time_elapsed         | 2218          |\n",
      "|    total_timesteps      | 580608        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5838887e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.983        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.24e+05      |\n",
      "|    n_updates            | 30890         |\n",
      "|    policy_gradient_loss | -3.83e-06     |\n",
      "|    reward               | 14.458625     |\n",
      "|    value_loss           | 6.52e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 568           |\n",
      "|    time_elapsed         | 2223          |\n",
      "|    total_timesteps      | 581632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0904117e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0.722         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.5e+05       |\n",
      "|    n_updates            | 30900         |\n",
      "|    policy_gradient_loss | -0.000127     |\n",
      "|    reward               | -28.43693     |\n",
      "|    value_loss           | 3.02e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 279\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 569           |\n",
      "|    time_elapsed         | 2227          |\n",
      "|    total_timesteps      | 582656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.8845693e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.5e+04       |\n",
      "|    n_updates            | 30910         |\n",
      "|    policy_gradient_loss | -2.92e-05     |\n",
      "|    reward               | -13.243575    |\n",
      "|    value_loss           | 1.1e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 570           |\n",
      "|    time_elapsed         | 2231          |\n",
      "|    total_timesteps      | 583680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4512334e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.94e+04      |\n",
      "|    n_updates            | 30920         |\n",
      "|    policy_gradient_loss | -2.29e-05     |\n",
      "|    reward               | -28.886654    |\n",
      "|    value_loss           | 1.79e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 571           |\n",
      "|    time_elapsed         | 2235          |\n",
      "|    total_timesteps      | 584704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2891327e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.17e+04      |\n",
      "|    n_updates            | 30930         |\n",
      "|    policy_gradient_loss | 5.34e-06      |\n",
      "|    reward               | -56.1916      |\n",
      "|    value_loss           | 4.43e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 280\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1217101.81\n",
      "total_reward: 217101.81\n",
      "total_cost: 828083.25\n",
      "total_trades: 758\n",
      "=================================\n",
      "Episode: 281\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 572           |\n",
      "|    time_elapsed         | 2240          |\n",
      "|    total_timesteps      | 585728        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7362181e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.95e+05      |\n",
      "|    n_updates            | 30940         |\n",
      "|    policy_gradient_loss | -5.01e-05     |\n",
      "|    reward               | -30.777021    |\n",
      "|    value_loss           | 5.93e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 573          |\n",
      "|    time_elapsed         | 2244         |\n",
      "|    total_timesteps      | 586752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.453592e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.42e+05     |\n",
      "|    n_updates            | 30950        |\n",
      "|    policy_gradient_loss | -8.96e-05    |\n",
      "|    reward               | -53.845467   |\n",
      "|    value_loss           | 4.87e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 574           |\n",
      "|    time_elapsed         | 2248          |\n",
      "|    total_timesteps      | 587776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5657937e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.07e+05      |\n",
      "|    n_updates            | 30960         |\n",
      "|    policy_gradient_loss | 5.95e-06      |\n",
      "|    reward               | -93.2011      |\n",
      "|    value_loss           | 2.15e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 282\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 575           |\n",
      "|    time_elapsed         | 2252          |\n",
      "|    total_timesteps      | 588800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7823566e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.89e+05      |\n",
      "|    n_updates            | 30970         |\n",
      "|    policy_gradient_loss | -5.44e-06     |\n",
      "|    reward               | -28.96334     |\n",
      "|    value_loss           | 7.79e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 2257         |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.964415e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.09e+05     |\n",
      "|    n_updates            | 30980        |\n",
      "|    policy_gradient_loss | -7.58e-05    |\n",
      "|    reward               | -51.219463   |\n",
      "|    value_loss           | 2.18e+05     |\n",
      "------------------------------------------\n",
      "Episode: 283\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 577          |\n",
      "|    time_elapsed         | 2261         |\n",
      "|    total_timesteps      | 590848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.891263e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.02e+04     |\n",
      "|    n_updates            | 30990        |\n",
      "|    policy_gradient_loss | -3.02e-05    |\n",
      "|    reward               | 0.035916958  |\n",
      "|    value_loss           | 1.82e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 578           |\n",
      "|    time_elapsed         | 2265          |\n",
      "|    total_timesteps      | 591872        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6673079e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.05e+05      |\n",
      "|    n_updates            | 31000         |\n",
      "|    policy_gradient_loss | -1.94e-05     |\n",
      "|    reward               | -34.267185    |\n",
      "|    value_loss           | 1.21e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 579          |\n",
      "|    time_elapsed         | 2269         |\n",
      "|    total_timesteps      | 592896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.114044e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.29e+04     |\n",
      "|    n_updates            | 31010        |\n",
      "|    policy_gradient_loss | -1.73e-05    |\n",
      "|    reward               | -81.896736   |\n",
      "|    value_loss           | 2.65e+04     |\n",
      "------------------------------------------\n",
      "Episode: 284\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1080270.16\n",
      "total_reward: 80270.16\n",
      "total_cost: 762393.80\n",
      "total_trades: 754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 2273        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.19678e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.41e+05    |\n",
      "|    n_updates            | 31020       |\n",
      "|    policy_gradient_loss | 2.6e-05     |\n",
      "|    reward               | 43.805504   |\n",
      "|    value_loss           | 1.08e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 581           |\n",
      "|    time_elapsed         | 2277          |\n",
      "|    total_timesteps      | 594944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2908382e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.03e+05      |\n",
      "|    n_updates            | 31030         |\n",
      "|    policy_gradient_loss | -0.000225     |\n",
      "|    reward               | 252.07118     |\n",
      "|    value_loss           | 6.07e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 582           |\n",
      "|    time_elapsed         | 2282          |\n",
      "|    total_timesteps      | 595968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2844022e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.54e+06      |\n",
      "|    n_updates            | 31040         |\n",
      "|    policy_gradient_loss | -0.000309     |\n",
      "|    reward               | 788.11646     |\n",
      "|    value_loss           | 9.08e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 285\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 583          |\n",
      "|    time_elapsed         | 2286         |\n",
      "|    total_timesteps      | 596992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.120295e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.79e+07     |\n",
      "|    n_updates            | 31050        |\n",
      "|    policy_gradient_loss | 6.87e-07     |\n",
      "|    reward               | 4.209285     |\n",
      "|    value_loss           | 5.59e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 584          |\n",
      "|    time_elapsed         | 2290         |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.519273e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.06e+07     |\n",
      "|    n_updates            | 31060        |\n",
      "|    policy_gradient_loss | -5.72e-06    |\n",
      "|    reward               | -42.923363   |\n",
      "|    value_loss           | 2.12e+07     |\n",
      "------------------------------------------\n",
      "Episode: 286\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 585          |\n",
      "|    time_elapsed         | 2294         |\n",
      "|    total_timesteps      | 599040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.987022e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.3e+04      |\n",
      "|    n_updates            | 31070        |\n",
      "|    policy_gradient_loss | -6.64e-05    |\n",
      "|    reward               | 28.241936    |\n",
      "|    value_loss           | 1.26e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 586           |\n",
      "|    time_elapsed         | 2298          |\n",
      "|    total_timesteps      | 600064        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1260097e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0.00971       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.09e+04      |\n",
      "|    n_updates            | 31080         |\n",
      "|    policy_gradient_loss | -1.47e-05     |\n",
      "|    reward               | -43.683624    |\n",
      "|    value_loss           | 1.22e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 287\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 261           |\n",
      "|    iterations           | 587           |\n",
      "|    time_elapsed         | 2302          |\n",
      "|    total_timesteps      | 601088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5513506e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.941        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.4e+05       |\n",
      "|    n_updates            | 31090         |\n",
      "|    policy_gradient_loss | -2.85e-05     |\n",
      "|    reward               | 3.6339705     |\n",
      "|    value_loss           | 2.85e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 588           |\n",
      "|    time_elapsed         | 2307          |\n",
      "|    total_timesteps      | 602112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6632257e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -13.8         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.73e+05      |\n",
      "|    n_updates            | 31100         |\n",
      "|    policy_gradient_loss | -0.000107     |\n",
      "|    reward               | -26.79377     |\n",
      "|    value_loss           | 5.53e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 589           |\n",
      "|    time_elapsed         | 2311          |\n",
      "|    total_timesteps      | 603136        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017731474 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.76e+04      |\n",
      "|    n_updates            | 31110         |\n",
      "|    policy_gradient_loss | -0.000252     |\n",
      "|    reward               | -79.333954    |\n",
      "|    value_loss           | 5.52e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 288\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 658854.35\n",
      "total_reward: -341145.65\n",
      "total_cost: 855581.95\n",
      "total_trades: 773\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 590           |\n",
      "|    time_elapsed         | 2315          |\n",
      "|    total_timesteps      | 604160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018229318 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.63e+05      |\n",
      "|    n_updates            | 31120         |\n",
      "|    policy_gradient_loss | 0.000335      |\n",
      "|    reward               | -43.82325     |\n",
      "|    value_loss           | 7.26e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 260            |\n",
      "|    iterations           | 591            |\n",
      "|    time_elapsed         | 2319           |\n",
      "|    total_timesteps      | 605184         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.41707715e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.05          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 8.97e+04       |\n",
      "|    n_updates            | 31130          |\n",
      "|    policy_gradient_loss | 2.51e-05       |\n",
      "|    reward               | -67.74489      |\n",
      "|    value_loss           | 1.8e+05        |\n",
      "--------------------------------------------\n",
      "Episode: 289\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 592           |\n",
      "|    time_elapsed         | 2323          |\n",
      "|    total_timesteps      | 606208        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7060665e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.63e+05      |\n",
      "|    n_updates            | 31140         |\n",
      "|    policy_gradient_loss | 1.25e-05      |\n",
      "|    reward               | -0.15155685   |\n",
      "|    value_loss           | 7.27e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 2328         |\n",
      "|    total_timesteps      | 607232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.695612e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.6e+05      |\n",
      "|    n_updates            | 31150        |\n",
      "|    policy_gradient_loss | -1.04e-05    |\n",
      "|    reward               | -82.37498    |\n",
      "|    value_loss           | 7.2e+05      |\n",
      "------------------------------------------\n",
      "Episode: 290\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 594           |\n",
      "|    time_elapsed         | 2333          |\n",
      "|    total_timesteps      | 608256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7990976e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.13e+05      |\n",
      "|    n_updates            | 31160         |\n",
      "|    policy_gradient_loss | -6.95e-05     |\n",
      "|    reward               | 6.08229       |\n",
      "|    value_loss           | 4.27e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 595           |\n",
      "|    time_elapsed         | 2337          |\n",
      "|    total_timesteps      | 609280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0920415e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.737         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.68e+04      |\n",
      "|    n_updates            | 31170         |\n",
      "|    policy_gradient_loss | -5.01e-05     |\n",
      "|    reward               | -10.612403    |\n",
      "|    value_loss           | 9.35e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 291\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 596           |\n",
      "|    time_elapsed         | 2342          |\n",
      "|    total_timesteps      | 610304        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1849159e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+05      |\n",
      "|    n_updates            | 31180         |\n",
      "|    policy_gradient_loss | -0.000142     |\n",
      "|    reward               | -13.331078    |\n",
      "|    value_loss           | 2.12e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 597           |\n",
      "|    time_elapsed         | 2346          |\n",
      "|    total_timesteps      | 611328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4174671e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.77e+05      |\n",
      "|    n_updates            | 31190         |\n",
      "|    policy_gradient_loss | 4.22e-05      |\n",
      "|    reward               | 17.054012     |\n",
      "|    value_loss           | 7.53e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 598           |\n",
      "|    time_elapsed         | 2350          |\n",
      "|    total_timesteps      | 612352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024315988 |\n",
      "|    clip_fraction        | 0.2           |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.36e+04      |\n",
      "|    n_updates            | 31200         |\n",
      "|    policy_gradient_loss | -0.00071      |\n",
      "|    reward               | 93.03103      |\n",
      "|    value_loss           | 1.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 292\n",
      "Current company: ['V']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3743460.05\n",
      "total_reward: 2743460.05\n",
      "total_cost: 1689606.32\n",
      "total_trades: 859\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 599           |\n",
      "|    time_elapsed         | 2354          |\n",
      "|    total_timesteps      | 613376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023438781 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.28e+05      |\n",
      "|    n_updates            | 31210         |\n",
      "|    policy_gradient_loss | 0.000372      |\n",
      "|    reward               | -30.800331    |\n",
      "|    value_loss           | 1.26e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 293\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 2358         |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.107022e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.99e+06     |\n",
      "|    n_updates            | 31220        |\n",
      "|    policy_gradient_loss | -0.000522    |\n",
      "|    reward               | -10.428645   |\n",
      "|    value_loss           | 3.98e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 601          |\n",
      "|    time_elapsed         | 2362         |\n",
      "|    total_timesteps      | 615424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.354639e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.26e+05     |\n",
      "|    n_updates            | 31230        |\n",
      "|    policy_gradient_loss | 3.85e-05     |\n",
      "|    reward               | -54.010612   |\n",
      "|    value_loss           | 2.52e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 602          |\n",
      "|    time_elapsed         | 2366         |\n",
      "|    total_timesteps      | 616448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.073954e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.28e+04     |\n",
      "|    n_updates            | 31240        |\n",
      "|    policy_gradient_loss | -5.83e-05    |\n",
      "|    reward               | -77.62627    |\n",
      "|    value_loss           | 1.86e+05     |\n",
      "------------------------------------------\n",
      "Episode: 294\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 603           |\n",
      "|    time_elapsed         | 2371          |\n",
      "|    total_timesteps      | 617472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5847264e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 2.98e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.69e+05      |\n",
      "|    n_updates            | 31250         |\n",
      "|    policy_gradient_loss | -4.82e-05     |\n",
      "|    reward               | -16.165472    |\n",
      "|    value_loss           | 9.38e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 604          |\n",
      "|    time_elapsed         | 2375         |\n",
      "|    total_timesteps      | 618496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.240471e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.99e+05     |\n",
      "|    n_updates            | 31260        |\n",
      "|    policy_gradient_loss | -2.88e-05    |\n",
      "|    reward               | -19.616577   |\n",
      "|    value_loss           | 9.98e+05     |\n",
      "------------------------------------------\n",
      "Episode: 295\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 605          |\n",
      "|    time_elapsed         | 2379         |\n",
      "|    total_timesteps      | 619520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.043966e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.18e+03     |\n",
      "|    n_updates            | 31270        |\n",
      "|    policy_gradient_loss | -3.25e-05    |\n",
      "|    reward               | -10.209814   |\n",
      "|    value_loss           | 1.24e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 606          |\n",
      "|    time_elapsed         | 2383         |\n",
      "|    total_timesteps      | 620544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.652452e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.04e+05     |\n",
      "|    n_updates            | 31280        |\n",
      "|    policy_gradient_loss | -1.16e-05    |\n",
      "|    reward               | -53.473495   |\n",
      "|    value_loss           | 4.09e+05     |\n",
      "------------------------------------------\n",
      "Episode: 296\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696858.56\n",
      "total_reward: -303141.44\n",
      "total_cost: 498178.54\n",
      "total_trades: 547\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 607           |\n",
      "|    time_elapsed         | 2387          |\n",
      "|    total_timesteps      | 621568        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7748326e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.29e+04      |\n",
      "|    n_updates            | 31290         |\n",
      "|    policy_gradient_loss | -2.13e-05     |\n",
      "|    reward               | -5.3897448    |\n",
      "|    value_loss           | 1.06e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 608           |\n",
      "|    time_elapsed         | 2391          |\n",
      "|    total_timesteps      | 622592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1378434e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.25e+05      |\n",
      "|    n_updates            | 31300         |\n",
      "|    policy_gradient_loss | 1.69e-05      |\n",
      "|    reward               | 65.50295      |\n",
      "|    value_loss           | 6.5e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 609           |\n",
      "|    time_elapsed         | 2395          |\n",
      "|    total_timesteps      | 623616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4709304e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.96e+05      |\n",
      "|    n_updates            | 31310         |\n",
      "|    policy_gradient_loss | 8.65e-06      |\n",
      "|    reward               | 110.5978      |\n",
      "|    value_loss           | 7.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 297\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 2400         |\n",
      "|    total_timesteps      | 624640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.010546e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.67e+05     |\n",
      "|    n_updates            | 31320        |\n",
      "|    policy_gradient_loss | -5.54e-06    |\n",
      "|    reward               | 3.6406045    |\n",
      "|    value_loss           | 1.74e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 611           |\n",
      "|    time_elapsed         | 2404          |\n",
      "|    total_timesteps      | 625664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6973506e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.47e+05      |\n",
      "|    n_updates            | 31330         |\n",
      "|    policy_gradient_loss | -6.77e-06     |\n",
      "|    reward               | 10.454746     |\n",
      "|    value_loss           | 8.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 298\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 612           |\n",
      "|    time_elapsed         | 2408          |\n",
      "|    total_timesteps      | 626688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9428553e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+05      |\n",
      "|    n_updates            | 31340         |\n",
      "|    policy_gradient_loss | -2.96e-05     |\n",
      "|    reward               | -0.41949525   |\n",
      "|    value_loss           | 2.13e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 299\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 613           |\n",
      "|    time_elapsed         | 2412          |\n",
      "|    total_timesteps      | 627712        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4931429e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.17e+05      |\n",
      "|    n_updates            | 31350         |\n",
      "|    policy_gradient_loss | 9.33e-06      |\n",
      "|    reward               | -28.391972    |\n",
      "|    value_loss           | 2.33e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 614           |\n",
      "|    time_elapsed         | 2416          |\n",
      "|    total_timesteps      | 628736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6610214e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.92e+04      |\n",
      "|    n_updates            | 31360         |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    reward               | -72.7931      |\n",
      "|    value_loss           | 3.84e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 300\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696179.66\n",
      "total_reward: -303820.34\n",
      "total_cost: 775604.78\n",
      "total_trades: 829\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 615           |\n",
      "|    time_elapsed         | 2421          |\n",
      "|    total_timesteps      | 629760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7875125e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.83e+05      |\n",
      "|    n_updates            | 31370         |\n",
      "|    policy_gradient_loss | 1.56e-05      |\n",
      "|    reward               | -3.962509     |\n",
      "|    value_loss           | 5.66e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 2425        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.84845e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.6e+05     |\n",
      "|    n_updates            | 31380       |\n",
      "|    policy_gradient_loss | 4.76e-06    |\n",
      "|    reward               | -46.060444  |\n",
      "|    value_loss           | 1.12e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 617          |\n",
      "|    time_elapsed         | 2429         |\n",
      "|    total_timesteps      | 631808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.733447e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.07e+05     |\n",
      "|    n_updates            | 31390        |\n",
      "|    policy_gradient_loss | -4.12e-06    |\n",
      "|    reward               | -27.805      |\n",
      "|    value_loss           | 2.14e+05     |\n",
      "------------------------------------------\n",
      "Episode: 301\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 260           |\n",
      "|    iterations           | 618           |\n",
      "|    time_elapsed         | 2433          |\n",
      "|    total_timesteps      | 632832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5757042e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.71e+05      |\n",
      "|    n_updates            | 31400         |\n",
      "|    policy_gradient_loss | -6.13e-06     |\n",
      "|    reward               | 8.629379      |\n",
      "|    value_loss           | 3.43e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 2438        |\n",
      "|    total_timesteps      | 633856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.83317e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.04e+04    |\n",
      "|    n_updates            | 31410       |\n",
      "|    policy_gradient_loss | -7.28e-05   |\n",
      "|    reward               | 13.404292   |\n",
      "|    value_loss           | 1.21e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 302\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 620           |\n",
      "|    time_elapsed         | 2443          |\n",
      "|    total_timesteps      | 634880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1356964e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.58e+04      |\n",
      "|    n_updates            | 31420         |\n",
      "|    policy_gradient_loss | -0.000226     |\n",
      "|    reward               | 11.566718     |\n",
      "|    value_loss           | 1.72e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 303\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 621           |\n",
      "|    time_elapsed         | 2447          |\n",
      "|    total_timesteps      | 635904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8267194e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.47e+05      |\n",
      "|    n_updates            | 31430         |\n",
      "|    policy_gradient_loss | -3.96e-05     |\n",
      "|    reward               | 10.19334      |\n",
      "|    value_loss           | 2.94e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 622           |\n",
      "|    time_elapsed         | 2451          |\n",
      "|    total_timesteps      | 636928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9520673e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -0.0056       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.04e+05      |\n",
      "|    n_updates            | 31440         |\n",
      "|    policy_gradient_loss | -4.69e-06     |\n",
      "|    reward               | 8.573909      |\n",
      "|    value_loss           | 2.09e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 304\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 672840.90\n",
      "total_reward: -327159.10\n",
      "total_cost: 938206.51\n",
      "total_trades: 719\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 623           |\n",
      "|    time_elapsed         | 2455          |\n",
      "|    total_timesteps      | 637952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8906153e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.534        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.76e+04      |\n",
      "|    n_updates            | 31450         |\n",
      "|    policy_gradient_loss | -3.47e-05     |\n",
      "|    reward               | -25.261816    |\n",
      "|    value_loss           | 1.77e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 624          |\n",
      "|    time_elapsed         | 2459         |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.112984e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.0317      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.83e+05     |\n",
      "|    n_updates            | 31460        |\n",
      "|    policy_gradient_loss | 1.33e-05     |\n",
      "|    reward               | -35.142857   |\n",
      "|    value_loss           | 5.69e+05     |\n",
      "------------------------------------------\n",
      "Episode: 305\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 625           |\n",
      "|    time_elapsed         | 2463          |\n",
      "|    total_timesteps      | 640000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4594788e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.46e+04      |\n",
      "|    n_updates            | 31470         |\n",
      "|    policy_gradient_loss | -0.000107     |\n",
      "|    reward               | -33.636673    |\n",
      "|    value_loss           | 1.49e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 626           |\n",
      "|    time_elapsed         | 2468          |\n",
      "|    total_timesteps      | 641024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4542951e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.03e+05      |\n",
      "|    n_updates            | 31480         |\n",
      "|    policy_gradient_loss | -7.56e-05     |\n",
      "|    reward               | -24.062298    |\n",
      "|    value_loss           | 2.05e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 306\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 627           |\n",
      "|    time_elapsed         | 2472          |\n",
      "|    total_timesteps      | 642048        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9930845e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.45e+04      |\n",
      "|    n_updates            | 31490         |\n",
      "|    policy_gradient_loss | -0.000225     |\n",
      "|    reward               | -14.6460085   |\n",
      "|    value_loss           | 8.9e+04       |\n",
      "-------------------------------------------\n",
      "Episode: 307\n",
      "Episode: 308\n",
      "Current company: ['TRV']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696072.98\n",
      "total_reward: -303927.02\n",
      "total_cost: 121245.72\n",
      "total_trades: 127\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 628          |\n",
      "|    time_elapsed         | 2476         |\n",
      "|    total_timesteps      | 643072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.926854e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.06e+05     |\n",
      "|    n_updates            | 31500        |\n",
      "|    policy_gradient_loss | 4.76e-06     |\n",
      "|    reward               | 92.55079     |\n",
      "|    value_loss           | 1.01e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 629           |\n",
      "|    time_elapsed         | 2480          |\n",
      "|    total_timesteps      | 644096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0251256e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -0.00106      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.48e+05      |\n",
      "|    n_updates            | 31510         |\n",
      "|    policy_gradient_loss | -3.6e-05      |\n",
      "|    reward               | 13.7873125    |\n",
      "|    value_loss           | 2.97e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 630           |\n",
      "|    time_elapsed         | 2484          |\n",
      "|    total_timesteps      | 645120        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2140372e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.23         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.04e+05      |\n",
      "|    n_updates            | 31520         |\n",
      "|    policy_gradient_loss | -1.48e-05     |\n",
      "|    reward               | 43.85214      |\n",
      "|    value_loss           | 1.81e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 309\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 631           |\n",
      "|    time_elapsed         | 2488          |\n",
      "|    total_timesteps      | 646144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9691728e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.169        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.17e+05      |\n",
      "|    n_updates            | 31530         |\n",
      "|    policy_gradient_loss | -6.7e-06      |\n",
      "|    reward               | -21.554739    |\n",
      "|    value_loss           | 2.37e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 632           |\n",
      "|    time_elapsed         | 2492          |\n",
      "|    total_timesteps      | 647168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.6001743e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.647         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.36e+05      |\n",
      "|    n_updates            | 31540         |\n",
      "|    policy_gradient_loss | -3.59e-05     |\n",
      "|    reward               | -74.88135     |\n",
      "|    value_loss           | 4.74e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 633           |\n",
      "|    time_elapsed         | 2496          |\n",
      "|    total_timesteps      | 648192        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5590922e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.29e+05      |\n",
      "|    n_updates            | 31550         |\n",
      "|    policy_gradient_loss | -2.94e-05     |\n",
      "|    reward               | -100.72455    |\n",
      "|    value_loss           | 4.6e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 310\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 634           |\n",
      "|    time_elapsed         | 2501          |\n",
      "|    total_timesteps      | 649216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4604607e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.48e+05      |\n",
      "|    n_updates            | 31560         |\n",
      "|    policy_gradient_loss | -2.9e-06      |\n",
      "|    reward               | -13.448793    |\n",
      "|    value_loss           | 1.11e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 635           |\n",
      "|    time_elapsed         | 2505          |\n",
      "|    total_timesteps      | 650240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018544326 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.12e+05      |\n",
      "|    n_updates            | 31570         |\n",
      "|    policy_gradient_loss | -0.00062      |\n",
      "|    reward               | -60.77576     |\n",
      "|    value_loss           | 2.24e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 311\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 636           |\n",
      "|    time_elapsed         | 2509          |\n",
      "|    total_timesteps      | 651264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016949477 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.85e+05      |\n",
      "|    n_updates            | 31580         |\n",
      "|    policy_gradient_loss | 0.000483      |\n",
      "|    reward               | 87.99726      |\n",
      "|    value_loss           | 3.71e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 637          |\n",
      "|    time_elapsed         | 2513         |\n",
      "|    total_timesteps      | 652288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.346106e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.24e+05     |\n",
      "|    n_updates            | 31590        |\n",
      "|    policy_gradient_loss | -0.000133    |\n",
      "|    reward               | 113.03747    |\n",
      "|    value_loss           | 6.48e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 638          |\n",
      "|    time_elapsed         | 2517         |\n",
      "|    total_timesteps      | 653312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.698464e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.73e+06     |\n",
      "|    n_updates            | 31600        |\n",
      "|    policy_gradient_loss | 7.4e-05      |\n",
      "|    reward               | 218.66763    |\n",
      "|    value_loss           | 3.47e+06     |\n",
      "------------------------------------------\n",
      "Episode: 312\n",
      "Current company: ['V']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3217416.59\n",
      "total_reward: 2217416.59\n",
      "total_cost: 2425545.99\n",
      "total_trades: 963\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 639           |\n",
      "|    time_elapsed         | 2521          |\n",
      "|    total_timesteps      | 654336        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0231161e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.78e+06      |\n",
      "|    n_updates            | 31610         |\n",
      "|    policy_gradient_loss | -0.000174     |\n",
      "|    reward               | -30.143055    |\n",
      "|    value_loss           | 1.16e+07      |\n",
      "-------------------------------------------\n",
      "Episode: 313\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 640          |\n",
      "|    time_elapsed         | 2525         |\n",
      "|    total_timesteps      | 655360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.090807e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.49e+05     |\n",
      "|    n_updates            | 31620        |\n",
      "|    policy_gradient_loss | -6.99e-05    |\n",
      "|    reward               | 14.364817    |\n",
      "|    value_loss           | 1.5e+06      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 641           |\n",
      "|    time_elapsed         | 2530          |\n",
      "|    total_timesteps      | 656384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3778994e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.15e+05      |\n",
      "|    n_updates            | 31630         |\n",
      "|    policy_gradient_loss | 5.52e-05      |\n",
      "|    reward               | 91.41138      |\n",
      "|    value_loss           | 4.29e+05      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 259       |\n",
      "|    iterations           | 642       |\n",
      "|    time_elapsed         | 2534      |\n",
      "|    total_timesteps      | 657408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.06     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.07e+05  |\n",
      "|    n_updates            | 31640     |\n",
      "|    policy_gradient_loss | 1.92e-06  |\n",
      "|    reward               | 128.46696 |\n",
      "|    value_loss           | 6.14e+05  |\n",
      "---------------------------------------\n",
      "Episode: 314\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 643           |\n",
      "|    time_elapsed         | 2538          |\n",
      "|    total_timesteps      | 658432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2165401e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.23e+06      |\n",
      "|    n_updates            | 31650         |\n",
      "|    policy_gradient_loss | -2.74e-06     |\n",
      "|    reward               | -5.694381     |\n",
      "|    value_loss           | 8.47e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 644           |\n",
      "|    time_elapsed         | 2542          |\n",
      "|    total_timesteps      | 659456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1342345e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.93e+05      |\n",
      "|    n_updates            | 31660         |\n",
      "|    policy_gradient_loss | -2.84e-05     |\n",
      "|    reward               | 84.01748      |\n",
      "|    value_loss           | 1.19e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 645           |\n",
      "|    time_elapsed         | 2546          |\n",
      "|    total_timesteps      | 660480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0043226e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.94e+05      |\n",
      "|    n_updates            | 31670         |\n",
      "|    policy_gradient_loss | -2.28e-05     |\n",
      "|    reward               | 281.8145      |\n",
      "|    value_loss           | 7.87e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 315\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 646           |\n",
      "|    time_elapsed         | 2550          |\n",
      "|    total_timesteps      | 661504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3347245e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.48e+06      |\n",
      "|    n_updates            | 31680         |\n",
      "|    policy_gradient_loss | 1.64e-05      |\n",
      "|    reward               | -34.450333    |\n",
      "|    value_loss           | 4.97e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 316\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697445.45\n",
      "total_reward: -302554.55\n",
      "total_cost: 561481.04\n",
      "total_trades: 603\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 2555        |\n",
      "|    total_timesteps      | 662528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.11411e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.46e+06    |\n",
      "|    n_updates            | 31690       |\n",
      "|    policy_gradient_loss | -5.8e-06    |\n",
      "|    reward               | 16.765543   |\n",
      "|    value_loss           | 2.92e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 648           |\n",
      "|    time_elapsed         | 2559          |\n",
      "|    total_timesteps      | 663552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5854603e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.822         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.82e+05      |\n",
      "|    n_updates            | 31700         |\n",
      "|    policy_gradient_loss | -4.7e-05      |\n",
      "|    reward               | 29.82596      |\n",
      "|    value_loss           | 5.66e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 649          |\n",
      "|    time_elapsed         | 2563         |\n",
      "|    total_timesteps      | 664576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.388306e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.75e+05     |\n",
      "|    n_updates            | 31710        |\n",
      "|    policy_gradient_loss | -4.3e-05     |\n",
      "|    reward               | 85.59401     |\n",
      "|    value_loss           | 5.6e+05      |\n",
      "------------------------------------------\n",
      "Episode: 317\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 650          |\n",
      "|    time_elapsed         | 2567         |\n",
      "|    total_timesteps      | 665600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.507004e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.12e+05     |\n",
      "|    n_updates            | 31720        |\n",
      "|    policy_gradient_loss | -3.64e-06    |\n",
      "|    reward               | -9.982465    |\n",
      "|    value_loss           | 8.39e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 651           |\n",
      "|    time_elapsed         | 2571          |\n",
      "|    total_timesteps      | 666624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3440149e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.12e+05      |\n",
      "|    n_updates            | 31730         |\n",
      "|    policy_gradient_loss | -3.85e-06     |\n",
      "|    reward               | -69.33402     |\n",
      "|    value_loss           | 4.26e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 652           |\n",
      "|    time_elapsed         | 2576          |\n",
      "|    total_timesteps      | 667648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4040145e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.64e+04      |\n",
      "|    n_updates            | 31740         |\n",
      "|    policy_gradient_loss | -1.54e-07     |\n",
      "|    reward               | -88.94936     |\n",
      "|    value_loss           | 1.94e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 318\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 653           |\n",
      "|    time_elapsed         | 2581          |\n",
      "|    total_timesteps      | 668672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6239937e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.91e+05      |\n",
      "|    n_updates            | 31750         |\n",
      "|    policy_gradient_loss | -1.45e-07     |\n",
      "|    reward               | -37.397213    |\n",
      "|    value_loss           | 1.58e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 654           |\n",
      "|    time_elapsed         | 2585          |\n",
      "|    total_timesteps      | 669696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4808105e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.1e+05       |\n",
      "|    n_updates            | 31760         |\n",
      "|    policy_gradient_loss | -1.43e-06     |\n",
      "|    reward               | -78.198746    |\n",
      "|    value_loss           | 6.21e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 319\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 655           |\n",
      "|    time_elapsed         | 2590          |\n",
      "|    total_timesteps      | 670720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1630424e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.56e+05      |\n",
      "|    n_updates            | 31770         |\n",
      "|    policy_gradient_loss | -1.84e-05     |\n",
      "|    reward               | -1.5126848    |\n",
      "|    value_loss           | 7.12e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 656           |\n",
      "|    time_elapsed         | 2594          |\n",
      "|    total_timesteps      | 671744        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5861664e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.58e+05      |\n",
      "|    n_updates            | 31780         |\n",
      "|    policy_gradient_loss | 8.03e-06      |\n",
      "|    reward               | -2.7350078    |\n",
      "|    value_loss           | 1.32e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 320\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1399084.72\n",
      "total_reward: 399084.72\n",
      "total_cost: 446990.49\n",
      "total_trades: 459\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 657           |\n",
      "|    time_elapsed         | 2598          |\n",
      "|    total_timesteps      | 672768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2427716e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.15e+05      |\n",
      "|    n_updates            | 31790         |\n",
      "|    policy_gradient_loss | -9.2e-06      |\n",
      "|    reward               | 19.12067      |\n",
      "|    value_loss           | 2.3e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 658           |\n",
      "|    time_elapsed         | 2602          |\n",
      "|    total_timesteps      | 673792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0390493e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.56e+04      |\n",
      "|    n_updates            | 31800         |\n",
      "|    policy_gradient_loss | -0.000139     |\n",
      "|    reward               | 43.69144      |\n",
      "|    value_loss           | 5.12e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 321\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 659           |\n",
      "|    time_elapsed         | 2606          |\n",
      "|    total_timesteps      | 674816        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8774836e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.03e+04      |\n",
      "|    n_updates            | 31810         |\n",
      "|    policy_gradient_loss | -0.000147     |\n",
      "|    reward               | -17.112621    |\n",
      "|    value_loss           | 6.07e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 660           |\n",
      "|    time_elapsed         | 2610          |\n",
      "|    total_timesteps      | 675840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8629845e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+05      |\n",
      "|    n_updates            | 31820         |\n",
      "|    policy_gradient_loss | -4.27e-05     |\n",
      "|    reward               | -43.56647     |\n",
      "|    value_loss           | 3.24e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 661           |\n",
      "|    time_elapsed         | 2614          |\n",
      "|    total_timesteps      | 676864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4754277e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.75e+04      |\n",
      "|    n_updates            | 31830         |\n",
      "|    policy_gradient_loss | -2.19e-05     |\n",
      "|    reward               | -91.34435     |\n",
      "|    value_loss           | 7.49e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 322\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 662           |\n",
      "|    time_elapsed         | 2619          |\n",
      "|    total_timesteps      | 677888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3297692e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.5e+05       |\n",
      "|    n_updates            | 31840         |\n",
      "|    policy_gradient_loss | -1.86e-05     |\n",
      "|    reward               | -12.930473    |\n",
      "|    value_loss           | 7.01e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 323\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 2623        |\n",
      "|    total_timesteps      | 678912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000176879 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+05    |\n",
      "|    n_updates            | 31850       |\n",
      "|    policy_gradient_loss | -0.000171   |\n",
      "|    reward               | 6.339584    |\n",
      "|    value_loss           | 2.33e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 2627        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000291429 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+05    |\n",
      "|    n_updates            | 31860       |\n",
      "|    policy_gradient_loss | -0.000518   |\n",
      "|    reward               | 78.63185    |\n",
      "|    value_loss           | 2.03e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 665          |\n",
      "|    time_elapsed         | 2631         |\n",
      "|    total_timesteps      | 680960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.742438e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.53e+05     |\n",
      "|    n_updates            | 31870        |\n",
      "|    policy_gradient_loss | -0.000132    |\n",
      "|    reward               | 1.6670157    |\n",
      "|    value_loss           | 1.71e+06     |\n",
      "------------------------------------------\n",
      "Episode: 324\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1343527.94\n",
      "total_reward: 343527.94\n",
      "total_cost: 1560671.58\n",
      "total_trades: 885\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 258            |\n",
      "|    iterations           | 666            |\n",
      "|    time_elapsed         | 2635           |\n",
      "|    total_timesteps      | 681984         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.29766995e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.04          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 5.48e+05       |\n",
      "|    n_updates            | 31880          |\n",
      "|    policy_gradient_loss | -0.000142      |\n",
      "|    reward               | 3.2443645      |\n",
      "|    value_loss           | 1.1e+06        |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 667          |\n",
      "|    time_elapsed         | 2639         |\n",
      "|    total_timesteps      | 683008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.042784e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12e+04     |\n",
      "|    n_updates            | 31890        |\n",
      "|    policy_gradient_loss | -0.000142    |\n",
      "|    reward               | -58.85713    |\n",
      "|    value_loss           | 2.25e+04     |\n",
      "------------------------------------------\n",
      "Episode: 325\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 668          |\n",
      "|    time_elapsed         | 2643         |\n",
      "|    total_timesteps      | 684032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.992191e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.81e+04     |\n",
      "|    n_updates            | 31900        |\n",
      "|    policy_gradient_loss | -0.000366    |\n",
      "|    reward               | 4.7874937    |\n",
      "|    value_loss           | 1.56e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 669           |\n",
      "|    time_elapsed         | 2647          |\n",
      "|    total_timesteps      | 685056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5471963e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.15e+05      |\n",
      "|    n_updates            | 31910         |\n",
      "|    policy_gradient_loss | -6.07e-05     |\n",
      "|    reward               | -5.6754932    |\n",
      "|    value_loss           | 4.31e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 670          |\n",
      "|    time_elapsed         | 2651         |\n",
      "|    total_timesteps      | 686080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.291336e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.14e+03     |\n",
      "|    n_updates            | 31920        |\n",
      "|    policy_gradient_loss | -9.28e-05    |\n",
      "|    reward               | -70.97677    |\n",
      "|    value_loss           | 1.43e+04     |\n",
      "------------------------------------------\n",
      "Episode: 326\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 671           |\n",
      "|    time_elapsed         | 2656          |\n",
      "|    total_timesteps      | 687104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.5411244e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.55e+05      |\n",
      "|    n_updates            | 31930         |\n",
      "|    policy_gradient_loss | 3.7e-05       |\n",
      "|    reward               | -37.21335     |\n",
      "|    value_loss           | 3.11e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 672           |\n",
      "|    time_elapsed         | 2659          |\n",
      "|    total_timesteps      | 688128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5245343e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.79e+05      |\n",
      "|    n_updates            | 31940         |\n",
      "|    policy_gradient_loss | -0.000105     |\n",
      "|    reward               | -67.71176     |\n",
      "|    value_loss           | 7.59e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 673           |\n",
      "|    time_elapsed         | 2663          |\n",
      "|    total_timesteps      | 689152        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8481008e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.52e+05      |\n",
      "|    n_updates            | 31950         |\n",
      "|    policy_gradient_loss | 1.61e-05      |\n",
      "|    reward               | -103.25084    |\n",
      "|    value_loss           | 3.05e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 327\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 674          |\n",
      "|    time_elapsed         | 2667         |\n",
      "|    total_timesteps      | 690176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.011113e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48e+05     |\n",
      "|    n_updates            | 31960        |\n",
      "|    policy_gradient_loss | -1.3e-05     |\n",
      "|    reward               | -22.24953    |\n",
      "|    value_loss           | 1.9e+06      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 675           |\n",
      "|    time_elapsed         | 2671          |\n",
      "|    total_timesteps      | 691200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1775311e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.6e+05       |\n",
      "|    n_updates            | 31970         |\n",
      "|    policy_gradient_loss | -0.000159     |\n",
      "|    reward               | -41.810658    |\n",
      "|    value_loss           | 3.2e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 328\n",
      "Current company: ['HON']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 993290.41\n",
      "total_reward: -6709.59\n",
      "total_cost: 1025910.27\n",
      "total_trades: 917\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 676          |\n",
      "|    time_elapsed         | 2676         |\n",
      "|    total_timesteps      | 692224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.398815e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.81e+04     |\n",
      "|    n_updates            | 31980        |\n",
      "|    policy_gradient_loss | -0.000185    |\n",
      "|    reward               | 1.550919     |\n",
      "|    value_loss           | 1.96e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 677           |\n",
      "|    time_elapsed         | 2679          |\n",
      "|    total_timesteps      | 693248        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5268102e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.87e+05      |\n",
      "|    n_updates            | 31990         |\n",
      "|    policy_gradient_loss | -6.67e-05     |\n",
      "|    reward               | 126.91175     |\n",
      "|    value_loss           | 7.73e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 678          |\n",
      "|    time_elapsed         | 2683         |\n",
      "|    total_timesteps      | 694272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.198382e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.33e+05     |\n",
      "|    n_updates            | 32000        |\n",
      "|    policy_gradient_loss | -0.000176    |\n",
      "|    reward               | 271.95343    |\n",
      "|    value_loss           | 1.27e+06     |\n",
      "------------------------------------------\n",
      "Episode: 329\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 679          |\n",
      "|    time_elapsed         | 2687         |\n",
      "|    total_timesteps      | 695296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.993744e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.08e+06     |\n",
      "|    n_updates            | 32010        |\n",
      "|    policy_gradient_loss | 5.43e-05     |\n",
      "|    reward               | -28.5409     |\n",
      "|    value_loss           | 1.62e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 2692        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 1.91445e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.68e+06    |\n",
      "|    n_updates            | 32020       |\n",
      "|    policy_gradient_loss | 3.75e-06    |\n",
      "|    reward               | -67.65281   |\n",
      "|    value_loss           | 7.37e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 681           |\n",
      "|    time_elapsed         | 2696          |\n",
      "|    total_timesteps      | 697344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1967571e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.76e+05      |\n",
      "|    n_updates            | 32030         |\n",
      "|    policy_gradient_loss | -3.31e-06     |\n",
      "|    reward               | -58.93914     |\n",
      "|    value_loss           | 3.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 330\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 682           |\n",
      "|    time_elapsed         | 2700          |\n",
      "|    total_timesteps      | 698368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7357753e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.77e+05      |\n",
      "|    n_updates            | 32040         |\n",
      "|    policy_gradient_loss | -7.18e-06     |\n",
      "|    reward               | -49.8603      |\n",
      "|    value_loss           | 3.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 331\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 683           |\n",
      "|    time_elapsed         | 2704          |\n",
      "|    total_timesteps      | 699392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1647425e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.46e+04      |\n",
      "|    n_updates            | 32050         |\n",
      "|    policy_gradient_loss | -0.000411     |\n",
      "|    reward               | 4.209778      |\n",
      "|    value_loss           | 1.09e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 684           |\n",
      "|    time_elapsed         | 2708          |\n",
      "|    total_timesteps      | 700416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5623612e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.48e+04      |\n",
      "|    n_updates            | 32060         |\n",
      "|    policy_gradient_loss | -3.47e-05     |\n",
      "|    reward               | -30.522089    |\n",
      "|    value_loss           | 1.7e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 332\n",
      "Current company: ['CVX']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1251954.74\n",
      "total_reward: 251954.74\n",
      "total_cost: 1146803.75\n",
      "total_trades: 947\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 685           |\n",
      "|    time_elapsed         | 2712          |\n",
      "|    total_timesteps      | 701440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0707644e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.48e+04      |\n",
      "|    n_updates            | 32070         |\n",
      "|    policy_gradient_loss | 5.4e-05       |\n",
      "|    reward               | -6.73351      |\n",
      "|    value_loss           | 1.5e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 333\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 686          |\n",
      "|    time_elapsed         | 2716         |\n",
      "|    total_timesteps      | 702464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.856754e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.13e+05     |\n",
      "|    n_updates            | 32080        |\n",
      "|    policy_gradient_loss | -5.65e-05    |\n",
      "|    reward               | -8.804771    |\n",
      "|    value_loss           | 4.27e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 687           |\n",
      "|    time_elapsed         | 2720          |\n",
      "|    total_timesteps      | 703488        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2993848e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.82e+04      |\n",
      "|    n_updates            | 32090         |\n",
      "|    policy_gradient_loss | -1.14e-05     |\n",
      "|    reward               | -48.298424    |\n",
      "|    value_loss           | 1.17e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 688           |\n",
      "|    time_elapsed         | 2724          |\n",
      "|    total_timesteps      | 704512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7314527e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.5e+04       |\n",
      "|    n_updates            | 32100         |\n",
      "|    policy_gradient_loss | 1.45e-06      |\n",
      "|    reward               | -56.151684    |\n",
      "|    value_loss           | 1.35e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 334\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 689           |\n",
      "|    time_elapsed         | 2728          |\n",
      "|    total_timesteps      | 705536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2511737e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.17e+05      |\n",
      "|    n_updates            | 32110         |\n",
      "|    policy_gradient_loss | -2.78e-05     |\n",
      "|    reward               | -30.410557    |\n",
      "|    value_loss           | 1.04e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 2732         |\n",
      "|    total_timesteps      | 706560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.817185e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.01e+05     |\n",
      "|    n_updates            | 32120        |\n",
      "|    policy_gradient_loss | -2.4e-05     |\n",
      "|    reward               | 15.328225    |\n",
      "|    value_loss           | 4.07e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 691           |\n",
      "|    time_elapsed         | 2736          |\n",
      "|    total_timesteps      | 707584        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9265066e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.38e+04      |\n",
      "|    n_updates            | 32130         |\n",
      "|    policy_gradient_loss | -2.62e-05     |\n",
      "|    reward               | 26.320004     |\n",
      "|    value_loss           | 1.28e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 335\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 2740         |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.088172e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.65e+05     |\n",
      "|    n_updates            | 32140        |\n",
      "|    policy_gradient_loss | -1.41e-05    |\n",
      "|    reward               | -8.780262    |\n",
      "|    value_loss           | 3.3e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 693           |\n",
      "|    time_elapsed         | 2744          |\n",
      "|    total_timesteps      | 709632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032523426 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+04      |\n",
      "|    n_updates            | 32150         |\n",
      "|    policy_gradient_loss | -0.000596     |\n",
      "|    reward               | -65.43218     |\n",
      "|    value_loss           | 4.47e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 336\n",
      "Current company: ['TRV']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1147326.63\n",
      "total_reward: 147326.63\n",
      "total_cost: 1014788.82\n",
      "total_trades: 969\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 694           |\n",
      "|    time_elapsed         | 2748          |\n",
      "|    total_timesteps      | 710656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031153735 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.94e+05      |\n",
      "|    n_updates            | 32160         |\n",
      "|    policy_gradient_loss | 0.000469      |\n",
      "|    reward               | 15.45579      |\n",
      "|    value_loss           | 3.89e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 695           |\n",
      "|    time_elapsed         | 2752          |\n",
      "|    total_timesteps      | 711680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4791126e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0.0465        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.57e+05      |\n",
      "|    n_updates            | 32170         |\n",
      "|    policy_gradient_loss | -0.00011      |\n",
      "|    reward               | 103.786964    |\n",
      "|    value_loss           | 1.11e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 696           |\n",
      "|    time_elapsed         | 2756          |\n",
      "|    total_timesteps      | 712704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0373845e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.833         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.45e+05      |\n",
      "|    n_updates            | 32180         |\n",
      "|    policy_gradient_loss | 6.16e-05      |\n",
      "|    reward               | 222.64758     |\n",
      "|    value_loss           | 1.7e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 337\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 697           |\n",
      "|    time_elapsed         | 2760          |\n",
      "|    total_timesteps      | 713728        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1769589e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.0737       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.74e+06      |\n",
      "|    n_updates            | 32190         |\n",
      "|    policy_gradient_loss | 5.81e-06      |\n",
      "|    reward               | -9.679061     |\n",
      "|    value_loss           | 5.52e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 338\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 698          |\n",
      "|    time_elapsed         | 2765         |\n",
      "|    total_timesteps      | 714752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.699702e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.34e+06     |\n",
      "|    n_updates            | 32200        |\n",
      "|    policy_gradient_loss | -5.95e-06    |\n",
      "|    reward               | -3.255793    |\n",
      "|    value_loss           | 2.69e+06     |\n",
      "------------------------------------------\n",
      "Episode: 339\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 699           |\n",
      "|    time_elapsed         | 2768          |\n",
      "|    total_timesteps      | 715776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1716038e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.43e+05      |\n",
      "|    n_updates            | 32210         |\n",
      "|    policy_gradient_loss | -1.34e-05     |\n",
      "|    reward               | 133.89496     |\n",
      "|    value_loss           | 2.87e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 700           |\n",
      "|    time_elapsed         | 2772          |\n",
      "|    total_timesteps      | 716800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.9994865e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.776         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.5e+05       |\n",
      "|    n_updates            | 32220         |\n",
      "|    policy_gradient_loss | -9.76e-06     |\n",
      "|    reward               | 102.849335    |\n",
      "|    value_loss           | 1.5e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 340\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1665995.07\n",
      "total_reward: 665995.07\n",
      "total_cost: 1694727.59\n",
      "total_trades: 823\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 701           |\n",
      "|    time_elapsed         | 2776          |\n",
      "|    total_timesteps      | 717824        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6115373e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -0.268        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.04e+05      |\n",
      "|    n_updates            | 32230         |\n",
      "|    policy_gradient_loss | -5.49e-05     |\n",
      "|    reward               | -23.64271     |\n",
      "|    value_loss           | 1.41e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 702           |\n",
      "|    time_elapsed         | 2780          |\n",
      "|    total_timesteps      | 718848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.2491897e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.44          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75e+06      |\n",
      "|    n_updates            | 32240         |\n",
      "|    policy_gradient_loss | -2.01e-05     |\n",
      "|    reward               | -67.99571     |\n",
      "|    value_loss           | 3.5e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 341\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 703           |\n",
      "|    time_elapsed         | 2784          |\n",
      "|    total_timesteps      | 719872        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1478551e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.51e+05      |\n",
      "|    n_updates            | 32250         |\n",
      "|    policy_gradient_loss | -4.03e-06     |\n",
      "|    reward               | -3.6382847    |\n",
      "|    value_loss           | 3.05e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 704           |\n",
      "|    time_elapsed         | 2788          |\n",
      "|    total_timesteps      | 720896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.8038116e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.06e+04      |\n",
      "|    n_updates            | 32260         |\n",
      "|    policy_gradient_loss | -0.000126     |\n",
      "|    reward               | -0.43287796   |\n",
      "|    value_loss           | 1.21e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 342\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 705           |\n",
      "|    time_elapsed         | 2793          |\n",
      "|    total_timesteps      | 721920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013420574 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.99e+04      |\n",
      "|    n_updates            | 32270         |\n",
      "|    policy_gradient_loss | 4.64e-05      |\n",
      "|    reward               | -5.4437656    |\n",
      "|    value_loss           | 5.99e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 343\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 706           |\n",
      "|    time_elapsed         | 2797          |\n",
      "|    total_timesteps      | 722944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2147316e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.88e+04      |\n",
      "|    n_updates            | 32280         |\n",
      "|    policy_gradient_loss | -8.34e-05     |\n",
      "|    reward               | 0.13271666    |\n",
      "|    value_loss           | 7.77e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 344\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 685038.02\n",
      "total_reward: -314961.98\n",
      "total_cost: 44722.68\n",
      "total_trades: 45\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 707           |\n",
      "|    time_elapsed         | 2801          |\n",
      "|    total_timesteps      | 723968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8851227e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.07e+05      |\n",
      "|    n_updates            | 32290         |\n",
      "|    policy_gradient_loss | -5.97e-05     |\n",
      "|    reward               | -10.284652    |\n",
      "|    value_loss           | 4.17e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 708           |\n",
      "|    time_elapsed         | 2805          |\n",
      "|    total_timesteps      | 724992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8046896e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.64e+04      |\n",
      "|    n_updates            | 32300         |\n",
      "|    policy_gradient_loss | -0.000167     |\n",
      "|    reward               | -60.43416     |\n",
      "|    value_loss           | 1.13e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 345\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 709          |\n",
      "|    time_elapsed         | 2809         |\n",
      "|    total_timesteps      | 726016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.475676e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.55e+05     |\n",
      "|    n_updates            | 32310        |\n",
      "|    policy_gradient_loss | 7.37e-05     |\n",
      "|    reward               | -36.367054   |\n",
      "|    value_loss           | 3.1e+05      |\n",
      "------------------------------------------\n",
      "Episode: 346\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 710           |\n",
      "|    time_elapsed         | 2813          |\n",
      "|    total_timesteps      | 727040        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4888432e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.78e+05      |\n",
      "|    n_updates            | 32320         |\n",
      "|    policy_gradient_loss | -4.78e-05     |\n",
      "|    reward               | -14.307545    |\n",
      "|    value_loss           | 7.56e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 711           |\n",
      "|    time_elapsed         | 2818          |\n",
      "|    total_timesteps      | 728064        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0600739e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.67e+03      |\n",
      "|    n_updates            | 32330         |\n",
      "|    policy_gradient_loss | -4.52e-05     |\n",
      "|    reward               | -65.5666      |\n",
      "|    value_loss           | 1.13e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 347\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 712           |\n",
      "|    time_elapsed         | 2823          |\n",
      "|    total_timesteps      | 729088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8773636e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.21e+05      |\n",
      "|    n_updates            | 32340         |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    reward               | -25.46345     |\n",
      "|    value_loss           | 6.43e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 713          |\n",
      "|    time_elapsed         | 2827         |\n",
      "|    total_timesteps      | 730112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.033472e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.7e+05      |\n",
      "|    n_updates            | 32350        |\n",
      "|    policy_gradient_loss | -4.81e-06    |\n",
      "|    reward               | -47.026703   |\n",
      "|    value_loss           | 9.4e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 714           |\n",
      "|    time_elapsed         | 2831          |\n",
      "|    total_timesteps      | 731136        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4268672e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.66e+04      |\n",
      "|    n_updates            | 32360         |\n",
      "|    policy_gradient_loss | -3.94e-05     |\n",
      "|    reward               | -47.4446      |\n",
      "|    value_loss           | 1.33e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 348\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 662143.83\n",
      "total_reward: -337856.17\n",
      "total_cost: 1148767.44\n",
      "total_trades: 973\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 258           |\n",
      "|    iterations           | 715           |\n",
      "|    time_elapsed         | 2836          |\n",
      "|    total_timesteps      | 732160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3910409e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.16e+04      |\n",
      "|    n_updates            | 32370         |\n",
      "|    policy_gradient_loss | -0.000114     |\n",
      "|    reward               | -48.73626     |\n",
      "|    value_loss           | 1.44e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 716          |\n",
      "|    time_elapsed         | 2841         |\n",
      "|    total_timesteps      | 733184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.890208e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.11e+04     |\n",
      "|    n_updates            | 32380        |\n",
      "|    policy_gradient_loss | 1.91e-05     |\n",
      "|    reward               | -89.42306    |\n",
      "|    value_loss           | 1.03e+05     |\n",
      "------------------------------------------\n",
      "Episode: 349\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 717          |\n",
      "|    time_elapsed         | 2846         |\n",
      "|    total_timesteps      | 734208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.665425e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.41e+05     |\n",
      "|    n_updates            | 32390        |\n",
      "|    policy_gradient_loss | 4.23e-05     |\n",
      "|    reward               | -22.738262   |\n",
      "|    value_loss           | 1.08e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 718           |\n",
      "|    time_elapsed         | 2851          |\n",
      "|    total_timesteps      | 735232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5429687e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.69e+05      |\n",
      "|    n_updates            | 32400         |\n",
      "|    policy_gradient_loss | -2.01e-05     |\n",
      "|    reward               | -66.75038     |\n",
      "|    value_loss           | 5.4e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 350\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 719           |\n",
      "|    time_elapsed         | 2855          |\n",
      "|    total_timesteps      | 736256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4580083e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+05      |\n",
      "|    n_updates            | 32410         |\n",
      "|    policy_gradient_loss | -4.87e-05     |\n",
      "|    reward               | 1.0771561     |\n",
      "|    value_loss           | 3.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 720           |\n",
      "|    time_elapsed         | 2860          |\n",
      "|    total_timesteps      | 737280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7290384e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.06e+05      |\n",
      "|    n_updates            | 32420         |\n",
      "|    policy_gradient_loss | -4.35e-05     |\n",
      "|    reward               | -51.9154      |\n",
      "|    value_loss           | 8.12e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 351\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 721           |\n",
      "|    time_elapsed         | 2864          |\n",
      "|    total_timesteps      | 738304        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5423459e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.52e+04      |\n",
      "|    n_updates            | 32430         |\n",
      "|    policy_gradient_loss | -8.35e-05     |\n",
      "|    reward               | -6.737269     |\n",
      "|    value_loss           | 1.3e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 2868         |\n",
      "|    total_timesteps      | 739328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.257898e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.29e+05     |\n",
      "|    n_updates            | 32440        |\n",
      "|    policy_gradient_loss | 3.97e-05     |\n",
      "|    reward               | 13.708557    |\n",
      "|    value_loss           | 2.58e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 723           |\n",
      "|    time_elapsed         | 2872          |\n",
      "|    total_timesteps      | 740352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0559452e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.58e+05      |\n",
      "|    n_updates            | 32450         |\n",
      "|    policy_gradient_loss | 1.21e-05      |\n",
      "|    reward               | -42.03256     |\n",
      "|    value_loss           | 5.17e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 352\n",
      "Current company: ['V']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1190213.52\n",
      "total_reward: 190213.52\n",
      "total_cost: 1567651.30\n",
      "total_trades: 1045\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 724           |\n",
      "|    time_elapsed         | 2876          |\n",
      "|    total_timesteps      | 741376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6223792e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 32460         |\n",
      "|    policy_gradient_loss | -3.98e-05     |\n",
      "|    reward               | -1.9963728    |\n",
      "|    value_loss           | 2.47e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 725           |\n",
      "|    time_elapsed         | 2880          |\n",
      "|    total_timesteps      | 742400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8073479e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.71e+04      |\n",
      "|    n_updates            | 32470         |\n",
      "|    policy_gradient_loss | -2.61e-06     |\n",
      "|    reward               | -40.47194     |\n",
      "|    value_loss           | 9.41e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 353\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 726          |\n",
      "|    time_elapsed         | 2884         |\n",
      "|    total_timesteps      | 743424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.732702e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.79e+04     |\n",
      "|    n_updates            | 32480        |\n",
      "|    policy_gradient_loss | -0.000197    |\n",
      "|    reward               | -19.375252   |\n",
      "|    value_loss           | 1.36e+05     |\n",
      "------------------------------------------\n",
      "Episode: 354\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 727          |\n",
      "|    time_elapsed         | 2889         |\n",
      "|    total_timesteps      | 744448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.550196e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.63e+05     |\n",
      "|    n_updates            | 32490        |\n",
      "|    policy_gradient_loss | -3.71e-05    |\n",
      "|    reward               | -31.856674   |\n",
      "|    value_loss           | 7.27e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 728          |\n",
      "|    time_elapsed         | 2893         |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004214832 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.62e+04     |\n",
      "|    n_updates            | 32500        |\n",
      "|    policy_gradient_loss | -0.000496    |\n",
      "|    reward               | -22.80815    |\n",
      "|    value_loss           | 5.25e+04     |\n",
      "------------------------------------------\n",
      "Episode: 355\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 729           |\n",
      "|    time_elapsed         | 2897          |\n",
      "|    total_timesteps      | 746496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031878147 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.96e+04      |\n",
      "|    n_updates            | 32510         |\n",
      "|    policy_gradient_loss | 0.000308      |\n",
      "|    reward               | 12.165447     |\n",
      "|    value_loss           | 9.94e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 730           |\n",
      "|    time_elapsed         | 2901          |\n",
      "|    total_timesteps      | 747520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033140258 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.16e+04      |\n",
      "|    n_updates            | 32520         |\n",
      "|    policy_gradient_loss | -0.000674     |\n",
      "|    reward               | 31.303082     |\n",
      "|    value_loss           | 4.32e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 731           |\n",
      "|    time_elapsed         | 2905          |\n",
      "|    total_timesteps      | 748544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026277476 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.22e+05      |\n",
      "|    n_updates            | 32530         |\n",
      "|    policy_gradient_loss | -0.000349     |\n",
      "|    reward               | 3.2344291     |\n",
      "|    value_loss           | 2.44e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 356\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1332050.87\n",
      "total_reward: 332050.87\n",
      "total_cost: 1573891.96\n",
      "total_trades: 1109\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 732          |\n",
      "|    time_elapsed         | 2909         |\n",
      "|    total_timesteps      | 749568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.155573e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.14e+05     |\n",
      "|    n_updates            | 32540        |\n",
      "|    policy_gradient_loss | 1.15e-05     |\n",
      "|    reward               | -34.488808   |\n",
      "|    value_loss           | 2.28e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 733          |\n",
      "|    time_elapsed         | 2913         |\n",
      "|    total_timesteps      | 750592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.155783e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.85e+04     |\n",
      "|    n_updates            | 32550        |\n",
      "|    policy_gradient_loss | -5.18e-05    |\n",
      "|    reward               | -74.28205    |\n",
      "|    value_loss           | 7.71e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 734           |\n",
      "|    time_elapsed         | 2918          |\n",
      "|    total_timesteps      | 751616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4057226e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.49e+05      |\n",
      "|    n_updates            | 32560         |\n",
      "|    policy_gradient_loss | 0.0002        |\n",
      "|    reward               | -95.80032     |\n",
      "|    value_loss           | 4.98e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 357\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 735           |\n",
      "|    time_elapsed         | 2922          |\n",
      "|    total_timesteps      | 752640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4432084e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.63e+05      |\n",
      "|    n_updates            | 32570         |\n",
      "|    policy_gradient_loss | 1.87e-05      |\n",
      "|    reward               | -43.82971     |\n",
      "|    value_loss           | 1.33e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 736           |\n",
      "|    time_elapsed         | 2926          |\n",
      "|    total_timesteps      | 753664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4896505e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.91e+05      |\n",
      "|    n_updates            | 32580         |\n",
      "|    policy_gradient_loss | -0.000161     |\n",
      "|    reward               | -68.669106    |\n",
      "|    value_loss           | 3.82e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 358\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 737           |\n",
      "|    time_elapsed         | 2930          |\n",
      "|    total_timesteps      | 754688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5900761e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.64e+05      |\n",
      "|    n_updates            | 32590         |\n",
      "|    policy_gradient_loss | -3.07e-05     |\n",
      "|    reward               | 51.666897     |\n",
      "|    value_loss           | 5.27e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 738          |\n",
      "|    time_elapsed         | 2934         |\n",
      "|    total_timesteps      | 755712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.115732e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.66e+05     |\n",
      "|    n_updates            | 32600        |\n",
      "|    policy_gradient_loss | -2.06e-05    |\n",
      "|    reward               | 100.88431    |\n",
      "|    value_loss           | 1.13e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 739           |\n",
      "|    time_elapsed         | 2938          |\n",
      "|    total_timesteps      | 756736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7252827e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -1.02         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.35e+06      |\n",
      "|    n_updates            | 32610         |\n",
      "|    policy_gradient_loss | 4.31e-06      |\n",
      "|    reward               | -28.53593     |\n",
      "|    value_loss           | 2.69e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 359\n",
      "Episode: 360\n",
      "Current company: ['DOW']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1216336.09\n",
      "total_reward: 216336.09\n",
      "total_cost: 108421.47\n",
      "total_trades: 95\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 2942         |\n",
      "|    total_timesteps      | 757760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.341135e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.09e+05     |\n",
      "|    n_updates            | 32620        |\n",
      "|    policy_gradient_loss | -9.17e-06    |\n",
      "|    reward               | 0.08097165   |\n",
      "|    value_loss           | 4.18e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 741           |\n",
      "|    time_elapsed         | 2946          |\n",
      "|    total_timesteps      | 758784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7993887e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.36e+05      |\n",
      "|    n_updates            | 32630         |\n",
      "|    policy_gradient_loss | -2.8e-05      |\n",
      "|    reward               | -22.59457     |\n",
      "|    value_loss           | 2.73e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 742           |\n",
      "|    time_elapsed         | 2950          |\n",
      "|    total_timesteps      | 759808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7296536e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.21e+03      |\n",
      "|    n_updates            | 32640         |\n",
      "|    policy_gradient_loss | -0.000126     |\n",
      "|    reward               | -68.74024     |\n",
      "|    value_loss           | 8.45e+03      |\n",
      "-------------------------------------------\n",
      "Episode: 361\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 743           |\n",
      "|    time_elapsed         | 2956          |\n",
      "|    total_timesteps      | 760832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.9291116e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.58e+05      |\n",
      "|    n_updates            | 32650         |\n",
      "|    policy_gradient_loss | -0.000187     |\n",
      "|    reward               | -17.737625    |\n",
      "|    value_loss           | 7.15e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 362\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 744           |\n",
      "|    time_elapsed         | 2960          |\n",
      "|    total_timesteps      | 761856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9799743e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.66e+05      |\n",
      "|    n_updates            | 32660         |\n",
      "|    policy_gradient_loss | -7.75e-05     |\n",
      "|    reward               | -26.261007    |\n",
      "|    value_loss           | 5.32e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 363\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 745          |\n",
      "|    time_elapsed         | 2964         |\n",
      "|    total_timesteps      | 762880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.096845e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.99e+04     |\n",
      "|    n_updates            | 32670        |\n",
      "|    policy_gradient_loss | -3.56e-05    |\n",
      "|    reward               | -11.192408   |\n",
      "|    value_loss           | 1.8e+05      |\n",
      "------------------------------------------\n",
      "Episode: 364\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697493.79\n",
      "total_reward: -302506.21\n",
      "total_cost: 316517.13\n",
      "total_trades: 349\n",
      "=================================\n",
      "Episode: 365\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 746           |\n",
      "|    time_elapsed         | 2969          |\n",
      "|    total_timesteps      | 763904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1662796e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.31e+05      |\n",
      "|    n_updates            | 32680         |\n",
      "|    policy_gradient_loss | -8.28e-05     |\n",
      "|    reward               | 98.793274     |\n",
      "|    value_loss           | 2.62e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 747           |\n",
      "|    time_elapsed         | 2972          |\n",
      "|    total_timesteps      | 764928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9516133e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0.00356       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+05      |\n",
      "|    n_updates            | 32690         |\n",
      "|    policy_gradient_loss | -0.000132     |\n",
      "|    reward               | -2.671568     |\n",
      "|    value_loss           | 3.24e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 748           |\n",
      "|    time_elapsed         | 2976          |\n",
      "|    total_timesteps      | 765952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3858837e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -1.96         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.1e+05       |\n",
      "|    n_updates            | 32700         |\n",
      "|    policy_gradient_loss | 0.000125      |\n",
      "|    reward               | 32.024216     |\n",
      "|    value_loss           | 8.22e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 366\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 749           |\n",
      "|    time_elapsed         | 2980          |\n",
      "|    total_timesteps      | 766976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4881836e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 0.132         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.95e+04      |\n",
      "|    n_updates            | 32710         |\n",
      "|    policy_gradient_loss | -0.000111     |\n",
      "|    reward               | -33.60187     |\n",
      "|    value_loss           | 9.99e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 750           |\n",
      "|    time_elapsed         | 2985          |\n",
      "|    total_timesteps      | 768000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9655738e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.807         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.31e+04      |\n",
      "|    n_updates            | 32720         |\n",
      "|    policy_gradient_loss | -0.00014      |\n",
      "|    reward               | -71.93714     |\n",
      "|    value_loss           | 1.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 367\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 751           |\n",
      "|    time_elapsed         | 2989          |\n",
      "|    total_timesteps      | 769024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3261174e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.4e+05       |\n",
      "|    n_updates            | 32730         |\n",
      "|    policy_gradient_loss | -5.36e-05     |\n",
      "|    reward               | -49.875946    |\n",
      "|    value_loss           | 4.8e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 368\n",
      "Current company: ['TRV']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699398.43\n",
      "total_reward: -300601.57\n",
      "total_cost: 512591.33\n",
      "total_trades: 608\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 752          |\n",
      "|    time_elapsed         | 2993         |\n",
      "|    total_timesteps      | 770048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.696885e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51e+05     |\n",
      "|    n_updates            | 32740        |\n",
      "|    policy_gradient_loss | -3.22e-05    |\n",
      "|    reward               | -23.899717   |\n",
      "|    value_loss           | 3.03e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 753           |\n",
      "|    time_elapsed         | 2997          |\n",
      "|    total_timesteps      | 771072        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7507423e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.61e+05      |\n",
      "|    n_updates            | 32750         |\n",
      "|    policy_gradient_loss | 1.51e-05      |\n",
      "|    reward               | -54.617634    |\n",
      "|    value_loss           | 5.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 754           |\n",
      "|    time_elapsed         | 3001          |\n",
      "|    total_timesteps      | 772096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7648715e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+05      |\n",
      "|    n_updates            | 32760         |\n",
      "|    policy_gradient_loss | 6.88e-06      |\n",
      "|    reward               | -96.62471     |\n",
      "|    value_loss           | 4.46e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 369\n",
      "Episode: 370\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 755           |\n",
      "|    time_elapsed         | 3006          |\n",
      "|    total_timesteps      | 773120        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7928036e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.73e+05      |\n",
      "|    n_updates            | 32770         |\n",
      "|    policy_gradient_loss | -8.48e-06     |\n",
      "|    reward               | -8.967908     |\n",
      "|    value_loss           | 1.15e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 756           |\n",
      "|    time_elapsed         | 3010          |\n",
      "|    total_timesteps      | 774144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3400138e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.73e+05      |\n",
      "|    n_updates            | 32780         |\n",
      "|    policy_gradient_loss | -4.05e-05     |\n",
      "|    reward               | -38.520554    |\n",
      "|    value_loss           | 5.47e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 371\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 757          |\n",
      "|    time_elapsed         | 3014         |\n",
      "|    total_timesteps      | 775168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004024097 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.32e+04     |\n",
      "|    n_updates            | 32790        |\n",
      "|    policy_gradient_loss | -0.000563    |\n",
      "|    reward               | -8.159991    |\n",
      "|    value_loss           | 2.63e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 758          |\n",
      "|    time_elapsed         | 3018         |\n",
      "|    total_timesteps      | 776192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003656717 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.12e+05     |\n",
      "|    n_updates            | 32800        |\n",
      "|    policy_gradient_loss | 0.00017      |\n",
      "|    reward               | -63.708225   |\n",
      "|    value_loss           | 4.25e+05     |\n",
      "------------------------------------------\n",
      "Episode: 372\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693167.43\n",
      "total_reward: -306832.57\n",
      "total_cost: 877401.75\n",
      "total_trades: 941\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 759          |\n",
      "|    time_elapsed         | 3023         |\n",
      "|    total_timesteps      | 777216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001288522 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.14e+05     |\n",
      "|    n_updates            | 32810        |\n",
      "|    policy_gradient_loss | -0.000609    |\n",
      "|    reward               | -17.088964   |\n",
      "|    value_loss           | 2.27e+05     |\n",
      "------------------------------------------\n",
      "Episode: 373\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 760          |\n",
      "|    time_elapsed         | 3027         |\n",
      "|    total_timesteps      | 778240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.293284e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.12e+05     |\n",
      "|    n_updates            | 32820        |\n",
      "|    policy_gradient_loss | -0.000542    |\n",
      "|    reward               | -4.4386377   |\n",
      "|    value_loss           | 8.24e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 761           |\n",
      "|    time_elapsed         | 3031          |\n",
      "|    total_timesteps      | 779264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2367377e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.03e+04      |\n",
      "|    n_updates            | 32830         |\n",
      "|    policy_gradient_loss | -7.88e-05     |\n",
      "|    reward               | -4.9358892    |\n",
      "|    value_loss           | 4.06e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 374\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 762           |\n",
      "|    time_elapsed         | 3035          |\n",
      "|    total_timesteps      | 780288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024049194 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.68e+03      |\n",
      "|    n_updates            | 32840         |\n",
      "|    policy_gradient_loss | -0.000187     |\n",
      "|    reward               | -1.7160048    |\n",
      "|    value_loss           | 1.34e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 375\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 763           |\n",
      "|    time_elapsed         | 3040          |\n",
      "|    total_timesteps      | 781312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012527173 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.24e+04      |\n",
      "|    n_updates            | 32850         |\n",
      "|    policy_gradient_loss | -0.000169     |\n",
      "|    reward               | -16.630981    |\n",
      "|    value_loss           | 1.05e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 376\n",
      "Current company: ['CAT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 690144.52\n",
      "total_reward: -309855.48\n",
      "total_cost: 746355.59\n",
      "total_trades: 731\n",
      "=================================\n",
      "Episode: 377\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 764          |\n",
      "|    time_elapsed         | 3044         |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001135373 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.25e+04     |\n",
      "|    n_updates            | 32860        |\n",
      "|    policy_gradient_loss | -7.66e-05    |\n",
      "|    reward               | -4.5864506   |\n",
      "|    value_loss           | 2.5e+04      |\n",
      "------------------------------------------\n",
      "Episode: 378\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 765           |\n",
      "|    time_elapsed         | 3048          |\n",
      "|    total_timesteps      | 783360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012343266 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.79e+05      |\n",
      "|    n_updates            | 32870         |\n",
      "|    policy_gradient_loss | -0.000343     |\n",
      "|    reward               | -10.741606    |\n",
      "|    value_loss           | 3.58e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 766           |\n",
      "|    time_elapsed         | 3052          |\n",
      "|    total_timesteps      | 784384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039517583 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -0.0092       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.49e+04      |\n",
      "|    n_updates            | 32880         |\n",
      "|    policy_gradient_loss | -0.000194     |\n",
      "|    reward               | -39.803013    |\n",
      "|    value_loss           | 5.01e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 767           |\n",
      "|    time_elapsed         | 3056          |\n",
      "|    total_timesteps      | 785408        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3755223e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.138        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+05      |\n",
      "|    n_updates            | 32890         |\n",
      "|    policy_gradient_loss | 7.89e-05      |\n",
      "|    reward               | -69.88448     |\n",
      "|    value_loss           | 2.11e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 379\n",
      "Episode: 380\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695596.45\n",
      "total_reward: -304403.55\n",
      "total_cost: 174700.29\n",
      "total_trades: 167\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 768           |\n",
      "|    time_elapsed         | 3060          |\n",
      "|    total_timesteps      | 786432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4145854e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.0618       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.34e+05      |\n",
      "|    n_updates            | 32900         |\n",
      "|    policy_gradient_loss | 4.61e-05      |\n",
      "|    reward               | 43.407047     |\n",
      "|    value_loss           | 9.52e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 769          |\n",
      "|    time_elapsed         | 3064         |\n",
      "|    total_timesteps      | 787456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.229551e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.85        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 32910        |\n",
      "|    policy_gradient_loss | -3.63e-05    |\n",
      "|    reward               | -20.366148   |\n",
      "|    value_loss           | 3.02e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 770          |\n",
      "|    time_elapsed         | 3068         |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.339672e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.62e+04     |\n",
      "|    n_updates            | 32920        |\n",
      "|    policy_gradient_loss | -7.67e-05    |\n",
      "|    reward               | 4.417732     |\n",
      "|    value_loss           | 7.86e+04     |\n",
      "------------------------------------------\n",
      "Episode: 381\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 771          |\n",
      "|    time_elapsed         | 3072         |\n",
      "|    total_timesteps      | 789504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.722032e-05 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.33e+04     |\n",
      "|    n_updates            | 32930        |\n",
      "|    policy_gradient_loss | 0.00112      |\n",
      "|    reward               | 0.8172962    |\n",
      "|    value_loss           | 1.27e+05     |\n",
      "------------------------------------------\n",
      "Episode: 382\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 3077        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014041815 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.34e+04    |\n",
      "|    n_updates            | 32940       |\n",
      "|    policy_gradient_loss | 0.00856     |\n",
      "|    reward               | -27.562725  |\n",
      "|    value_loss           | 8.7e+04     |\n",
      "-----------------------------------------\n",
      "Episode: 383\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 3081        |\n",
      "|    total_timesteps      | 791552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001278339 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.96       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.65e+04    |\n",
      "|    n_updates            | 32950       |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    reward               | -56.32713   |\n",
      "|    value_loss           | 1.73e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 384\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699022.48\n",
      "total_reward: -300977.52\n",
      "total_cost: 345213.27\n",
      "total_trades: 371\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 774          |\n",
      "|    time_elapsed         | 3085         |\n",
      "|    total_timesteps      | 792576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.866393e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.998       |\n",
      "|    explained_variance   | -1.64        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 32960        |\n",
      "|    policy_gradient_loss | 4.36e-05     |\n",
      "|    reward               | -30.74337    |\n",
      "|    value_loss           | 2.99e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 775           |\n",
      "|    time_elapsed         | 3089          |\n",
      "|    total_timesteps      | 793600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2466393e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.964        |\n",
      "|    explained_variance   | -1.06         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.25e+05      |\n",
      "|    n_updates            | 32970         |\n",
      "|    policy_gradient_loss | 9.06e-05      |\n",
      "|    reward               | -59.266064    |\n",
      "|    value_loss           | 2.59e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 385\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 776           |\n",
      "|    time_elapsed         | 3093          |\n",
      "|    total_timesteps      | 794624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8707942e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.56e+05      |\n",
      "|    n_updates            | 32980         |\n",
      "|    policy_gradient_loss | -1.37e-05     |\n",
      "|    reward               | -19.280767    |\n",
      "|    value_loss           | 3.11e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 386\n",
      "Episode: 387\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 777           |\n",
      "|    time_elapsed         | 3098          |\n",
      "|    total_timesteps      | 795648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.3236955e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.12e+05      |\n",
      "|    n_updates            | 32990         |\n",
      "|    policy_gradient_loss | 8.99e-06      |\n",
      "|    reward               | -26.666082    |\n",
      "|    value_loss           | 2.24e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 778          |\n",
      "|    time_elapsed         | 3102         |\n",
      "|    total_timesteps      | 796672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.388268e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.29e+04     |\n",
      "|    n_updates            | 33000        |\n",
      "|    policy_gradient_loss | -2.31e-06    |\n",
      "|    reward               | -82.88826    |\n",
      "|    value_loss           | 6.58e+04     |\n",
      "------------------------------------------\n",
      "Episode: 388\n",
      "Current company: ['TRV']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695063.72\n",
      "total_reward: -304936.28\n",
      "total_cost: 656726.40\n",
      "total_trades: 733\n",
      "=================================\n",
      "Episode: 389\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 779           |\n",
      "|    time_elapsed         | 3107          |\n",
      "|    total_timesteps      | 797696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7567072e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.58e+05      |\n",
      "|    n_updates            | 33010         |\n",
      "|    policy_gradient_loss | -9.36e-06     |\n",
      "|    reward               | -42.011715    |\n",
      "|    value_loss           | 5.17e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 390\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 780          |\n",
      "|    time_elapsed         | 3112         |\n",
      "|    total_timesteps      | 798720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.289249e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.79e+04     |\n",
      "|    n_updates            | 33020        |\n",
      "|    policy_gradient_loss | -4.8e-05     |\n",
      "|    reward               | -44.826992   |\n",
      "|    value_loss           | 1.56e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 781          |\n",
      "|    time_elapsed         | 3116         |\n",
      "|    total_timesteps      | 799744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.666508e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.58e+05     |\n",
      "|    n_updates            | 33030        |\n",
      "|    policy_gradient_loss | -2.33e-05    |\n",
      "|    reward               | -61.341843   |\n",
      "|    value_loss           | 3.16e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 782          |\n",
      "|    time_elapsed         | 3120         |\n",
      "|    total_timesteps      | 800768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.512296e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.93e+05     |\n",
      "|    n_updates            | 33040        |\n",
      "|    policy_gradient_loss | -5.26e-06    |\n",
      "|    reward               | -115.36369   |\n",
      "|    value_loss           | 5.86e+05     |\n",
      "------------------------------------------\n",
      "Episode: 391\n",
      "Episode: 392\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 688964.58\n",
      "total_reward: -311035.42\n",
      "total_cost: 329092.51\n",
      "total_trades: 349\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 783           |\n",
      "|    time_elapsed         | 3124          |\n",
      "|    total_timesteps      | 801792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8987339e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.78e+05      |\n",
      "|    n_updates            | 33050         |\n",
      "|    policy_gradient_loss | -3.03e-06     |\n",
      "|    reward               | -0.07202445   |\n",
      "|    value_loss           | 1.76e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 784          |\n",
      "|    time_elapsed         | 3129         |\n",
      "|    total_timesteps      | 802816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.685755e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.41e+05     |\n",
      "|    n_updates            | 33060        |\n",
      "|    policy_gradient_loss | -6.04e-06    |\n",
      "|    reward               | -56.528656   |\n",
      "|    value_loss           | 4.83e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 785           |\n",
      "|    time_elapsed         | 3133          |\n",
      "|    total_timesteps      | 803840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3519387e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.24e+05      |\n",
      "|    n_updates            | 33070         |\n",
      "|    policy_gradient_loss | -4.35e-05     |\n",
      "|    reward               | -76.657715    |\n",
      "|    value_loss           | 2.47e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 393\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 3138        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.43244e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.47e+05    |\n",
      "|    n_updates            | 33080       |\n",
      "|    policy_gradient_loss | -3.25e-05   |\n",
      "|    reward               | -4.573259   |\n",
      "|    value_loss           | 8.94e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 787           |\n",
      "|    time_elapsed         | 3142          |\n",
      "|    total_timesteps      | 805888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9732473e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.09e+05      |\n",
      "|    n_updates            | 33090         |\n",
      "|    policy_gradient_loss | -8.59e-06     |\n",
      "|    reward               | -39.302906    |\n",
      "|    value_loss           | 8.19e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 3146         |\n",
      "|    total_timesteps      | 806912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.974458e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.07e+04     |\n",
      "|    n_updates            | 33100        |\n",
      "|    policy_gradient_loss | -0.00017     |\n",
      "|    reward               | -109.62245   |\n",
      "|    value_loss           | 8.14e+04     |\n",
      "------------------------------------------\n",
      "Episode: 394\n",
      "Episode: 395\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 789          |\n",
      "|    time_elapsed         | 3151         |\n",
      "|    total_timesteps      | 807936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.407108e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.14e+05     |\n",
      "|    n_updates            | 33110        |\n",
      "|    policy_gradient_loss | 2.57e-05     |\n",
      "|    reward               | -16.656303   |\n",
      "|    value_loss           | 8.29e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 790          |\n",
      "|    time_elapsed         | 3155         |\n",
      "|    total_timesteps      | 808960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.201234e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.85e+05     |\n",
      "|    n_updates            | 33120        |\n",
      "|    policy_gradient_loss | -9.65e-05    |\n",
      "|    reward               | -76.702866   |\n",
      "|    value_loss           | 3.71e+05     |\n",
      "------------------------------------------\n",
      "Episode: 396\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697482.16\n",
      "total_reward: -302517.84\n",
      "total_cost: 633504.80\n",
      "total_trades: 645\n",
      "=================================\n",
      "Episode: 397\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 791           |\n",
      "|    time_elapsed         | 3159          |\n",
      "|    total_timesteps      | 809984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9112714e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.937        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.42e+05      |\n",
      "|    n_updates            | 33130         |\n",
      "|    policy_gradient_loss | -2.78e-05     |\n",
      "|    reward               | -24.897764    |\n",
      "|    value_loss           | 2.83e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 792           |\n",
      "|    time_elapsed         | 3164          |\n",
      "|    total_timesteps      | 811008        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3422763e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.937        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.77e+04      |\n",
      "|    n_updates            | 33140         |\n",
      "|    policy_gradient_loss | -4.09e-05     |\n",
      "|    reward               | -60.746082    |\n",
      "|    value_loss           | 1.15e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 398\n",
      "Episode: 399\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 793          |\n",
      "|    time_elapsed         | 3168         |\n",
      "|    total_timesteps      | 812032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.843991e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.77e+05     |\n",
      "|    n_updates            | 33150        |\n",
      "|    policy_gradient_loss | -3.2e-05     |\n",
      "|    reward               | -14.499127   |\n",
      "|    value_loss           | 3.55e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 3172        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.00062e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.6e+04     |\n",
      "|    n_updates            | 33160       |\n",
      "|    policy_gradient_loss | -2.9e-06    |\n",
      "|    reward               | -32.787155  |\n",
      "|    value_loss           | 1.52e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 795           |\n",
      "|    time_elapsed         | 3177          |\n",
      "|    total_timesteps      | 814080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4732511e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+04      |\n",
      "|    n_updates            | 33170         |\n",
      "|    policy_gradient_loss | -2.5e-05      |\n",
      "|    reward               | -73.08451     |\n",
      "|    value_loss           | 3.22e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 400\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1108357.62\n",
      "total_reward: 108357.62\n",
      "total_cost: 1263057.98\n",
      "total_trades: 1199\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 796          |\n",
      "|    time_elapsed         | 3181         |\n",
      "|    total_timesteps      | 815104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.712892e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.939       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.88e+05     |\n",
      "|    n_updates            | 33180        |\n",
      "|    policy_gradient_loss | -2.99e-05    |\n",
      "|    reward               | -36.83433    |\n",
      "|    value_loss           | 3.76e+05     |\n",
      "------------------------------------------\n",
      "Episode: 401\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 797           |\n",
      "|    time_elapsed         | 3185          |\n",
      "|    total_timesteps      | 816128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.7334774e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.4e+05       |\n",
      "|    n_updates            | 33190         |\n",
      "|    policy_gradient_loss | -7.41e-06     |\n",
      "|    reward               | -9.508759     |\n",
      "|    value_loss           | 8.81e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 3189        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0         |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.87e+05    |\n",
      "|    n_updates            | 33200       |\n",
      "|    policy_gradient_loss | 3.52e-06    |\n",
      "|    reward               | -0.29748398 |\n",
      "|    value_loss           | 5.74e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 799           |\n",
      "|    time_elapsed         | 3193          |\n",
      "|    total_timesteps      | 818176        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3127842e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.57e+04      |\n",
      "|    n_updates            | 33210         |\n",
      "|    policy_gradient_loss | -0.000244     |\n",
      "|    reward               | -37.05502     |\n",
      "|    value_loss           | 5.14e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 402\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 800           |\n",
      "|    time_elapsed         | 3198          |\n",
      "|    total_timesteps      | 819200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1278603e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.941        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.87e+04      |\n",
      "|    n_updates            | 33220         |\n",
      "|    policy_gradient_loss | -0.000143     |\n",
      "|    reward               | -35.905235    |\n",
      "|    value_loss           | 1.97e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 403\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 801           |\n",
      "|    time_elapsed         | 3202          |\n",
      "|    total_timesteps      | 820224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7103815e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.941        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.26e+05      |\n",
      "|    n_updates            | 33230         |\n",
      "|    policy_gradient_loss | 0.000118      |\n",
      "|    reward               | 72.63978      |\n",
      "|    value_loss           | 4.53e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 802          |\n",
      "|    time_elapsed         | 3206         |\n",
      "|    total_timesteps      | 821248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.557055e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.69e+05     |\n",
      "|    n_updates            | 33240        |\n",
      "|    policy_gradient_loss | -7.41e-06    |\n",
      "|    reward               | 77.08376     |\n",
      "|    value_loss           | 7.38e+05     |\n",
      "------------------------------------------\n",
      "Episode: 404\n",
      "Current company: ['HON']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1574890.41\n",
      "total_reward: 574890.41\n",
      "total_cost: 2200797.34\n",
      "total_trades: 1236\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 803           |\n",
      "|    time_elapsed         | 3211          |\n",
      "|    total_timesteps      | 822272        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9371814e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.941        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.76e+05      |\n",
      "|    n_updates            | 33250         |\n",
      "|    policy_gradient_loss | 2.44e-06      |\n",
      "|    reward               | -22.863485    |\n",
      "|    value_loss           | 1.55e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 405\n",
      "Episode: 406\n",
      "Episode: 407\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 804          |\n",
      "|    time_elapsed         | 3215         |\n",
      "|    total_timesteps      | 823296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.433118e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.34e+05     |\n",
      "|    n_updates            | 33260        |\n",
      "|    policy_gradient_loss | 4.6e-07      |\n",
      "|    reward               | -26.857841   |\n",
      "|    value_loss           | 1.07e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 805           |\n",
      "|    time_elapsed         | 3220          |\n",
      "|    total_timesteps      | 824320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6720733e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.941        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.16e+04      |\n",
      "|    n_updates            | 33270         |\n",
      "|    policy_gradient_loss | -2.29e-05     |\n",
      "|    reward               | -76.953735    |\n",
      "|    value_loss           | 1.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 408\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699514.71\n",
      "total_reward: -300485.29\n",
      "total_cost: 522425.88\n",
      "total_trades: 609\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 806          |\n",
      "|    time_elapsed         | 3225         |\n",
      "|    total_timesteps      | 825344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.338837e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.942       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.11e+05     |\n",
      "|    n_updates            | 33280        |\n",
      "|    policy_gradient_loss | 2.32e-05     |\n",
      "|    reward               | -19.950754   |\n",
      "|    value_loss           | 4.22e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 807          |\n",
      "|    time_elapsed         | 3229         |\n",
      "|    total_timesteps      | 826368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003168317 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.942       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81e+04     |\n",
      "|    n_updates            | 33290        |\n",
      "|    policy_gradient_loss | -0.000273    |\n",
      "|    reward               | -1.3060117   |\n",
      "|    value_loss           | 3.63e+04     |\n",
      "------------------------------------------\n",
      "Episode: 409\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 808          |\n",
      "|    time_elapsed         | 3233         |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002561796 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.944       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.2e+04      |\n",
      "|    n_updates            | 33300        |\n",
      "|    policy_gradient_loss | 0.000773     |\n",
      "|    reward               | -28.032999   |\n",
      "|    value_loss           | 4.4e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 809          |\n",
      "|    time_elapsed         | 3237         |\n",
      "|    total_timesteps      | 828416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.864883e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.945       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.07e+04     |\n",
      "|    n_updates            | 33310        |\n",
      "|    policy_gradient_loss | -0.00021     |\n",
      "|    reward               | -65.23998    |\n",
      "|    value_loss           | 8.15e+04     |\n",
      "------------------------------------------\n",
      "Episode: 410\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 810          |\n",
      "|    time_elapsed         | 3242         |\n",
      "|    total_timesteps      | 829440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.971613e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.948       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.35e+05     |\n",
      "|    n_updates            | 33320        |\n",
      "|    policy_gradient_loss | -0.000195    |\n",
      "|    reward               | -48.890434   |\n",
      "|    value_loss           | 4.7e+05      |\n",
      "------------------------------------------\n",
      "Episode: 411\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 811          |\n",
      "|    time_elapsed         | 3246         |\n",
      "|    total_timesteps      | 830464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.400747e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42e+05     |\n",
      "|    n_updates            | 33330        |\n",
      "|    policy_gradient_loss | 6.37e-05     |\n",
      "|    reward               | -8.520145    |\n",
      "|    value_loss           | 2.84e+05     |\n",
      "------------------------------------------\n",
      "Episode: 412\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699438.25\n",
      "total_reward: -300561.75\n",
      "total_cost: 371019.43\n",
      "total_trades: 436\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 812          |\n",
      "|    time_elapsed         | 3250         |\n",
      "|    total_timesteps      | 831488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.985471e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.23e+05     |\n",
      "|    n_updates            | 33340        |\n",
      "|    policy_gradient_loss | -3.46e-06    |\n",
      "|    reward               | 29.12902     |\n",
      "|    value_loss           | 8.46e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 813           |\n",
      "|    time_elapsed         | 3255          |\n",
      "|    total_timesteps      | 832512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7066562e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.979        |\n",
      "|    explained_variance   | 0.64          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+05      |\n",
      "|    n_updates            | 33350         |\n",
      "|    policy_gradient_loss | -2.86e-05     |\n",
      "|    reward               | -32.752678    |\n",
      "|    value_loss           | 3e+05         |\n",
      "-------------------------------------------\n",
      "Episode: 413\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 814           |\n",
      "|    time_elapsed         | 3259          |\n",
      "|    total_timesteps      | 833536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0099105e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.983        |\n",
      "|    explained_variance   | 0.437         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.56e+05      |\n",
      "|    n_updates            | 33360         |\n",
      "|    policy_gradient_loss | 3.8e-06       |\n",
      "|    reward               | -4.448804     |\n",
      "|    value_loss           | 7.14e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 815           |\n",
      "|    time_elapsed         | 3263          |\n",
      "|    total_timesteps      | 834560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4563557e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.22e+05      |\n",
      "|    n_updates            | 33370         |\n",
      "|    policy_gradient_loss | -4.68e-05     |\n",
      "|    reward               | -45.246033    |\n",
      "|    value_loss           | 2.44e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 816           |\n",
      "|    time_elapsed         | 3267          |\n",
      "|    total_timesteps      | 835584        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5635916e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.6e+04       |\n",
      "|    n_updates            | 33380         |\n",
      "|    policy_gradient_loss | 5.46e-06      |\n",
      "|    reward               | -50.060776    |\n",
      "|    value_loss           | 9.19e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 414\n",
      "Episode: 415\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 3272        |\n",
      "|    total_timesteps      | 836608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.68806e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.81e+04    |\n",
      "|    n_updates            | 33390       |\n",
      "|    policy_gradient_loss | 1.64e-05    |\n",
      "|    reward               | -38.08562   |\n",
      "|    value_loss           | 1.96e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 416\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695178.50\n",
      "total_reward: -304821.50\n",
      "total_cost: 473839.21\n",
      "total_trades: 549\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 818           |\n",
      "|    time_elapsed         | 3276          |\n",
      "|    total_timesteps      | 837632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3768315e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.5e+04       |\n",
      "|    n_updates            | 33400         |\n",
      "|    policy_gradient_loss | -9.47e-05     |\n",
      "|    reward               | 14.173274     |\n",
      "|    value_loss           | 9.02e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 819           |\n",
      "|    time_elapsed         | 3280          |\n",
      "|    total_timesteps      | 838656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3523386e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.05e+05      |\n",
      "|    n_updates            | 33410         |\n",
      "|    policy_gradient_loss | -1.93e-05     |\n",
      "|    reward               | -3.6818352    |\n",
      "|    value_loss           | 2.12e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 820           |\n",
      "|    time_elapsed         | 3285          |\n",
      "|    total_timesteps      | 839680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0334417e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.36e+04      |\n",
      "|    n_updates            | 33420         |\n",
      "|    policy_gradient_loss | -1.78e-05     |\n",
      "|    reward               | -74.99994     |\n",
      "|    value_loss           | 2.73e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 417\n",
      "Episode: 418\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 821          |\n",
      "|    time_elapsed         | 3290         |\n",
      "|    total_timesteps      | 840704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008956145 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.65e+04     |\n",
      "|    n_updates            | 33430        |\n",
      "|    policy_gradient_loss | -0.000514    |\n",
      "|    reward               | -21.081892   |\n",
      "|    value_loss           | 1.73e+05     |\n",
      "------------------------------------------\n",
      "Episode: 419\n",
      "Episode: 420\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694657.83\n",
      "total_reward: -305342.17\n",
      "total_cost: 110849.49\n",
      "total_trades: 119\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 255          |\n",
      "|    iterations           | 822          |\n",
      "|    time_elapsed         | 3295         |\n",
      "|    total_timesteps      | 841728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021713744 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.46e+04     |\n",
      "|    n_updates            | 33440        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | 5.015005     |\n",
      "|    value_loss           | 6.92e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 823           |\n",
      "|    time_elapsed         | 3300          |\n",
      "|    total_timesteps      | 842752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026245724 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.73e+05      |\n",
      "|    n_updates            | 33450         |\n",
      "|    policy_gradient_loss | 0.000342      |\n",
      "|    reward               | -30.57728     |\n",
      "|    value_loss           | 3.47e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 824           |\n",
      "|    time_elapsed         | 3305          |\n",
      "|    total_timesteps      | 843776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0031737e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.908        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75e+04      |\n",
      "|    n_updates            | 33460         |\n",
      "|    policy_gradient_loss | 0.000186      |\n",
      "|    reward               | -70.36756     |\n",
      "|    value_loss           | 3.51e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 421\n",
      "Episode: 422\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 825           |\n",
      "|    time_elapsed         | 3309          |\n",
      "|    total_timesteps      | 844800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7543941e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.907        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.6e+05       |\n",
      "|    n_updates            | 33470         |\n",
      "|    policy_gradient_loss | 1.96e-05      |\n",
      "|    reward               | 4.3308086     |\n",
      "|    value_loss           | 7.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 826           |\n",
      "|    time_elapsed         | 3314          |\n",
      "|    total_timesteps      | 845824        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0227543e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.923        |\n",
      "|    explained_variance   | 0.168         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.08e+05      |\n",
      "|    n_updates            | 33480         |\n",
      "|    policy_gradient_loss | -1.5e-05      |\n",
      "|    reward               | -19.355692    |\n",
      "|    value_loss           | 1.02e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 827           |\n",
      "|    time_elapsed         | 3318          |\n",
      "|    total_timesteps      | 846848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1333336e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.58e+04      |\n",
      "|    n_updates            | 33490         |\n",
      "|    policy_gradient_loss | -2.95e-05     |\n",
      "|    reward               | -53.580986    |\n",
      "|    value_loss           | 1.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 423\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 828           |\n",
      "|    time_elapsed         | 3323          |\n",
      "|    total_timesteps      | 847872        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9904692e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.908        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+05      |\n",
      "|    n_updates            | 33500         |\n",
      "|    policy_gradient_loss | -1.94e-05     |\n",
      "|    reward               | 1.1043159     |\n",
      "|    value_loss           | 2.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 424\n",
      "Current company: ['JPM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698600.83\n",
      "total_reward: -301399.17\n",
      "total_cost: 248628.04\n",
      "total_trades: 257\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 829           |\n",
      "|    time_elapsed         | 3327          |\n",
      "|    total_timesteps      | 848896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4086482e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.907        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.47e+05      |\n",
      "|    n_updates            | 33510         |\n",
      "|    policy_gradient_loss | -1.87e-06     |\n",
      "|    reward               | 17.241962     |\n",
      "|    value_loss           | 4.94e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 3332        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002241759 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.903      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.47e+04    |\n",
      "|    n_updates            | 33520       |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | 2.5563173   |\n",
      "|    value_loss           | 6.93e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 425\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 3336        |\n",
      "|    total_timesteps      | 850944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002241146 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97e+04    |\n",
      "|    n_updates            | 33530       |\n",
      "|    policy_gradient_loss | 4.29e-05    |\n",
      "|    reward               | -2.4555051  |\n",
      "|    value_loss           | 1.79e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 832           |\n",
      "|    time_elapsed         | 3341          |\n",
      "|    total_timesteps      | 851968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019370811 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.876        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.46e+04      |\n",
      "|    n_updates            | 33540         |\n",
      "|    policy_gradient_loss | 0.000142      |\n",
      "|    reward               | -56.553837    |\n",
      "|    value_loss           | 4.92e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 833           |\n",
      "|    time_elapsed         | 3345          |\n",
      "|    total_timesteps      | 852992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5507161e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.872        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.12e+05      |\n",
      "|    n_updates            | 33550         |\n",
      "|    policy_gradient_loss | -1.88e-05     |\n",
      "|    reward               | -74.89534     |\n",
      "|    value_loss           | 2.23e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 426\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 834          |\n",
      "|    time_elapsed         | 3350         |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.897752e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.87        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.25e+05     |\n",
      "|    n_updates            | 33560        |\n",
      "|    policy_gradient_loss | -4.04e-05    |\n",
      "|    reward               | -1.4404653   |\n",
      "|    value_loss           | 1.05e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 835           |\n",
      "|    time_elapsed         | 3354          |\n",
      "|    total_timesteps      | 855040        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2549572e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.87         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.54e+05      |\n",
      "|    n_updates            | 33570         |\n",
      "|    policy_gradient_loss | 9.79e-06      |\n",
      "|    reward               | -33.819893    |\n",
      "|    value_loss           | 9.09e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 836          |\n",
      "|    time_elapsed         | 3357         |\n",
      "|    total_timesteps      | 856064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.322311e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.87        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.45e+04     |\n",
      "|    n_updates            | 33580        |\n",
      "|    policy_gradient_loss | -2.26e-05    |\n",
      "|    reward               | 16.466114    |\n",
      "|    value_loss           | 2.9e+04      |\n",
      "------------------------------------------\n",
      "Episode: 427\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 837          |\n",
      "|    time_elapsed         | 3361         |\n",
      "|    total_timesteps      | 857088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.396293e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.87        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35e+05     |\n",
      "|    n_updates            | 33590        |\n",
      "|    policy_gradient_loss | 1.88e-05     |\n",
      "|    reward               | -36.287468   |\n",
      "|    value_loss           | 2.69e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 838           |\n",
      "|    time_elapsed         | 3365          |\n",
      "|    total_timesteps      | 858112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7148787e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.869        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.16e+05      |\n",
      "|    n_updates            | 33600         |\n",
      "|    policy_gradient_loss | -4.56e-05     |\n",
      "|    reward               | -47.478596    |\n",
      "|    value_loss           | 2.32e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 428\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2192260.64\n",
      "total_reward: 1192260.64\n",
      "total_cost: 1293635.36\n",
      "total_trades: 967\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 839        |\n",
      "|    time_elapsed         | 3370       |\n",
      "|    total_timesteps      | 859136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 6.5848e-06 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.868     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.58e+05   |\n",
      "|    n_updates            | 33610      |\n",
      "|    policy_gradient_loss | -7.31e-06  |\n",
      "|    reward               | 11.689711  |\n",
      "|    value_loss           | 3.15e+05   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 840           |\n",
      "|    time_elapsed         | 3374          |\n",
      "|    total_timesteps      | 860160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0233516e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.875        |\n",
      "|    explained_variance   | 0.096         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.02e+05      |\n",
      "|    n_updates            | 33620         |\n",
      "|    policy_gradient_loss | -2.41e-05     |\n",
      "|    reward               | 45.660957     |\n",
      "|    value_loss           | 4.05e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 841          |\n",
      "|    time_elapsed         | 3378         |\n",
      "|    total_timesteps      | 861184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.654882e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.965       |\n",
      "|    explained_variance   | -1.69        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.4e+05      |\n",
      "|    n_updates            | 33630        |\n",
      "|    policy_gradient_loss | -2.12e-05    |\n",
      "|    reward               | 59.753487    |\n",
      "|    value_loss           | 8.84e+05     |\n",
      "------------------------------------------\n",
      "Episode: 429\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 842           |\n",
      "|    time_elapsed         | 3382          |\n",
      "|    total_timesteps      | 862208        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7788413e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.868        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.79e+05      |\n",
      "|    n_updates            | 33640         |\n",
      "|    policy_gradient_loss | -2.2e-05      |\n",
      "|    reward               | -13.401614    |\n",
      "|    value_loss           | 1.16e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 843          |\n",
      "|    time_elapsed         | 3386         |\n",
      "|    total_timesteps      | 863232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.284122e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.49e+05     |\n",
      "|    n_updates            | 33650        |\n",
      "|    policy_gradient_loss | 2.08e-06     |\n",
      "|    reward               | -68.52565    |\n",
      "|    value_loss           | 1.3e+06      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 844           |\n",
      "|    time_elapsed         | 3390          |\n",
      "|    total_timesteps      | 864256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2399396e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.868        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.03e+05      |\n",
      "|    n_updates            | 33660         |\n",
      "|    policy_gradient_loss | -2.74e-05     |\n",
      "|    reward               | -96.655464    |\n",
      "|    value_loss           | 2.06e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 430\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 845          |\n",
      "|    time_elapsed         | 3394         |\n",
      "|    total_timesteps      | 865280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.081964e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.76e+05     |\n",
      "|    n_updates            | 33670        |\n",
      "|    policy_gradient_loss | 6.8e-06      |\n",
      "|    reward               | -34.02058    |\n",
      "|    value_loss           | 1.55e+06     |\n",
      "------------------------------------------\n",
      "Episode: 431\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 846           |\n",
      "|    time_elapsed         | 3398          |\n",
      "|    total_timesteps      | 866304        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4214387e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.867        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.66e+05      |\n",
      "|    n_updates            | 33680         |\n",
      "|    policy_gradient_loss | -1.44e-06     |\n",
      "|    reward               | -12.505871    |\n",
      "|    value_loss           | 5.33e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 847          |\n",
      "|    time_elapsed         | 3403         |\n",
      "|    total_timesteps      | 867328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.448237e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42e+05     |\n",
      "|    n_updates            | 33690        |\n",
      "|    policy_gradient_loss | -2.41e-07    |\n",
      "|    reward               | -52.02338    |\n",
      "|    value_loss           | 2.85e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 848           |\n",
      "|    time_elapsed         | 3407          |\n",
      "|    total_timesteps      | 868352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0704693e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.867        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.37e+05      |\n",
      "|    n_updates            | 33700         |\n",
      "|    policy_gradient_loss | -1.28e-05     |\n",
      "|    reward               | -80.45219     |\n",
      "|    value_loss           | 4.75e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 432\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1271219.93\n",
      "total_reward: 271219.93\n",
      "total_cost: 1003277.44\n",
      "total_trades: 1032\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 849           |\n",
      "|    time_elapsed         | 3411          |\n",
      "|    total_timesteps      | 869376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7517013e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.867        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.17e+05      |\n",
      "|    n_updates            | 33710         |\n",
      "|    policy_gradient_loss | -0.0001       |\n",
      "|    reward               | -29.826895    |\n",
      "|    value_loss           | 1.63e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 433\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 850           |\n",
      "|    time_elapsed         | 3415          |\n",
      "|    total_timesteps      | 870400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6750065e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.866        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.3e+05       |\n",
      "|    n_updates            | 33720         |\n",
      "|    policy_gradient_loss | -0.000114     |\n",
      "|    reward               | -27.441519    |\n",
      "|    value_loss           | 2.61e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 851           |\n",
      "|    time_elapsed         | 3419          |\n",
      "|    total_timesteps      | 871424        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0585878e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.868        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.64e+05      |\n",
      "|    n_updates            | 33730         |\n",
      "|    policy_gradient_loss | -2.81e-05     |\n",
      "|    reward               | 27.02998      |\n",
      "|    value_loss           | 3.28e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 3423         |\n",
      "|    total_timesteps      | 872448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.752577e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.869       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03e+04     |\n",
      "|    n_updates            | 33740        |\n",
      "|    policy_gradient_loss | -3.96e-05    |\n",
      "|    reward               | 15.882932    |\n",
      "|    value_loss           | 8.06e+04     |\n",
      "------------------------------------------\n",
      "Episode: 434\n",
      "Episode: 435\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 853          |\n",
      "|    time_elapsed         | 3428         |\n",
      "|    total_timesteps      | 873472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.412729e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.869       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.63e+05     |\n",
      "|    n_updates            | 33750        |\n",
      "|    policy_gradient_loss | -0.000204    |\n",
      "|    reward               | -6.4343004   |\n",
      "|    value_loss           | 3.26e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 854           |\n",
      "|    time_elapsed         | 3432          |\n",
      "|    total_timesteps      | 874496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2581895e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.87         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.34e+04      |\n",
      "|    n_updates            | 33760         |\n",
      "|    policy_gradient_loss | -5.17e-05     |\n",
      "|    reward               | -3.524314     |\n",
      "|    value_loss           | 6.68e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 855           |\n",
      "|    time_elapsed         | 3436          |\n",
      "|    total_timesteps      | 875520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6900205e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.875        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.62e+03      |\n",
      "|    n_updates            | 33770         |\n",
      "|    policy_gradient_loss | -0.000153     |\n",
      "|    reward               | -35.485836    |\n",
      "|    value_loss           | 1.93e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 436\n",
      "Current company: ['TRV']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1320066.51\n",
      "total_reward: 320066.51\n",
      "total_cost: 1461460.05\n",
      "total_trades: 1086\n",
      "=================================\n",
      "Episode: 437\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 856           |\n",
      "|    time_elapsed         | 3440          |\n",
      "|    total_timesteps      | 876544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1394615e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.12e+04      |\n",
      "|    n_updates            | 33780         |\n",
      "|    policy_gradient_loss | 4.29e-05      |\n",
      "|    reward               | 0.25362852    |\n",
      "|    value_loss           | 6.24e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 857           |\n",
      "|    time_elapsed         | 3445          |\n",
      "|    total_timesteps      | 877568        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2548484e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.25e+05      |\n",
      "|    n_updates            | 33790         |\n",
      "|    policy_gradient_loss | 1.2e-05       |\n",
      "|    reward               | -71.77831     |\n",
      "|    value_loss           | 2.5e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 438\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 858           |\n",
      "|    time_elapsed         | 3449          |\n",
      "|    total_timesteps      | 878592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7497527e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.14e+05      |\n",
      "|    n_updates            | 33800         |\n",
      "|    policy_gradient_loss | -9.52e-05     |\n",
      "|    reward               | -15.301495    |\n",
      "|    value_loss           | 2.29e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 859          |\n",
      "|    time_elapsed         | 3453         |\n",
      "|    total_timesteps      | 879616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.777715e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.881       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.72e+05     |\n",
      "|    n_updates            | 33810        |\n",
      "|    policy_gradient_loss | -9.62e-05    |\n",
      "|    reward               | 22.96257     |\n",
      "|    value_loss           | 1.34e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 860          |\n",
      "|    time_elapsed         | 3457         |\n",
      "|    total_timesteps      | 880640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.401686e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.85e+04     |\n",
      "|    n_updates            | 33820        |\n",
      "|    policy_gradient_loss | 8.09e-06     |\n",
      "|    reward               | -38.349655   |\n",
      "|    value_loss           | 7.71e+04     |\n",
      "------------------------------------------\n",
      "Episode: 439\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 861           |\n",
      "|    time_elapsed         | 3461          |\n",
      "|    total_timesteps      | 881664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9668597e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.69e+04      |\n",
      "|    n_updates            | 33830         |\n",
      "|    policy_gradient_loss | -6.5e-06      |\n",
      "|    reward               | 141.49869     |\n",
      "|    value_loss           | 1.54e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 862          |\n",
      "|    time_elapsed         | 3465         |\n",
      "|    total_timesteps      | 882688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.920286e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.899       |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.24e+05     |\n",
      "|    n_updates            | 33840        |\n",
      "|    policy_gradient_loss | 1.5e-05      |\n",
      "|    reward               | 257.2314     |\n",
      "|    value_loss           | 1.85e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 863           |\n",
      "|    time_elapsed         | 3469          |\n",
      "|    total_timesteps      | 883712        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6647391e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.285        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6e+06         |\n",
      "|    n_updates            | 33850         |\n",
      "|    policy_gradient_loss | -2.31e-06     |\n",
      "|    reward               | 267.343       |\n",
      "|    value_loss           | 1.21e+07      |\n",
      "-------------------------------------------\n",
      "Episode: 440\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3954929.30\n",
      "total_reward: 2954929.30\n",
      "total_cost: 2649997.58\n",
      "total_trades: 844\n",
      "=================================\n",
      "Episode: 441\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 864           |\n",
      "|    time_elapsed         | 3474          |\n",
      "|    total_timesteps      | 884736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7462298e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.183        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01e+07      |\n",
      "|    n_updates            | 33860         |\n",
      "|    policy_gradient_loss | 9.61e-07      |\n",
      "|    reward               | -33.39598     |\n",
      "|    value_loss           | 2.03e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 865          |\n",
      "|    time_elapsed         | 3478         |\n",
      "|    total_timesteps      | 885760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.313226e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.907       |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.5e+06      |\n",
      "|    n_updates            | 33870        |\n",
      "|    policy_gradient_loss | -3.19e-06    |\n",
      "|    reward               | -29.821255   |\n",
      "|    value_loss           | 3.01e+06     |\n",
      "------------------------------------------\n",
      "Episode: 442\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 866           |\n",
      "|    time_elapsed         | 3482          |\n",
      "|    total_timesteps      | 886784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1245796e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6e+04         |\n",
      "|    n_updates            | 33880         |\n",
      "|    policy_gradient_loss | -4.78e-05     |\n",
      "|    reward               | -0.16099091   |\n",
      "|    value_loss           | 1.2e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 867          |\n",
      "|    time_elapsed         | 3486         |\n",
      "|    total_timesteps      | 887808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.962451e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.881       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.25e+05     |\n",
      "|    n_updates            | 33890        |\n",
      "|    policy_gradient_loss | -0.00012     |\n",
      "|    reward               | -40.51635    |\n",
      "|    value_loss           | 6.5e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 3490         |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.445939e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.8e+04      |\n",
      "|    n_updates            | 33900        |\n",
      "|    policy_gradient_loss | -1.78e-06    |\n",
      "|    reward               | -41.903454   |\n",
      "|    value_loss           | 1.56e+05     |\n",
      "------------------------------------------\n",
      "Episode: 443\n",
      "Episode: 444\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 688562.06\n",
      "total_reward: -311437.94\n",
      "total_cost: 38528.20\n",
      "total_trades: 43\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 869           |\n",
      "|    time_elapsed         | 3494          |\n",
      "|    total_timesteps      | 889856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0002404e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.75e+05      |\n",
      "|    n_updates            | 33910         |\n",
      "|    policy_gradient_loss | -2.3e-05      |\n",
      "|    reward               | -21.93031     |\n",
      "|    value_loss           | 5.5e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 870          |\n",
      "|    time_elapsed         | 3499         |\n",
      "|    total_timesteps      | 890880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.466833e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44e+05     |\n",
      "|    n_updates            | 33920        |\n",
      "|    policy_gradient_loss | 1.8e-06      |\n",
      "|    reward               | -41.783386   |\n",
      "|    value_loss           | 2.87e+05     |\n",
      "------------------------------------------\n",
      "Episode: 445\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 871          |\n",
      "|    time_elapsed         | 3503         |\n",
      "|    total_timesteps      | 891904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.086737e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.6e+04      |\n",
      "|    n_updates            | 33930        |\n",
      "|    policy_gradient_loss | -1.28e-06    |\n",
      "|    reward               | -9.215078    |\n",
      "|    value_loss           | 1.32e+05     |\n",
      "------------------------------------------\n",
      "Episode: 446\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 872           |\n",
      "|    time_elapsed         | 3507          |\n",
      "|    total_timesteps      | 892928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4505349e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.5e+05       |\n",
      "|    n_updates            | 33940         |\n",
      "|    policy_gradient_loss | 2.74e-06      |\n",
      "|    reward               | -39.203323    |\n",
      "|    value_loss           | 1.5e+06       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 873           |\n",
      "|    time_elapsed         | 3511          |\n",
      "|    total_timesteps      | 893952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2011885e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.26e+04      |\n",
      "|    n_updates            | 33950         |\n",
      "|    policy_gradient_loss | -1.95e-05     |\n",
      "|    reward               | -68.1451      |\n",
      "|    value_loss           | 6.54e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 447\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 874           |\n",
      "|    time_elapsed         | 3515          |\n",
      "|    total_timesteps      | 894976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3741235e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 2.98e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.58e+05      |\n",
      "|    n_updates            | 33960         |\n",
      "|    policy_gradient_loss | 1.42e-06      |\n",
      "|    reward               | -19.847878    |\n",
      "|    value_loss           | 9.17e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 875           |\n",
      "|    time_elapsed         | 3519          |\n",
      "|    total_timesteps      | 896000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6577846e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.08e+05      |\n",
      "|    n_updates            | 33970         |\n",
      "|    policy_gradient_loss | -4.93e-06     |\n",
      "|    reward               | -49.965477    |\n",
      "|    value_loss           | 4.17e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 876          |\n",
      "|    time_elapsed         | 3523         |\n",
      "|    total_timesteps      | 897024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.870235e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.08e+05     |\n",
      "|    n_updates            | 33980        |\n",
      "|    policy_gradient_loss | -1.34e-05    |\n",
      "|    reward               | -80.29569    |\n",
      "|    value_loss           | 2.16e+05     |\n",
      "------------------------------------------\n",
      "Episode: 448\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1123951.81\n",
      "total_reward: 123951.81\n",
      "total_cost: 1206082.62\n",
      "total_trades: 1119\n",
      "=================================\n",
      "Episode: 449\n",
      "Episode: 450\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 877          |\n",
      "|    time_elapsed         | 3528         |\n",
      "|    total_timesteps      | 898048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.091991e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.24e+05     |\n",
      "|    n_updates            | 33990        |\n",
      "|    policy_gradient_loss | 1.52e-05     |\n",
      "|    reward               | 12.479152    |\n",
      "|    value_loss           | 8.48e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 878          |\n",
      "|    time_elapsed         | 3533         |\n",
      "|    total_timesteps      | 899072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.782372e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.42e+05     |\n",
      "|    n_updates            | 34000        |\n",
      "|    policy_gradient_loss | -2.04e-05    |\n",
      "|    reward               | -19.474052   |\n",
      "|    value_loss           | 6.84e+05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 254            |\n",
      "|    iterations           | 879            |\n",
      "|    time_elapsed         | 3537           |\n",
      "|    total_timesteps      | 900096         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.02855265e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.881         |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 5.34e+04       |\n",
      "|    n_updates            | 34010          |\n",
      "|    policy_gradient_loss | -4.05e-05      |\n",
      "|    reward               | -43.74849      |\n",
      "|    value_loss           | 1.07e+05       |\n",
      "--------------------------------------------\n",
      "Episode: 451\n",
      "Episode: 452\n",
      "Current company: ['JPM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 689714.19\n",
      "total_reward: -310285.81\n",
      "total_cost: 106702.61\n",
      "total_trades: 121\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 880           |\n",
      "|    time_elapsed         | 3541          |\n",
      "|    total_timesteps      | 901120        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8840074e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.13e+05      |\n",
      "|    n_updates            | 34020         |\n",
      "|    policy_gradient_loss | 6.45e-05      |\n",
      "|    reward               | -8.778065     |\n",
      "|    value_loss           | 2.25e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 881          |\n",
      "|    time_elapsed         | 3545         |\n",
      "|    total_timesteps      | 902144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.929017e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.61e+05     |\n",
      "|    n_updates            | 34030        |\n",
      "|    policy_gradient_loss | 2.47e-06     |\n",
      "|    reward               | -46.80101    |\n",
      "|    value_loss           | 3.23e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 882           |\n",
      "|    time_elapsed         | 3549          |\n",
      "|    total_timesteps      | 903168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2887405e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.32e+04      |\n",
      "|    n_updates            | 34040         |\n",
      "|    policy_gradient_loss | -2.04e-06     |\n",
      "|    reward               | -92.88637     |\n",
      "|    value_loss           | 4.64e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 453\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 883          |\n",
      "|    time_elapsed         | 3553         |\n",
      "|    total_timesteps      | 904192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.055887e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.62e+05     |\n",
      "|    n_updates            | 34050        |\n",
      "|    policy_gradient_loss | 1.26e-05     |\n",
      "|    reward               | -2.1506574   |\n",
      "|    value_loss           | 1.33e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 884           |\n",
      "|    time_elapsed         | 3557          |\n",
      "|    total_timesteps      | 905216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6367994e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.45e+05      |\n",
      "|    n_updates            | 34060         |\n",
      "|    policy_gradient_loss | -8.49e-06     |\n",
      "|    reward               | -68.76985     |\n",
      "|    value_loss           | 1.29e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 885           |\n",
      "|    time_elapsed         | 3561          |\n",
      "|    total_timesteps      | 906240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3130484e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.47e+05      |\n",
      "|    n_updates            | 34070         |\n",
      "|    policy_gradient_loss | -2.71e-05     |\n",
      "|    reward               | -91.6854      |\n",
      "|    value_loss           | 2.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 454\n",
      "Episode: 455\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 886           |\n",
      "|    time_elapsed         | 3565          |\n",
      "|    total_timesteps      | 907264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0897867e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.5e+05       |\n",
      "|    n_updates            | 34080         |\n",
      "|    policy_gradient_loss | -0.000101     |\n",
      "|    reward               | -4.2458367    |\n",
      "|    value_loss           | 7e+05         |\n",
      "-------------------------------------------\n",
      "Episode: 456\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693991.80\n",
      "total_reward: -306008.20\n",
      "total_cost: 185787.92\n",
      "total_trades: 203\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 887           |\n",
      "|    time_elapsed         | 3570          |\n",
      "|    total_timesteps      | 908288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0618824e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.96e+05      |\n",
      "|    n_updates            | 34090         |\n",
      "|    policy_gradient_loss | 7.04e-06      |\n",
      "|    reward               | -26.351055    |\n",
      "|    value_loss           | 5.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 457\n",
      "Episode: 458\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 888           |\n",
      "|    time_elapsed         | 3574          |\n",
      "|    total_timesteps      | 909312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8693543e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.24e+04      |\n",
      "|    n_updates            | 34100         |\n",
      "|    policy_gradient_loss | -2.08e-05     |\n",
      "|    reward               | -5.0838375    |\n",
      "|    value_loss           | 4.5e+04       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 889           |\n",
      "|    time_elapsed         | 3578          |\n",
      "|    total_timesteps      | 910336        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3078755e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+05      |\n",
      "|    n_updates            | 34110         |\n",
      "|    policy_gradient_loss | 4.25e-05      |\n",
      "|    reward               | -5.375277     |\n",
      "|    value_loss           | 4.91e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 890          |\n",
      "|    time_elapsed         | 3582         |\n",
      "|    total_timesteps      | 911360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.260839e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.6e+04      |\n",
      "|    n_updates            | 34120        |\n",
      "|    policy_gradient_loss | -1.21e-05    |\n",
      "|    reward               | -8.571745    |\n",
      "|    value_loss           | 1.17e+05     |\n",
      "------------------------------------------\n",
      "Episode: 459\n",
      "Episode: 460\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 672223.89\n",
      "total_reward: -327776.11\n",
      "total_cost: 57940.53\n",
      "total_trades: 59\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 891           |\n",
      "|    time_elapsed         | 3586          |\n",
      "|    total_timesteps      | 912384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5639234e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.881        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.61e+04      |\n",
      "|    n_updates            | 34130         |\n",
      "|    policy_gradient_loss | -1.33e-05     |\n",
      "|    reward               | -23.1843      |\n",
      "|    value_loss           | 5.22e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 892          |\n",
      "|    time_elapsed         | 3590         |\n",
      "|    total_timesteps      | 913408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.555339e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.91e+04     |\n",
      "|    n_updates            | 34140        |\n",
      "|    policy_gradient_loss | -2.72e-05    |\n",
      "|    reward               | -2.5326278   |\n",
      "|    value_loss           | 1.58e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 893          |\n",
      "|    time_elapsed         | 3594         |\n",
      "|    total_timesteps      | 914432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.208437e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.37e+04     |\n",
      "|    n_updates            | 34150        |\n",
      "|    policy_gradient_loss | 4.19e-06     |\n",
      "|    reward               | -8.705561    |\n",
      "|    value_loss           | 4.75e+04     |\n",
      "------------------------------------------\n",
      "Episode: 461\n",
      "Episode: 462\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 894           |\n",
      "|    time_elapsed         | 3598          |\n",
      "|    total_timesteps      | 915456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1082815e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.883        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.2e+04       |\n",
      "|    n_updates            | 34160         |\n",
      "|    policy_gradient_loss | 1.2e-05       |\n",
      "|    reward               | 17.543129     |\n",
      "|    value_loss           | 8.39e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 895          |\n",
      "|    time_elapsed         | 3602         |\n",
      "|    total_timesteps      | 916480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.901085e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.13e+05     |\n",
      "|    n_updates            | 34170        |\n",
      "|    policy_gradient_loss | -4.13e-06    |\n",
      "|    reward               | -63.489914   |\n",
      "|    value_loss           | 4.27e+05     |\n",
      "------------------------------------------\n",
      "Episode: 463\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 896           |\n",
      "|    time_elapsed         | 3607          |\n",
      "|    total_timesteps      | 917504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3649773e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2e+05         |\n",
      "|    n_updates            | 34180         |\n",
      "|    policy_gradient_loss | -8.82e-06     |\n",
      "|    reward               | -30.208475    |\n",
      "|    value_loss           | 4e+05         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 897           |\n",
      "|    time_elapsed         | 3611          |\n",
      "|    total_timesteps      | 918528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3270487e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.881        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.13e+05      |\n",
      "|    n_updates            | 34190         |\n",
      "|    policy_gradient_loss | -6.76e-05     |\n",
      "|    reward               | -87.36397     |\n",
      "|    value_loss           | 2.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 464\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1280853.42\n",
      "total_reward: 280853.42\n",
      "total_cost: 1030901.06\n",
      "total_trades: 1037\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 898           |\n",
      "|    time_elapsed         | 3615          |\n",
      "|    total_timesteps      | 919552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5631466e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.88         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.72e+05      |\n",
      "|    n_updates            | 34200         |\n",
      "|    policy_gradient_loss | -0.000102     |\n",
      "|    reward               | -8.949796     |\n",
      "|    value_loss           | 1.14e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 465\n",
      "Episode: 466\n",
      "Episode: 467\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 899           |\n",
      "|    time_elapsed         | 3619          |\n",
      "|    total_timesteps      | 920576        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2816163e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.52e+05      |\n",
      "|    n_updates            | 34210         |\n",
      "|    policy_gradient_loss | 5.79e-06      |\n",
      "|    reward               | 4.633655      |\n",
      "|    value_loss           | 1.3e+06       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 900           |\n",
      "|    time_elapsed         | 3623          |\n",
      "|    total_timesteps      | 921600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2759272e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.35e+04      |\n",
      "|    n_updates            | 34220         |\n",
      "|    policy_gradient_loss | -9.02e-06     |\n",
      "|    reward               | 105.22693     |\n",
      "|    value_loss           | 1.07e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 901          |\n",
      "|    time_elapsed         | 3627         |\n",
      "|    total_timesteps      | 922624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.942428e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.879       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.79e+05     |\n",
      "|    n_updates            | 34230        |\n",
      "|    policy_gradient_loss | -7.53e-06    |\n",
      "|    reward               | 90.18212     |\n",
      "|    value_loss           | 5.58e+05     |\n",
      "------------------------------------------\n",
      "Episode: 468\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2141728.20\n",
      "total_reward: 1141728.20\n",
      "total_cost: 2146839.85\n",
      "total_trades: 1049\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 3631         |\n",
      "|    total_timesteps      | 923648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.927317e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.72e+06     |\n",
      "|    n_updates            | 34240        |\n",
      "|    policy_gradient_loss | -8.65e-06    |\n",
      "|    reward               | -21.940289   |\n",
      "|    value_loss           | 3.44e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 3635         |\n",
      "|    total_timesteps      | 924672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.983778e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.44e+05     |\n",
      "|    n_updates            | 34250        |\n",
      "|    policy_gradient_loss | -1.22e-05    |\n",
      "|    reward               | -67.57618    |\n",
      "|    value_loss           | 4.88e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 904           |\n",
      "|    time_elapsed         | 3639          |\n",
      "|    total_timesteps      | 925696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5816186e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.881        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+05      |\n",
      "|    n_updates            | 34260         |\n",
      "|    policy_gradient_loss | -1.28e-05     |\n",
      "|    reward               | -1.147478     |\n",
      "|    value_loss           | 2.97e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 469\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 905           |\n",
      "|    time_elapsed         | 3644          |\n",
      "|    total_timesteps      | 926720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4437904e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+05      |\n",
      "|    n_updates            | 34270         |\n",
      "|    policy_gradient_loss | -3.53e-05     |\n",
      "|    reward               | -26.42431     |\n",
      "|    value_loss           | 3.24e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 906          |\n",
      "|    time_elapsed         | 3648         |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.449424e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.82e+05     |\n",
      "|    n_updates            | 34280        |\n",
      "|    policy_gradient_loss | 1.21e-05     |\n",
      "|    reward               | -37.10062    |\n",
      "|    value_loss           | 7.63e+05     |\n",
      "------------------------------------------\n",
      "Episode: 470\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 907          |\n",
      "|    time_elapsed         | 3653         |\n",
      "|    total_timesteps      | 928768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.010508e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.26e+05     |\n",
      "|    n_updates            | 34290        |\n",
      "|    policy_gradient_loss | 2.9e-07      |\n",
      "|    reward               | -27.9526     |\n",
      "|    value_loss           | 4.52e+05     |\n",
      "------------------------------------------\n",
      "Episode: 471\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 908           |\n",
      "|    time_elapsed         | 3657          |\n",
      "|    total_timesteps      | 929792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1641532e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.883        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.64e+05      |\n",
      "|    n_updates            | 34300         |\n",
      "|    policy_gradient_loss | -1.38e-06     |\n",
      "|    reward               | -48.443123    |\n",
      "|    value_loss           | 5.28e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 472\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 671013.33\n",
      "total_reward: -328986.67\n",
      "total_cost: 506168.97\n",
      "total_trades: 555\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 909          |\n",
      "|    time_elapsed         | 3661         |\n",
      "|    total_timesteps      | 930816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.499103e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.91e+04     |\n",
      "|    n_updates            | 34310        |\n",
      "|    policy_gradient_loss | -5.24e-05    |\n",
      "|    reward               | -27.979567   |\n",
      "|    value_loss           | 1.38e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 3665         |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.337615e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.54e+05     |\n",
      "|    n_updates            | 34320        |\n",
      "|    policy_gradient_loss | -5.51e-05    |\n",
      "|    reward               | -63.06021    |\n",
      "|    value_loss           | 5.08e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 911           |\n",
      "|    time_elapsed         | 3669          |\n",
      "|    total_timesteps      | 932864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1866796e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.38e+05      |\n",
      "|    n_updates            | 34330         |\n",
      "|    policy_gradient_loss | 1.42e-05      |\n",
      "|    reward               | -38.229637    |\n",
      "|    value_loss           | 2.76e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 473\n",
      "Episode: 474\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 912           |\n",
      "|    time_elapsed         | 3673          |\n",
      "|    total_timesteps      | 933888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1851156e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.33e+05      |\n",
      "|    n_updates            | 34340         |\n",
      "|    policy_gradient_loss | -4.01e-06     |\n",
      "|    reward               | -30.19576     |\n",
      "|    value_loss           | 4.66e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 913          |\n",
      "|    time_elapsed         | 3678         |\n",
      "|    total_timesteps      | 934912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001918017 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.885       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.46e+04     |\n",
      "|    n_updates            | 34350        |\n",
      "|    policy_gradient_loss | -0.000326    |\n",
      "|    reward               | -29.625708   |\n",
      "|    value_loss           | 4.92e+04     |\n",
      "------------------------------------------\n",
      "Episode: 475\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 254            |\n",
      "|    iterations           | 914            |\n",
      "|    time_elapsed         | 3682           |\n",
      "|    total_timesteps      | 935936         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000106578926 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.884         |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.02e+05       |\n",
      "|    n_updates            | 34360          |\n",
      "|    policy_gradient_loss | -2.17e-05      |\n",
      "|    reward               | 10.4077635     |\n",
      "|    value_loss           | 2.05e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 915           |\n",
      "|    time_elapsed         | 3686          |\n",
      "|    total_timesteps      | 936960        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6859343e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.887        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.2e+04       |\n",
      "|    n_updates            | 34370         |\n",
      "|    policy_gradient_loss | -7.54e-05     |\n",
      "|    reward               | 24.59268      |\n",
      "|    value_loss           | 1.24e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 916           |\n",
      "|    time_elapsed         | 3690          |\n",
      "|    total_timesteps      | 937984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1562195e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.887        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.91e+04      |\n",
      "|    n_updates            | 34380         |\n",
      "|    policy_gradient_loss | 4.33e-05      |\n",
      "|    reward               | 107.88031     |\n",
      "|    value_loss           | 1.58e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 476\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1185520.57\n",
      "total_reward: 185520.57\n",
      "total_cost: 1802799.87\n",
      "total_trades: 1112\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 917           |\n",
      "|    time_elapsed         | 3694          |\n",
      "|    total_timesteps      | 939008        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0021613e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.887        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.93e+05      |\n",
      "|    n_updates            | 34390         |\n",
      "|    policy_gradient_loss | -4.05e-05     |\n",
      "|    reward               | -15.234561    |\n",
      "|    value_loss           | 7.86e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 477\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 918           |\n",
      "|    time_elapsed         | 3698          |\n",
      "|    total_timesteps      | 940032        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7555314e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.889        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.83e+05      |\n",
      "|    n_updates            | 34400         |\n",
      "|    policy_gradient_loss | -9.48e-05     |\n",
      "|    reward               | -35.029808    |\n",
      "|    value_loss           | 5.66e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 478\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 919           |\n",
      "|    time_elapsed         | 3702          |\n",
      "|    total_timesteps      | 941056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0885433e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.12e+04      |\n",
      "|    n_updates            | 34410         |\n",
      "|    policy_gradient_loss | -4.11e-05     |\n",
      "|    reward               | -23.2454      |\n",
      "|    value_loss           | 1.82e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 920          |\n",
      "|    time_elapsed         | 3706         |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.267591e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.11e+05     |\n",
      "|    n_updates            | 34420        |\n",
      "|    policy_gradient_loss | -9.68e-05    |\n",
      "|    reward               | 22.59709     |\n",
      "|    value_loss           | 4.23e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 921           |\n",
      "|    time_elapsed         | 3710          |\n",
      "|    total_timesteps      | 943104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6372297e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.41e+04      |\n",
      "|    n_updates            | 34430         |\n",
      "|    policy_gradient_loss | -4.47e-05     |\n",
      "|    reward               | -0.13146752   |\n",
      "|    value_loss           | 1.08e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 479\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 922           |\n",
      "|    time_elapsed         | 3714          |\n",
      "|    total_timesteps      | 944128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8695795e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.32e+04      |\n",
      "|    n_updates            | 34440         |\n",
      "|    policy_gradient_loss | 6.54e-05      |\n",
      "|    reward               | -7.9991617    |\n",
      "|    value_loss           | 1.67e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 923          |\n",
      "|    time_elapsed         | 3718         |\n",
      "|    total_timesteps      | 945152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.399637e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.16e+04     |\n",
      "|    n_updates            | 34450        |\n",
      "|    policy_gradient_loss | -0.000236    |\n",
      "|    reward               | -33.749928   |\n",
      "|    value_loss           | 8.32e+04     |\n",
      "------------------------------------------\n",
      "Episode: 480\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1362198.17\n",
      "total_reward: 362198.17\n",
      "total_cost: 1240895.29\n",
      "total_trades: 1024\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 3722         |\n",
      "|    total_timesteps      | 946176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.098195e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.89        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.99e+04     |\n",
      "|    n_updates            | 34460        |\n",
      "|    policy_gradient_loss | -0.000126    |\n",
      "|    reward               | -12.660821   |\n",
      "|    value_loss           | 1.2e+05      |\n",
      "------------------------------------------\n",
      "Episode: 481\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 925          |\n",
      "|    time_elapsed         | 3727         |\n",
      "|    total_timesteps      | 947200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.333591e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.888       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.68e+05     |\n",
      "|    n_updates            | 34470        |\n",
      "|    policy_gradient_loss | 7.87e-05     |\n",
      "|    reward               | -5.776747    |\n",
      "|    value_loss           | 3.36e+05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 254            |\n",
      "|    iterations           | 926            |\n",
      "|    time_elapsed         | 3731           |\n",
      "|    total_timesteps      | 948224         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.25374645e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.887         |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 3.87e+04       |\n",
      "|    n_updates            | 34480          |\n",
      "|    policy_gradient_loss | -9.41e-05      |\n",
      "|    reward               | -76.97652      |\n",
      "|    value_loss           | 7.75e+04       |\n",
      "--------------------------------------------\n",
      "Episode: 482\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 3735         |\n",
      "|    total_timesteps      | 949248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.291805e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.885       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.44e+05     |\n",
      "|    n_updates            | 34490        |\n",
      "|    policy_gradient_loss | 2.28e-05     |\n",
      "|    reward               | -12.311091   |\n",
      "|    value_loss           | 4.87e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 928           |\n",
      "|    time_elapsed         | 3739          |\n",
      "|    total_timesteps      | 950272        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0174699e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.47e+05      |\n",
      "|    n_updates            | 34500         |\n",
      "|    policy_gradient_loss | -8.19e-06     |\n",
      "|    reward               | -51.597893    |\n",
      "|    value_loss           | 1.29e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 929           |\n",
      "|    time_elapsed         | 3743          |\n",
      "|    total_timesteps      | 951296        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1956234e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.33e+04      |\n",
      "|    n_updates            | 34510         |\n",
      "|    policy_gradient_loss | -1.06e-05     |\n",
      "|    reward               | -85.34586     |\n",
      "|    value_loss           | 1.47e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 483\n",
      "Episode: 484\n",
      "Current company: ['JPM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 686214.90\n",
      "total_reward: -313785.10\n",
      "total_cost: 123862.07\n",
      "total_trades: 133\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 930          |\n",
      "|    time_elapsed         | 3747         |\n",
      "|    total_timesteps      | 952320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.508788e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.885       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.13e+05     |\n",
      "|    n_updates            | 34520        |\n",
      "|    policy_gradient_loss | 1.5e-05      |\n",
      "|    reward               | 28.402664    |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 931           |\n",
      "|    time_elapsed         | 3751          |\n",
      "|    total_timesteps      | 953344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0980293e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.29e+05      |\n",
      "|    n_updates            | 34530         |\n",
      "|    policy_gradient_loss | -2.19e-05     |\n",
      "|    reward               | 4.774211      |\n",
      "|    value_loss           | 6.58e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 932           |\n",
      "|    time_elapsed         | 3755          |\n",
      "|    total_timesteps      | 954368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7136335e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.74e+05      |\n",
      "|    n_updates            | 34540         |\n",
      "|    policy_gradient_loss | 1.23e-05      |\n",
      "|    reward               | -38.88162     |\n",
      "|    value_loss           | 3.49e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 485\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 933           |\n",
      "|    time_elapsed         | 3759          |\n",
      "|    total_timesteps      | 955392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6891863e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.55e+04      |\n",
      "|    n_updates            | 34550         |\n",
      "|    policy_gradient_loss | -2.16e-05     |\n",
      "|    reward               | -26.686064    |\n",
      "|    value_loss           | 1.71e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 934           |\n",
      "|    time_elapsed         | 3763          |\n",
      "|    total_timesteps      | 956416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4512334e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.41e+05      |\n",
      "|    n_updates            | 34560         |\n",
      "|    policy_gradient_loss | 8.28e-07      |\n",
      "|    reward               | -81.743004    |\n",
      "|    value_loss           | 4.83e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 935           |\n",
      "|    time_elapsed         | 3767          |\n",
      "|    total_timesteps      | 957440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3946632e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.886        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.74e+05      |\n",
      "|    n_updates            | 34570         |\n",
      "|    policy_gradient_loss | -1.3e-05      |\n",
      "|    reward               | -130.4393     |\n",
      "|    value_loss           | 5.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 486\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 936           |\n",
      "|    time_elapsed         | 3772          |\n",
      "|    total_timesteps      | 958464        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0622898e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.885        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.46e+06      |\n",
      "|    n_updates            | 34580         |\n",
      "|    policy_gradient_loss | -1.76e-05     |\n",
      "|    reward               | 14.106375     |\n",
      "|    value_loss           | 2.93e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 937          |\n",
      "|    time_elapsed         | 3776         |\n",
      "|    total_timesteps      | 959488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.992452e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.39e+05     |\n",
      "|    n_updates            | 34590        |\n",
      "|    policy_gradient_loss | -9.22e-05    |\n",
      "|    reward               | -4.9902663   |\n",
      "|    value_loss           | 2.78e+05     |\n",
      "------------------------------------------\n",
      "Episode: 487\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 938           |\n",
      "|    time_elapsed         | 3780          |\n",
      "|    total_timesteps      | 960512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0900925e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.78e+04      |\n",
      "|    n_updates            | 34600         |\n",
      "|    policy_gradient_loss | -0.000144     |\n",
      "|    reward               | -19.294567    |\n",
      "|    value_loss           | 3.56e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 254            |\n",
      "|    iterations           | 939            |\n",
      "|    time_elapsed         | 3784           |\n",
      "|    total_timesteps      | 961536         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000111628324 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.897         |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 2.05e+04       |\n",
      "|    n_updates            | 34610          |\n",
      "|    policy_gradient_loss | -0.000147      |\n",
      "|    reward               | -19.129162     |\n",
      "|    value_loss           | 4.11e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 940           |\n",
      "|    time_elapsed         | 3788          |\n",
      "|    total_timesteps      | 962560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1501713e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.902        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.43e+04      |\n",
      "|    n_updates            | 34620         |\n",
      "|    policy_gradient_loss | 0.000144      |\n",
      "|    reward               | -79.83612     |\n",
      "|    value_loss           | 1.29e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 488\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1670529.06\n",
      "total_reward: 670529.06\n",
      "total_cost: 1130664.56\n",
      "total_trades: 983\n",
      "=================================\n",
      "Episode: 489\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 941           |\n",
      "|    time_elapsed         | 3792          |\n",
      "|    total_timesteps      | 963584        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6944326e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.904        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.39e+05      |\n",
      "|    n_updates            | 34630         |\n",
      "|    policy_gradient_loss | 1.5e-05       |\n",
      "|    reward               | 5.6942477     |\n",
      "|    value_loss           | 8.79e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 942           |\n",
      "|    time_elapsed         | 3796          |\n",
      "|    total_timesteps      | 964608        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2549572e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.905        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.17e+05      |\n",
      "|    n_updates            | 34640         |\n",
      "|    policy_gradient_loss | 2.43e-07      |\n",
      "|    reward               | -53.81238     |\n",
      "|    value_loss           | 4.34e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 943           |\n",
      "|    time_elapsed         | 3800          |\n",
      "|    total_timesteps      | 965632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031380745 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.901        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.25e+04      |\n",
      "|    n_updates            | 34650         |\n",
      "|    policy_gradient_loss | -0.000474     |\n",
      "|    reward               | -116.02554    |\n",
      "|    value_loss           | 1.45e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 490\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 944           |\n",
      "|    time_elapsed         | 3804          |\n",
      "|    total_timesteps      | 966656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031119527 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.889        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.58e+05      |\n",
      "|    n_updates            | 34660         |\n",
      "|    policy_gradient_loss | 0.000293      |\n",
      "|    reward               | -32.430515    |\n",
      "|    value_loss           | 1.72e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 491\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 945           |\n",
      "|    time_elapsed         | 3808          |\n",
      "|    total_timesteps      | 967680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0222582e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+05      |\n",
      "|    n_updates            | 34670         |\n",
      "|    policy_gradient_loss | 8.82e-05      |\n",
      "|    reward               | -33.61547     |\n",
      "|    value_loss           | 3.22e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 3812        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.58667e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.73e+05    |\n",
      "|    n_updates            | 34680       |\n",
      "|    policy_gradient_loss | -9.43e-05   |\n",
      "|    reward               | -76.7487    |\n",
      "|    value_loss           | 3.47e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 947           |\n",
      "|    time_elapsed         | 3816          |\n",
      "|    total_timesteps      | 969728        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1641608e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.88e+05      |\n",
      "|    n_updates            | 34690         |\n",
      "|    policy_gradient_loss | 2.94e-05      |\n",
      "|    reward               | -131.83932    |\n",
      "|    value_loss           | 7.77e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 492\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 972252.57\n",
      "total_reward: -27747.43\n",
      "total_cost: 884749.24\n",
      "total_trades: 975\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 948          |\n",
      "|    time_elapsed         | 3820         |\n",
      "|    total_timesteps      | 970752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.004687e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.879       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.4e+06      |\n",
      "|    n_updates            | 34700        |\n",
      "|    policy_gradient_loss | 3.55e-06     |\n",
      "|    reward               | -35.089573   |\n",
      "|    value_loss           | 2.81e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 949          |\n",
      "|    time_elapsed         | 3824         |\n",
      "|    total_timesteps      | 971776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.709038e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.879       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.82e+05     |\n",
      "|    n_updates            | 34710        |\n",
      "|    policy_gradient_loss | -4.59e-06    |\n",
      "|    reward               | -4.8205113   |\n",
      "|    value_loss           | 1.16e+06     |\n",
      "------------------------------------------\n",
      "Episode: 493\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 950           |\n",
      "|    time_elapsed         | 3828          |\n",
      "|    total_timesteps      | 972800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.4175845e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.28e+03      |\n",
      "|    n_updates            | 34720         |\n",
      "|    policy_gradient_loss | -2.35e-05     |\n",
      "|    reward               | -8.362217     |\n",
      "|    value_loss           | 1.66e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 3832        |\n",
      "|    total_timesteps      | 973824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.31935e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.82e+05    |\n",
      "|    n_updates            | 34730       |\n",
      "|    policy_gradient_loss | 7.21e-05    |\n",
      "|    reward               | -41.907818  |\n",
      "|    value_loss           | 5.63e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 952           |\n",
      "|    time_elapsed         | 3836          |\n",
      "|    total_timesteps      | 974848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7000864e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.879        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.52e+04      |\n",
      "|    n_updates            | 34740         |\n",
      "|    policy_gradient_loss | -1.9e-05      |\n",
      "|    reward               | -109.10134    |\n",
      "|    value_loss           | 5.05e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 494\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 953           |\n",
      "|    time_elapsed         | 3840          |\n",
      "|    total_timesteps      | 975872        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5916885e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.32e+05      |\n",
      "|    n_updates            | 34750         |\n",
      "|    policy_gradient_loss | 2.48e-05      |\n",
      "|    reward               | 6.791357      |\n",
      "|    value_loss           | 1.26e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 954           |\n",
      "|    time_elapsed         | 3844          |\n",
      "|    total_timesteps      | 976896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3236498e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01e+06      |\n",
      "|    n_updates            | 34760         |\n",
      "|    policy_gradient_loss | -7.7e-06      |\n",
      "|    reward               | 83.054955     |\n",
      "|    value_loss           | 2.03e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 955           |\n",
      "|    time_elapsed         | 3848          |\n",
      "|    total_timesteps      | 977920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6368223e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.24e+05      |\n",
      "|    n_updates            | 34770         |\n",
      "|    policy_gradient_loss | -1.93e-05     |\n",
      "|    reward               | 27.528896     |\n",
      "|    value_loss           | 6.49e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 495\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 956           |\n",
      "|    time_elapsed         | 3852          |\n",
      "|    total_timesteps      | 978944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1902303e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.877        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.87e+05      |\n",
      "|    n_updates            | 34780         |\n",
      "|    policy_gradient_loss | -2.72e-06     |\n",
      "|    reward               | -14.778056    |\n",
      "|    value_loss           | 7.74e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 957           |\n",
      "|    time_elapsed         | 3856          |\n",
      "|    total_timesteps      | 979968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013220508 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.878        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.7e+04       |\n",
      "|    n_updates            | 34790         |\n",
      "|    policy_gradient_loss | -0.000289     |\n",
      "|    reward               | -87.51888     |\n",
      "|    value_loss           | 5.41e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 496\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 688607.09\n",
      "total_reward: -311392.91\n",
      "total_cost: 728603.97\n",
      "total_trades: 721\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 958           |\n",
      "|    time_elapsed         | 3860          |\n",
      "|    total_timesteps      | 980992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016053859 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.41e+05      |\n",
      "|    n_updates            | 34800         |\n",
      "|    policy_gradient_loss | -0.000195     |\n",
      "|    reward               | -28.065327    |\n",
      "|    value_loss           | 6.83e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 497\n",
      "Episode: 498\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 959           |\n",
      "|    time_elapsed         | 3864          |\n",
      "|    total_timesteps      | 982016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9662024e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.884        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.68e+05      |\n",
      "|    n_updates            | 34810         |\n",
      "|    policy_gradient_loss | 7.29e-05      |\n",
      "|    reward               | -25.891464    |\n",
      "|    value_loss           | 7.36e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 960          |\n",
      "|    time_elapsed         | 3868         |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.747141e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.58e+05     |\n",
      "|    n_updates            | 34820        |\n",
      "|    policy_gradient_loss | -5.73e-05    |\n",
      "|    reward               | -71.032394   |\n",
      "|    value_loss           | 3.16e+05     |\n",
      "------------------------------------------\n",
      "Episode: 499\n",
      "Episode: 500\n",
      "Current company: ['DOW']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 662596.90\n",
      "total_reward: -337403.10\n",
      "total_cost: 14190.76\n",
      "total_trades: 15\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 961          |\n",
      "|    time_elapsed         | 3872         |\n",
      "|    total_timesteps      | 984064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.864612e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.887       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.14e+05     |\n",
      "|    n_updates            | 34830        |\n",
      "|    policy_gradient_loss | -8.17e-05    |\n",
      "|    reward               | -4.8207607   |\n",
      "|    value_loss           | 4.28e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 962          |\n",
      "|    time_elapsed         | 3876         |\n",
      "|    total_timesteps      | 985088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.998431e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.82e+05     |\n",
      "|    n_updates            | 34840        |\n",
      "|    policy_gradient_loss | -0.000126    |\n",
      "|    reward               | 58.688744    |\n",
      "|    value_loss           | 1.36e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 3880        |\n",
      "|    total_timesteps      | 986112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.99998e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.32e+05    |\n",
      "|    n_updates            | 34850       |\n",
      "|    policy_gradient_loss | -3.26e-05   |\n",
      "|    reward               | 87.750656   |\n",
      "|    value_loss           | 4.64e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 501\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 964           |\n",
      "|    time_elapsed         | 3884          |\n",
      "|    total_timesteps      | 987136        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1453521e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.33e+05      |\n",
      "|    n_updates            | 34860         |\n",
      "|    policy_gradient_loss | 8.79e-06      |\n",
      "|    reward               | 50.31271      |\n",
      "|    value_loss           | 1.87e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 965           |\n",
      "|    time_elapsed         | 3888          |\n",
      "|    total_timesteps      | 988160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6530976e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.986        |\n",
      "|    explained_variance   | -1.14         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.01e+05      |\n",
      "|    n_updates            | 34870         |\n",
      "|    policy_gradient_loss | -1.31e-05     |\n",
      "|    reward               | -39.515514    |\n",
      "|    value_loss           | 4.04e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 966           |\n",
      "|    time_elapsed         | 3892          |\n",
      "|    total_timesteps      | 989184        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2479875e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+05      |\n",
      "|    n_updates            | 34880         |\n",
      "|    policy_gradient_loss | -1.16e-06     |\n",
      "|    reward               | 12.096705     |\n",
      "|    value_loss           | 2.79e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 502\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 967           |\n",
      "|    time_elapsed         | 3896          |\n",
      "|    total_timesteps      | 990208        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5628175e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.892        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.14e+04      |\n",
      "|    n_updates            | 34890         |\n",
      "|    policy_gradient_loss | -1.62e-05     |\n",
      "|    reward               | -44.098083    |\n",
      "|    value_loss           | 1.63e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 503\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 968           |\n",
      "|    time_elapsed         | 3900          |\n",
      "|    total_timesteps      | 991232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0058817e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.53e+05      |\n",
      "|    n_updates            | 34900         |\n",
      "|    policy_gradient_loss | 8.81e-06      |\n",
      "|    reward               | 7.9118457     |\n",
      "|    value_loss           | 3.06e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 969           |\n",
      "|    time_elapsed         | 3904          |\n",
      "|    total_timesteps      | 992256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8393697e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.25e+05      |\n",
      "|    n_updates            | 34910         |\n",
      "|    policy_gradient_loss | -5.83e-06     |\n",
      "|    reward               | -19.54368     |\n",
      "|    value_loss           | 4.5e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 970          |\n",
      "|    time_elapsed         | 3908         |\n",
      "|    total_timesteps      | 993280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.724754e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.892       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.19e+04     |\n",
      "|    n_updates            | 34920        |\n",
      "|    policy_gradient_loss | -1.05e-05    |\n",
      "|    reward               | -47.376537   |\n",
      "|    value_loss           | 8.4e+04      |\n",
      "------------------------------------------\n",
      "Episode: 504\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2042077.54\n",
      "total_reward: 1042077.54\n",
      "total_cost: 1384267.80\n",
      "total_trades: 1075\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 971          |\n",
      "|    time_elapsed         | 3912         |\n",
      "|    total_timesteps      | 994304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.226481e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.892       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 34930        |\n",
      "|    policy_gradient_loss | -1.12e-05    |\n",
      "|    reward               | -54.395473   |\n",
      "|    value_loss           | 2.82e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 972           |\n",
      "|    time_elapsed         | 3916          |\n",
      "|    total_timesteps      | 995328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6565117e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.24e+04      |\n",
      "|    n_updates            | 34940         |\n",
      "|    policy_gradient_loss | -2.36e-05     |\n",
      "|    reward               | -52.09393     |\n",
      "|    value_loss           | 1.45e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 505\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 973           |\n",
      "|    time_elapsed         | 3920          |\n",
      "|    total_timesteps      | 996352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9119547e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.74e+05      |\n",
      "|    n_updates            | 34950         |\n",
      "|    policy_gradient_loss | 9.64e-06      |\n",
      "|    reward               | -10.590414    |\n",
      "|    value_loss           | 7.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 506\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 974           |\n",
      "|    time_elapsed         | 3925          |\n",
      "|    total_timesteps      | 997376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1874363e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.91e+05      |\n",
      "|    n_updates            | 34960         |\n",
      "|    policy_gradient_loss | 2.11e-06      |\n",
      "|    reward               | 30.560848     |\n",
      "|    value_loss           | 9.81e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 3929        |\n",
      "|    total_timesteps      | 998400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.51263e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+05    |\n",
      "|    n_updates            | 34970       |\n",
      "|    policy_gradient_loss | -8.32e-05   |\n",
      "|    reward               | -28.208076  |\n",
      "|    value_loss           | 2.31e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 976           |\n",
      "|    time_elapsed         | 3933          |\n",
      "|    total_timesteps      | 999424        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2471573e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.897        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.9e+05       |\n",
      "|    n_updates            | 34980         |\n",
      "|    policy_gradient_loss | -2.82e-05     |\n",
      "|    reward               | -69.33285     |\n",
      "|    value_loss           | 3.8e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 507\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 977           |\n",
      "|    time_elapsed         | 3937          |\n",
      "|    total_timesteps      | 1000448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6975682e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.898        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+05      |\n",
      "|    n_updates            | 34990         |\n",
      "|    policy_gradient_loss | 1.24e-05      |\n",
      "|    reward               | -39.482304    |\n",
      "|    value_loss           | 4.9e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 978           |\n",
      "|    time_elapsed         | 3942          |\n",
      "|    total_timesteps      | 1001472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1597876e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.899        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.27e+04      |\n",
      "|    n_updates            | 35000         |\n",
      "|    policy_gradient_loss | -1.36e-05     |\n",
      "|    reward               | -75.20489     |\n",
      "|    value_loss           | 8.54e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 508\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 954073.45\n",
      "total_reward: -45926.55\n",
      "total_cost: 1030819.76\n",
      "total_trades: 1095\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 979          |\n",
      "|    time_elapsed         | 3946         |\n",
      "|    total_timesteps      | 1002496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.157229e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.33e+05     |\n",
      "|    n_updates            | 35010        |\n",
      "|    policy_gradient_loss | 6.35e-06     |\n",
      "|    reward               | 22.032434    |\n",
      "|    value_loss           | 1.07e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 980           |\n",
      "|    time_elapsed         | 3950          |\n",
      "|    total_timesteps      | 1003520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3061875e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 0.586         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.03e+05      |\n",
      "|    n_updates            | 35020         |\n",
      "|    policy_gradient_loss | -2.8e-05      |\n",
      "|    reward               | -11.401905    |\n",
      "|    value_loss           | 1.81e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 981           |\n",
      "|    time_elapsed         | 3954          |\n",
      "|    total_timesteps      | 1004544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8617796e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 0.62          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.57e+04      |\n",
      "|    n_updates            | 35030         |\n",
      "|    policy_gradient_loss | -4.65e-05     |\n",
      "|    reward               | -57.095726    |\n",
      "|    value_loss           | 1.32e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 509\n",
      "Episode: 510\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 982          |\n",
      "|    time_elapsed         | 3958         |\n",
      "|    total_timesteps      | 1005568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.517469e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.12e+04     |\n",
      "|    n_updates            | 35040        |\n",
      "|    policy_gradient_loss | -1.57e-05    |\n",
      "|    reward               | 5.803828     |\n",
      "|    value_loss           | 1.82e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 983           |\n",
      "|    time_elapsed         | 3962          |\n",
      "|    total_timesteps      | 1006592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2345321e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.896        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.48e+05      |\n",
      "|    n_updates            | 35050         |\n",
      "|    policy_gradient_loss | -4.34e-05     |\n",
      "|    reward               | -55.18637     |\n",
      "|    value_loss           | 2.97e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 984          |\n",
      "|    time_elapsed         | 3966         |\n",
      "|    total_timesteps      | 1007616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.870855e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.21e+04     |\n",
      "|    n_updates            | 35060        |\n",
      "|    policy_gradient_loss | 5.09e-05     |\n",
      "|    reward               | -122.57768   |\n",
      "|    value_loss           | 1.64e+05     |\n",
      "------------------------------------------\n",
      "Episode: 511\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 254          |\n",
      "|    iterations           | 985          |\n",
      "|    time_elapsed         | 3970         |\n",
      "|    total_timesteps      | 1008640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.729947e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.39e+05     |\n",
      "|    n_updates            | 35070        |\n",
      "|    policy_gradient_loss | 1.52e-05     |\n",
      "|    reward               | 76.030075    |\n",
      "|    value_loss           | 1.68e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 986           |\n",
      "|    time_elapsed         | 3974          |\n",
      "|    total_timesteps      | 1009664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1985186e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.987        |\n",
      "|    explained_variance   | 0.441         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.65e+05      |\n",
      "|    n_updates            | 35080         |\n",
      "|    policy_gradient_loss | -2.35e-05     |\n",
      "|    reward               | 25.510859     |\n",
      "|    value_loss           | 1.53e+06      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 254       |\n",
      "|    iterations           | 987       |\n",
      "|    time_elapsed         | 3978      |\n",
      "|    total_timesteps      | 1010688   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.894    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 9.07e+05  |\n",
      "|    n_updates            | 35090     |\n",
      "|    policy_gradient_loss | -1.87e-07 |\n",
      "|    reward               | 6.2244625 |\n",
      "|    value_loss           | 1.81e+06  |\n",
      "---------------------------------------\n",
      "Episode: 512\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1967982.96\n",
      "total_reward: 967982.96\n",
      "total_cost: 1779426.75\n",
      "total_trades: 1022\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 988           |\n",
      "|    time_elapsed         | 3982          |\n",
      "|    total_timesteps      | 1011712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6185804e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.93e+04      |\n",
      "|    n_updates            | 35100         |\n",
      "|    policy_gradient_loss | -2.21e-05     |\n",
      "|    reward               | -30.678928    |\n",
      "|    value_loss           | 1.19e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 513\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 989           |\n",
      "|    time_elapsed         | 3986          |\n",
      "|    total_timesteps      | 1012736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2935287e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.22e+04      |\n",
      "|    n_updates            | 35110         |\n",
      "|    policy_gradient_loss | -8.34e-05     |\n",
      "|    reward               | -17.819864    |\n",
      "|    value_loss           | 1.04e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 990           |\n",
      "|    time_elapsed         | 3990          |\n",
      "|    total_timesteps      | 1013760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2916432e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.81e+05      |\n",
      "|    n_updates            | 35120         |\n",
      "|    policy_gradient_loss | 8.14e-05      |\n",
      "|    reward               | -58.39949     |\n",
      "|    value_loss           | 3.62e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 991           |\n",
      "|    time_elapsed         | 3994          |\n",
      "|    total_timesteps      | 1014784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0506483e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.896        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.17e+05      |\n",
      "|    n_updates            | 35130         |\n",
      "|    policy_gradient_loss | 9.7e-06       |\n",
      "|    reward               | -103.25031    |\n",
      "|    value_loss           | 2.34e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 514\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 3999        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.17581e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.96e+05    |\n",
      "|    n_updates            | 35140       |\n",
      "|    policy_gradient_loss | -6.87e-06   |\n",
      "|    reward               | -34.820747  |\n",
      "|    value_loss           | 1.59e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 993           |\n",
      "|    time_elapsed         | 4003          |\n",
      "|    total_timesteps      | 1016832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5785103e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.897        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.58e+05      |\n",
      "|    n_updates            | 35150         |\n",
      "|    policy_gradient_loss | -0.000201     |\n",
      "|    reward               | -103.648346   |\n",
      "|    value_loss           | 3.16e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 515\n",
      "Episode: 516\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1527241.87\n",
      "total_reward: 527241.87\n",
      "total_cost: 149467.43\n",
      "total_trades: 137\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 994          |\n",
      "|    time_elapsed         | 4007         |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.523081e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.899       |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.28e+05     |\n",
      "|    n_updates            | 35160        |\n",
      "|    policy_gradient_loss | -0.000196    |\n",
      "|    reward               | -30.6935     |\n",
      "|    value_loss           | 1.26e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 995          |\n",
      "|    time_elapsed         | 4011         |\n",
      "|    total_timesteps      | 1018880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.163212e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.901       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.19e+05     |\n",
      "|    n_updates            | 35170        |\n",
      "|    policy_gradient_loss | -0.000109    |\n",
      "|    reward               | -22.023493   |\n",
      "|    value_loss           | 2.38e+05     |\n",
      "------------------------------------------\n",
      "Episode: 517\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 996           |\n",
      "|    time_elapsed         | 4015          |\n",
      "|    total_timesteps      | 1019904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0366901e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.901        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.09e+04      |\n",
      "|    n_updates            | 35180         |\n",
      "|    policy_gradient_loss | 3.6e-05       |\n",
      "|    reward               | -0.34         |\n",
      "|    value_loss           | 1.22e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 997           |\n",
      "|    time_elapsed         | 4019          |\n",
      "|    total_timesteps      | 1020928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7852746e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.901        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.32e+05      |\n",
      "|    n_updates            | 35190         |\n",
      "|    policy_gradient_loss | -5.94e-06     |\n",
      "|    reward               | -16.459084    |\n",
      "|    value_loss           | 6.64e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 998          |\n",
      "|    time_elapsed         | 4023         |\n",
      "|    total_timesteps      | 1021952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010018109 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.902       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.43e+03     |\n",
      "|    n_updates            | 35200        |\n",
      "|    policy_gradient_loss | -0.000578    |\n",
      "|    reward               | -86.17424    |\n",
      "|    value_loss           | 8.86e+03     |\n",
      "------------------------------------------\n",
      "Episode: 518\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 999          |\n",
      "|    time_elapsed         | 4027         |\n",
      "|    total_timesteps      | 1022976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011215548 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.905       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.15e+05     |\n",
      "|    n_updates            | 35210        |\n",
      "|    policy_gradient_loss | 0.000762     |\n",
      "|    reward               | -8.739103    |\n",
      "|    value_loss           | 8.31e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1000          |\n",
      "|    time_elapsed         | 4031          |\n",
      "|    total_timesteps      | 1024000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013405347 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.906        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.46e+05      |\n",
      "|    n_updates            | 35220         |\n",
      "|    policy_gradient_loss | 9.62e-05      |\n",
      "|    reward               | -12.617151    |\n",
      "|    value_loss           | 1.69e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1001          |\n",
      "|    time_elapsed         | 4036          |\n",
      "|    total_timesteps      | 1025024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014322624 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.908        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.45e+04      |\n",
      "|    n_updates            | 35230         |\n",
      "|    policy_gradient_loss | -0.000116     |\n",
      "|    reward               | -53.02021     |\n",
      "|    value_loss           | 2.89e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 519\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1002          |\n",
      "|    time_elapsed         | 4040          |\n",
      "|    total_timesteps      | 1026048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014814007 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.68e+05      |\n",
      "|    n_updates            | 35240         |\n",
      "|    policy_gradient_loss | -0.000586     |\n",
      "|    reward               | -32.557007    |\n",
      "|    value_loss           | 3.36e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 520\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699263.20\n",
      "total_reward: -300736.80\n",
      "total_cost: 547933.82\n",
      "total_trades: 585\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1003          |\n",
      "|    time_elapsed         | 4044          |\n",
      "|    total_timesteps      | 1027072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9466075e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.914        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.39e+05      |\n",
      "|    n_updates            | 35250         |\n",
      "|    policy_gradient_loss | -6.61e-05     |\n",
      "|    reward               | 11.362211     |\n",
      "|    value_loss           | 6.79e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1004         |\n",
      "|    time_elapsed         | 4048         |\n",
      "|    total_timesteps      | 1028096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.468835e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.958       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.93e+05     |\n",
      "|    n_updates            | 35260        |\n",
      "|    policy_gradient_loss | -1.9e-06     |\n",
      "|    reward               | 81.75924     |\n",
      "|    value_loss           | 3.87e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1005         |\n",
      "|    time_elapsed         | 4052         |\n",
      "|    total_timesteps      | 1029120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.373754e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.953       |\n",
      "|    explained_variance   | -1.49        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.34e+05     |\n",
      "|    n_updates            | 35270        |\n",
      "|    policy_gradient_loss | -2.03e-05    |\n",
      "|    reward               | 36.286354    |\n",
      "|    value_loss           | 1.07e+06     |\n",
      "------------------------------------------\n",
      "Episode: 521\n",
      "Episode: 522\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1006          |\n",
      "|    time_elapsed         | 4057          |\n",
      "|    total_timesteps      | 1030144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5320256e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.916        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.21e+05      |\n",
      "|    n_updates            | 35280         |\n",
      "|    policy_gradient_loss | 2.13e-06      |\n",
      "|    reward               | 5.2841725     |\n",
      "|    value_loss           | 8.43e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 4061         |\n",
      "|    total_timesteps      | 1031168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.306762e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.916       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.83e+06     |\n",
      "|    n_updates            | 35290        |\n",
      "|    policy_gradient_loss | -4.83e-06    |\n",
      "|    reward               | -28.93038    |\n",
      "|    value_loss           | 5.65e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1008         |\n",
      "|    time_elapsed         | 4065         |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.176559e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.916       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.35e+04     |\n",
      "|    n_updates            | 35300        |\n",
      "|    policy_gradient_loss | -1.34e-05    |\n",
      "|    reward               | -2.9227812   |\n",
      "|    value_loss           | 6.71e+04     |\n",
      "------------------------------------------\n",
      "Episode: 523\n",
      "Episode: 524\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698322.55\n",
      "total_reward: -301677.45\n",
      "total_cost: 153474.21\n",
      "total_trades: 179\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1009         |\n",
      "|    time_elapsed         | 4069         |\n",
      "|    total_timesteps      | 1033216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.194153e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.917       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.83e+04     |\n",
      "|    n_updates            | 35310        |\n",
      "|    policy_gradient_loss | -3.93e-05    |\n",
      "|    reward               | -4.654744    |\n",
      "|    value_loss           | 1.37e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1010         |\n",
      "|    time_elapsed         | 4074         |\n",
      "|    total_timesteps      | 1034240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.066162e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.918       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.22e+04     |\n",
      "|    n_updates            | 35320        |\n",
      "|    policy_gradient_loss | 1.7e-05      |\n",
      "|    reward               | 94.37053     |\n",
      "|    value_loss           | 1.25e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1011         |\n",
      "|    time_elapsed         | 4078         |\n",
      "|    total_timesteps      | 1035264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.553469e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.918       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.18e+05     |\n",
      "|    n_updates            | 35330        |\n",
      "|    policy_gradient_loss | -7.67e-05    |\n",
      "|    reward               | 103.82586    |\n",
      "|    value_loss           | 4.35e+05     |\n",
      "------------------------------------------\n",
      "Episode: 525\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1012         |\n",
      "|    time_elapsed         | 4082         |\n",
      "|    total_timesteps      | 1036288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.457892e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.918       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.93e+06     |\n",
      "|    n_updates            | 35340        |\n",
      "|    policy_gradient_loss | 3.48e-05     |\n",
      "|    reward               | -4.250052    |\n",
      "|    value_loss           | 3.86e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1013          |\n",
      "|    time_elapsed         | 4086          |\n",
      "|    total_timesteps      | 1037312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7415808e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.918        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.1e+05       |\n",
      "|    n_updates            | 35350         |\n",
      "|    policy_gradient_loss | 1.33e-06      |\n",
      "|    reward               | -8.920701     |\n",
      "|    value_loss           | 1.22e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 526\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1014         |\n",
      "|    time_elapsed         | 4090         |\n",
      "|    total_timesteps      | 1038336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015574401 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.923       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 35360        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | -15.397413   |\n",
      "|    value_loss           | 3.63e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1015          |\n",
      "|    time_elapsed         | 4095          |\n",
      "|    total_timesteps      | 1039360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054388423 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.929        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.29e+04      |\n",
      "|    n_updates            | 35370         |\n",
      "|    policy_gradient_loss | -0.000707     |\n",
      "|    reward               | -43.410084    |\n",
      "|    value_loss           | 4.58e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 527\n",
      "Episode: 528\n",
      "Current company: ['DOW']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 656487.75\n",
      "total_reward: -343512.25\n",
      "total_cost: 22199.39\n",
      "total_trades: 23\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1016         |\n",
      "|    time_elapsed         | 4099         |\n",
      "|    total_timesteps      | 1040384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001543943 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.99e+04     |\n",
      "|    n_updates            | 35380        |\n",
      "|    policy_gradient_loss | -8.17e-05    |\n",
      "|    reward               | -5.0035014   |\n",
      "|    value_loss           | 2e+05        |\n",
      "------------------------------------------\n",
      "Episode: 529\n",
      "Episode: 530\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1017          |\n",
      "|    time_elapsed         | 4103          |\n",
      "|    total_timesteps      | 1041408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4401041e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.53e+05      |\n",
      "|    n_updates            | 35390         |\n",
      "|    policy_gradient_loss | 5.05e-05      |\n",
      "|    reward               | -28.721704    |\n",
      "|    value_loss           | 7.07e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 531\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1018          |\n",
      "|    time_elapsed         | 4108          |\n",
      "|    total_timesteps      | 1042432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5271362e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.68e+04      |\n",
      "|    n_updates            | 35400         |\n",
      "|    policy_gradient_loss | -3.25e-07     |\n",
      "|    reward               | 22.0897       |\n",
      "|    value_loss           | 3.37e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1019          |\n",
      "|    time_elapsed         | 4111          |\n",
      "|    total_timesteps      | 1043456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4101563e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.932        |\n",
      "|    explained_variance   | -0.000124     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.34e+05      |\n",
      "|    n_updates            | 35410         |\n",
      "|    policy_gradient_loss | -6.54e-05     |\n",
      "|    reward               | 176.41081     |\n",
      "|    value_loss           | 6.68e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1020         |\n",
      "|    time_elapsed         | 4115         |\n",
      "|    total_timesteps      | 1044480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.760835e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.0185      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.21e+06     |\n",
      "|    n_updates            | 35420        |\n",
      "|    policy_gradient_loss | 2.26e-06     |\n",
      "|    reward               | 185.5107     |\n",
      "|    value_loss           | 2.45e+06     |\n",
      "------------------------------------------\n",
      "Episode: 532\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4917332.70\n",
      "total_reward: 3917332.70\n",
      "total_cost: 2000063.64\n",
      "total_trades: 853\n",
      "=================================\n",
      "Episode: 533\n",
      "Episode: 534\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1021          |\n",
      "|    time_elapsed         | 4120          |\n",
      "|    total_timesteps      | 1045504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1723175e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.276        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.09e+06      |\n",
      "|    n_updates            | 35430         |\n",
      "|    policy_gradient_loss | 1.92e-06      |\n",
      "|    reward               | -6.6609154    |\n",
      "|    value_loss           | 8.23e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1022          |\n",
      "|    time_elapsed         | 4125          |\n",
      "|    total_timesteps      | 1046528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5291305e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.966        |\n",
      "|    explained_variance   | 0.313         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.88e+06      |\n",
      "|    n_updates            | 35440         |\n",
      "|    policy_gradient_loss | -1.32e-05     |\n",
      "|    reward               | -21.365612    |\n",
      "|    value_loss           | 3.77e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1023         |\n",
      "|    time_elapsed         | 4129         |\n",
      "|    total_timesteps      | 1047552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.097637e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.932       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.7e+04      |\n",
      "|    n_updates            | 35450        |\n",
      "|    policy_gradient_loss | -2.52e-05    |\n",
      "|    reward               | -86.52635    |\n",
      "|    value_loss           | 3.4e+04      |\n",
      "------------------------------------------\n",
      "Episode: 535\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1024         |\n",
      "|    time_elapsed         | 4133         |\n",
      "|    total_timesteps      | 1048576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.660586e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.931       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.78e+05     |\n",
      "|    n_updates            | 35460        |\n",
      "|    policy_gradient_loss | -3.84e-05    |\n",
      "|    reward               | -3.7346053   |\n",
      "|    value_loss           | 5.57e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1025          |\n",
      "|    time_elapsed         | 4137          |\n",
      "|    total_timesteps      | 1049600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4266698e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.8e+05       |\n",
      "|    n_updates            | 35470         |\n",
      "|    policy_gradient_loss | -1.44e-06     |\n",
      "|    reward               | -7.517912     |\n",
      "|    value_loss           | 7.64e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 253            |\n",
      "|    iterations           | 1026           |\n",
      "|    time_elapsed         | 4141           |\n",
      "|    total_timesteps      | 1050624        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.01944315e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.93          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 2.47e+04       |\n",
      "|    n_updates            | 35480          |\n",
      "|    policy_gradient_loss | -6.31e-05      |\n",
      "|    reward               | -76.41334      |\n",
      "|    value_loss           | 4.93e+04       |\n",
      "--------------------------------------------\n",
      "Episode: 536\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1139975.54\n",
      "total_reward: 139975.54\n",
      "total_cost: 1485721.94\n",
      "total_trades: 1153\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1027          |\n",
      "|    time_elapsed         | 4145          |\n",
      "|    total_timesteps      | 1051648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4355755e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.22e+05      |\n",
      "|    n_updates            | 35490         |\n",
      "|    policy_gradient_loss | -2.77e-05     |\n",
      "|    reward               | -50.32342     |\n",
      "|    value_loss           | 4.45e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 537\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1028         |\n",
      "|    time_elapsed         | 4150         |\n",
      "|    total_timesteps      | 1052672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.272698e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.931       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.69e+04     |\n",
      "|    n_updates            | 35500        |\n",
      "|    policy_gradient_loss | -7.27e-05    |\n",
      "|    reward               | -44.399265   |\n",
      "|    value_loss           | 1.14e+05     |\n",
      "------------------------------------------\n",
      "Episode: 538\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1029          |\n",
      "|    time_elapsed         | 4154          |\n",
      "|    total_timesteps      | 1053696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4544075e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.929        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.84e+05      |\n",
      "|    n_updates            | 35510         |\n",
      "|    policy_gradient_loss | -0.000108     |\n",
      "|    reward               | -40.28674     |\n",
      "|    value_loss           | 3.67e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 539\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1030          |\n",
      "|    time_elapsed         | 4158          |\n",
      "|    total_timesteps      | 1054720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9004801e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.928        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.94e+04      |\n",
      "|    n_updates            | 35520         |\n",
      "|    policy_gradient_loss | -8.1e-05      |\n",
      "|    reward               | 1.8528436     |\n",
      "|    value_loss           | 9.89e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 540\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693288.33\n",
      "total_reward: -306711.67\n",
      "total_cost: 53441.26\n",
      "total_trades: 53\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1031         |\n",
      "|    time_elapsed         | 4163         |\n",
      "|    total_timesteps      | 1055744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.157323e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.3e+05      |\n",
      "|    n_updates            | 35530        |\n",
      "|    policy_gradient_loss | 1.84e-05     |\n",
      "|    reward               | -48.92268    |\n",
      "|    value_loss           | 1.06e+06     |\n",
      "------------------------------------------\n",
      "Episode: 541\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 4167         |\n",
      "|    total_timesteps      | 1056768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.792601e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.97e+04     |\n",
      "|    n_updates            | 35540        |\n",
      "|    policy_gradient_loss | -2.92e-05    |\n",
      "|    reward               | -24.17673    |\n",
      "|    value_loss           | 7.95e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1033          |\n",
      "|    time_elapsed         | 4171          |\n",
      "|    total_timesteps      | 1057792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2958266e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.926        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01e+05      |\n",
      "|    n_updates            | 35550         |\n",
      "|    policy_gradient_loss | -9.81e-06     |\n",
      "|    reward               | 26.073748     |\n",
      "|    value_loss           | 2.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 542\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1034          |\n",
      "|    time_elapsed         | 4175          |\n",
      "|    total_timesteps      | 1058816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040609424 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.06e+04      |\n",
      "|    n_updates            | 35560         |\n",
      "|    policy_gradient_loss | -0.000684     |\n",
      "|    reward               | -16.327707    |\n",
      "|    value_loss           | 6.12e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 543\n",
      "Episode: 544\n",
      "Current company: ['V']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699078.94\n",
      "total_reward: -300921.06\n",
      "total_cost: 122068.52\n",
      "total_trades: 131\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1035         |\n",
      "|    time_elapsed         | 4180         |\n",
      "|    total_timesteps      | 1059840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003687716 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.942       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.86e+06     |\n",
      "|    n_updates            | 35570        |\n",
      "|    policy_gradient_loss | -0.000762    |\n",
      "|    reward               | 30.225927    |\n",
      "|    value_loss           | 3.72e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1036          |\n",
      "|    time_elapsed         | 4184          |\n",
      "|    total_timesteps      | 1060864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4968543e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.994        |\n",
      "|    explained_variance   | 0.84          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.74e+04      |\n",
      "|    n_updates            | 35580         |\n",
      "|    policy_gradient_loss | -0.000229     |\n",
      "|    reward               | -22.418596    |\n",
      "|    value_loss           | 9.57e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1037         |\n",
      "|    time_elapsed         | 4188         |\n",
      "|    total_timesteps      | 1061888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.209535e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.969       |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.24e+05     |\n",
      "|    n_updates            | 35590        |\n",
      "|    policy_gradient_loss | -5.83e-06    |\n",
      "|    reward               | -72.57921    |\n",
      "|    value_loss           | 2.48e+05     |\n",
      "------------------------------------------\n",
      "Episode: 545\n",
      "Episode: 546\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1038          |\n",
      "|    time_elapsed         | 4192          |\n",
      "|    total_timesteps      | 1062912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6292553e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.951        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.78e+05      |\n",
      "|    n_updates            | 35600         |\n",
      "|    policy_gradient_loss | 7.06e-06      |\n",
      "|    reward               | -16.827623    |\n",
      "|    value_loss           | 5.56e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1039          |\n",
      "|    time_elapsed         | 4196          |\n",
      "|    total_timesteps      | 1063936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9650906e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.952        |\n",
      "|    explained_variance   | 0.00723       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.39e+05      |\n",
      "|    n_updates            | 35610         |\n",
      "|    policy_gradient_loss | -2.04e-06     |\n",
      "|    reward               | -3.231334     |\n",
      "|    value_loss           | 4.78e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1040         |\n",
      "|    time_elapsed         | 4200         |\n",
      "|    total_timesteps      | 1064960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.615898e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.06e+04     |\n",
      "|    n_updates            | 35620        |\n",
      "|    policy_gradient_loss | -8.75e-06    |\n",
      "|    reward               | -81.3159     |\n",
      "|    value_loss           | 8.14e+04     |\n",
      "------------------------------------------\n",
      "Episode: 547\n",
      "Episode: 548\n",
      "Current company: ['DOW']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 631800.36\n",
      "total_reward: -368199.64\n",
      "total_cost: 13377.29\n",
      "total_trades: 15\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1041         |\n",
      "|    time_elapsed         | 4205         |\n",
      "|    total_timesteps      | 1065984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.421912e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.41e+05     |\n",
      "|    n_updates            | 35630        |\n",
      "|    policy_gradient_loss | -1.65e-05    |\n",
      "|    reward               | -33.92399    |\n",
      "|    value_loss           | 4.83e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1042          |\n",
      "|    time_elapsed         | 4209          |\n",
      "|    total_timesteps      | 1067008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3257959e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.951        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.5e+05       |\n",
      "|    n_updates            | 35640         |\n",
      "|    policy_gradient_loss | -2.35e-05     |\n",
      "|    reward               | -71.37608     |\n",
      "|    value_loss           | 7e+05         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1043         |\n",
      "|    time_elapsed         | 4213         |\n",
      "|    total_timesteps      | 1068032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.325396e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.952       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.88e+05     |\n",
      "|    n_updates            | 35650        |\n",
      "|    policy_gradient_loss | 6.7e-07      |\n",
      "|    reward               | -67.23313    |\n",
      "|    value_loss           | 5.76e+05     |\n",
      "------------------------------------------\n",
      "Episode: 549\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1044          |\n",
      "|    time_elapsed         | 4217          |\n",
      "|    total_timesteps      | 1069056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9604645e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.952        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.31e+05      |\n",
      "|    n_updates            | 35660         |\n",
      "|    policy_gradient_loss | 2.83e-07      |\n",
      "|    reward               | -27.487007    |\n",
      "|    value_loss           | 1.06e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1045         |\n",
      "|    time_elapsed         | 4222         |\n",
      "|    total_timesteps      | 1070080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.945899e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.952       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.25e+04     |\n",
      "|    n_updates            | 35670        |\n",
      "|    policy_gradient_loss | -0.000172    |\n",
      "|    reward               | -25.907356   |\n",
      "|    value_loss           | 6.5e+04      |\n",
      "------------------------------------------\n",
      "Episode: 550\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1046         |\n",
      "|    time_elapsed         | 4226         |\n",
      "|    total_timesteps      | 1071104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.739277e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.952       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.46e+04     |\n",
      "|    n_updates            | 35680        |\n",
      "|    policy_gradient_loss | -5.91e-05    |\n",
      "|    reward               | 66.14488     |\n",
      "|    value_loss           | 1.49e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1047          |\n",
      "|    time_elapsed         | 4229          |\n",
      "|    total_timesteps      | 1072128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7752696e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | -0.000348     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.13e+05      |\n",
      "|    n_updates            | 35690         |\n",
      "|    policy_gradient_loss | -5.31e-05     |\n",
      "|    reward               | 58.699017     |\n",
      "|    value_loss           | 4.27e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1048          |\n",
      "|    time_elapsed         | 4233          |\n",
      "|    total_timesteps      | 1073152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5901169e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -0.0236       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.62e+05      |\n",
      "|    n_updates            | 35700         |\n",
      "|    policy_gradient_loss | -2.12e-05     |\n",
      "|    reward               | 86.68797      |\n",
      "|    value_loss           | 7.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 551\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1049          |\n",
      "|    time_elapsed         | 4237          |\n",
      "|    total_timesteps      | 1074176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2349919e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.816        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+06      |\n",
      "|    n_updates            | 35710         |\n",
      "|    policy_gradient_loss | -6.84e-06     |\n",
      "|    reward               | 9.501094      |\n",
      "|    value_loss           | 2.16e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1050         |\n",
      "|    time_elapsed         | 4241         |\n",
      "|    total_timesteps      | 1075200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.211914e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.992       |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.36e+05     |\n",
      "|    n_updates            | 35720        |\n",
      "|    policy_gradient_loss | -3.43e-05    |\n",
      "|    reward               | 13.877608    |\n",
      "|    value_loss           | 6.81e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1051          |\n",
      "|    time_elapsed         | 4246          |\n",
      "|    total_timesteps      | 1076224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7654536e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.93e+04      |\n",
      "|    n_updates            | 35730         |\n",
      "|    policy_gradient_loss | -8.53e-06     |\n",
      "|    reward               | -90.65648     |\n",
      "|    value_loss           | 4.07e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 552\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 901486.38\n",
      "total_reward: -98513.62\n",
      "total_cost: 1583421.94\n",
      "total_trades: 1177\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1052          |\n",
      "|    time_elapsed         | 4250          |\n",
      "|    total_timesteps      | 1077248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5017577e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.22e+05      |\n",
      "|    n_updates            | 35740         |\n",
      "|    policy_gradient_loss | -2.59e-05     |\n",
      "|    reward               | -36.958168    |\n",
      "|    value_loss           | 4.45e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1053          |\n",
      "|    time_elapsed         | 4254          |\n",
      "|    total_timesteps      | 1078272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7144655e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.12e+04      |\n",
      "|    n_updates            | 35750         |\n",
      "|    policy_gradient_loss | -0.000173     |\n",
      "|    reward               | -75.875084    |\n",
      "|    value_loss           | 6.29e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 553\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1054          |\n",
      "|    time_elapsed         | 4258          |\n",
      "|    total_timesteps      | 1079296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4728284e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.947        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.15e+05      |\n",
      "|    n_updates            | 35760         |\n",
      "|    policy_gradient_loss | 4.18e-05      |\n",
      "|    reward               | -0.9303254    |\n",
      "|    value_loss           | 8.31e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1055         |\n",
      "|    time_elapsed         | 4262         |\n",
      "|    total_timesteps      | 1080320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.853355e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.946       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.79e+05     |\n",
      "|    n_updates            | 35770        |\n",
      "|    policy_gradient_loss | -3.89e-06    |\n",
      "|    reward               | -52.980003   |\n",
      "|    value_loss           | 9.57e+05     |\n",
      "------------------------------------------\n",
      "Episode: 554\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1056          |\n",
      "|    time_elapsed         | 4266          |\n",
      "|    total_timesteps      | 1081344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5620912e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.09e+04      |\n",
      "|    n_updates            | 35780         |\n",
      "|    policy_gradient_loss | -3.76e-05     |\n",
      "|    reward               | -8.694229     |\n",
      "|    value_loss           | 1.42e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1057          |\n",
      "|    time_elapsed         | 4271          |\n",
      "|    total_timesteps      | 1082368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4602126e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.947        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.12e+05      |\n",
      "|    n_updates            | 35790         |\n",
      "|    policy_gradient_loss | -1.95e-06     |\n",
      "|    reward               | -50.808823    |\n",
      "|    value_loss           | 8.25e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 555\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1058         |\n",
      "|    time_elapsed         | 4275         |\n",
      "|    total_timesteps      | 1083392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.192903e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.948       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.27e+04     |\n",
      "|    n_updates            | 35800        |\n",
      "|    policy_gradient_loss | -7.53e-05    |\n",
      "|    reward               | -33.384518   |\n",
      "|    value_loss           | 1.26e+05     |\n",
      "------------------------------------------\n",
      "Episode: 556\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 682636.46\n",
      "total_reward: -317363.54\n",
      "total_cost: 221754.57\n",
      "total_trades: 235\n",
      "=================================\n",
      "Episode: 557\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1059         |\n",
      "|    time_elapsed         | 4279         |\n",
      "|    total_timesteps      | 1084416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.167641e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3e+05        |\n",
      "|    n_updates            | 35810        |\n",
      "|    policy_gradient_loss | 3.32e-05     |\n",
      "|    reward               | -30.327066   |\n",
      "|    value_loss           | 6.01e+05     |\n",
      "------------------------------------------\n",
      "Episode: 558\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1060         |\n",
      "|    time_elapsed         | 4283         |\n",
      "|    total_timesteps      | 1085440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.679539e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.8e+04      |\n",
      "|    n_updates            | 35820        |\n",
      "|    policy_gradient_loss | -2.04e-05    |\n",
      "|    reward               | 37.323387    |\n",
      "|    value_loss           | 5.62e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1061          |\n",
      "|    time_elapsed         | 4287          |\n",
      "|    total_timesteps      | 1086464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4938414e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.969        |\n",
      "|    explained_variance   | 0.756         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.02e+05      |\n",
      "|    n_updates            | 35830         |\n",
      "|    policy_gradient_loss | -1.03e-05     |\n",
      "|    reward               | 87.546814     |\n",
      "|    value_loss           | 4.06e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1062          |\n",
      "|    time_elapsed         | 4292          |\n",
      "|    total_timesteps      | 1087488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1886157e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.993        |\n",
      "|    explained_variance   | -1.23         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.3e+06       |\n",
      "|    n_updates            | 35840         |\n",
      "|    policy_gradient_loss | -9.93e-06     |\n",
      "|    reward               | 80.92305      |\n",
      "|    value_loss           | 2.6e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 559\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1063          |\n",
      "|    time_elapsed         | 4296          |\n",
      "|    total_timesteps      | 1088512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3125828e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.948        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.3e+05       |\n",
      "|    n_updates            | 35850         |\n",
      "|    policy_gradient_loss | -3.97e-06     |\n",
      "|    reward               | -30.288677    |\n",
      "|    value_loss           | 1.86e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 560\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 692876.08\n",
      "total_reward: -307123.92\n",
      "total_cost: 337835.09\n",
      "total_trades: 417\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 253         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 4300        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.67177e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.948      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.2e+06     |\n",
      "|    n_updates            | 35860       |\n",
      "|    policy_gradient_loss | -7.34e-07   |\n",
      "|    reward               | -10.703047  |\n",
      "|    value_loss           | 2.39e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1065         |\n",
      "|    time_elapsed         | 4304         |\n",
      "|    total_timesteps      | 1090560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.757335e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.948       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.39e+05     |\n",
      "|    n_updates            | 35870        |\n",
      "|    policy_gradient_loss | -1.66e-05    |\n",
      "|    reward               | 20.571566    |\n",
      "|    value_loss           | 2.79e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1066          |\n",
      "|    time_elapsed         | 4308          |\n",
      "|    total_timesteps      | 1091584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.5320713e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.947        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.84e+04      |\n",
      "|    n_updates            | 35880         |\n",
      "|    policy_gradient_loss | -7.45e-06     |\n",
      "|    reward               | -32.66568     |\n",
      "|    value_loss           | 1.77e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 561\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1067          |\n",
      "|    time_elapsed         | 4312          |\n",
      "|    total_timesteps      | 1092608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0745385e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.947        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.19e+04      |\n",
      "|    n_updates            | 35890         |\n",
      "|    policy_gradient_loss | -6.81e-05     |\n",
      "|    reward               | -14.993978    |\n",
      "|    value_loss           | 1.64e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1068          |\n",
      "|    time_elapsed         | 4317          |\n",
      "|    total_timesteps      | 1093632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1119293e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.73e+04      |\n",
      "|    n_updates            | 35900         |\n",
      "|    policy_gradient_loss | 8.14e-06      |\n",
      "|    reward               | -30.55766     |\n",
      "|    value_loss           | 5.45e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 562\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1069          |\n",
      "|    time_elapsed         | 4321          |\n",
      "|    total_timesteps      | 1094656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1311293e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.944        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.37e+04      |\n",
      "|    n_updates            | 35910         |\n",
      "|    policy_gradient_loss | -8.91e-05     |\n",
      "|    reward               | -8.67609      |\n",
      "|    value_loss           | 6.75e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1070          |\n",
      "|    time_elapsed         | 4325          |\n",
      "|    total_timesteps      | 1095680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5136625e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.942        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.01e+05      |\n",
      "|    n_updates            | 35920         |\n",
      "|    policy_gradient_loss | -2.54e-05     |\n",
      "|    reward               | -38.61102     |\n",
      "|    value_loss           | 8.02e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 563\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1071          |\n",
      "|    time_elapsed         | 4330          |\n",
      "|    total_timesteps      | 1096704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6526624e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.94         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.8e+04       |\n",
      "|    n_updates            | 35930         |\n",
      "|    policy_gradient_loss | -0.000101     |\n",
      "|    reward               | 19.945068     |\n",
      "|    value_loss           | 7.61e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1072          |\n",
      "|    time_elapsed         | 4335          |\n",
      "|    total_timesteps      | 1097728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.1929535e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.84e+05      |\n",
      "|    n_updates            | 35940         |\n",
      "|    policy_gradient_loss | -2.16e-05     |\n",
      "|    reward               | -48.62757     |\n",
      "|    value_loss           | 3.68e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 564\n",
      "Current company: ['HON']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697681.61\n",
      "total_reward: -302318.39\n",
      "total_cost: 1135324.34\n",
      "total_trades: 1095\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1073         |\n",
      "|    time_elapsed         | 4339         |\n",
      "|    total_timesteps      | 1098752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.668518e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.09e+04     |\n",
      "|    n_updates            | 35950        |\n",
      "|    policy_gradient_loss | -0.000286    |\n",
      "|    reward               | -8.561683    |\n",
      "|    value_loss           | 1.22e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1074         |\n",
      "|    time_elapsed         | 4343         |\n",
      "|    total_timesteps      | 1099776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.739233e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.934       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.08e+05     |\n",
      "|    n_updates            | 35960        |\n",
      "|    policy_gradient_loss | -7.81e-05    |\n",
      "|    reward               | -46.8476     |\n",
      "|    value_loss           | 1.42e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1075          |\n",
      "|    time_elapsed         | 4347          |\n",
      "|    total_timesteps      | 1100800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3899466e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.933        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.05e+04      |\n",
      "|    n_updates            | 35970         |\n",
      "|    policy_gradient_loss | -5.97e-05     |\n",
      "|    reward               | -104.01994    |\n",
      "|    value_loss           | 1.41e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 565\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1076          |\n",
      "|    time_elapsed         | 4351          |\n",
      "|    total_timesteps      | 1101824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1394732e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.71e+05      |\n",
      "|    n_updates            | 35980         |\n",
      "|    policy_gradient_loss | -0.000173     |\n",
      "|    reward               | -63.12747     |\n",
      "|    value_loss           | 1.15e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 566\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1077          |\n",
      "|    time_elapsed         | 4355          |\n",
      "|    total_timesteps      | 1102848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2510067e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.41e+05      |\n",
      "|    n_updates            | 35990         |\n",
      "|    policy_gradient_loss | 1.43e-06      |\n",
      "|    reward               | -55.41962     |\n",
      "|    value_loss           | 4.83e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 567\n",
      "Episode: 568\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697623.90\n",
      "total_reward: -302376.10\n",
      "total_cost: 110332.41\n",
      "total_trades: 125\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1078          |\n",
      "|    time_elapsed         | 4360          |\n",
      "|    total_timesteps      | 1103872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6350532e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.24e+05      |\n",
      "|    n_updates            | 36000         |\n",
      "|    policy_gradient_loss | -3.3e-06      |\n",
      "|    reward               | -38.914955    |\n",
      "|    value_loss           | 2.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 569\n",
      "Episode: 570\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1079          |\n",
      "|    time_elapsed         | 4364          |\n",
      "|    total_timesteps      | 1104896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7576967e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.86e+05      |\n",
      "|    n_updates            | 36010         |\n",
      "|    policy_gradient_loss | -2.91e-05     |\n",
      "|    reward               | -0.56         |\n",
      "|    value_loss           | 3.75e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1080          |\n",
      "|    time_elapsed         | 4368          |\n",
      "|    total_timesteps      | 1105920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5467016e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.929        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+05      |\n",
      "|    n_updates            | 36020         |\n",
      "|    policy_gradient_loss | -1.63e-05     |\n",
      "|    reward               | 9.197762      |\n",
      "|    value_loss           | 2.88e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1081         |\n",
      "|    time_elapsed         | 4372         |\n",
      "|    total_timesteps      | 1106944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011136411 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.15e+04     |\n",
      "|    n_updates            | 36030        |\n",
      "|    policy_gradient_loss | -0.000569    |\n",
      "|    reward               | 32.854813    |\n",
      "|    value_loss           | 6.31e+04     |\n",
      "------------------------------------------\n",
      "Episode: 571\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1082         |\n",
      "|    time_elapsed         | 4376         |\n",
      "|    total_timesteps      | 1107968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030236375 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.97        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.1e+04      |\n",
      "|    n_updates            | 36040        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | -20.927338   |\n",
      "|    value_loss           | 8.2e+04      |\n",
      "------------------------------------------\n",
      "Episode: 572\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699235.46\n",
      "total_reward: -300764.54\n",
      "total_cost: 416271.67\n",
      "total_trades: 499\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1083         |\n",
      "|    time_elapsed         | 4381         |\n",
      "|    total_timesteps      | 1108992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008861988 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.982       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.92e+05     |\n",
      "|    n_updates            | 36050        |\n",
      "|    policy_gradient_loss | 0.000786     |\n",
      "|    reward               | -14.975046   |\n",
      "|    value_loss           | 3.84e+05     |\n",
      "------------------------------------------\n",
      "Episode: 573\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1084         |\n",
      "|    time_elapsed         | 4385         |\n",
      "|    total_timesteps      | 1110016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.892267e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.981       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.19e+05     |\n",
      "|    n_updates            | 36060        |\n",
      "|    policy_gradient_loss | 6.39e-05     |\n",
      "|    reward               | -12.871291   |\n",
      "|    value_loss           | 4.39e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1085         |\n",
      "|    time_elapsed         | 4389         |\n",
      "|    total_timesteps      | 1111040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013933373 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.98        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.37e+03     |\n",
      "|    n_updates            | 36070        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | -75.0185     |\n",
      "|    value_loss           | 1.68e+04     |\n",
      "------------------------------------------\n",
      "Episode: 574\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1086         |\n",
      "|    time_elapsed         | 4394         |\n",
      "|    total_timesteps      | 1112064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013898457 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.978       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.93e+05     |\n",
      "|    n_updates            | 36080        |\n",
      "|    policy_gradient_loss | 0.00067      |\n",
      "|    reward               | -26.151213   |\n",
      "|    value_loss           | 3.86e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1087          |\n",
      "|    time_elapsed         | 4398          |\n",
      "|    total_timesteps      | 1113088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019486231 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.07e+05      |\n",
      "|    n_updates            | 36090         |\n",
      "|    policy_gradient_loss | -0.000629     |\n",
      "|    reward               | -30.755518    |\n",
      "|    value_loss           | 1.01e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 253          |\n",
      "|    iterations           | 1088         |\n",
      "|    time_elapsed         | 4402         |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.754208e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.54e+04     |\n",
      "|    n_updates            | 36100        |\n",
      "|    policy_gradient_loss | -1.39e-05    |\n",
      "|    reward               | -74.077225   |\n",
      "|    value_loss           | 3.09e+04     |\n",
      "------------------------------------------\n",
      "Episode: 575\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1089          |\n",
      "|    time_elapsed         | 4406          |\n",
      "|    total_timesteps      | 1115136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6586855e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.972        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4e+05         |\n",
      "|    n_updates            | 36110         |\n",
      "|    policy_gradient_loss | 5.27e-05      |\n",
      "|    reward               | -40.075237    |\n",
      "|    value_loss           | 8.01e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 576\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698939.97\n",
      "total_reward: -301060.03\n",
      "total_cost: 441314.57\n",
      "total_trades: 507\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 1090          |\n",
      "|    time_elapsed         | 4411          |\n",
      "|    total_timesteps      | 1116160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5712692e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.972        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.56e+05      |\n",
      "|    n_updates            | 36120         |\n",
      "|    policy_gradient_loss | -0.000158     |\n",
      "|    reward               | 11.949948     |\n",
      "|    value_loss           | 3.12e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1091         |\n",
      "|    time_elapsed         | 4416         |\n",
      "|    total_timesteps      | 1117184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.054513e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.97        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.55e+05     |\n",
      "|    n_updates            | 36130        |\n",
      "|    policy_gradient_loss | -1.49e-05    |\n",
      "|    reward               | -41.68512    |\n",
      "|    value_loss           | 3.1e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1092          |\n",
      "|    time_elapsed         | 4420          |\n",
      "|    total_timesteps      | 1118208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4685945e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.969        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.19e+05      |\n",
      "|    n_updates            | 36140         |\n",
      "|    policy_gradient_loss | -1.36e-05     |\n",
      "|    reward               | -115.368904   |\n",
      "|    value_loss           | 2.39e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 577\n",
      "Episode: 578\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 4424        |\n",
      "|    total_timesteps      | 1119232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.38597e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.968      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.54e+05    |\n",
      "|    n_updates            | 36150       |\n",
      "|    policy_gradient_loss | 1.18e-05    |\n",
      "|    reward               | -20.558327  |\n",
      "|    value_loss           | 7.08e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1094          |\n",
      "|    time_elapsed         | 4428          |\n",
      "|    total_timesteps      | 1120256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0259835e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.968        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.07e+05      |\n",
      "|    n_updates            | 36160         |\n",
      "|    policy_gradient_loss | -2.63e-05     |\n",
      "|    reward               | -63.068115    |\n",
      "|    value_loss           | 4.14e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 579\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1095          |\n",
      "|    time_elapsed         | 4433          |\n",
      "|    total_timesteps      | 1121280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1746458e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.968        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.13e+05      |\n",
      "|    n_updates            | 36170         |\n",
      "|    policy_gradient_loss | 2.08e-06      |\n",
      "|    reward               | -3.719122     |\n",
      "|    value_loss           | 2.26e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1096          |\n",
      "|    time_elapsed         | 4437          |\n",
      "|    total_timesteps      | 1122304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8803054e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.968        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.47e+05      |\n",
      "|    n_updates            | 36180         |\n",
      "|    policy_gradient_loss | -0.000148     |\n",
      "|    reward               | -52.423378    |\n",
      "|    value_loss           | 2.94e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 580\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1325794.85\n",
      "total_reward: 325794.85\n",
      "total_cost: 1333705.96\n",
      "total_trades: 1218\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1097         |\n",
      "|    time_elapsed         | 4441         |\n",
      "|    total_timesteps      | 1123328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.769959e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.969       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.24e+05     |\n",
      "|    n_updates            | 36190        |\n",
      "|    policy_gradient_loss | -4.21e-05    |\n",
      "|    reward               | -6.049251    |\n",
      "|    value_loss           | 2.48e+05     |\n",
      "------------------------------------------\n",
      "Episode: 581\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 4446        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.87455e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.09e+05    |\n",
      "|    n_updates            | 36200       |\n",
      "|    policy_gradient_loss | 1.49e-05    |\n",
      "|    reward               | -19.848085  |\n",
      "|    value_loss           | 6.19e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 582\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1099         |\n",
      "|    time_elapsed         | 4450         |\n",
      "|    total_timesteps      | 1125376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.721813e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.97        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.92e+04     |\n",
      "|    n_updates            | 36210        |\n",
      "|    policy_gradient_loss | -5.61e-06    |\n",
      "|    reward               | 6.713084     |\n",
      "|    value_loss           | 1.19e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 4454        |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.79907e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.04e+04    |\n",
      "|    n_updates            | 36220       |\n",
      "|    policy_gradient_loss | -2.93e-05   |\n",
      "|    reward               | -30.617575  |\n",
      "|    value_loss           | 6.09e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 583\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 4458        |\n",
      "|    total_timesteps      | 1127424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.14333e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82e+04    |\n",
      "|    n_updates            | 36230       |\n",
      "|    policy_gradient_loss | 2.34e-05    |\n",
      "|    reward               | -16.367607  |\n",
      "|    value_loss           | 9.65e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 584\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 682233.47\n",
      "total_reward: -317766.53\n",
      "total_cost: 78853.16\n",
      "total_trades: 93\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1102          |\n",
      "|    time_elapsed         | 4462          |\n",
      "|    total_timesteps      | 1128448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8999285e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.971        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.48e+05      |\n",
      "|    n_updates            | 36240         |\n",
      "|    policy_gradient_loss | -9.97e-06     |\n",
      "|    reward               | -45.756786    |\n",
      "|    value_loss           | 6.96e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 585\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1103         |\n",
      "|    time_elapsed         | 4467         |\n",
      "|    total_timesteps      | 1129472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.934286e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.971       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.79e+04     |\n",
      "|    n_updates            | 36250        |\n",
      "|    policy_gradient_loss | -3.03e-05    |\n",
      "|    reward               | -26.567247   |\n",
      "|    value_loss           | 1.36e+05     |\n",
      "------------------------------------------\n",
      "Episode: 586\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1104          |\n",
      "|    time_elapsed         | 4473          |\n",
      "|    total_timesteps      | 1130496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6849752e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.972        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.65e+05      |\n",
      "|    n_updates            | 36260         |\n",
      "|    policy_gradient_loss | -1.5e-05      |\n",
      "|    reward               | -18.593584    |\n",
      "|    value_loss           | 3.29e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 587\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1105          |\n",
      "|    time_elapsed         | 4479          |\n",
      "|    total_timesteps      | 1131520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5681372e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.972        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1e+05         |\n",
      "|    n_updates            | 36270         |\n",
      "|    policy_gradient_loss | 6.58e-06      |\n",
      "|    reward               | -4.9506583    |\n",
      "|    value_loss           | 2.01e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 588\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 685736.98\n",
      "total_reward: -314263.02\n",
      "total_cost: 464639.97\n",
      "total_trades: 507\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1106          |\n",
      "|    time_elapsed         | 4484          |\n",
      "|    total_timesteps      | 1132544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.2352275e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.972        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75e+05      |\n",
      "|    n_updates            | 36280         |\n",
      "|    policy_gradient_loss | -2.36e-05     |\n",
      "|    reward               | -3.9004776    |\n",
      "|    value_loss           | 3.5e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 589\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1107          |\n",
      "|    time_elapsed         | 4489          |\n",
      "|    total_timesteps      | 1133568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5225378e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.972        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.53e+04      |\n",
      "|    n_updates            | 36290         |\n",
      "|    policy_gradient_loss | -2.11e-05     |\n",
      "|    reward               | 16.476793     |\n",
      "|    value_loss           | 1.91e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1108         |\n",
      "|    time_elapsed         | 4494         |\n",
      "|    total_timesteps      | 1134592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.841779e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.971       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.15e+04     |\n",
      "|    n_updates            | 36300        |\n",
      "|    policy_gradient_loss | -1.92e-05    |\n",
      "|    reward               | 50.016567    |\n",
      "|    value_loss           | 1.03e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1109          |\n",
      "|    time_elapsed         | 4499          |\n",
      "|    total_timesteps      | 1135616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1030504e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.97         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.37e+05      |\n",
      "|    n_updates            | 36310         |\n",
      "|    policy_gradient_loss | 1.97e-05      |\n",
      "|    reward               | 41.36463      |\n",
      "|    value_loss           | 2.74e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 590\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1110          |\n",
      "|    time_elapsed         | 4504          |\n",
      "|    total_timesteps      | 1136640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0570664e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.97         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.69e+05      |\n",
      "|    n_updates            | 36320         |\n",
      "|    policy_gradient_loss | 5.94e-06      |\n",
      "|    reward               | -23.243753    |\n",
      "|    value_loss           | 1.34e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1111          |\n",
      "|    time_elapsed         | 4509          |\n",
      "|    total_timesteps      | 1137664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4185476e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.971        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.16e+04      |\n",
      "|    n_updates            | 36330         |\n",
      "|    policy_gradient_loss | -8.34e-05     |\n",
      "|    reward               | -77.23302     |\n",
      "|    value_loss           | 1.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 591\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1112         |\n",
      "|    time_elapsed         | 4513         |\n",
      "|    total_timesteps      | 1138688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.402779e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.05e+05     |\n",
      "|    n_updates            | 36340        |\n",
      "|    policy_gradient_loss | 1.7e-05      |\n",
      "|    reward               | -10.33284    |\n",
      "|    value_loss           | 6.09e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1113         |\n",
      "|    time_elapsed         | 4518         |\n",
      "|    total_timesteps      | 1139712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.791037e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.974       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.84e+05     |\n",
      "|    n_updates            | 36350        |\n",
      "|    policy_gradient_loss | -4.56e-05    |\n",
      "|    reward               | -53.257782   |\n",
      "|    value_loss           | 7.69e+05     |\n",
      "------------------------------------------\n",
      "Episode: 592\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694602.89\n",
      "total_reward: -305397.11\n",
      "total_cost: 661653.45\n",
      "total_trades: 709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 4522        |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.88831e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.975      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11e+04    |\n",
      "|    n_updates            | 36360       |\n",
      "|    policy_gradient_loss | -1.03e-05   |\n",
      "|    reward               | -20.048733  |\n",
      "|    value_loss           | 1.82e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1115          |\n",
      "|    time_elapsed         | 4526          |\n",
      "|    total_timesteps      | 1141760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2899982e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.25e+05      |\n",
      "|    n_updates            | 36370         |\n",
      "|    policy_gradient_loss | -1.9e-06      |\n",
      "|    reward               | -67.192726    |\n",
      "|    value_loss           | 2.5e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 593\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1116          |\n",
      "|    time_elapsed         | 4530          |\n",
      "|    total_timesteps      | 1142784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2072726e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.29e+05      |\n",
      "|    n_updates            | 36380         |\n",
      "|    policy_gradient_loss | -4.9e-05      |\n",
      "|    reward               | 0.833663      |\n",
      "|    value_loss           | 2.59e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 594\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1117         |\n",
      "|    time_elapsed         | 4534         |\n",
      "|    total_timesteps      | 1143808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.823401e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.976       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.01e+05     |\n",
      "|    n_updates            | 36390        |\n",
      "|    policy_gradient_loss | -3.58e-05    |\n",
      "|    reward               | 44.77117     |\n",
      "|    value_loss           | 1.2e+06      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1118         |\n",
      "|    time_elapsed         | 4539         |\n",
      "|    total_timesteps      | 1144832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.739306e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.04e+04     |\n",
      "|    n_updates            | 36400        |\n",
      "|    policy_gradient_loss | -1.21e-05    |\n",
      "|    reward               | -58.115173   |\n",
      "|    value_loss           | 1.63e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1119         |\n",
      "|    time_elapsed         | 4543         |\n",
      "|    total_timesteps      | 1145856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005696364 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.978       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.94e+04     |\n",
      "|    n_updates            | 36410        |\n",
      "|    policy_gradient_loss | -0.000906    |\n",
      "|    reward               | -50.49356    |\n",
      "|    value_loss           | 1.39e+05     |\n",
      "------------------------------------------\n",
      "Episode: 595\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1120         |\n",
      "|    time_elapsed         | 4547         |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005864378 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.981       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.2e+05      |\n",
      "|    n_updates            | 36420        |\n",
      "|    policy_gradient_loss | -3.76e-05    |\n",
      "|    reward               | -22.48744    |\n",
      "|    value_loss           | 4.4e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1121          |\n",
      "|    time_elapsed         | 4551          |\n",
      "|    total_timesteps      | 1147904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3399363e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.981        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.21e+04      |\n",
      "|    n_updates            | 36430         |\n",
      "|    policy_gradient_loss | -7.54e-05     |\n",
      "|    reward               | -51.34584     |\n",
      "|    value_loss           | 8.42e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 596\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1781018.46\n",
      "total_reward: 781018.46\n",
      "total_cost: 1291865.20\n",
      "total_trades: 1160\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1122          |\n",
      "|    time_elapsed         | 4555          |\n",
      "|    total_timesteps      | 1148928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014048535 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.17e+05      |\n",
      "|    n_updates            | 36440         |\n",
      "|    policy_gradient_loss | -0.0003       |\n",
      "|    reward               | -9.268963     |\n",
      "|    value_loss           | 4.34e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1123          |\n",
      "|    time_elapsed         | 4559          |\n",
      "|    total_timesteps      | 1149952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0513598e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.977        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.37e+04      |\n",
      "|    n_updates            | 36450         |\n",
      "|    policy_gradient_loss | -0.0001       |\n",
      "|    reward               | -40.99143     |\n",
      "|    value_loss           | 1.28e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 597\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1124         |\n",
      "|    time_elapsed         | 4564         |\n",
      "|    total_timesteps      | 1150976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.929353e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.977       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.08e+04     |\n",
      "|    n_updates            | 36460        |\n",
      "|    policy_gradient_loss | -8.78e-05    |\n",
      "|    reward               | -2.2557817   |\n",
      "|    value_loss           | 1.22e+05     |\n",
      "------------------------------------------\n",
      "Episode: 598\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1125         |\n",
      "|    time_elapsed         | 4568         |\n",
      "|    total_timesteps      | 1152000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.335423e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.977       |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03e+05     |\n",
      "|    n_updates            | 36470        |\n",
      "|    policy_gradient_loss | 6.12e-05     |\n",
      "|    reward               | -31.186176   |\n",
      "|    value_loss           | 8.07e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1126          |\n",
      "|    time_elapsed         | 4572          |\n",
      "|    total_timesteps      | 1153024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9826188e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.977        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.37e+04      |\n",
      "|    n_updates            | 36480         |\n",
      "|    policy_gradient_loss | -1.69e-05     |\n",
      "|    reward               | 11.218716     |\n",
      "|    value_loss           | 4.75e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 599\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1127         |\n",
      "|    time_elapsed         | 4577         |\n",
      "|    total_timesteps      | 1154048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.618737e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.976       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.26e+04     |\n",
      "|    n_updates            | 36490        |\n",
      "|    policy_gradient_loss | -0.000106    |\n",
      "|    reward               | -25.70025    |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n",
      "Episode: 600\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 642593.07\n",
      "total_reward: -357406.93\n",
      "total_cost: 153351.05\n",
      "total_trades: 189\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1128         |\n",
      "|    time_elapsed         | 4581         |\n",
      "|    total_timesteps      | 1155072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.348366e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.975       |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.73e+04     |\n",
      "|    n_updates            | 36500        |\n",
      "|    policy_gradient_loss | -0.000161    |\n",
      "|    reward               | -35.08902    |\n",
      "|    value_loss           | 1.55e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1129          |\n",
      "|    time_elapsed         | 4585          |\n",
      "|    total_timesteps      | 1156096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6690075e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.9e+04       |\n",
      "|    n_updates            | 36510         |\n",
      "|    policy_gradient_loss | -2e-05        |\n",
      "|    reward               | -89.33097     |\n",
      "|    value_loss           | 5.81e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 601\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1130          |\n",
      "|    time_elapsed         | 4589          |\n",
      "|    total_timesteps      | 1157120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8501072e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.58e+05      |\n",
      "|    n_updates            | 36520         |\n",
      "|    policy_gradient_loss | -0.000196     |\n",
      "|    reward               | -50.523216    |\n",
      "|    value_loss           | 9.17e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 252           |\n",
      "|    iterations           | 1131          |\n",
      "|    time_elapsed         | 4594          |\n",
      "|    total_timesteps      | 1158144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010800001 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.65e+04      |\n",
      "|    n_updates            | 36530         |\n",
      "|    policy_gradient_loss | -0.000488     |\n",
      "|    reward               | -52.294598    |\n",
      "|    value_loss           | 1.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 602\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1132         |\n",
      "|    time_elapsed         | 4598         |\n",
      "|    total_timesteps      | 1159168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.148727e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.58e+05     |\n",
      "|    n_updates            | 36540        |\n",
      "|    policy_gradient_loss | 8.18e-05     |\n",
      "|    reward               | -2.2109754   |\n",
      "|    value_loss           | 7.16e+05     |\n",
      "------------------------------------------\n",
      "Episode: 603\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1133         |\n",
      "|    time_elapsed         | 4602         |\n",
      "|    total_timesteps      | 1160192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002705481 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.97        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.44e+05     |\n",
      "|    n_updates            | 36550        |\n",
      "|    policy_gradient_loss | -0.000427    |\n",
      "|    reward               | -31.12311    |\n",
      "|    value_loss           | 6.87e+05     |\n",
      "------------------------------------------\n",
      "Episode: 604\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693920.78\n",
      "total_reward: -306079.22\n",
      "total_cost: 382890.51\n",
      "total_trades: 427\n",
      "=================================\n",
      "Episode: 605\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 4607         |\n",
      "|    total_timesteps      | 1161216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002740291 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.965       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.86e+04     |\n",
      "|    n_updates            | 36560        |\n",
      "|    policy_gradient_loss | -0.000105    |\n",
      "|    reward               | -2.3362653   |\n",
      "|    value_loss           | 7.73e+04     |\n",
      "------------------------------------------\n",
      "Episode: 606\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1135         |\n",
      "|    time_elapsed         | 4612         |\n",
      "|    total_timesteps      | 1162240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.693683e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.984       |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.15e+05     |\n",
      "|    n_updates            | 36570        |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    reward               | 16.740528    |\n",
      "|    value_loss           | 2.31e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1136          |\n",
      "|    time_elapsed         | 4616          |\n",
      "|    total_timesteps      | 1163264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6505248e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.995        |\n",
      "|    explained_variance   | 0.569         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.32e+04      |\n",
      "|    n_updates            | 36580         |\n",
      "|    policy_gradient_loss | 4.83e-05      |\n",
      "|    reward               | -14.616259    |\n",
      "|    value_loss           | 1.1e+05       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 4620        |\n",
      "|    total_timesteps      | 1164288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000600586 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.961      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.69e+04    |\n",
      "|    n_updates            | 36590       |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    reward               | -59.146317  |\n",
      "|    value_loss           | 3.39e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 607\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1138          |\n",
      "|    time_elapsed         | 4624          |\n",
      "|    total_timesteps      | 1165312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065917755 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.38e+05      |\n",
      "|    n_updates            | 36600         |\n",
      "|    policy_gradient_loss | 0.000171      |\n",
      "|    reward               | -21.943222    |\n",
      "|    value_loss           | 2.76e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1139          |\n",
      "|    time_elapsed         | 4628          |\n",
      "|    total_timesteps      | 1166336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8145732e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.983        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.31e+04      |\n",
      "|    n_updates            | 36610         |\n",
      "|    policy_gradient_loss | 6.53e-05      |\n",
      "|    reward               | -62.707977    |\n",
      "|    value_loss           | 1.46e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 608\n",
      "Current company: ['CAT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1090004.69\n",
      "total_reward: 90004.69\n",
      "total_cost: 1236091.03\n",
      "total_trades: 1207\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1140         |\n",
      "|    time_elapsed         | 4633         |\n",
      "|    total_timesteps      | 1167360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.193085e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.982       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.63e+05     |\n",
      "|    n_updates            | 36620        |\n",
      "|    policy_gradient_loss | 0.0001       |\n",
      "|    reward               | -0.08288565  |\n",
      "|    value_loss           | 5.26e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1141          |\n",
      "|    time_elapsed         | 4637          |\n",
      "|    total_timesteps      | 1168384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1047966e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.981        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.13e+05      |\n",
      "|    n_updates            | 36630         |\n",
      "|    policy_gradient_loss | -7.08e-06     |\n",
      "|    reward               | -39.562515    |\n",
      "|    value_loss           | 8.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 609\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1142          |\n",
      "|    time_elapsed         | 4641          |\n",
      "|    total_timesteps      | 1169408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4042168e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.982        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.84e+04      |\n",
      "|    n_updates            | 36640         |\n",
      "|    policy_gradient_loss | -1.86e-05     |\n",
      "|    reward               | -47.814972    |\n",
      "|    value_loss           | 7.69e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 610\n",
      "Episode: 611\n",
      "Episode: 612\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 668815.20\n",
      "total_reward: -331184.80\n",
      "total_cost: 48271.84\n",
      "total_trades: 49\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1143          |\n",
      "|    time_elapsed         | 4646          |\n",
      "|    total_timesteps      | 1170432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0356652e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.984        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.34e+05      |\n",
      "|    n_updates            | 36650         |\n",
      "|    policy_gradient_loss | -0.000246     |\n",
      "|    reward               | -12.00272     |\n",
      "|    value_loss           | 2.68e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1144          |\n",
      "|    time_elapsed         | 4650          |\n",
      "|    total_timesteps      | 1171456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089189433 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.988        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.83e+04      |\n",
      "|    n_updates            | 36660         |\n",
      "|    policy_gradient_loss | -0.000536     |\n",
      "|    reward               | -62.9328      |\n",
      "|    value_loss           | 5.66e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 613\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1145         |\n",
      "|    time_elapsed         | 4654         |\n",
      "|    total_timesteps      | 1172480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007684952 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.994       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51e+05     |\n",
      "|    n_updates            | 36670        |\n",
      "|    policy_gradient_loss | -0.000338    |\n",
      "|    reward               | 9.396022     |\n",
      "|    value_loss           | 3.02e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1146          |\n",
      "|    time_elapsed         | 4658          |\n",
      "|    total_timesteps      | 1173504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013380713 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.996        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.08e+05      |\n",
      "|    n_updates            | 36680         |\n",
      "|    policy_gradient_loss | -0.000444     |\n",
      "|    reward               | 5.7384543     |\n",
      "|    value_loss           | 1.22e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1147          |\n",
      "|    time_elapsed         | 4662          |\n",
      "|    total_timesteps      | 1174528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010360568 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.996        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.34e+04      |\n",
      "|    n_updates            | 36690         |\n",
      "|    policy_gradient_loss | -0.000236     |\n",
      "|    reward               | -46.63229     |\n",
      "|    value_loss           | 6.67e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 614\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1148          |\n",
      "|    time_elapsed         | 4667          |\n",
      "|    total_timesteps      | 1175552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4163276e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.998        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.14e+05      |\n",
      "|    n_updates            | 36700         |\n",
      "|    policy_gradient_loss | -4.62e-05     |\n",
      "|    reward               | -24.413168    |\n",
      "|    value_loss           | 2.29e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 615\n",
      "Episode: 616\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 675156.90\n",
      "total_reward: -324843.10\n",
      "total_cost: 37081.42\n",
      "total_trades: 39\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1149         |\n",
      "|    time_elapsed         | 4671         |\n",
      "|    total_timesteps      | 1176576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.540035e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.999       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.93e+05     |\n",
      "|    n_updates            | 36710        |\n",
      "|    policy_gradient_loss | -5.9e-05     |\n",
      "|    reward               | 2.0065963    |\n",
      "|    value_loss           | 3.87e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1150          |\n",
      "|    time_elapsed         | 4675          |\n",
      "|    total_timesteps      | 1177600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9967355e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.999        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.96e+04      |\n",
      "|    n_updates            | 36720         |\n",
      "|    policy_gradient_loss | -1.14e-05     |\n",
      "|    reward               | -70.78067     |\n",
      "|    value_loss           | 9.92e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 617\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1151          |\n",
      "|    time_elapsed         | 4680          |\n",
      "|    total_timesteps      | 1178624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4705834e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.35e+05      |\n",
      "|    n_updates            | 36730         |\n",
      "|    policy_gradient_loss | -0.000124     |\n",
      "|    reward               | -19.179811    |\n",
      "|    value_loss           | 2.71e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 618\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1152          |\n",
      "|    time_elapsed         | 4684          |\n",
      "|    total_timesteps      | 1179648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2369495e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.44e+05      |\n",
      "|    n_updates            | 36740         |\n",
      "|    policy_gradient_loss | -8.51e-06     |\n",
      "|    reward               | -33.75969     |\n",
      "|    value_loss           | 4.88e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 619\n",
      "Episode: 620\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695568.82\n",
      "total_reward: -304431.18\n",
      "total_cost: 199123.03\n",
      "total_trades: 229\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1153          |\n",
      "|    time_elapsed         | 4688          |\n",
      "|    total_timesteps      | 1180672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3822573e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.2e+05       |\n",
      "|    n_updates            | 36750         |\n",
      "|    policy_gradient_loss | -1.25e-05     |\n",
      "|    reward               | 34.210907     |\n",
      "|    value_loss           | 2.41e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1154          |\n",
      "|    time_elapsed         | 4692          |\n",
      "|    total_timesteps      | 1181696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2277818e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0.864         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.45e+04      |\n",
      "|    n_updates            | 36760         |\n",
      "|    policy_gradient_loss | 1.95e-05      |\n",
      "|    reward               | 45.38247      |\n",
      "|    value_loss           | 9.15e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1155         |\n",
      "|    time_elapsed         | 4696         |\n",
      "|    total_timesteps      | 1182720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.946502e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.77e+05     |\n",
      "|    n_updates            | 36770        |\n",
      "|    policy_gradient_loss | -1.32e-05    |\n",
      "|    reward               | -2.8844588   |\n",
      "|    value_loss           | 7.54e+05     |\n",
      "------------------------------------------\n",
      "Episode: 621\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1156         |\n",
      "|    time_elapsed         | 4701         |\n",
      "|    total_timesteps      | 1183744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.220086e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.43e+05     |\n",
      "|    n_updates            | 36780        |\n",
      "|    policy_gradient_loss | 2.54e-06     |\n",
      "|    reward               | 21.509468    |\n",
      "|    value_loss           | 4.87e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1157         |\n",
      "|    time_elapsed         | 4705         |\n",
      "|    total_timesteps      | 1184768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.245797e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.68e+04     |\n",
      "|    n_updates            | 36790        |\n",
      "|    policy_gradient_loss | -0.000118    |\n",
      "|    reward               | 76.99227     |\n",
      "|    value_loss           | 1.74e+05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 251            |\n",
      "|    iterations           | 1158           |\n",
      "|    time_elapsed         | 4709           |\n",
      "|    total_timesteps      | 1185792        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.48639665e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1             |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 5.12e+05       |\n",
      "|    n_updates            | 36800          |\n",
      "|    policy_gradient_loss | 8.82e-05       |\n",
      "|    reward               | -35.365604     |\n",
      "|    value_loss           | 1.02e+06       |\n",
      "--------------------------------------------\n",
      "Episode: 622\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1159          |\n",
      "|    time_elapsed         | 4713          |\n",
      "|    total_timesteps      | 1186816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5026966e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.67e+05      |\n",
      "|    n_updates            | 36810         |\n",
      "|    policy_gradient_loss | -1.69e-05     |\n",
      "|    reward               | -32.90058     |\n",
      "|    value_loss           | 5.35e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 623\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1160          |\n",
      "|    time_elapsed         | 4718          |\n",
      "|    total_timesteps      | 1187840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2546854e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.13e+04      |\n",
      "|    n_updates            | 36820         |\n",
      "|    policy_gradient_loss | -5.39e-05     |\n",
      "|    reward               | 9.026693      |\n",
      "|    value_loss           | 8.27e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1161          |\n",
      "|    time_elapsed         | 4723          |\n",
      "|    total_timesteps      | 1188864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012517127 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.64e+04      |\n",
      "|    n_updates            | 36830         |\n",
      "|    policy_gradient_loss | -0.000125     |\n",
      "|    reward               | -42.682003    |\n",
      "|    value_loss           | 1.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 624\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697843.28\n",
      "total_reward: -302156.72\n",
      "total_cost: 1225182.56\n",
      "total_trades: 1067\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 4727        |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.93091e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.47e+04    |\n",
      "|    n_updates            | 36840       |\n",
      "|    policy_gradient_loss | 0.000247    |\n",
      "|    reward               | -8.850776   |\n",
      "|    value_loss           | 6.94e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1163          |\n",
      "|    time_elapsed         | 4731          |\n",
      "|    total_timesteps      | 1190912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2134605e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.06e+05      |\n",
      "|    n_updates            | 36850         |\n",
      "|    policy_gradient_loss | 0.000178      |\n",
      "|    reward               | -3.8756132    |\n",
      "|    value_loss           | 4.12e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 4735         |\n",
      "|    total_timesteps      | 1191936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053380826 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.985       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.85e+04     |\n",
      "|    n_updates            | 36860        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -86.932755   |\n",
      "|    value_loss           | 5.7e+04      |\n",
      "------------------------------------------\n",
      "Episode: 625\n",
      "Episode: 626\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 4739        |\n",
      "|    total_timesteps      | 1192960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042890202 |\n",
      "|    clip_fraction        | 0.638       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.1e+05     |\n",
      "|    n_updates            | 36870       |\n",
      "|    policy_gradient_loss | 0.0362      |\n",
      "|    reward               | 7.4834886   |\n",
      "|    value_loss           | 4.21e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1166         |\n",
      "|    time_elapsed         | 4743         |\n",
      "|    total_timesteps      | 1193984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042044437 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.963       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.62e+05     |\n",
      "|    n_updates            | 36880        |\n",
      "|    policy_gradient_loss | 0.00127      |\n",
      "|    reward               | -6.532744    |\n",
      "|    value_loss           | 3.24e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1167         |\n",
      "|    time_elapsed         | 4747         |\n",
      "|    total_timesteps      | 1195008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004293801 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.946       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.24e+04     |\n",
      "|    n_updates            | 36890        |\n",
      "|    policy_gradient_loss | -0.000328    |\n",
      "|    reward               | -70.6845     |\n",
      "|    value_loss           | 2.48e+04     |\n",
      "------------------------------------------\n",
      "Episode: 627\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1168          |\n",
      "|    time_elapsed         | 4752          |\n",
      "|    total_timesteps      | 1196032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9469854e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.937        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.37e+05      |\n",
      "|    n_updates            | 36900         |\n",
      "|    policy_gradient_loss | 4.82e-05      |\n",
      "|    reward               | -16.935246    |\n",
      "|    value_loss           | 4.74e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1169         |\n",
      "|    time_elapsed         | 4756         |\n",
      "|    total_timesteps      | 1197056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.860778e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.933       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.1e+05      |\n",
      "|    n_updates            | 36910        |\n",
      "|    policy_gradient_loss | -6.76e-05    |\n",
      "|    reward               | -70.350716   |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n",
      "Episode: 628\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699365.53\n",
      "total_reward: -300634.47\n",
      "total_cost: 903652.04\n",
      "total_trades: 1016\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1170          |\n",
      "|    time_elapsed         | 4760          |\n",
      "|    total_timesteps      | 1198080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4133984e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.932        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.2e+05       |\n",
      "|    n_updates            | 36920         |\n",
      "|    policy_gradient_loss | -1.24e-05     |\n",
      "|    reward               | 0.014795541   |\n",
      "|    value_loss           | 4.4e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1171          |\n",
      "|    time_elapsed         | 4764          |\n",
      "|    total_timesteps      | 1199104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0279625e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.33e+05      |\n",
      "|    n_updates            | 36930         |\n",
      "|    policy_gradient_loss | -5.53e-06     |\n",
      "|    reward               | -33.439846    |\n",
      "|    value_loss           | 1.87e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1172          |\n",
      "|    time_elapsed         | 4768          |\n",
      "|    total_timesteps      | 1200128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2887328e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.85e+04      |\n",
      "|    n_updates            | 36940         |\n",
      "|    policy_gradient_loss | -7.18e-06     |\n",
      "|    reward               | -97.01091     |\n",
      "|    value_loss           | 1.97e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 629\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1173          |\n",
      "|    time_elapsed         | 4772          |\n",
      "|    total_timesteps      | 1201152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.3004124e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.932        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.48e+05      |\n",
      "|    n_updates            | 36950         |\n",
      "|    policy_gradient_loss | -2.65e-05     |\n",
      "|    reward               | -12.798361    |\n",
      "|    value_loss           | 6.97e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1174          |\n",
      "|    time_elapsed         | 4776          |\n",
      "|    total_timesteps      | 1202176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0262544e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.932        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.85e+05      |\n",
      "|    n_updates            | 36960         |\n",
      "|    policy_gradient_loss | -2.56e-05     |\n",
      "|    reward               | -77.68539     |\n",
      "|    value_loss           | 1.57e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 630\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1175          |\n",
      "|    time_elapsed         | 4781          |\n",
      "|    total_timesteps      | 1203200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8748764e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.932        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.96e+05      |\n",
      "|    n_updates            | 36970         |\n",
      "|    policy_gradient_loss | -2.51e-06     |\n",
      "|    reward               | -44.97905     |\n",
      "|    value_loss           | 3.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 631\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1176          |\n",
      "|    time_elapsed         | 4785          |\n",
      "|    total_timesteps      | 1204224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5660341e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.58e+04      |\n",
      "|    n_updates            | 36980         |\n",
      "|    policy_gradient_loss | -3.53e-05     |\n",
      "|    reward               | -48.209526    |\n",
      "|    value_loss           | 9.18e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1177          |\n",
      "|    time_elapsed         | 4789          |\n",
      "|    total_timesteps      | 1205248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9834843e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.04e+05      |\n",
      "|    n_updates            | 36990         |\n",
      "|    policy_gradient_loss | 5.34e-06      |\n",
      "|    reward               | -23.148155    |\n",
      "|    value_loss           | 4.08e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 4793         |\n",
      "|    total_timesteps      | 1206272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.497706e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.93        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.28e+05     |\n",
      "|    n_updates            | 37000        |\n",
      "|    policy_gradient_loss | -3.65e-06    |\n",
      "|    reward               | -71.94293    |\n",
      "|    value_loss           | 2.56e+05     |\n",
      "------------------------------------------\n",
      "Episode: 632\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1062142.28\n",
      "total_reward: 62142.28\n",
      "total_cost: 1190654.55\n",
      "total_trades: 1096\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1179          |\n",
      "|    time_elapsed         | 4797          |\n",
      "|    total_timesteps      | 1207296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1382508e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.35e+05      |\n",
      "|    n_updates            | 37010         |\n",
      "|    policy_gradient_loss | -9.78e-06     |\n",
      "|    reward               | -40.696705    |\n",
      "|    value_loss           | 6.71e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 633\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1180          |\n",
      "|    time_elapsed         | 4801          |\n",
      "|    total_timesteps      | 1208320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4330802e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.932        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+05      |\n",
      "|    n_updates            | 37020         |\n",
      "|    policy_gradient_loss | -2.4e-05      |\n",
      "|    reward               | 62.7995       |\n",
      "|    value_loss           | 2.43e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 4806        |\n",
      "|    total_timesteps      | 1209344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.84287e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.933      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.76e+05    |\n",
      "|    n_updates            | 37030       |\n",
      "|    policy_gradient_loss | -2.51e-05   |\n",
      "|    reward               | 44.25555    |\n",
      "|    value_loss           | 5.53e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 634\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1182          |\n",
      "|    time_elapsed         | 4810          |\n",
      "|    total_timesteps      | 1210368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8227223e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.934        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.51e+05      |\n",
      "|    n_updates            | 37040         |\n",
      "|    policy_gradient_loss | -4.83e-05     |\n",
      "|    reward               | -5.1130023    |\n",
      "|    value_loss           | 1.5e+06       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1183         |\n",
      "|    time_elapsed         | 4814         |\n",
      "|    total_timesteps      | 1211392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.775395e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.54e+05     |\n",
      "|    n_updates            | 37050        |\n",
      "|    policy_gradient_loss | 5.29e-07     |\n",
      "|    reward               | -60.78828    |\n",
      "|    value_loss           | 7.07e+05     |\n",
      "------------------------------------------\n",
      "Episode: 635\n",
      "Episode: 636\n",
      "Current company: ['JPM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 676258.56\n",
      "total_reward: -323741.44\n",
      "total_cost: 146560.76\n",
      "total_trades: 165\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1184          |\n",
      "|    time_elapsed         | 4818          |\n",
      "|    total_timesteps      | 1212416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5883505e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.83e+04      |\n",
      "|    n_updates            | 37060         |\n",
      "|    policy_gradient_loss | -8.12e-05     |\n",
      "|    reward               | -20.456425    |\n",
      "|    value_loss           | 1.57e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 637\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1185          |\n",
      "|    time_elapsed         | 4822          |\n",
      "|    total_timesteps      | 1213440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4662859e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.19e+05      |\n",
      "|    n_updates            | 37070         |\n",
      "|    policy_gradient_loss | -0.000144     |\n",
      "|    reward               | -12.442166    |\n",
      "|    value_loss           | 4.39e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 638\n",
      "Episode: 639\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1186         |\n",
      "|    time_elapsed         | 4827         |\n",
      "|    total_timesteps      | 1214464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.916067e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.94        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.78e+04     |\n",
      "|    n_updates            | 37080        |\n",
      "|    policy_gradient_loss | -5.92e-06    |\n",
      "|    reward               | -21.552801   |\n",
      "|    value_loss           | 1.56e+05     |\n",
      "------------------------------------------\n",
      "Episode: 640\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695401.32\n",
      "total_reward: -304598.68\n",
      "total_cost: 405364.32\n",
      "total_trades: 475\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 1187       |\n",
      "|    time_elapsed         | 4831       |\n",
      "|    total_timesteps      | 1215488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 3.7066e-05 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.942     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.4e+04    |\n",
      "|    n_updates            | 37090      |\n",
      "|    policy_gradient_loss | -0.000255  |\n",
      "|    reward               | -18.250982 |\n",
      "|    value_loss           | 8.82e+04   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1188          |\n",
      "|    time_elapsed         | 4835          |\n",
      "|    total_timesteps      | 1216512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2205367e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.31e+05      |\n",
      "|    n_updates            | 37100         |\n",
      "|    policy_gradient_loss | -1.09e-05     |\n",
      "|    reward               | -62.583347    |\n",
      "|    value_loss           | 4.63e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 641\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1189         |\n",
      "|    time_elapsed         | 4839         |\n",
      "|    total_timesteps      | 1217536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.358038e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.27e+05     |\n",
      "|    n_updates            | 37110        |\n",
      "|    policy_gradient_loss | -5.07e-05    |\n",
      "|    reward               | 3.5995398    |\n",
      "|    value_loss           | 2.54e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1190          |\n",
      "|    time_elapsed         | 4843          |\n",
      "|    total_timesteps      | 1218560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7856516e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.93e+05      |\n",
      "|    n_updates            | 37120         |\n",
      "|    policy_gradient_loss | -4.46e-07     |\n",
      "|    reward               | -78.9573      |\n",
      "|    value_loss           | 3.86e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 642\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1191          |\n",
      "|    time_elapsed         | 4847          |\n",
      "|    total_timesteps      | 1219584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2915774e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+05      |\n",
      "|    n_updates            | 37130         |\n",
      "|    policy_gradient_loss | -8.44e-06     |\n",
      "|    reward               | -15.475855    |\n",
      "|    value_loss           | 2.98e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1192          |\n",
      "|    time_elapsed         | 4851          |\n",
      "|    total_timesteps      | 1220608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4501275e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0.742         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+05      |\n",
      "|    n_updates            | 37140         |\n",
      "|    policy_gradient_loss | -4.84e-05     |\n",
      "|    reward               | -54.078728    |\n",
      "|    value_loss           | 2.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 643\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1193          |\n",
      "|    time_elapsed         | 4856          |\n",
      "|    total_timesteps      | 1221632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0500738e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.951        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.54e+04      |\n",
      "|    n_updates            | 37150         |\n",
      "|    policy_gradient_loss | 8.1e-06       |\n",
      "|    reward               | -19.690256    |\n",
      "|    value_loss           | 1.71e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1194          |\n",
      "|    time_elapsed         | 4860          |\n",
      "|    total_timesteps      | 1222656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3480894e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.951        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.31e+05      |\n",
      "|    n_updates            | 37160         |\n",
      "|    policy_gradient_loss | -2.81e-05     |\n",
      "|    reward               | -49.147465    |\n",
      "|    value_loss           | 2.62e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1195          |\n",
      "|    time_elapsed         | 4864          |\n",
      "|    total_timesteps      | 1223680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6056001e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.78e+04      |\n",
      "|    n_updates            | 37170         |\n",
      "|    policy_gradient_loss | 6.05e-06      |\n",
      "|    reward               | -102.478615   |\n",
      "|    value_loss           | 1.97e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 644\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694037.91\n",
      "total_reward: -305962.09\n",
      "total_cost: 978059.83\n",
      "total_trades: 1101\n",
      "=================================\n",
      "Episode: 645\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1196         |\n",
      "|    time_elapsed         | 4869         |\n",
      "|    total_timesteps      | 1224704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.194444e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.953       |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.78e+05     |\n",
      "|    n_updates            | 37180        |\n",
      "|    policy_gradient_loss | -1.85e-05    |\n",
      "|    reward               | -14.812824   |\n",
      "|    value_loss           | 1.16e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1197          |\n",
      "|    time_elapsed         | 4873          |\n",
      "|    total_timesteps      | 1225728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1018786e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.8e+05       |\n",
      "|    n_updates            | 37190         |\n",
      "|    policy_gradient_loss | -2.1e-06      |\n",
      "|    reward               | -78.72053     |\n",
      "|    value_loss           | 1.36e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 646\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1198          |\n",
      "|    time_elapsed         | 4878          |\n",
      "|    total_timesteps      | 1226752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0553506e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.72e+05      |\n",
      "|    n_updates            | 37200         |\n",
      "|    policy_gradient_loss | -2.2e-05      |\n",
      "|    reward               | -63.38345     |\n",
      "|    value_loss           | 3.43e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 647\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1199          |\n",
      "|    time_elapsed         | 4883          |\n",
      "|    total_timesteps      | 1227776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.9674646e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.42e+05      |\n",
      "|    n_updates            | 37210         |\n",
      "|    policy_gradient_loss | 7.67e-07      |\n",
      "|    reward               | -62.797913    |\n",
      "|    value_loss           | 2.84e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 648\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699599.66\n",
      "total_reward: -300400.34\n",
      "total_cost: 318405.97\n",
      "total_trades: 389\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1200          |\n",
      "|    time_elapsed         | 4888          |\n",
      "|    total_timesteps      | 1228800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5343844e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.85e+05      |\n",
      "|    n_updates            | 37220         |\n",
      "|    policy_gradient_loss | -1.13e-05     |\n",
      "|    reward               | -26.164402    |\n",
      "|    value_loss           | 3.71e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 649\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1201         |\n",
      "|    time_elapsed         | 4893         |\n",
      "|    total_timesteps      | 1229824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013893482 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.11e+04     |\n",
      "|    n_updates            | 37230        |\n",
      "|    policy_gradient_loss | -0.000843    |\n",
      "|    reward               | -6.6406503   |\n",
      "|    value_loss           | 4.22e+04     |\n",
      "------------------------------------------\n",
      "Episode: 650\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1202         |\n",
      "|    time_elapsed         | 4898         |\n",
      "|    total_timesteps      | 1230848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016763569 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.961       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.07e+05     |\n",
      "|    n_updates            | 37240        |\n",
      "|    policy_gradient_loss | 4.32e-05     |\n",
      "|    reward               | -3.4355645   |\n",
      "|    value_loss           | 4.13e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1203         |\n",
      "|    time_elapsed         | 4903         |\n",
      "|    total_timesteps      | 1231872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002860627 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.962       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.13e+04     |\n",
      "|    n_updates            | 37250        |\n",
      "|    policy_gradient_loss | -0.000379    |\n",
      "|    reward               | -23.167076   |\n",
      "|    value_loss           | 1.83e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 1204         |\n",
      "|    time_elapsed         | 4908         |\n",
      "|    total_timesteps      | 1232896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020666425 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.966       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.61e+04     |\n",
      "|    n_updates            | 37260        |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    reward               | -72.404465   |\n",
      "|    value_loss           | 3.23e+04     |\n",
      "------------------------------------------\n",
      "Episode: 651\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 4914        |\n",
      "|    total_timesteps      | 1233920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005166115 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+05    |\n",
      "|    n_updates            | 37270       |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    reward               | -48.224895  |\n",
      "|    value_loss           | 2.26e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 652\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696298.82\n",
      "total_reward: -303701.18\n",
      "total_cost: 476741.99\n",
      "total_trades: 457\n",
      "=================================\n",
      "Episode: 653\n",
      "Episode: 654\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 1206          |\n",
      "|    time_elapsed         | 4919          |\n",
      "|    total_timesteps      | 1234944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9532163e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.967        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.8e+04       |\n",
      "|    n_updates            | 37280         |\n",
      "|    policy_gradient_loss | 0.000256      |\n",
      "|    reward               | -5.9355626    |\n",
      "|    value_loss           | 1.76e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1207         |\n",
      "|    time_elapsed         | 4924         |\n",
      "|    total_timesteps      | 1235968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004905984 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.971       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.17e+04     |\n",
      "|    n_updates            | 37290        |\n",
      "|    policy_gradient_loss | -0.00074     |\n",
      "|    reward               | -48.147514   |\n",
      "|    value_loss           | 6.34e+04     |\n",
      "------------------------------------------\n",
      "Episode: 655\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1208         |\n",
      "|    time_elapsed         | 4930         |\n",
      "|    total_timesteps      | 1236992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001584973 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.974       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 37300        |\n",
      "|    policy_gradient_loss | -0.000122    |\n",
      "|    reward               | -10.995797   |\n",
      "|    value_loss           | 2.82e+05     |\n",
      "------------------------------------------\n",
      "Episode: 656\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693048.03\n",
      "total_reward: -306951.97\n",
      "total_cost: 299702.32\n",
      "total_trades: 345\n",
      "=================================\n",
      "Episode: 657\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1209          |\n",
      "|    time_elapsed         | 4935          |\n",
      "|    total_timesteps      | 1238016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9849103e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.46e+05      |\n",
      "|    n_updates            | 37310         |\n",
      "|    policy_gradient_loss | -3.61e-05     |\n",
      "|    reward               | -11.432766    |\n",
      "|    value_loss           | 1.09e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1210         |\n",
      "|    time_elapsed         | 4940         |\n",
      "|    total_timesteps      | 1239040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.331473e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.975       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.11e+04     |\n",
      "|    n_updates            | 37320        |\n",
      "|    policy_gradient_loss | -0.000152    |\n",
      "|    reward               | -31.280289   |\n",
      "|    value_loss           | 1.22e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1211          |\n",
      "|    time_elapsed         | 4945          |\n",
      "|    total_timesteps      | 1240064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3224857e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.15e+04      |\n",
      "|    n_updates            | 37330         |\n",
      "|    policy_gradient_loss | 6.23e-05      |\n",
      "|    reward               | -63.872635    |\n",
      "|    value_loss           | 6.32e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 658\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1212          |\n",
      "|    time_elapsed         | 4949          |\n",
      "|    total_timesteps      | 1241088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1925586e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.01e+05      |\n",
      "|    n_updates            | 37340         |\n",
      "|    policy_gradient_loss | -6.23e-05     |\n",
      "|    reward               | -42.756252    |\n",
      "|    value_loss           | 4.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 659\n",
      "Episode: 660\n",
      "Current company: ['CVX']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 685541.62\n",
      "total_reward: -314458.38\n",
      "total_cost: 267229.37\n",
      "total_trades: 287\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1213          |\n",
      "|    time_elapsed         | 4954          |\n",
      "|    total_timesteps      | 1242112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6358251e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28e+05      |\n",
      "|    n_updates            | 37350         |\n",
      "|    policy_gradient_loss | -2.82e-05     |\n",
      "|    reward               | -5.790188     |\n",
      "|    value_loss           | 2.56e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1214         |\n",
      "|    time_elapsed         | 4958         |\n",
      "|    total_timesteps      | 1243136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.396579e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.976       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.61e+04     |\n",
      "|    n_updates            | 37360        |\n",
      "|    policy_gradient_loss | -6.08e-05    |\n",
      "|    reward               | -34.563297   |\n",
      "|    value_loss           | 1.32e+05     |\n",
      "------------------------------------------\n",
      "Episode: 661\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1215          |\n",
      "|    time_elapsed         | 4962          |\n",
      "|    total_timesteps      | 1244160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9194867e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.44e+04      |\n",
      "|    n_updates            | 37370         |\n",
      "|    policy_gradient_loss | -6.51e-05     |\n",
      "|    reward               | 0.8769624     |\n",
      "|    value_loss           | 6.87e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 4966        |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.45173e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.71e+04    |\n",
      "|    n_updates            | 37380       |\n",
      "|    policy_gradient_loss | -3.1e-05    |\n",
      "|    reward               | -56.162754  |\n",
      "|    value_loss           | 1.34e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 662\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1217          |\n",
      "|    time_elapsed         | 4971          |\n",
      "|    total_timesteps      | 1246208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5985006e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.981        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.12e+05      |\n",
      "|    n_updates            | 37390         |\n",
      "|    policy_gradient_loss | -2.01e-05     |\n",
      "|    reward               | -19.880234    |\n",
      "|    value_loss           | 2.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1218          |\n",
      "|    time_elapsed         | 4975          |\n",
      "|    total_timesteps      | 1247232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8728543e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.983        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.11e+05      |\n",
      "|    n_updates            | 37400         |\n",
      "|    policy_gradient_loss | 7.85e-06      |\n",
      "|    reward               | -71.108574    |\n",
      "|    value_loss           | 2.23e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 663\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1219         |\n",
      "|    time_elapsed         | 4979         |\n",
      "|    total_timesteps      | 1248256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.600749e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.983       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.59e+05     |\n",
      "|    n_updates            | 37410        |\n",
      "|    policy_gradient_loss | 1.67e-06     |\n",
      "|    reward               | -9.53549     |\n",
      "|    value_loss           | 3.18e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1220         |\n",
      "|    time_elapsed         | 4983         |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039491286 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.976       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.01e+04     |\n",
      "|    n_updates            | 37420        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -61.48368    |\n",
      "|    value_loss           | 4.03e+04     |\n",
      "------------------------------------------\n",
      "Episode: 664\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1215332.02\n",
      "total_reward: 215332.02\n",
      "total_cost: 1283834.79\n",
      "total_trades: 1205\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1221         |\n",
      "|    time_elapsed         | 4988         |\n",
      "|    total_timesteps      | 1250304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012206577 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.962       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.09e+05     |\n",
      "|    n_updates            | 37430        |\n",
      "|    policy_gradient_loss | -6.6e-05     |\n",
      "|    reward               | -14.323838   |\n",
      "|    value_loss           | 4.18e+05     |\n",
      "------------------------------------------\n",
      "Episode: 665\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1222          |\n",
      "|    time_elapsed         | 4992          |\n",
      "|    total_timesteps      | 1251328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016007287 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.958        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.79e+05      |\n",
      "|    n_updates            | 37440         |\n",
      "|    policy_gradient_loss | -9.7e-05      |\n",
      "|    reward               | -0.02         |\n",
      "|    value_loss           | 7.59e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1223         |\n",
      "|    time_elapsed         | 4996         |\n",
      "|    total_timesteps      | 1252352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.298184e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.956       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.66e+05     |\n",
      "|    n_updates            | 37450        |\n",
      "|    policy_gradient_loss | -2.53e-05    |\n",
      "|    reward               | -56.098644   |\n",
      "|    value_loss           | 3.32e+05     |\n",
      "------------------------------------------\n",
      "Episode: 666\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1224          |\n",
      "|    time_elapsed         | 5000          |\n",
      "|    total_timesteps      | 1253376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9867963e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.956        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.01e+04      |\n",
      "|    n_updates            | 37460         |\n",
      "|    policy_gradient_loss | -0.000124     |\n",
      "|    reward               | 42.356216     |\n",
      "|    value_loss           | 1.4e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1225         |\n",
      "|    time_elapsed         | 5004         |\n",
      "|    total_timesteps      | 1254400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.773815e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.33e+05     |\n",
      "|    n_updates            | 37470        |\n",
      "|    policy_gradient_loss | -0.000113    |\n",
      "|    reward               | -10.525999   |\n",
      "|    value_loss           | 8.79e+05     |\n",
      "------------------------------------------\n",
      "Episode: 667\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1226          |\n",
      "|    time_elapsed         | 5008          |\n",
      "|    total_timesteps      | 1255424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5099143e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 0.0359        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.82e+05      |\n",
      "|    n_updates            | 37480         |\n",
      "|    policy_gradient_loss | -1.56e-05     |\n",
      "|    reward               | 15.18282      |\n",
      "|    value_loss           | 5.9e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1227          |\n",
      "|    time_elapsed         | 5012          |\n",
      "|    total_timesteps      | 1256448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8684659e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.139        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.59e+05      |\n",
      "|    n_updates            | 37490         |\n",
      "|    policy_gradient_loss | -5.48e-06     |\n",
      "|    reward               | 69.9737       |\n",
      "|    value_loss           | 3.25e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1228          |\n",
      "|    time_elapsed         | 5016          |\n",
      "|    total_timesteps      | 1257472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1915108e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.996        |\n",
      "|    explained_variance   | 0.598         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.25e+05      |\n",
      "|    n_updates            | 37500         |\n",
      "|    policy_gradient_loss | -6.95e-06     |\n",
      "|    reward               | 61.00936      |\n",
      "|    value_loss           | 6.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 668\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2299418.79\n",
      "total_reward: 1299418.79\n",
      "total_cost: 2179624.77\n",
      "total_trades: 1184\n",
      "=================================\n",
      "Episode: 669\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1229          |\n",
      "|    time_elapsed         | 5020          |\n",
      "|    total_timesteps      | 1258496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.5460564e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.97e+05      |\n",
      "|    n_updates            | 37510         |\n",
      "|    policy_gradient_loss | -5.15e-06     |\n",
      "|    reward               | 26.357943     |\n",
      "|    value_loss           | 1.79e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 670\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1230         |\n",
      "|    time_elapsed         | 5024         |\n",
      "|    total_timesteps      | 1259520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.565824e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.953       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.66e+05     |\n",
      "|    n_updates            | 37520        |\n",
      "|    policy_gradient_loss | 2.25e-06     |\n",
      "|    reward               | 1.9417437    |\n",
      "|    value_loss           | 1.53e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1231          |\n",
      "|    time_elapsed         | 5029          |\n",
      "|    total_timesteps      | 1260544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2607855e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.5e+05       |\n",
      "|    n_updates            | 37530         |\n",
      "|    policy_gradient_loss | -5.96e-06     |\n",
      "|    reward               | -34.744915    |\n",
      "|    value_loss           | 3.01e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1232          |\n",
      "|    time_elapsed         | 5033          |\n",
      "|    total_timesteps      | 1261568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7852697e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.4e+04       |\n",
      "|    n_updates            | 37540         |\n",
      "|    policy_gradient_loss | -0.000187     |\n",
      "|    reward               | -77.36383     |\n",
      "|    value_loss           | 1.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 671\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1233          |\n",
      "|    time_elapsed         | 5037          |\n",
      "|    total_timesteps      | 1262592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1486503e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.19e+05      |\n",
      "|    n_updates            | 37550         |\n",
      "|    policy_gradient_loss | -0.000223     |\n",
      "|    reward               | -39.84977     |\n",
      "|    value_loss           | 6.38e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1234          |\n",
      "|    time_elapsed         | 5041          |\n",
      "|    total_timesteps      | 1263616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2171571e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.03e+05      |\n",
      "|    n_updates            | 37560         |\n",
      "|    policy_gradient_loss | -4.2e-05      |\n",
      "|    reward               | -71.33284     |\n",
      "|    value_loss           | 4.06e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 672\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 681419.48\n",
      "total_reward: -318580.52\n",
      "total_cost: 1111181.42\n",
      "total_trades: 1137\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1235          |\n",
      "|    time_elapsed         | 5046          |\n",
      "|    total_timesteps      | 1264640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7330749e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.4e+05       |\n",
      "|    n_updates            | 37570         |\n",
      "|    policy_gradient_loss | 2.68e-05      |\n",
      "|    reward               | -4.5741143    |\n",
      "|    value_loss           | 6.81e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1236          |\n",
      "|    time_elapsed         | 5050          |\n",
      "|    total_timesteps      | 1265664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7654384e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.08e+05      |\n",
      "|    n_updates            | 37580         |\n",
      "|    policy_gradient_loss | -1.08e-05     |\n",
      "|    reward               | -68.22917     |\n",
      "|    value_loss           | 8.16e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 673\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1237          |\n",
      "|    time_elapsed         | 5054          |\n",
      "|    total_timesteps      | 1266688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0844544e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.17e+05      |\n",
      "|    n_updates            | 37590         |\n",
      "|    policy_gradient_loss | -6.72e-06     |\n",
      "|    reward               | -23.819912    |\n",
      "|    value_loss           | 2.34e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1238          |\n",
      "|    time_elapsed         | 5058          |\n",
      "|    total_timesteps      | 1267712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0522351e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.88e+05      |\n",
      "|    n_updates            | 37600         |\n",
      "|    policy_gradient_loss | -6.6e-05      |\n",
      "|    reward               | -11.843955    |\n",
      "|    value_loss           | 1.38e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1239          |\n",
      "|    time_elapsed         | 5062          |\n",
      "|    total_timesteps      | 1268736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5782076e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.17e+04      |\n",
      "|    n_updates            | 37610         |\n",
      "|    policy_gradient_loss | -7.57e-05     |\n",
      "|    reward               | -34.601814    |\n",
      "|    value_loss           | 4.36e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 674\n",
      "Episode: 675\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1240          |\n",
      "|    time_elapsed         | 5067          |\n",
      "|    total_timesteps      | 1269760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0178868e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.02e+04      |\n",
      "|    n_updates            | 37620         |\n",
      "|    policy_gradient_loss | -0.000207     |\n",
      "|    reward               | -1.8329042    |\n",
      "|    value_loss           | 1.81e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1241          |\n",
      "|    time_elapsed         | 5071          |\n",
      "|    total_timesteps      | 1270784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020997314 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.952        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.16e+05      |\n",
      "|    n_updates            | 37630         |\n",
      "|    policy_gradient_loss | -0.000872     |\n",
      "|    reward               | -59.194828    |\n",
      "|    value_loss           | 2.32e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 676\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695250.06\n",
      "total_reward: -304749.94\n",
      "total_cost: 703390.69\n",
      "total_trades: 759\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1242         |\n",
      "|    time_elapsed         | 5075         |\n",
      "|    total_timesteps      | 1271808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001246077 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.948       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.95e+04     |\n",
      "|    n_updates            | 37640        |\n",
      "|    policy_gradient_loss | -1.31e-05    |\n",
      "|    reward               | -18.041798   |\n",
      "|    value_loss           | 9.95e+04     |\n",
      "------------------------------------------\n",
      "Episode: 677\n",
      "Episode: 678\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1243          |\n",
      "|    time_elapsed         | 5080          |\n",
      "|    total_timesteps      | 1272832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3430563e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.96e+05      |\n",
      "|    n_updates            | 37650         |\n",
      "|    policy_gradient_loss | -0.000145     |\n",
      "|    reward               | -26.231236    |\n",
      "|    value_loss           | 5.94e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 679\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1244          |\n",
      "|    time_elapsed         | 5084          |\n",
      "|    total_timesteps      | 1273856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2026459e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.09e+05      |\n",
      "|    n_updates            | 37660         |\n",
      "|    policy_gradient_loss | -8.37e-05     |\n",
      "|    reward               | -18.485737    |\n",
      "|    value_loss           | 2.19e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1245          |\n",
      "|    time_elapsed         | 5088          |\n",
      "|    total_timesteps      | 1274880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1975644e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.12e+04      |\n",
      "|    n_updates            | 37670         |\n",
      "|    policy_gradient_loss | 2.68e-05      |\n",
      "|    reward               | -40.623276    |\n",
      "|    value_loss           | 1.63e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1246          |\n",
      "|    time_elapsed         | 5092          |\n",
      "|    total_timesteps      | 1275904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5960693e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.945        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.17e+04      |\n",
      "|    n_updates            | 37680         |\n",
      "|    policy_gradient_loss | -1.06e-05     |\n",
      "|    reward               | -45.50511     |\n",
      "|    value_loss           | 1.64e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 680\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 690196.58\n",
      "total_reward: -309803.42\n",
      "total_cost: 1211984.93\n",
      "total_trades: 1131\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1247         |\n",
      "|    time_elapsed         | 5096         |\n",
      "|    total_timesteps      | 1276928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.960472e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.944       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.62e+05     |\n",
      "|    n_updates            | 37690        |\n",
      "|    policy_gradient_loss | -1.21e-05    |\n",
      "|    reward               | 8.431099     |\n",
      "|    value_loss           | 5.25e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1248          |\n",
      "|    time_elapsed         | 5100          |\n",
      "|    total_timesteps      | 1277952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.8376615e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.999        |\n",
      "|    explained_variance   | 0.617         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.33e+05      |\n",
      "|    n_updates            | 37700         |\n",
      "|    policy_gradient_loss | -1.98e-05     |\n",
      "|    reward               | -11.607333    |\n",
      "|    value_loss           | 2.67e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 681\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1249          |\n",
      "|    time_elapsed         | 5104          |\n",
      "|    total_timesteps      | 1278976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4877296e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.21         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.24e+04      |\n",
      "|    n_updates            | 37710         |\n",
      "|    policy_gradient_loss | -4.61e-05     |\n",
      "|    reward               | -4.4223704    |\n",
      "|    value_loss           | 1.13e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1250          |\n",
      "|    time_elapsed         | 5108          |\n",
      "|    total_timesteps      | 1280000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9028465e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+05      |\n",
      "|    n_updates            | 37720         |\n",
      "|    policy_gradient_loss | -2.99e-05     |\n",
      "|    reward               | -56.60933     |\n",
      "|    value_loss           | 3e+05         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1251         |\n",
      "|    time_elapsed         | 5112         |\n",
      "|    total_timesteps      | 1281024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.470371e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.944       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.74e+04     |\n",
      "|    n_updates            | 37730        |\n",
      "|    policy_gradient_loss | -2.41e-05    |\n",
      "|    reward               | -78.59119    |\n",
      "|    value_loss           | 1.56e+05     |\n",
      "------------------------------------------\n",
      "Episode: 682\n",
      "Episode: 683\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1252         |\n",
      "|    time_elapsed         | 5117         |\n",
      "|    total_timesteps      | 1282048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.173512e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.943       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.42e+05     |\n",
      "|    n_updates            | 37740        |\n",
      "|    policy_gradient_loss | 1.74e-05     |\n",
      "|    reward               | -5.5283117   |\n",
      "|    value_loss           | 8.84e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1253         |\n",
      "|    time_elapsed         | 5121         |\n",
      "|    total_timesteps      | 1283072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.366149e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.943       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.3e+05      |\n",
      "|    n_updates            | 37750        |\n",
      "|    policy_gradient_loss | -1.63e-05    |\n",
      "|    reward               | -46.85059    |\n",
      "|    value_loss           | 1.26e+06     |\n",
      "------------------------------------------\n",
      "Episode: 684\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696857.81\n",
      "total_reward: -303142.19\n",
      "total_cost: 577832.40\n",
      "total_trades: 625\n",
      "=================================\n",
      "Episode: 685\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1254          |\n",
      "|    time_elapsed         | 5125          |\n",
      "|    total_timesteps      | 1284096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0672957e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.943        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.16e+04      |\n",
      "|    n_updates            | 37760         |\n",
      "|    policy_gradient_loss | -7.22e-05     |\n",
      "|    reward               | -28.251251    |\n",
      "|    value_loss           | 6.33e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1255         |\n",
      "|    time_elapsed         | 5129         |\n",
      "|    total_timesteps      | 1285120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.351205e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.942       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.46e+05     |\n",
      "|    n_updates            | 37770        |\n",
      "|    policy_gradient_loss | -5.32e-05    |\n",
      "|    reward               | -56.335514   |\n",
      "|    value_loss           | 2.93e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1256          |\n",
      "|    time_elapsed         | 5133          |\n",
      "|    total_timesteps      | 1286144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6841339e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.941        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.92e+05      |\n",
      "|    n_updates            | 37780         |\n",
      "|    policy_gradient_loss | -0.000115     |\n",
      "|    reward               | -92.80001     |\n",
      "|    value_loss           | 3.85e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 686\n",
      "Episode: 687\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1257         |\n",
      "|    time_elapsed         | 5138         |\n",
      "|    total_timesteps      | 1287168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.192822e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.24e+05     |\n",
      "|    n_updates            | 37790        |\n",
      "|    policy_gradient_loss | 1.71e-05     |\n",
      "|    reward               | -15.700594   |\n",
      "|    value_loss           | 1.25e+06     |\n",
      "------------------------------------------\n",
      "Episode: 688\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699567.22\n",
      "total_reward: -300432.78\n",
      "total_cost: 284564.80\n",
      "total_trades: 315\n",
      "=================================\n",
      "Episode: 689\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1258         |\n",
      "|    time_elapsed         | 5142         |\n",
      "|    total_timesteps      | 1288192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.855683e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.16e+05     |\n",
      "|    n_updates            | 37800        |\n",
      "|    policy_gradient_loss | -1.39e-05    |\n",
      "|    reward               | -5.778924    |\n",
      "|    value_loss           | 8.32e+05     |\n",
      "------------------------------------------\n",
      "Episode: 690\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1259          |\n",
      "|    time_elapsed         | 5147          |\n",
      "|    total_timesteps      | 1289216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1817628e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.94         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.12e+04      |\n",
      "|    n_updates            | 37810         |\n",
      "|    policy_gradient_loss | -0.000163     |\n",
      "|    reward               | -22.627365    |\n",
      "|    value_loss           | 1.02e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1260          |\n",
      "|    time_elapsed         | 5150          |\n",
      "|    total_timesteps      | 1290240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6539125e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.96         |\n",
      "|    explained_variance   | 0.474         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.88e+04      |\n",
      "|    n_updates            | 37820         |\n",
      "|    policy_gradient_loss | 8.3e-06       |\n",
      "|    reward               | -14.849607    |\n",
      "|    value_loss           | 1.99e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1261         |\n",
      "|    time_elapsed         | 5154         |\n",
      "|    total_timesteps      | 1291264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.995979e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.745       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.56e+04     |\n",
      "|    n_updates            | 37830        |\n",
      "|    policy_gradient_loss | -2.3e-05     |\n",
      "|    reward               | 7.2474504    |\n",
      "|    value_loss           | 1.02e+05     |\n",
      "------------------------------------------\n",
      "Episode: 691\n",
      "Episode: 692\n",
      "Current company: ['CAT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 689501.39\n",
      "total_reward: -310498.61\n",
      "total_cost: 180079.45\n",
      "total_trades: 187\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1262          |\n",
      "|    time_elapsed         | 5159          |\n",
      "|    total_timesteps      | 1292288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9261067e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.403        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.15e+04      |\n",
      "|    n_updates            | 37840         |\n",
      "|    policy_gradient_loss | -1.8e-05      |\n",
      "|    reward               | -5.4044766    |\n",
      "|    value_loss           | 7.09e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 693\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1263          |\n",
      "|    time_elapsed         | 5163          |\n",
      "|    total_timesteps      | 1293312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016187149 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.944        |\n",
      "|    explained_variance   | 0.829         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.68e+03      |\n",
      "|    n_updates            | 37850         |\n",
      "|    policy_gradient_loss | -0.000252     |\n",
      "|    reward               | 7.1604652     |\n",
      "|    value_loss           | 1.14e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1264          |\n",
      "|    time_elapsed         | 5167          |\n",
      "|    total_timesteps      | 1294336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048938015 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.946        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.11e+05      |\n",
      "|    n_updates            | 37860         |\n",
      "|    policy_gradient_loss | -0.000515     |\n",
      "|    reward               | 36.19017      |\n",
      "|    value_loss           | 2.21e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1265         |\n",
      "|    time_elapsed         | 5171         |\n",
      "|    total_timesteps      | 1295360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.006871e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.34e+05     |\n",
      "|    n_updates            | 37870        |\n",
      "|    policy_gradient_loss | 9.97e-06     |\n",
      "|    reward               | -41.213665   |\n",
      "|    value_loss           | 4.68e+05     |\n",
      "------------------------------------------\n",
      "Episode: 694\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1266          |\n",
      "|    time_elapsed         | 5175          |\n",
      "|    total_timesteps      | 1296384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2306107e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.56e+05      |\n",
      "|    n_updates            | 37880         |\n",
      "|    policy_gradient_loss | -0.000188     |\n",
      "|    reward               | -27.795847    |\n",
      "|    value_loss           | 3.11e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 695\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1267         |\n",
      "|    time_elapsed         | 5180         |\n",
      "|    total_timesteps      | 1297408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012994353 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.972       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.47e+04     |\n",
      "|    n_updates            | 37890        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | 5.272194     |\n",
      "|    value_loss           | 1.49e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1268         |\n",
      "|    time_elapsed         | 5184         |\n",
      "|    total_timesteps      | 1298432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024255654 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.958       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.17e+05     |\n",
      "|    n_updates            | 37900        |\n",
      "|    policy_gradient_loss | 0.00152      |\n",
      "|    reward               | -28.158815   |\n",
      "|    value_loss           | 2.35e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1269         |\n",
      "|    time_elapsed         | 5188         |\n",
      "|    total_timesteps      | 1299456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002921358 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.47e+04     |\n",
      "|    n_updates            | 37910        |\n",
      "|    policy_gradient_loss | -0.000291    |\n",
      "|    reward               | 35.169403    |\n",
      "|    value_loss           | 2.94e+04     |\n",
      "------------------------------------------\n",
      "Episode: 696\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3042210.86\n",
      "total_reward: 2042210.86\n",
      "total_cost: 1710676.94\n",
      "total_trades: 1152\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1270         |\n",
      "|    time_elapsed         | 5192         |\n",
      "|    total_timesteps      | 1300480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.312101e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.932       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.22e+05     |\n",
      "|    n_updates            | 37920        |\n",
      "|    policy_gradient_loss | -0.000153    |\n",
      "|    reward               | -36.747204   |\n",
      "|    value_loss           | 4.45e+05     |\n",
      "------------------------------------------\n",
      "Episode: 697\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1271          |\n",
      "|    time_elapsed         | 5196          |\n",
      "|    total_timesteps      | 1301504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3409102e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.927        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.58e+05      |\n",
      "|    n_updates            | 37930         |\n",
      "|    policy_gradient_loss | -0.000251     |\n",
      "|    reward               | -27.843489    |\n",
      "|    value_loss           | 5.16e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1272         |\n",
      "|    time_elapsed         | 5200         |\n",
      "|    total_timesteps      | 1302528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.138433e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.925       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.27e+05     |\n",
      "|    n_updates            | 37940        |\n",
      "|    policy_gradient_loss | -0.000139    |\n",
      "|    reward               | -77.412285   |\n",
      "|    value_loss           | 2.55e+05     |\n",
      "------------------------------------------\n",
      "Episode: 698\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1273          |\n",
      "|    time_elapsed         | 5205          |\n",
      "|    total_timesteps      | 1303552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0675008e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.923        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.1e+05       |\n",
      "|    n_updates            | 37950         |\n",
      "|    policy_gradient_loss | -1.05e-05     |\n",
      "|    reward               | 54.374393     |\n",
      "|    value_loss           | 2.2e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 699\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1274          |\n",
      "|    time_elapsed         | 5209          |\n",
      "|    total_timesteps      | 1304576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7487986e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.921        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.6e+05       |\n",
      "|    n_updates            | 37960         |\n",
      "|    policy_gradient_loss | -7.26e-05     |\n",
      "|    reward               | -39.22502     |\n",
      "|    value_loss           | 1.12e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1275         |\n",
      "|    time_elapsed         | 5214         |\n",
      "|    total_timesteps      | 1305600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010292733 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.922       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.19e+04     |\n",
      "|    n_updates            | 37970        |\n",
      "|    policy_gradient_loss | -0.00078     |\n",
      "|    reward               | -97.65583    |\n",
      "|    value_loss           | 1.24e+05     |\n",
      "------------------------------------------\n",
      "Episode: 700\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699876.92\n",
      "total_reward: -300123.08\n",
      "total_cost: 854150.53\n",
      "total_trades: 882\n",
      "=================================\n",
      "Episode: 701\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1276         |\n",
      "|    time_elapsed         | 5219         |\n",
      "|    total_timesteps      | 1306624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012142446 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.926       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.92e+05     |\n",
      "|    n_updates            | 37980        |\n",
      "|    policy_gradient_loss | 0.000305     |\n",
      "|    reward               | -25.835989   |\n",
      "|    value_loss           | 7.85e+05     |\n",
      "------------------------------------------\n",
      "Episode: 702\n",
      "Episode: 703\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1277         |\n",
      "|    time_elapsed         | 5223         |\n",
      "|    total_timesteps      | 1307648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001847265 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.19e+04     |\n",
      "|    n_updates            | 37990        |\n",
      "|    policy_gradient_loss | -0.000204    |\n",
      "|    reward               | 6.679091     |\n",
      "|    value_loss           | 8.38e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1278          |\n",
      "|    time_elapsed         | 5227          |\n",
      "|    total_timesteps      | 1308672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1669253e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.926        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.82e+05      |\n",
      "|    n_updates            | 38000         |\n",
      "|    policy_gradient_loss | -0.000255     |\n",
      "|    reward               | -43.15553     |\n",
      "|    value_loss           | 3.65e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1279         |\n",
      "|    time_elapsed         | 5231         |\n",
      "|    total_timesteps      | 1309696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.739283e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.89e+04     |\n",
      "|    n_updates            | 38010        |\n",
      "|    policy_gradient_loss | 3.23e-05     |\n",
      "|    reward               | -28.402082   |\n",
      "|    value_loss           | 9.79e+04     |\n",
      "------------------------------------------\n",
      "Episode: 704\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1274195.12\n",
      "total_reward: 274195.12\n",
      "total_cost: 1336586.89\n",
      "total_trades: 1259\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1280          |\n",
      "|    time_elapsed         | 5236          |\n",
      "|    total_timesteps      | 1310720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.8289304e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.928        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.32e+05      |\n",
      "|    n_updates            | 38020         |\n",
      "|    policy_gradient_loss | 1.29e-05      |\n",
      "|    reward               | -29.673376    |\n",
      "|    value_loss           | 6.65e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1281         |\n",
      "|    time_elapsed         | 5240         |\n",
      "|    total_timesteps      | 1311744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.081506e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.928       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.24e+05     |\n",
      "|    n_updates            | 38030        |\n",
      "|    policy_gradient_loss | -5.94e-07    |\n",
      "|    reward               | -84.56217    |\n",
      "|    value_loss           | 2.48e+05     |\n",
      "------------------------------------------\n",
      "Episode: 705\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1282         |\n",
      "|    time_elapsed         | 5244         |\n",
      "|    total_timesteps      | 1312768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.906944e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.928       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.14e+05     |\n",
      "|    n_updates            | 38040        |\n",
      "|    policy_gradient_loss | -4.83e-06    |\n",
      "|    reward               | 9.221298     |\n",
      "|    value_loss           | 6.28e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1283         |\n",
      "|    time_elapsed         | 5248         |\n",
      "|    total_timesteps      | 1313792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.614106e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.928       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.37e+05     |\n",
      "|    n_updates            | 38050        |\n",
      "|    policy_gradient_loss | -1.74e-06    |\n",
      "|    reward               | 19.357176    |\n",
      "|    value_loss           | 2.75e+05     |\n",
      "------------------------------------------\n",
      "Episode: 706\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1284          |\n",
      "|    time_elapsed         | 5253          |\n",
      "|    total_timesteps      | 1314816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6060734e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.929        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.38e+05      |\n",
      "|    n_updates            | 38060         |\n",
      "|    policy_gradient_loss | -6.59e-05     |\n",
      "|    reward               | -23.209923    |\n",
      "|    value_loss           | 2.76e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1285          |\n",
      "|    time_elapsed         | 5257          |\n",
      "|    total_timesteps      | 1315840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4349657e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.929        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01e+05      |\n",
      "|    n_updates            | 38070         |\n",
      "|    policy_gradient_loss | -5.45e-06     |\n",
      "|    reward               | -45.99841     |\n",
      "|    value_loss           | 2.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 707\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 250        |\n",
      "|    iterations           | 1286       |\n",
      "|    time_elapsed         | 5261       |\n",
      "|    total_timesteps      | 1316864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 7.7195e-07 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.929     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.66e+04   |\n",
      "|    n_updates            | 38080      |\n",
      "|    policy_gradient_loss | -1.15e-05  |\n",
      "|    reward               | -15.004308 |\n",
      "|    value_loss           | 1.53e+05   |\n",
      "----------------------------------------\n",
      "Episode: 708\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 691024.81\n",
      "total_reward: -308975.19\n",
      "total_cost: 172752.12\n",
      "total_trades: 185\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1287          |\n",
      "|    time_elapsed         | 5266          |\n",
      "|    total_timesteps      | 1317888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2044329e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.93         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.45e+05      |\n",
      "|    n_updates            | 38090         |\n",
      "|    policy_gradient_loss | -9.85e-06     |\n",
      "|    reward               | -18.546093    |\n",
      "|    value_loss           | 8.9e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1288          |\n",
      "|    time_elapsed         | 5270          |\n",
      "|    total_timesteps      | 1318912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016128214 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.931        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.67e+04      |\n",
      "|    n_updates            | 38100         |\n",
      "|    policy_gradient_loss | -0.000399     |\n",
      "|    reward               | -82.39994     |\n",
      "|    value_loss           | 5.35e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 709\n",
      "Episode: 710\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1289         |\n",
      "|    time_elapsed         | 5274         |\n",
      "|    total_timesteps      | 1319936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002103729 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.71e+05     |\n",
      "|    n_updates            | 38110        |\n",
      "|    policy_gradient_loss | -0.000743    |\n",
      "|    reward               | 20.954388    |\n",
      "|    value_loss           | 5.42e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 1290        |\n",
      "|    time_elapsed         | 5278        |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.04026e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.78e+05    |\n",
      "|    n_updates            | 38120       |\n",
      "|    policy_gradient_loss | 6.53e-06    |\n",
      "|    reward               | -33.670925  |\n",
      "|    value_loss           | 5.58e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 711\n",
      "Episode: 712\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699863.49\n",
      "total_reward: -300136.51\n",
      "total_cost: 57738.70\n",
      "total_trades: 57\n",
      "=================================\n",
      "Episode: 713\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1291          |\n",
      "|    time_elapsed         | 5283          |\n",
      "|    total_timesteps      | 1321984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0299089e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.94         |\n",
      "|    explained_variance   | 0.199         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.44e+04      |\n",
      "|    n_updates            | 38130         |\n",
      "|    policy_gradient_loss | -8.74e-05     |\n",
      "|    reward               | -37.052322    |\n",
      "|    value_loss           | 1.49e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 714\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1292         |\n",
      "|    time_elapsed         | 5287         |\n",
      "|    total_timesteps      | 1323008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.342998e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.934       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48e+04     |\n",
      "|    n_updates            | 38140        |\n",
      "|    policy_gradient_loss | 2.73e-05     |\n",
      "|    reward               | -0.7992861   |\n",
      "|    value_loss           | 1.9e+05      |\n",
      "------------------------------------------\n",
      "Episode: 715\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1293          |\n",
      "|    time_elapsed         | 5292          |\n",
      "|    total_timesteps      | 1324032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1974632e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.933        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.03e+05      |\n",
      "|    n_updates            | 38150         |\n",
      "|    policy_gradient_loss | -3.94e-05     |\n",
      "|    reward               | 4.470582      |\n",
      "|    value_loss           | 4.06e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1294         |\n",
      "|    time_elapsed         | 5296         |\n",
      "|    total_timesteps      | 1325056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.118855e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.932       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.31e+05     |\n",
      "|    n_updates            | 38160        |\n",
      "|    policy_gradient_loss | -9.64e-05    |\n",
      "|    reward               | -29.98933    |\n",
      "|    value_loss           | 2.62e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1295         |\n",
      "|    time_elapsed         | 5300         |\n",
      "|    total_timesteps      | 1326080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.780278e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.25e+04     |\n",
      "|    n_updates            | 38170        |\n",
      "|    policy_gradient_loss | -0.000251    |\n",
      "|    reward               | -49.702763   |\n",
      "|    value_loss           | 4.5e+04      |\n",
      "------------------------------------------\n",
      "Episode: 716\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1059491.24\n",
      "total_reward: 59491.24\n",
      "total_cost: 1274314.08\n",
      "total_trades: 1197\n",
      "=================================\n",
      "Episode: 717\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1296          |\n",
      "|    time_elapsed         | 5304          |\n",
      "|    total_timesteps      | 1327104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010578032 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.929        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.56e+05      |\n",
      "|    n_updates            | 38180         |\n",
      "|    policy_gradient_loss | -0.000284     |\n",
      "|    reward               | -26.452616    |\n",
      "|    value_loss           | 3.11e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 718\n",
      "Episode: 719\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1297          |\n",
      "|    time_elapsed         | 5309          |\n",
      "|    total_timesteps      | 1328128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7214817e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.927        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.43e+05      |\n",
      "|    n_updates            | 38190         |\n",
      "|    policy_gradient_loss | -0.000126     |\n",
      "|    reward               | -15.138947    |\n",
      "|    value_loss           | 6.86e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 720\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695830.22\n",
      "total_reward: -304169.78\n",
      "total_cost: 158382.56\n",
      "total_trades: 171\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1298          |\n",
      "|    time_elapsed         | 5313          |\n",
      "|    total_timesteps      | 1329152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041401718 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.925        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.54e+04      |\n",
      "|    n_updates            | 38200         |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    reward               | 13.541589     |\n",
      "|    value_loss           | 5.09e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1299          |\n",
      "|    time_elapsed         | 5318          |\n",
      "|    total_timesteps      | 1330176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040159904 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.917        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.24e+04      |\n",
      "|    n_updates            | 38210         |\n",
      "|    policy_gradient_loss | -0.000127     |\n",
      "|    reward               | -16.174986    |\n",
      "|    value_loss           | 1.05e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 721\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1300          |\n",
      "|    time_elapsed         | 5322          |\n",
      "|    total_timesteps      | 1331200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010218425 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+05      |\n",
      "|    n_updates            | 38220         |\n",
      "|    policy_gradient_loss | -0.000222     |\n",
      "|    reward               | 0.60954535    |\n",
      "|    value_loss           | 2.43e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 5326        |\n",
      "|    total_timesteps      | 1332224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.03227e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.53e+04    |\n",
      "|    n_updates            | 38230       |\n",
      "|    policy_gradient_loss | 1.66e-05    |\n",
      "|    reward               | -61.26901   |\n",
      "|    value_loss           | 1.11e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 722\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1302          |\n",
      "|    time_elapsed         | 5330          |\n",
      "|    total_timesteps      | 1333248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9774208e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.914        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.13e+04      |\n",
      "|    n_updates            | 38240         |\n",
      "|    policy_gradient_loss | -8.1e-05      |\n",
      "|    reward               | -46.427986    |\n",
      "|    value_loss           | 1.43e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 723\n",
      "Episode: 724\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1281718.42\n",
      "total_reward: 281718.42\n",
      "total_cost: 169020.08\n",
      "total_trades: 156\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1303          |\n",
      "|    time_elapsed         | 5335          |\n",
      "|    total_timesteps      | 1334272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.5116986e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.917        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.02e+05      |\n",
      "|    n_updates            | 38250         |\n",
      "|    policy_gradient_loss | 1.81e-05      |\n",
      "|    reward               | -22.322056    |\n",
      "|    value_loss           | 4.05e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1304          |\n",
      "|    time_elapsed         | 5339          |\n",
      "|    total_timesteps      | 1335296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1415055e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.918        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.06e+04      |\n",
      "|    n_updates            | 38260         |\n",
      "|    policy_gradient_loss | -1.6e-06      |\n",
      "|    reward               | -86.94058     |\n",
      "|    value_loss           | 1.41e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 725\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1305         |\n",
      "|    time_elapsed         | 5343         |\n",
      "|    total_timesteps      | 1336320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.569332e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.917       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.47e+05     |\n",
      "|    n_updates            | 38270        |\n",
      "|    policy_gradient_loss | -0.000117    |\n",
      "|    reward               | 31.513271    |\n",
      "|    value_loss           | 6.95e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1306          |\n",
      "|    time_elapsed         | 5347          |\n",
      "|    total_timesteps      | 1337344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3426761e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.918        |\n",
      "|    explained_variance   | 0.00393       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.11e+05      |\n",
      "|    n_updates            | 38280         |\n",
      "|    policy_gradient_loss | 1.96e-05      |\n",
      "|    reward               | -38.149162    |\n",
      "|    value_loss           | 1.42e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 726\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1307          |\n",
      "|    time_elapsed         | 5351          |\n",
      "|    total_timesteps      | 1338368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8754508e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.0156        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28e+05      |\n",
      "|    n_updates            | 38290         |\n",
      "|    policy_gradient_loss | -1.45e-05     |\n",
      "|    reward               | 33.722797     |\n",
      "|    value_loss           | 2.62e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1308          |\n",
      "|    time_elapsed         | 5355          |\n",
      "|    total_timesteps      | 1339392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5049009e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.998        |\n",
      "|    explained_variance   | -0.905        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.15e+05      |\n",
      "|    n_updates            | 38300         |\n",
      "|    policy_gradient_loss | -4.41e-05     |\n",
      "|    reward               | 7.622885      |\n",
      "|    value_loss           | 1.04e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 727\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1309          |\n",
      "|    time_elapsed         | 5358          |\n",
      "|    total_timesteps      | 1340416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1781383e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.0103        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+05      |\n",
      "|    n_updates            | 38310         |\n",
      "|    policy_gradient_loss | 3.2e-06       |\n",
      "|    reward               | 7.755454      |\n",
      "|    value_loss           | 3.29e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1310          |\n",
      "|    time_elapsed         | 5362          |\n",
      "|    total_timesteps      | 1341440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7229544e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -0.0376       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.54e+05      |\n",
      "|    n_updates            | 38320         |\n",
      "|    policy_gradient_loss | -2.19e-05     |\n",
      "|    reward               | 24.776653     |\n",
      "|    value_loss           | 3.22e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1311         |\n",
      "|    time_elapsed         | 5367         |\n",
      "|    total_timesteps      | 1342464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.136259e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.986       |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.23e+05     |\n",
      "|    n_updates            | 38330        |\n",
      "|    policy_gradient_loss | -2.19e-06    |\n",
      "|    reward               | 3.8718007    |\n",
      "|    value_loss           | 1.26e+06     |\n",
      "------------------------------------------\n",
      "Episode: 728\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2839400.59\n",
      "total_reward: 1839400.59\n",
      "total_cost: 1963411.88\n",
      "total_trades: 1183\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1312          |\n",
      "|    time_elapsed         | 5371          |\n",
      "|    total_timesteps      | 1343488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9604645e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.916        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.27e+05      |\n",
      "|    n_updates            | 38340         |\n",
      "|    policy_gradient_loss | -2.65e-06     |\n",
      "|    reward               | 8.904034      |\n",
      "|    value_loss           | 2.59e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 729\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1313          |\n",
      "|    time_elapsed         | 5375          |\n",
      "|    total_timesteps      | 1344512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0646257e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.916        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.75e+05      |\n",
      "|    n_updates            | 38350         |\n",
      "|    policy_gradient_loss | -1.38e-05     |\n",
      "|    reward               | -28.887989    |\n",
      "|    value_loss           | 7.68e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 730\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1314          |\n",
      "|    time_elapsed         | 5379          |\n",
      "|    total_timesteps      | 1345536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3296958e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.916        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.42e+04      |\n",
      "|    n_updates            | 38360         |\n",
      "|    policy_gradient_loss | -1.26e-05     |\n",
      "|    reward               | -0.05585339   |\n",
      "|    value_loss           | 1.08e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1315          |\n",
      "|    time_elapsed         | 5385          |\n",
      "|    total_timesteps      | 1346560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3860408e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.916        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.15e+05      |\n",
      "|    n_updates            | 38370         |\n",
      "|    policy_gradient_loss | -0.000149     |\n",
      "|    reward               | -1.4048309    |\n",
      "|    value_loss           | 4.3e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1316          |\n",
      "|    time_elapsed         | 5389          |\n",
      "|    total_timesteps      | 1347584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6955542e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.918        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.18e+04      |\n",
      "|    n_updates            | 38380         |\n",
      "|    policy_gradient_loss | -4.8e-05      |\n",
      "|    reward               | -27.780394    |\n",
      "|    value_loss           | 1.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 731\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1317         |\n",
      "|    time_elapsed         | 5393         |\n",
      "|    total_timesteps      | 1348608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.285231e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.92        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.36e+04     |\n",
      "|    n_updates            | 38390        |\n",
      "|    policy_gradient_loss | -0.000112    |\n",
      "|    reward               | -20.109098   |\n",
      "|    value_loss           | 4.73e+04     |\n",
      "------------------------------------------\n",
      "Episode: 732\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699006.42\n",
      "total_reward: -300993.58\n",
      "total_cost: 596255.99\n",
      "total_trades: 619\n",
      "=================================\n",
      "Episode: 733\n",
      "Episode: 734\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1318         |\n",
      "|    time_elapsed         | 5398         |\n",
      "|    total_timesteps      | 1349632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.723494e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.923       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.22e+04     |\n",
      "|    n_updates            | 38400        |\n",
      "|    policy_gradient_loss | -1.01e-05    |\n",
      "|    reward               | -16.546335   |\n",
      "|    value_loss           | 6.44e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 1319         |\n",
      "|    time_elapsed         | 5402         |\n",
      "|    total_timesteps      | 1350656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.286529e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.923       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.59e+05     |\n",
      "|    n_updates            | 38410        |\n",
      "|    policy_gradient_loss | -9e-05       |\n",
      "|    reward               | -35.614365   |\n",
      "|    value_loss           | 3.18e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 250           |\n",
      "|    iterations           | 1320          |\n",
      "|    time_elapsed         | 5406          |\n",
      "|    total_timesteps      | 1351680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1315216e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.922        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.88e+04      |\n",
      "|    n_updates            | 38420         |\n",
      "|    policy_gradient_loss | 2.53e-05      |\n",
      "|    reward               | -88.4644      |\n",
      "|    value_loss           | 9.77e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 735\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1321          |\n",
      "|    time_elapsed         | 5410          |\n",
      "|    total_timesteps      | 1352704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6286808e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.921        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.16e+05      |\n",
      "|    n_updates            | 38430         |\n",
      "|    policy_gradient_loss | -2.07e-06     |\n",
      "|    reward               | -14.866993    |\n",
      "|    value_loss           | 6.33e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1322          |\n",
      "|    time_elapsed         | 5415          |\n",
      "|    total_timesteps      | 1353728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7956634e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.921        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.79e+05      |\n",
      "|    n_updates            | 38440         |\n",
      "|    policy_gradient_loss | -6.3e-05      |\n",
      "|    reward               | -9.372102     |\n",
      "|    value_loss           | 7.58e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1323          |\n",
      "|    time_elapsed         | 5419          |\n",
      "|    total_timesteps      | 1354752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038208178 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.925        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.73e+03      |\n",
      "|    n_updates            | 38450         |\n",
      "|    policy_gradient_loss | -0.000607     |\n",
      "|    reward               | -82.95615     |\n",
      "|    value_loss           | 1.35e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 736\n",
      "Current company: ['V']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 957948.23\n",
      "total_reward: -42051.77\n",
      "total_cost: 1511345.06\n",
      "total_trades: 1253\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1324          |\n",
      "|    time_elapsed         | 5423          |\n",
      "|    total_timesteps      | 1355776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061070226 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.943        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.42e+05      |\n",
      "|    n_updates            | 38460         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | -50.586464    |\n",
      "|    value_loss           | 2.84e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 737\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1325          |\n",
      "|    time_elapsed         | 5427          |\n",
      "|    total_timesteps      | 1356800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013621966 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.955        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.17e+04      |\n",
      "|    n_updates            | 38470         |\n",
      "|    policy_gradient_loss | -0.00042      |\n",
      "|    reward               | 8.873349      |\n",
      "|    value_loss           | 1.84e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1326          |\n",
      "|    time_elapsed         | 5431          |\n",
      "|    total_timesteps      | 1357824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2488413e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.961        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.54e+05      |\n",
      "|    n_updates            | 38480         |\n",
      "|    policy_gradient_loss | 5.52e-05      |\n",
      "|    reward               | -35.794903    |\n",
      "|    value_loss           | 5.08e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 738\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1327         |\n",
      "|    time_elapsed         | 5436         |\n",
      "|    total_timesteps      | 1358848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.704475e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.964       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.09e+05     |\n",
      "|    n_updates            | 38490        |\n",
      "|    policy_gradient_loss | -0.000123    |\n",
      "|    reward               | -2.3787224   |\n",
      "|    value_loss           | 4.17e+05     |\n",
      "------------------------------------------\n",
      "Episode: 739\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1328          |\n",
      "|    time_elapsed         | 5440          |\n",
      "|    total_timesteps      | 1359872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4608834e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.965        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.18e+05      |\n",
      "|    n_updates            | 38500         |\n",
      "|    policy_gradient_loss | -0.000105     |\n",
      "|    reward               | -43.919613    |\n",
      "|    value_loss           | 4.37e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 740\n",
      "Current company: ['IBM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698900.94\n",
      "total_reward: -301099.06\n",
      "total_cost: 559495.84\n",
      "total_trades: 559\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1329         |\n",
      "|    time_elapsed         | 5444         |\n",
      "|    total_timesteps      | 1360896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055636857 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.978       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42e+04     |\n",
      "|    n_updates            | 38510        |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    reward               | -27.18578    |\n",
      "|    value_loss           | 2.83e+04     |\n",
      "------------------------------------------\n",
      "Episode: 741\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 1330       |\n",
      "|    time_elapsed         | 5448       |\n",
      "|    total_timesteps      | 1361920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00402087 |\n",
      "|    clip_fraction        | 0.0404     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.987     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.19e+04   |\n",
      "|    n_updates            | 38520      |\n",
      "|    policy_gradient_loss | -0.000865  |\n",
      "|    reward               | -33.75853  |\n",
      "|    value_loss           | 1.24e+05   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1331          |\n",
      "|    time_elapsed         | 5453          |\n",
      "|    total_timesteps      | 1362944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042178237 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.37e+05      |\n",
      "|    n_updates            | 38530         |\n",
      "|    policy_gradient_loss | -0.000655     |\n",
      "|    reward               | -64.48668     |\n",
      "|    value_loss           | 2.74e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 5457         |\n",
      "|    total_timesteps      | 1363968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.412133e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.974       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.37e+05     |\n",
      "|    n_updates            | 38540        |\n",
      "|    policy_gradient_loss | -1.14e-06    |\n",
      "|    reward               | -70.59489    |\n",
      "|    value_loss           | 2.75e+05     |\n",
      "------------------------------------------\n",
      "Episode: 742\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1333         |\n",
      "|    time_elapsed         | 5461         |\n",
      "|    total_timesteps      | 1364992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.499017e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.19e+05     |\n",
      "|    n_updates            | 38550        |\n",
      "|    policy_gradient_loss | -5.42e-05    |\n",
      "|    reward               | -20.560081   |\n",
      "|    value_loss           | 6.45e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1334          |\n",
      "|    time_elapsed         | 5465          |\n",
      "|    total_timesteps      | 1366016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7912584e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.975        |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.45e+05      |\n",
      "|    n_updates            | 38560         |\n",
      "|    policy_gradient_loss | -0.000294     |\n",
      "|    reward               | -43.78226     |\n",
      "|    value_loss           | 2.91e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 743\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1335         |\n",
      "|    time_elapsed         | 5469         |\n",
      "|    total_timesteps      | 1367040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001143532 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.983       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.72e+05     |\n",
      "|    n_updates            | 38570        |\n",
      "|    policy_gradient_loss | -0.000412    |\n",
      "|    reward               | -6.0250807   |\n",
      "|    value_loss           | 3.44e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1336          |\n",
      "|    time_elapsed         | 5474          |\n",
      "|    total_timesteps      | 1368064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3180794e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.988        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.12e+05      |\n",
      "|    n_updates            | 38580         |\n",
      "|    policy_gradient_loss | -2.91e-05     |\n",
      "|    reward               | -26.774546    |\n",
      "|    value_loss           | 8.24e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1337         |\n",
      "|    time_elapsed         | 5477         |\n",
      "|    total_timesteps      | 1369088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.218165e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.99        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.44e+04     |\n",
      "|    n_updates            | 38590        |\n",
      "|    policy_gradient_loss | -5.86e-05    |\n",
      "|    reward               | -43.47882    |\n",
      "|    value_loss           | 6.9e+04      |\n",
      "------------------------------------------\n",
      "Episode: 744\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1042619.24\n",
      "total_reward: 42619.24\n",
      "total_cost: 1229850.86\n",
      "total_trades: 1102\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1338          |\n",
      "|    time_elapsed         | 5482          |\n",
      "|    total_timesteps      | 1370112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3159704e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.989        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28e+05      |\n",
      "|    n_updates            | 38600         |\n",
      "|    policy_gradient_loss | -5.47e-05     |\n",
      "|    reward               | 6.9009476     |\n",
      "|    value_loss           | 2.56e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1339          |\n",
      "|    time_elapsed         | 5486          |\n",
      "|    total_timesteps      | 1371136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9619626e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.989        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.1e+05       |\n",
      "|    n_updates            | 38610         |\n",
      "|    policy_gradient_loss | -5.88e-05     |\n",
      "|    reward               | -6.6452537    |\n",
      "|    value_loss           | 4.23e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1340         |\n",
      "|    time_elapsed         | 5490         |\n",
      "|    total_timesteps      | 1372160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002677685 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.992       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.12e+03     |\n",
      "|    n_updates            | 38620        |\n",
      "|    policy_gradient_loss | -0.000204    |\n",
      "|    reward               | -11.777021   |\n",
      "|    value_loss           | 1.82e+04     |\n",
      "------------------------------------------\n",
      "Episode: 745\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1341          |\n",
      "|    time_elapsed         | 5494          |\n",
      "|    total_timesteps      | 1373184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041089987 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.78e+04      |\n",
      "|    n_updates            | 38630         |\n",
      "|    policy_gradient_loss | -0.000309     |\n",
      "|    reward               | -12.075578    |\n",
      "|    value_loss           | 3.57e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 746\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 249            |\n",
      "|    iterations           | 1342           |\n",
      "|    time_elapsed         | 5498           |\n",
      "|    total_timesteps      | 1374208        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000117545365 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.01          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 7.96e+04       |\n",
      "|    n_updates            | 38640          |\n",
      "|    policy_gradient_loss | 2.27e-05       |\n",
      "|    reward               | 6.915266       |\n",
      "|    value_loss           | 1.59e+05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1343         |\n",
      "|    time_elapsed         | 5503         |\n",
      "|    total_timesteps      | 1375232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.307053e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.83e+04     |\n",
      "|    n_updates            | 38650        |\n",
      "|    policy_gradient_loss | 5.16e-05     |\n",
      "|    reward               | -39.250443   |\n",
      "|    value_loss           | 1.77e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1344         |\n",
      "|    time_elapsed         | 5507         |\n",
      "|    total_timesteps      | 1376256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.977084e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.11e+04     |\n",
      "|    n_updates            | 38660        |\n",
      "|    policy_gradient_loss | -0.000364    |\n",
      "|    reward               | -84.66054    |\n",
      "|    value_loss           | 4.23e+04     |\n",
      "------------------------------------------\n",
      "Episode: 747\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1345          |\n",
      "|    time_elapsed         | 5512          |\n",
      "|    total_timesteps      | 1377280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.8201836e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.31e+05      |\n",
      "|    n_updates            | 38670         |\n",
      "|    policy_gradient_loss | 0.000242      |\n",
      "|    reward               | -22.412497    |\n",
      "|    value_loss           | 8.62e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1346          |\n",
      "|    time_elapsed         | 5517          |\n",
      "|    total_timesteps      | 1378304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1813652e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.69e+05      |\n",
      "|    n_updates            | 38680         |\n",
      "|    policy_gradient_loss | -4.87e-05     |\n",
      "|    reward               | -67.96161     |\n",
      "|    value_loss           | 5.39e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 748\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695367.11\n",
      "total_reward: -304632.89\n",
      "total_cost: 1064348.23\n",
      "total_trades: 1085\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1347          |\n",
      "|    time_elapsed         | 5522          |\n",
      "|    total_timesteps      | 1379328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5281992e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.16e+05      |\n",
      "|    n_updates            | 38690         |\n",
      "|    policy_gradient_loss | 1.01e-05      |\n",
      "|    reward               | 2.0521252     |\n",
      "|    value_loss           | 4.32e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1348          |\n",
      "|    time_elapsed         | 5527          |\n",
      "|    total_timesteps      | 1380352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0775478e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.39e+05      |\n",
      "|    n_updates            | 38700         |\n",
      "|    policy_gradient_loss | -6.39e-06     |\n",
      "|    reward               | -49.069527    |\n",
      "|    value_loss           | 8.79e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 749\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1349          |\n",
      "|    time_elapsed         | 5531          |\n",
      "|    total_timesteps      | 1381376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7823338e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.03e+05      |\n",
      "|    n_updates            | 38710         |\n",
      "|    policy_gradient_loss | 4.28e-06      |\n",
      "|    reward               | -15.637307    |\n",
      "|    value_loss           | 2.06e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1350          |\n",
      "|    time_elapsed         | 5536          |\n",
      "|    total_timesteps      | 1382400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1475134e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.83e+04      |\n",
      "|    n_updates            | 38720         |\n",
      "|    policy_gradient_loss | -2.74e-05     |\n",
      "|    reward               | -72.501366    |\n",
      "|    value_loss           | 1.97e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 750\n",
      "Episode: 751\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1351          |\n",
      "|    time_elapsed         | 5540          |\n",
      "|    total_timesteps      | 1383424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1380914e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.7e+05       |\n",
      "|    n_updates            | 38730         |\n",
      "|    policy_gradient_loss | -1.58e-06     |\n",
      "|    reward               | -7.3141108    |\n",
      "|    value_loss           | 3.4e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 752\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698037.04\n",
      "total_reward: -301962.96\n",
      "total_cost: 194400.93\n",
      "total_trades: 193\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1352          |\n",
      "|    time_elapsed         | 5545          |\n",
      "|    total_timesteps      | 1384448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0477379e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.64e+05      |\n",
      "|    n_updates            | 38740         |\n",
      "|    policy_gradient_loss | 2.95e-06      |\n",
      "|    reward               | -9.172504     |\n",
      "|    value_loss           | 7.29e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1353         |\n",
      "|    time_elapsed         | 5549         |\n",
      "|    total_timesteps      | 1385472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.047078e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.76e+04     |\n",
      "|    n_updates            | 38750        |\n",
      "|    policy_gradient_loss | -0.00012     |\n",
      "|    reward               | -59.000248   |\n",
      "|    value_loss           | 5.52e+04     |\n",
      "------------------------------------------\n",
      "Episode: 753\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1354          |\n",
      "|    time_elapsed         | 5553          |\n",
      "|    total_timesteps      | 1386496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1291355e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.63e+04      |\n",
      "|    n_updates            | 38760         |\n",
      "|    policy_gradient_loss | 0.000126      |\n",
      "|    reward               | 2.8013518     |\n",
      "|    value_loss           | 1.73e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1355         |\n",
      "|    time_elapsed         | 5557         |\n",
      "|    total_timesteps      | 1387520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.937733e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.36e+05     |\n",
      "|    n_updates            | 38770        |\n",
      "|    policy_gradient_loss | 1.15e-05     |\n",
      "|    reward               | -31.834982   |\n",
      "|    value_loss           | 4.71e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1356          |\n",
      "|    time_elapsed         | 5561          |\n",
      "|    total_timesteps      | 1388544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8337813e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.95e+04      |\n",
      "|    n_updates            | 38780         |\n",
      "|    policy_gradient_loss | -0.00024      |\n",
      "|    reward               | -88.69872     |\n",
      "|    value_loss           | 3.91e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 754\n",
      "Episode: 755\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1357         |\n",
      "|    time_elapsed         | 5565         |\n",
      "|    total_timesteps      | 1389568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.627082e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.31e+05     |\n",
      "|    n_updates            | 38790        |\n",
      "|    policy_gradient_loss | -5.38e-05    |\n",
      "|    reward               | -43.35398    |\n",
      "|    value_loss           | 1.06e+06     |\n",
      "------------------------------------------\n",
      "Episode: 756\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 680235.47\n",
      "total_reward: -319764.53\n",
      "total_cost: 226457.29\n",
      "total_trades: 277\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1358          |\n",
      "|    time_elapsed         | 5570          |\n",
      "|    total_timesteps      | 1390592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5634578e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.91e+05      |\n",
      "|    n_updates            | 38800         |\n",
      "|    policy_gradient_loss | 5.84e-05      |\n",
      "|    reward               | 4.518256      |\n",
      "|    value_loss           | 3.83e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1359          |\n",
      "|    time_elapsed         | 5574          |\n",
      "|    total_timesteps      | 1391616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013309397 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.96e+04      |\n",
      "|    n_updates            | 38810         |\n",
      "|    policy_gradient_loss | -0.000536     |\n",
      "|    reward               | -44.662228    |\n",
      "|    value_loss           | 1.19e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 757\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 1360        |\n",
      "|    time_elapsed         | 5578        |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002124509 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.09e+04    |\n",
      "|    n_updates            | 38820       |\n",
      "|    policy_gradient_loss | -0.000716   |\n",
      "|    reward               | 14.96133    |\n",
      "|    value_loss           | 6.19e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1361         |\n",
      "|    time_elapsed         | 5582         |\n",
      "|    total_timesteps      | 1393664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014265613 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.53e+05     |\n",
      "|    n_updates            | 38830        |\n",
      "|    policy_gradient_loss | 0.000527     |\n",
      "|    reward               | -57.904484   |\n",
      "|    value_loss           | 5.06e+05     |\n",
      "------------------------------------------\n",
      "Episode: 758\n",
      "Episode: 759\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1362          |\n",
      "|    time_elapsed         | 5586          |\n",
      "|    total_timesteps      | 1394688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017090235 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.997        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.46e+04      |\n",
      "|    n_updates            | 38840         |\n",
      "|    policy_gradient_loss | -0.000142     |\n",
      "|    reward               | -14.46529     |\n",
      "|    value_loss           | 1.69e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 5590         |\n",
      "|    total_timesteps      | 1395712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002575465 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.993       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.52e+04     |\n",
      "|    n_updates            | 38850        |\n",
      "|    policy_gradient_loss | -0.000537    |\n",
      "|    reward               | -39.335102   |\n",
      "|    value_loss           | 1.1e+05      |\n",
      "------------------------------------------\n",
      "Episode: 760\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697698.02\n",
      "total_reward: -302301.98\n",
      "total_cost: 1085922.84\n",
      "total_trades: 941\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1364          |\n",
      "|    time_elapsed         | 5594          |\n",
      "|    total_timesteps      | 1396736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020853861 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.985        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4e+04         |\n",
      "|    n_updates            | 38860         |\n",
      "|    policy_gradient_loss | -0.00015      |\n",
      "|    reward               | -16.657406    |\n",
      "|    value_loss           | 8.02e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 761\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1365         |\n",
      "|    time_elapsed         | 5598         |\n",
      "|    total_timesteps      | 1397760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.326374e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.981       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.13e+05     |\n",
      "|    n_updates            | 38870        |\n",
      "|    policy_gradient_loss | 9.98e-05     |\n",
      "|    reward               | -50.056023   |\n",
      "|    value_loss           | 8.26e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 5602        |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.23647e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86e+04    |\n",
      "|    n_updates            | 38880       |\n",
      "|    policy_gradient_loss | -2.59e-05   |\n",
      "|    reward               | -91.290436  |\n",
      "|    value_loss           | 1.57e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 762\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1367          |\n",
      "|    time_elapsed         | 5607          |\n",
      "|    total_timesteps      | 1399808       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9362272e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.05e+05      |\n",
      "|    n_updates            | 38890         |\n",
      "|    policy_gradient_loss | -3.18e-05     |\n",
      "|    reward               | -16.980906    |\n",
      "|    value_loss           | 1.21e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1368          |\n",
      "|    time_elapsed         | 5611          |\n",
      "|    total_timesteps      | 1400832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4025718e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.977        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.13e+05      |\n",
      "|    n_updates            | 38900         |\n",
      "|    policy_gradient_loss | -2.48e-05     |\n",
      "|    reward               | -9.897943     |\n",
      "|    value_loss           | 1.63e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1369         |\n",
      "|    time_elapsed         | 5614         |\n",
      "|    total_timesteps      | 1401856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006254959 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.982       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.45e+03     |\n",
      "|    n_updates            | 38910        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    reward               | 128.34976    |\n",
      "|    value_loss           | 1.49e+04     |\n",
      "------------------------------------------\n",
      "Episode: 763\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1370         |\n",
      "|    time_elapsed         | 5619         |\n",
      "|    total_timesteps      | 1402880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007240368 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.77e+06     |\n",
      "|    n_updates            | 38920        |\n",
      "|    policy_gradient_loss | -0.000505    |\n",
      "|    reward               | -50.67621    |\n",
      "|    value_loss           | 3.54e+06     |\n",
      "------------------------------------------\n",
      "Episode: 764\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699432.52\n",
      "total_reward: -300567.48\n",
      "total_cost: 230710.77\n",
      "total_trades: 259\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1371         |\n",
      "|    time_elapsed         | 5623         |\n",
      "|    total_timesteps      | 1403904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.664257e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.71e+06     |\n",
      "|    n_updates            | 38930        |\n",
      "|    policy_gradient_loss | 5.2e-05      |\n",
      "|    reward               | -42.954678   |\n",
      "|    value_loss           | 3.42e+06     |\n",
      "------------------------------------------\n",
      "Episode: 765\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1372          |\n",
      "|    time_elapsed         | 5627          |\n",
      "|    total_timesteps      | 1404928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6111491e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.98e+04      |\n",
      "|    n_updates            | 38940         |\n",
      "|    policy_gradient_loss | -9.42e-05     |\n",
      "|    reward               | -26.427132    |\n",
      "|    value_loss           | 5.95e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 766\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1373          |\n",
      "|    time_elapsed         | 5631          |\n",
      "|    total_timesteps      | 1405952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6556703e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.31e+05      |\n",
      "|    n_updates            | 38950         |\n",
      "|    policy_gradient_loss | -1.62e-05     |\n",
      "|    reward               | -48.56747     |\n",
      "|    value_loss           | 2.63e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1374         |\n",
      "|    time_elapsed         | 5635         |\n",
      "|    total_timesteps      | 1406976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.784146e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03e+05     |\n",
      "|    n_updates            | 38960        |\n",
      "|    policy_gradient_loss | -2.91e-05    |\n",
      "|    reward               | -82.33881    |\n",
      "|    value_loss           | 2.07e+05     |\n",
      "------------------------------------------\n",
      "Episode: 767\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1375          |\n",
      "|    time_elapsed         | 5639          |\n",
      "|    total_timesteps      | 1408000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4127734e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.57e+05      |\n",
      "|    n_updates            | 38970         |\n",
      "|    policy_gradient_loss | -5.13e-05     |\n",
      "|    reward               | -41.57848     |\n",
      "|    value_loss           | 7.15e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 768\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699673.50\n",
      "total_reward: -300326.50\n",
      "total_cost: 206016.64\n",
      "total_trades: 209\n",
      "=================================\n",
      "Episode: 769\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1376         |\n",
      "|    time_elapsed         | 5643         |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.735806e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03e+05     |\n",
      "|    n_updates            | 38980        |\n",
      "|    policy_gradient_loss | 2.91e-06     |\n",
      "|    reward               | 17.846556    |\n",
      "|    value_loss           | 8.06e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1377          |\n",
      "|    time_elapsed         | 5647          |\n",
      "|    total_timesteps      | 1410048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0407955e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.83e+04      |\n",
      "|    n_updates            | 38990         |\n",
      "|    policy_gradient_loss | -0.000118     |\n",
      "|    reward               | -4.468129     |\n",
      "|    value_loss           | 9.66e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 770\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1378          |\n",
      "|    time_elapsed         | 5651          |\n",
      "|    total_timesteps      | 1411072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4899899e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.85e+04      |\n",
      "|    n_updates            | 39000         |\n",
      "|    policy_gradient_loss | -5.09e-05     |\n",
      "|    reward               | -9.05755      |\n",
      "|    value_loss           | 1.97e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 771\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1379         |\n",
      "|    time_elapsed         | 5655         |\n",
      "|    total_timesteps      | 1412096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010001438 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.79e+04     |\n",
      "|    n_updates            | 39010        |\n",
      "|    policy_gradient_loss | -0.000455    |\n",
      "|    reward               | -9.155649    |\n",
      "|    value_loss           | 3.58e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1380         |\n",
      "|    time_elapsed         | 5659         |\n",
      "|    total_timesteps      | 1413120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010684486 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.98e+04     |\n",
      "|    n_updates            | 39020        |\n",
      "|    policy_gradient_loss | 0.000443     |\n",
      "|    reward               | -64.444244   |\n",
      "|    value_loss           | 7.96e+04     |\n",
      "------------------------------------------\n",
      "Episode: 772\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 647996.28\n",
      "total_reward: -352003.72\n",
      "total_cost: 980614.79\n",
      "total_trades: 907\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1381          |\n",
      "|    time_elapsed         | 5664          |\n",
      "|    total_timesteps      | 1414144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011260406 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.98e+05      |\n",
      "|    n_updates            | 39030         |\n",
      "|    policy_gradient_loss | -7.53e-05     |\n",
      "|    reward               | 11.820179     |\n",
      "|    value_loss           | 5.97e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1382          |\n",
      "|    time_elapsed         | 5668          |\n",
      "|    total_timesteps      | 1415168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9319705e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.93e+05      |\n",
      "|    n_updates            | 39040         |\n",
      "|    policy_gradient_loss | -2.98e-05     |\n",
      "|    reward               | 2.9394007     |\n",
      "|    value_loss           | 3.87e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1383          |\n",
      "|    time_elapsed         | 5672          |\n",
      "|    total_timesteps      | 1416192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2103119e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.69e+05      |\n",
      "|    n_updates            | 39050         |\n",
      "|    policy_gradient_loss | 2.86e-05      |\n",
      "|    reward               | -4.9479156    |\n",
      "|    value_loss           | 3.38e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 773\n",
      "Episode: 774\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1384          |\n",
      "|    time_elapsed         | 5676          |\n",
      "|    total_timesteps      | 1417216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0570762e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.24e+04      |\n",
      "|    n_updates            | 39060         |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    reward               | 3.2839851     |\n",
      "|    value_loss           | 8.48e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1385         |\n",
      "|    time_elapsed         | 5681         |\n",
      "|    total_timesteps      | 1418240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.288539e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -0.00912     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.88e+04     |\n",
      "|    n_updates            | 39070        |\n",
      "|    policy_gradient_loss | -3.08e-05    |\n",
      "|    reward               | -38.808193   |\n",
      "|    value_loss           | 1.58e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1386          |\n",
      "|    time_elapsed         | 5685          |\n",
      "|    total_timesteps      | 1419264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2959936e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.583         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.22e+05      |\n",
      "|    n_updates            | 39080         |\n",
      "|    policy_gradient_loss | -3.41e-05     |\n",
      "|    reward               | 20.289862     |\n",
      "|    value_loss           | 2.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 775\n",
      "Episode: 776\n",
      "Current company: ['DOW']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 643454.91\n",
      "total_reward: -356545.09\n",
      "total_cost: 15834.96\n",
      "total_trades: 17\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1387          |\n",
      "|    time_elapsed         | 5689          |\n",
      "|    total_timesteps      | 1420288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3591489e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 0.0185        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.53e+05      |\n",
      "|    n_updates            | 39090         |\n",
      "|    policy_gradient_loss | -7.39e-08     |\n",
      "|    reward               | -17.922115    |\n",
      "|    value_loss           | 3.21e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1388          |\n",
      "|    time_elapsed         | 5693          |\n",
      "|    total_timesteps      | 1421312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0372637e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0.946         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+04      |\n",
      "|    n_updates            | 39100         |\n",
      "|    policy_gradient_loss | -0.00031      |\n",
      "|    reward               | -70.65476     |\n",
      "|    value_loss           | 2.9e+04       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1389          |\n",
      "|    time_elapsed         | 5697          |\n",
      "|    total_timesteps      | 1422336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4720247e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.85e+05      |\n",
      "|    n_updates            | 39110         |\n",
      "|    policy_gradient_loss | -4.47e-05     |\n",
      "|    reward               | -12.060196    |\n",
      "|    value_loss           | 3.71e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 777\n",
      "Episode: 778\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1390          |\n",
      "|    time_elapsed         | 5701          |\n",
      "|    total_timesteps      | 1423360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9597736e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.02e+05      |\n",
      "|    n_updates            | 39120         |\n",
      "|    policy_gradient_loss | -2.1e-05      |\n",
      "|    reward               | -62.050217    |\n",
      "|    value_loss           | 8.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 779\n",
      "Episode: 780\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698660.05\n",
      "total_reward: -301339.95\n",
      "total_cost: 101185.08\n",
      "total_trades: 127\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1391          |\n",
      "|    time_elapsed         | 5705          |\n",
      "|    total_timesteps      | 1424384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7087848e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+05      |\n",
      "|    n_updates            | 39130         |\n",
      "|    policy_gradient_loss | -0.000159     |\n",
      "|    reward               | 18.697416     |\n",
      "|    value_loss           | 2.42e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1392          |\n",
      "|    time_elapsed         | 5709          |\n",
      "|    total_timesteps      | 1425408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0736287e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.95e+04      |\n",
      "|    n_updates            | 39140         |\n",
      "|    policy_gradient_loss | -6.58e-06     |\n",
      "|    reward               | 43.753643     |\n",
      "|    value_loss           | 1.59e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1393          |\n",
      "|    time_elapsed         | 5714          |\n",
      "|    total_timesteps      | 1426432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2113887e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.85e+05      |\n",
      "|    n_updates            | 39150         |\n",
      "|    policy_gradient_loss | -6.66e-05     |\n",
      "|    reward               | -32.73749     |\n",
      "|    value_loss           | 9.7e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 781\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 5718         |\n",
      "|    total_timesteps      | 1427456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.888497e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.02e+05     |\n",
      "|    n_updates            | 39160        |\n",
      "|    policy_gradient_loss | -1.91e-05    |\n",
      "|    reward               | 52.276695    |\n",
      "|    value_loss           | 1.41e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1395         |\n",
      "|    time_elapsed         | 5722         |\n",
      "|    total_timesteps      | 1428480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.163303e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.78e+04     |\n",
      "|    n_updates            | 39170        |\n",
      "|    policy_gradient_loss | -5.09e-05    |\n",
      "|    reward               | 83.949066    |\n",
      "|    value_loss           | 1.96e+05     |\n",
      "------------------------------------------\n",
      "Episode: 782\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1396         |\n",
      "|    time_elapsed         | 5726         |\n",
      "|    total_timesteps      | 1429504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.844216e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.2e+06      |\n",
      "|    n_updates            | 39180        |\n",
      "|    policy_gradient_loss | 7.92e-05     |\n",
      "|    reward               | -24.631956   |\n",
      "|    value_loss           | 2.4e+06      |\n",
      "------------------------------------------\n",
      "Episode: 783\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1397         |\n",
      "|    time_elapsed         | 5730         |\n",
      "|    total_timesteps      | 1430528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.638009e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.61e+06     |\n",
      "|    n_updates            | 39190        |\n",
      "|    policy_gradient_loss | -2.34e-05    |\n",
      "|    reward               | 17.4382      |\n",
      "|    value_loss           | 3.22e+06     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 249            |\n",
      "|    iterations           | 1398           |\n",
      "|    time_elapsed         | 5734           |\n",
      "|    total_timesteps      | 1431552        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000115699426 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.04          |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 4.47e+04       |\n",
      "|    n_updates            | 39200          |\n",
      "|    policy_gradient_loss | -0.000427      |\n",
      "|    reward               | 43.15871       |\n",
      "|    value_loss           | 8.95e+04       |\n",
      "--------------------------------------------\n",
      "Episode: 784\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2048045.10\n",
      "total_reward: 1048045.10\n",
      "total_cost: 1785946.18\n",
      "total_trades: 1067\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 249            |\n",
      "|    iterations           | 1399           |\n",
      "|    time_elapsed         | 5738           |\n",
      "|    total_timesteps      | 1432576        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000102502934 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.04          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 2.06e+05       |\n",
      "|    n_updates            | 39210          |\n",
      "|    policy_gradient_loss | 0.000364       |\n",
      "|    reward               | -2.4054017     |\n",
      "|    value_loss           | 4.19e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1400          |\n",
      "|    time_elapsed         | 5742          |\n",
      "|    total_timesteps      | 1433600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0068528e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.99e+05      |\n",
      "|    n_updates            | 39220         |\n",
      "|    policy_gradient_loss | -2.71e-05     |\n",
      "|    reward               | -37.7625      |\n",
      "|    value_loss           | 1.43e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1401          |\n",
      "|    time_elapsed         | 5746          |\n",
      "|    total_timesteps      | 1434624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4546247e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.07e+04      |\n",
      "|    n_updates            | 39230         |\n",
      "|    policy_gradient_loss | 1.32e-05      |\n",
      "|    reward               | -70.93454     |\n",
      "|    value_loss           | 6.27e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 785\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1402          |\n",
      "|    time_elapsed         | 5750          |\n",
      "|    total_timesteps      | 1435648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7905133e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.1e+05       |\n",
      "|    n_updates            | 39240         |\n",
      "|    policy_gradient_loss | -2.23e-06     |\n",
      "|    reward               | 10.261256     |\n",
      "|    value_loss           | 4.27e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1403          |\n",
      "|    time_elapsed         | 5754          |\n",
      "|    total_timesteps      | 1436672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.1374816e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.76e+05      |\n",
      "|    n_updates            | 39250         |\n",
      "|    policy_gradient_loss | -7.63e-05     |\n",
      "|    reward               | -16.495668    |\n",
      "|    value_loss           | 7.53e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1404         |\n",
      "|    time_elapsed         | 5758         |\n",
      "|    total_timesteps      | 1437696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019703766 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.92e+03     |\n",
      "|    n_updates            | 39260        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    reward               | 77.334656    |\n",
      "|    value_loss           | 1.98e+04     |\n",
      "------------------------------------------\n",
      "Episode: 786\n",
      "Episode: 787\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 5763        |\n",
      "|    total_timesteps      | 1438720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011189181 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.989      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.48e+05    |\n",
      "|    n_updates            | 39270       |\n",
      "|    policy_gradient_loss | 0.00469     |\n",
      "|    reward               | -27.93339   |\n",
      "|    value_loss           | 2.97e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1406         |\n",
      "|    time_elapsed         | 5767         |\n",
      "|    total_timesteps      | 1439744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008796296 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.961       |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.82e+05     |\n",
      "|    n_updates            | 39280        |\n",
      "|    policy_gradient_loss | 0.000627     |\n",
      "|    reward               | -45.831802   |\n",
      "|    value_loss           | 3.64e+05     |\n",
      "------------------------------------------\n",
      "Episode: 788\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 860649.39\n",
      "total_reward: -139350.61\n",
      "total_cost: 1131323.38\n",
      "total_trades: 1069\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1407         |\n",
      "|    time_elapsed         | 5771         |\n",
      "|    total_timesteps      | 1440768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.426302e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.31e+04     |\n",
      "|    n_updates            | 39290        |\n",
      "|    policy_gradient_loss | -0.000199    |\n",
      "|    reward               | -13.334108   |\n",
      "|    value_loss           | 1.06e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1408          |\n",
      "|    time_elapsed         | 5775          |\n",
      "|    total_timesteps      | 1441792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0835531e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.987        |\n",
      "|    explained_variance   | 0.78          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.78e+05      |\n",
      "|    n_updates            | 39300         |\n",
      "|    policy_gradient_loss | -6.89e-05     |\n",
      "|    reward               | -16.456287    |\n",
      "|    value_loss           | 9.58e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1409          |\n",
      "|    time_elapsed         | 5779          |\n",
      "|    total_timesteps      | 1442816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1139858e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.969        |\n",
      "|    explained_variance   | 0.707         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.21e+04      |\n",
      "|    n_updates            | 39310         |\n",
      "|    policy_gradient_loss | -1.69e-06     |\n",
      "|    reward               | -73.14619     |\n",
      "|    value_loss           | 1.25e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 789\n",
      "Episode: 790\n",
      "Episode: 791\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1410          |\n",
      "|    time_elapsed         | 5784          |\n",
      "|    total_timesteps      | 1443840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9195722e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.947        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.09e+05      |\n",
      "|    n_updates            | 39320         |\n",
      "|    policy_gradient_loss | -2.74e-05     |\n",
      "|    reward               | -12.864911    |\n",
      "|    value_loss           | 4.18e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1411          |\n",
      "|    time_elapsed         | 5788          |\n",
      "|    total_timesteps      | 1444864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2782402e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.948        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.57e+05      |\n",
      "|    n_updates            | 39330         |\n",
      "|    policy_gradient_loss | -1.28e-05     |\n",
      "|    reward               | -42.45387     |\n",
      "|    value_loss           | 5.14e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 792\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699734.91\n",
      "total_reward: -300265.09\n",
      "total_cost: 770185.25\n",
      "total_trades: 793\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1412         |\n",
      "|    time_elapsed         | 5792         |\n",
      "|    total_timesteps      | 1445888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.006166e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.08e+04     |\n",
      "|    n_updates            | 39340        |\n",
      "|    policy_gradient_loss | -7.61e-05    |\n",
      "|    reward               | -13.370504   |\n",
      "|    value_loss           | 6.18e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1413          |\n",
      "|    time_elapsed         | 5797          |\n",
      "|    total_timesteps      | 1446912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2789096e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.49e+05      |\n",
      "|    n_updates            | 39350         |\n",
      "|    policy_gradient_loss | 3.06e-05      |\n",
      "|    reward               | 10.057359     |\n",
      "|    value_loss           | 6.98e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1414          |\n",
      "|    time_elapsed         | 5801          |\n",
      "|    total_timesteps      | 1447936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9951486e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.87e+04      |\n",
      "|    n_updates            | 39360         |\n",
      "|    policy_gradient_loss | -2.43e-05     |\n",
      "|    reward               | -9.608893     |\n",
      "|    value_loss           | 9.73e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 793\n",
      "Episode: 794\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1415         |\n",
      "|    time_elapsed         | 5805         |\n",
      "|    total_timesteps      | 1448960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001272973 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.946       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.06e+04     |\n",
      "|    n_updates            | 39370        |\n",
      "|    policy_gradient_loss | -0.000455    |\n",
      "|    reward               | -25.739243   |\n",
      "|    value_loss           | 4.12e+04     |\n",
      "------------------------------------------\n",
      "Episode: 795\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1416          |\n",
      "|    time_elapsed         | 5810          |\n",
      "|    total_timesteps      | 1449984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017897709 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.934        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.39e+04      |\n",
      "|    n_updates            | 39380         |\n",
      "|    policy_gradient_loss | -4.3e-05      |\n",
      "|    reward               | -17.829496    |\n",
      "|    value_loss           | 1.28e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 1417        |\n",
      "|    time_elapsed         | 5814        |\n",
      "|    total_timesteps      | 1451008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.59513e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.02e+05    |\n",
      "|    n_updates            | 39390       |\n",
      "|    policy_gradient_loss | -0.000265   |\n",
      "|    reward               | -29.88494   |\n",
      "|    value_loss           | 2.05e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1418          |\n",
      "|    time_elapsed         | 5817          |\n",
      "|    total_timesteps      | 1452032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3161057e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -0.527        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.07e+05      |\n",
      "|    n_updates            | 39400         |\n",
      "|    policy_gradient_loss | -2.6e-05      |\n",
      "|    reward               | -0.8052687    |\n",
      "|    value_loss           | 2.33e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 796\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1694255.48\n",
      "total_reward: 694255.48\n",
      "total_cost: 1122203.64\n",
      "total_trades: 841\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 5821        |\n",
      "|    total_timesteps      | 1453056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.67756e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0964      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83e+04    |\n",
      "|    n_updates            | 39410       |\n",
      "|    policy_gradient_loss | -2.01e-05   |\n",
      "|    reward               | -50.855125  |\n",
      "|    value_loss           | 1.63e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 797\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1420          |\n",
      "|    time_elapsed         | 5826          |\n",
      "|    total_timesteps      | 1454080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8604409e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.922        |\n",
      "|    explained_variance   | 0.129         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.08e+04      |\n",
      "|    n_updates            | 39420         |\n",
      "|    policy_gradient_loss | -2.27e-05     |\n",
      "|    reward               | 23.3283       |\n",
      "|    value_loss           | 6.22e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1421         |\n",
      "|    time_elapsed         | 5830         |\n",
      "|    total_timesteps      | 1455104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015435335 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.922       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.11e+05     |\n",
      "|    n_updates            | 39430        |\n",
      "|    policy_gradient_loss | -0.000756    |\n",
      "|    reward               | 22.306782    |\n",
      "|    value_loss           | 2.23e+05     |\n",
      "------------------------------------------\n",
      "Episode: 798\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1422         |\n",
      "|    time_elapsed         | 5834         |\n",
      "|    total_timesteps      | 1456128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018810784 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.925       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.4e+05      |\n",
      "|    n_updates            | 39440        |\n",
      "|    policy_gradient_loss | -0.000353    |\n",
      "|    reward               | -12.9802685  |\n",
      "|    value_loss           | 2.82e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1423          |\n",
      "|    time_elapsed         | 5839          |\n",
      "|    total_timesteps      | 1457152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020304229 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.924        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.47e+04      |\n",
      "|    n_updates            | 39450         |\n",
      "|    policy_gradient_loss | 0.0003        |\n",
      "|    reward               | -66.31981     |\n",
      "|    value_loss           | 1.9e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 799\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1424         |\n",
      "|    time_elapsed         | 5843         |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.462436e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.924       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.84e+04     |\n",
      "|    n_updates            | 39460        |\n",
      "|    policy_gradient_loss | -0.000173    |\n",
      "|    reward               | -24.345737   |\n",
      "|    value_loss           | 1.77e+05     |\n",
      "------------------------------------------\n",
      "Episode: 800\n",
      "Current company: ['CAT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 691678.55\n",
      "total_reward: -308321.45\n",
      "total_cost: 634527.15\n",
      "total_trades: 633\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1425          |\n",
      "|    time_elapsed         | 5848          |\n",
      "|    total_timesteps      | 1459200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2422693e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.925        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.07e+05      |\n",
      "|    n_updates            | 39470         |\n",
      "|    policy_gradient_loss | -0.00015      |\n",
      "|    reward               | -8.988251     |\n",
      "|    value_loss           | 2.14e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1426          |\n",
      "|    time_elapsed         | 5852          |\n",
      "|    total_timesteps      | 1460224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6536796e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.926        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.74e+04      |\n",
      "|    n_updates            | 39480         |\n",
      "|    policy_gradient_loss | 6.87e-05      |\n",
      "|    reward               | -58.84927     |\n",
      "|    value_loss           | 1.95e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 801\n",
      "Episode: 802\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1427          |\n",
      "|    time_elapsed         | 5856          |\n",
      "|    total_timesteps      | 1461248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5323086e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.926        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.32e+04      |\n",
      "|    n_updates            | 39490         |\n",
      "|    policy_gradient_loss | -0.000288     |\n",
      "|    reward               | -37.27908     |\n",
      "|    value_loss           | 1.07e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 803\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 1428       |\n",
      "|    time_elapsed         | 5861       |\n",
      "|    total_timesteps      | 1462272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 5.7831e-05 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.927     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.98e+04   |\n",
      "|    n_updates            | 39500      |\n",
      "|    policy_gradient_loss | -0.000152  |\n",
      "|    reward               | -29.1744   |\n",
      "|    value_loss           | 1.4e+05    |\n",
      "----------------------------------------\n",
      "Episode: 804\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 688289.71\n",
      "total_reward: -311710.29\n",
      "total_cost: 294123.86\n",
      "total_trades: 319\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1429         |\n",
      "|    time_elapsed         | 5865         |\n",
      "|    total_timesteps      | 1463296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.744231e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.931       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.71e+04     |\n",
      "|    n_updates            | 39510        |\n",
      "|    policy_gradient_loss | -0.000217    |\n",
      "|    reward               | -4.6668477   |\n",
      "|    value_loss           | 1.74e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1430          |\n",
      "|    time_elapsed         | 5869          |\n",
      "|    total_timesteps      | 1464320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1779753e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.933        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.53e+04      |\n",
      "|    n_updates            | 39520         |\n",
      "|    policy_gradient_loss | -7.39e-05     |\n",
      "|    reward               | -68.8756      |\n",
      "|    value_loss           | 5.07e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 805\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1431          |\n",
      "|    time_elapsed         | 5874          |\n",
      "|    total_timesteps      | 1465344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3198314e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.935        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.65e+05      |\n",
      "|    n_updates            | 39530         |\n",
      "|    policy_gradient_loss | -0.000197     |\n",
      "|    reward               | -26.973557    |\n",
      "|    value_loss           | 3.3e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1432         |\n",
      "|    time_elapsed         | 5878         |\n",
      "|    total_timesteps      | 1466368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.088187e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.936       |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.61e+05     |\n",
      "|    n_updates            | 39540        |\n",
      "|    policy_gradient_loss | 1.71e-05     |\n",
      "|    reward               | -65.69234    |\n",
      "|    value_loss           | 1.12e+06     |\n",
      "------------------------------------------\n",
      "Episode: 806\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1433          |\n",
      "|    time_elapsed         | 5883          |\n",
      "|    total_timesteps      | 1467392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7912396e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75e+05      |\n",
      "|    n_updates            | 39550         |\n",
      "|    policy_gradient_loss | -3.78e-05     |\n",
      "|    reward               | -8.660661     |\n",
      "|    value_loss           | 3.51e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1434          |\n",
      "|    time_elapsed         | 5888          |\n",
      "|    total_timesteps      | 1468416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6944326e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.69e+05      |\n",
      "|    n_updates            | 39560         |\n",
      "|    policy_gradient_loss | -3.41e-05     |\n",
      "|    reward               | -56.012917    |\n",
      "|    value_loss           | 1.54e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 807\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1435          |\n",
      "|    time_elapsed         | 5894          |\n",
      "|    total_timesteps      | 1469440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0631276e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.51e+05      |\n",
      "|    n_updates            | 39570         |\n",
      "|    policy_gradient_loss | -7.75e-05     |\n",
      "|    reward               | -49.36512     |\n",
      "|    value_loss           | 3.02e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 808\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 691581.64\n",
      "total_reward: -308418.36\n",
      "total_cost: 546712.49\n",
      "total_trades: 637\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1436         |\n",
      "|    time_elapsed         | 5899         |\n",
      "|    total_timesteps      | 1470464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.117625e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03e+05     |\n",
      "|    n_updates            | 39580        |\n",
      "|    policy_gradient_loss | 3.69e-05     |\n",
      "|    reward               | -27.632357   |\n",
      "|    value_loss           | 2.06e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1437          |\n",
      "|    time_elapsed         | 5904          |\n",
      "|    total_timesteps      | 1471488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7823262e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.05e+05      |\n",
      "|    n_updates            | 39590         |\n",
      "|    policy_gradient_loss | -2.41e-05     |\n",
      "|    reward               | -45.732315    |\n",
      "|    value_loss           | 4.11e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 809\n",
      "Episode: 810\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1438         |\n",
      "|    time_elapsed         | 5909         |\n",
      "|    total_timesteps      | 1472512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.248119e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.41e+04     |\n",
      "|    n_updates            | 39600        |\n",
      "|    policy_gradient_loss | -0.000223    |\n",
      "|    reward               | 5.20308      |\n",
      "|    value_loss           | 4.82e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1439          |\n",
      "|    time_elapsed         | 5915          |\n",
      "|    total_timesteps      | 1473536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1696825e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.55e+05      |\n",
      "|    n_updates            | 39610         |\n",
      "|    policy_gradient_loss | 7.05e-05      |\n",
      "|    reward               | -37.275753    |\n",
      "|    value_loss           | 7.1e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 249           |\n",
      "|    iterations           | 1440          |\n",
      "|    time_elapsed         | 5919          |\n",
      "|    total_timesteps      | 1474560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013622758 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.43e+04      |\n",
      "|    n_updates            | 39620         |\n",
      "|    policy_gradient_loss | -0.000215     |\n",
      "|    reward               | -24.032454    |\n",
      "|    value_loss           | 8.87e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 811\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 249            |\n",
      "|    iterations           | 1441           |\n",
      "|    time_elapsed         | 5924           |\n",
      "|    total_timesteps      | 1475584        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000103707134 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.938         |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 6.19e+04       |\n",
      "|    n_updates            | 39630          |\n",
      "|    policy_gradient_loss | 0.000536       |\n",
      "|    reward               | -22.292692     |\n",
      "|    value_loss           | 1.24e+05       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 1442         |\n",
      "|    time_elapsed         | 5929         |\n",
      "|    total_timesteps      | 1476608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.452924e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.82e+04     |\n",
      "|    n_updates            | 39640        |\n",
      "|    policy_gradient_loss | -9.62e-05    |\n",
      "|    reward               | -72.222885   |\n",
      "|    value_loss           | 5.65e+04     |\n",
      "------------------------------------------\n",
      "Episode: 812\n",
      "Current company: ['PG']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699456.85\n",
      "total_reward: -300543.15\n",
      "total_cost: 765296.68\n",
      "total_trades: 853\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1443          |\n",
      "|    time_elapsed         | 5935          |\n",
      "|    total_timesteps      | 1477632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0350943e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.935        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.99e+05      |\n",
      "|    n_updates            | 39650         |\n",
      "|    policy_gradient_loss | -1.01e-05     |\n",
      "|    reward               | -34.73866     |\n",
      "|    value_loss           | 3.99e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 813\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1444         |\n",
      "|    time_elapsed         | 5940         |\n",
      "|    total_timesteps      | 1478656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.014175e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.934       |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.98e+05     |\n",
      "|    n_updates            | 39660        |\n",
      "|    policy_gradient_loss | -3.59e-05    |\n",
      "|    reward               | 11.194312    |\n",
      "|    value_loss           | 5.97e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1445          |\n",
      "|    time_elapsed         | 5945          |\n",
      "|    total_timesteps      | 1479680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5212295e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.933        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+05      |\n",
      "|    n_updates            | 39670         |\n",
      "|    policy_gradient_loss | -5.31e-05     |\n",
      "|    reward               | -32.31072     |\n",
      "|    value_loss           | 2.88e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1446          |\n",
      "|    time_elapsed         | 5950          |\n",
      "|    total_timesteps      | 1480704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2263204e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.933        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.38e+04      |\n",
      "|    n_updates            | 39680         |\n",
      "|    policy_gradient_loss | -5.94e-05     |\n",
      "|    reward               | -28.895699    |\n",
      "|    value_loss           | 6.76e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 814\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1447         |\n",
      "|    time_elapsed         | 5955         |\n",
      "|    total_timesteps      | 1481728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.522619e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.55e+04     |\n",
      "|    n_updates            | 39690        |\n",
      "|    policy_gradient_loss | 2.14e-05     |\n",
      "|    reward               | 49.454826    |\n",
      "|    value_loss           | 1.31e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1448         |\n",
      "|    time_elapsed         | 5959         |\n",
      "|    total_timesteps      | 1482752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.609022e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.936       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.64e+05     |\n",
      "|    n_updates            | 39700        |\n",
      "|    policy_gradient_loss | -8.58e-07    |\n",
      "|    reward               | 56.821384    |\n",
      "|    value_loss           | 7.29e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1449          |\n",
      "|    time_elapsed         | 5964          |\n",
      "|    total_timesteps      | 1483776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3483375e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.935        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.48e+05      |\n",
      "|    n_updates            | 39710         |\n",
      "|    policy_gradient_loss | -3.76e-05     |\n",
      "|    reward               | 33.502712     |\n",
      "|    value_loss           | 1.7e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 815\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1450          |\n",
      "|    time_elapsed         | 5969          |\n",
      "|    total_timesteps      | 1484800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8996652e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.935        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+06      |\n",
      "|    n_updates            | 39720         |\n",
      "|    policy_gradient_loss | -3.55e-05     |\n",
      "|    reward               | -39.357586    |\n",
      "|    value_loss           | 2.03e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1451         |\n",
      "|    time_elapsed         | 5974         |\n",
      "|    total_timesteps      | 1485824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.165616e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.21e+05     |\n",
      "|    n_updates            | 39730        |\n",
      "|    policy_gradient_loss | -0.000134    |\n",
      "|    reward               | -84.965225   |\n",
      "|    value_loss           | 4.41e+05     |\n",
      "------------------------------------------\n",
      "Episode: 816\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698337.00\n",
      "total_reward: -301663.00\n",
      "total_cost: 887328.02\n",
      "total_trades: 999\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1452          |\n",
      "|    time_elapsed         | 5980          |\n",
      "|    total_timesteps      | 1486848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3621094e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.937        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.27e+05      |\n",
      "|    n_updates            | 39740         |\n",
      "|    policy_gradient_loss | -7.1e-05      |\n",
      "|    reward               | -37.22255     |\n",
      "|    value_loss           | 6.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 817\n",
      "Episode: 818\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1453          |\n",
      "|    time_elapsed         | 5985          |\n",
      "|    total_timesteps      | 1487872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1745724e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.17e+05      |\n",
      "|    n_updates            | 39750         |\n",
      "|    policy_gradient_loss | -9.04e-05     |\n",
      "|    reward               | -9.822667     |\n",
      "|    value_loss           | 8.34e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1454          |\n",
      "|    time_elapsed         | 5990          |\n",
      "|    total_timesteps      | 1488896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1508465e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.66e+05      |\n",
      "|    n_updates            | 39760         |\n",
      "|    policy_gradient_loss | -6.66e-06     |\n",
      "|    reward               | -23.319548    |\n",
      "|    value_loss           | 3.32e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1455          |\n",
      "|    time_elapsed         | 5995          |\n",
      "|    total_timesteps      | 1489920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5152112e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.14e+04      |\n",
      "|    n_updates            | 39770         |\n",
      "|    policy_gradient_loss | -3.74e-05     |\n",
      "|    reward               | -84.56058     |\n",
      "|    value_loss           | 1.43e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 819\n",
      "Episode: 820\n",
      "Current company: ['V']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699666.76\n",
      "total_reward: -300333.24\n",
      "total_cost: 181090.49\n",
      "total_trades: 198\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 6001        |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.77132e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.49e+05    |\n",
      "|    n_updates            | 39780       |\n",
      "|    policy_gradient_loss | 5.8e-06     |\n",
      "|    reward               | -7.1320124  |\n",
      "|    value_loss           | 1.1e+06     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1457          |\n",
      "|    time_elapsed         | 6006          |\n",
      "|    total_timesteps      | 1491968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7347047e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.938        |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+05      |\n",
      "|    n_updates            | 39790         |\n",
      "|    policy_gradient_loss | -2.44e-05     |\n",
      "|    reward               | -51.91184     |\n",
      "|    value_loss           | 3.24e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1458          |\n",
      "|    time_elapsed         | 6011          |\n",
      "|    total_timesteps      | 1492992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6193447e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+05      |\n",
      "|    n_updates            | 39800         |\n",
      "|    policy_gradient_loss | 5.11e-06      |\n",
      "|    reward               | -72.09006     |\n",
      "|    value_loss           | 2.12e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 821\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1459          |\n",
      "|    time_elapsed         | 6016          |\n",
      "|    total_timesteps      | 1494016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2589887e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.94         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.43e+05      |\n",
      "|    n_updates            | 39810         |\n",
      "|    policy_gradient_loss | -8.15e-05     |\n",
      "|    reward               | 27.801603     |\n",
      "|    value_loss           | 8.86e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1460         |\n",
      "|    time_elapsed         | 6020         |\n",
      "|    total_timesteps      | 1495040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.606152e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.939       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.29e+05     |\n",
      "|    n_updates            | 39820        |\n",
      "|    policy_gradient_loss | -0.000135    |\n",
      "|    reward               | -37.568684   |\n",
      "|    value_loss           | 4.59e+05     |\n",
      "------------------------------------------\n",
      "Episode: 822\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1461         |\n",
      "|    time_elapsed         | 6024         |\n",
      "|    total_timesteps      | 1496064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008417028 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.07e+04     |\n",
      "|    n_updates            | 39830        |\n",
      "|    policy_gradient_loss | -0.000667    |\n",
      "|    reward               | 1.1265054    |\n",
      "|    value_loss           | 1.01e+05     |\n",
      "------------------------------------------\n",
      "Episode: 823\n",
      "Episode: 824\n",
      "Current company: ['JPM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 684714.82\n",
      "total_reward: -315285.18\n",
      "total_cost: 190399.41\n",
      "total_trades: 205\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1462          |\n",
      "|    time_elapsed         | 6029          |\n",
      "|    total_timesteps      | 1497088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055849674 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.932        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.14e+05      |\n",
      "|    n_updates            | 39840         |\n",
      "|    policy_gradient_loss | 0.000557      |\n",
      "|    reward               | -11.591657    |\n",
      "|    value_loss           | 6.28e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1463         |\n",
      "|    time_elapsed         | 6033         |\n",
      "|    total_timesteps      | 1498112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.162286e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.932       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.56e+04     |\n",
      "|    n_updates            | 39850        |\n",
      "|    policy_gradient_loss | 6.51e-05     |\n",
      "|    reward               | 7.694634     |\n",
      "|    value_loss           | 3.12e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1464         |\n",
      "|    time_elapsed         | 6037         |\n",
      "|    total_timesteps      | 1499136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.878923e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.934       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.19e+04     |\n",
      "|    n_updates            | 39860        |\n",
      "|    policy_gradient_loss | 4.89e-05     |\n",
      "|    reward               | 8.67711      |\n",
      "|    value_loss           | 6.39e+04     |\n",
      "------------------------------------------\n",
      "Episode: 825\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1465          |\n",
      "|    time_elapsed         | 6042          |\n",
      "|    total_timesteps      | 1500160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1799391e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.933        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.77e+04      |\n",
      "|    n_updates            | 39870         |\n",
      "|    policy_gradient_loss | -5.57e-05     |\n",
      "|    reward               | 104.31184     |\n",
      "|    value_loss           | 3.55e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1466         |\n",
      "|    time_elapsed         | 6046         |\n",
      "|    total_timesteps      | 1501184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.156589e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.34e+05     |\n",
      "|    n_updates            | 39880        |\n",
      "|    policy_gradient_loss | 7.2e-05      |\n",
      "|    reward               | 41.86766     |\n",
      "|    value_loss           | 1.28e+06     |\n",
      "------------------------------------------\n",
      "Episode: 826\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1467          |\n",
      "|    time_elapsed         | 6049          |\n",
      "|    total_timesteps      | 1502208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1595042e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -0.0198       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.57e+05      |\n",
      "|    n_updates            | 39890         |\n",
      "|    policy_gradient_loss | -4.01e-06     |\n",
      "|    reward               | 4.976195      |\n",
      "|    value_loss           | 1.35e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1468          |\n",
      "|    time_elapsed         | 6053          |\n",
      "|    total_timesteps      | 1503232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3224857e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.0469        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.52e+05      |\n",
      "|    n_updates            | 39900         |\n",
      "|    policy_gradient_loss | -2.67e-06     |\n",
      "|    reward               | 23.034351     |\n",
      "|    value_loss           | 1.32e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1469          |\n",
      "|    time_elapsed         | 6057          |\n",
      "|    total_timesteps      | 1504256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1816536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.994        |\n",
      "|    explained_variance   | 0.322         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.94e+05      |\n",
      "|    n_updates            | 39910         |\n",
      "|    policy_gradient_loss | -9e-06        |\n",
      "|    reward               | 38.683144     |\n",
      "|    value_loss           | 7.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 827\n",
      "Episode: 828\n",
      "Current company: ['DOW']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 634514.08\n",
      "total_reward: -365485.92\n",
      "total_cost: 10849.20\n",
      "total_trades: 11\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1470          |\n",
      "|    time_elapsed         | 6062          |\n",
      "|    total_timesteps      | 1505280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4274265e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.935        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.01e+05      |\n",
      "|    n_updates            | 39920         |\n",
      "|    policy_gradient_loss | -3.19e-05     |\n",
      "|    reward               | -20.620346    |\n",
      "|    value_loss           | 6.03e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1471          |\n",
      "|    time_elapsed         | 6066          |\n",
      "|    total_timesteps      | 1506304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1360541e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.935        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.88e+05      |\n",
      "|    n_updates            | 39930         |\n",
      "|    policy_gradient_loss | -3.74e-05     |\n",
      "|    reward               | -18.001745    |\n",
      "|    value_loss           | 1.38e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1472         |\n",
      "|    time_elapsed         | 6070         |\n",
      "|    total_timesteps      | 1507328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.419351e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.936       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42e+04     |\n",
      "|    n_updates            | 39940        |\n",
      "|    policy_gradient_loss | -7.02e-05    |\n",
      "|    reward               | -38.060707   |\n",
      "|    value_loss           | 2.84e+04     |\n",
      "------------------------------------------\n",
      "Episode: 829\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1473         |\n",
      "|    time_elapsed         | 6075         |\n",
      "|    total_timesteps      | 1508352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.728845e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.938       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.24e+04     |\n",
      "|    n_updates            | 39950        |\n",
      "|    policy_gradient_loss | 3.44e-05     |\n",
      "|    reward               | -19.18738    |\n",
      "|    value_loss           | 1.25e+05     |\n",
      "------------------------------------------\n",
      "Episode: 830\n",
      "Episode: 831\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1474         |\n",
      "|    time_elapsed         | 6079         |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.109828e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.939       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.92e+04     |\n",
      "|    n_updates            | 39960        |\n",
      "|    policy_gradient_loss | -1.9e-05     |\n",
      "|    reward               | -2.452961    |\n",
      "|    value_loss           | 7.85e+04     |\n",
      "------------------------------------------\n",
      "Episode: 832\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 677764.12\n",
      "total_reward: -322235.88\n",
      "total_cost: 160673.33\n",
      "total_trades: 185\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1475          |\n",
      "|    time_elapsed         | 6083          |\n",
      "|    total_timesteps      | 1510400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8000428e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.47e+05      |\n",
      "|    n_updates            | 39970         |\n",
      "|    policy_gradient_loss | -0.000143     |\n",
      "|    reward               | -7.3925576    |\n",
      "|    value_loss           | 2.95e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1476          |\n",
      "|    time_elapsed         | 6087          |\n",
      "|    total_timesteps      | 1511424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9508956e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.94         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.24e+04      |\n",
      "|    n_updates            | 39980         |\n",
      "|    policy_gradient_loss | 6.36e-06      |\n",
      "|    reward               | -57.984173    |\n",
      "|    value_loss           | 4.47e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1477         |\n",
      "|    time_elapsed         | 6092         |\n",
      "|    total_timesteps      | 1512448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.407403e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.94        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.69e+04     |\n",
      "|    n_updates            | 39990        |\n",
      "|    policy_gradient_loss | -2.6e-05     |\n",
      "|    reward               | -78.85109    |\n",
      "|    value_loss           | 1.74e+05     |\n",
      "------------------------------------------\n",
      "Episode: 833\n",
      "Episode: 834\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1478         |\n",
      "|    time_elapsed         | 6097         |\n",
      "|    total_timesteps      | 1513472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.856541e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.94        |\n",
      "|    explained_variance   | 3.58e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.21e+05     |\n",
      "|    n_updates            | 40000        |\n",
      "|    policy_gradient_loss | -2.56e-06    |\n",
      "|    reward               | -32.521385   |\n",
      "|    value_loss           | 1.04e+06     |\n",
      "------------------------------------------\n",
      "Episode: 835\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1479         |\n",
      "|    time_elapsed         | 6102         |\n",
      "|    total_timesteps      | 1514496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.613819e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.939       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.62e+04     |\n",
      "|    n_updates            | 40010        |\n",
      "|    policy_gradient_loss | -0.000103    |\n",
      "|    reward               | -27.049328   |\n",
      "|    value_loss           | 9.26e+04     |\n",
      "------------------------------------------\n",
      "Episode: 836\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 689885.12\n",
      "total_reward: -310114.88\n",
      "total_cost: 290524.95\n",
      "total_trades: 313\n",
      "=================================\n",
      "Episode: 837\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1480          |\n",
      "|    time_elapsed         | 6107          |\n",
      "|    total_timesteps      | 1515520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9959483e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.939        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.08e+05      |\n",
      "|    n_updates            | 40020         |\n",
      "|    policy_gradient_loss | 0.000101      |\n",
      "|    reward               | 1.2991114     |\n",
      "|    value_loss           | 2.16e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1481          |\n",
      "|    time_elapsed         | 6111          |\n",
      "|    total_timesteps      | 1516544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035945058 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.942        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.36e+04      |\n",
      "|    n_updates            | 40030         |\n",
      "|    policy_gradient_loss | -0.000619     |\n",
      "|    reward               | -50.358353    |\n",
      "|    value_loss           | 6.72e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1482          |\n",
      "|    time_elapsed         | 6115          |\n",
      "|    total_timesteps      | 1517568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037861068 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.95         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.33e+05      |\n",
      "|    n_updates            | 40040         |\n",
      "|    policy_gradient_loss | -0.000334     |\n",
      "|    reward               | -82.18121     |\n",
      "|    value_loss           | 2.67e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 838\n",
      "Episode: 839\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1483          |\n",
      "|    time_elapsed         | 6120          |\n",
      "|    total_timesteps      | 1518592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6960853e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | -3.58e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.63e+05      |\n",
      "|    n_updates            | 40050         |\n",
      "|    policy_gradient_loss | 9.31e-06      |\n",
      "|    reward               | -5.3911495    |\n",
      "|    value_loss           | 9.27e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 840\n",
      "Current company: ['CVX']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 677698.41\n",
      "total_reward: -322301.59\n",
      "total_cost: 466107.99\n",
      "total_trades: 519\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1484          |\n",
      "|    time_elapsed         | 6124          |\n",
      "|    total_timesteps      | 1519616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1103187e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.956        |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.7e+05       |\n",
      "|    n_updates            | 40060         |\n",
      "|    policy_gradient_loss | 3.98e-05      |\n",
      "|    reward               | -8.407767     |\n",
      "|    value_loss           | 5.4e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 841\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 1485        |\n",
      "|    time_elapsed         | 6129        |\n",
      "|    total_timesteps      | 1520640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 1.92906e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5e+05     |\n",
      "|    n_updates            | 40070       |\n",
      "|    policy_gradient_loss | -2.22e-05   |\n",
      "|    reward               | -20.05102   |\n",
      "|    value_loss           | 2.99e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 842\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1486         |\n",
      "|    time_elapsed         | 6134         |\n",
      "|    total_timesteps      | 1521664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.945586e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.4e+04      |\n",
      "|    n_updates            | 40080        |\n",
      "|    policy_gradient_loss | -2.87e-05    |\n",
      "|    reward               | -40.001812   |\n",
      "|    value_loss           | 1.08e+05     |\n",
      "------------------------------------------\n",
      "Episode: 843\n",
      "Episode: 844\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693177.86\n",
      "total_reward: -306822.14\n",
      "total_cost: 150558.27\n",
      "total_trades: 181\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1487          |\n",
      "|    time_elapsed         | 6138          |\n",
      "|    total_timesteps      | 1522688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6601206e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.957        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.07e+04      |\n",
      "|    n_updates            | 40090         |\n",
      "|    policy_gradient_loss | 4.21e-06      |\n",
      "|    reward               | -23.69906     |\n",
      "|    value_loss           | 1.01e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 845\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 6143        |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.76044e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.958      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92e+04    |\n",
      "|    n_updates            | 40100       |\n",
      "|    policy_gradient_loss | -4.42e-06   |\n",
      "|    reward               | -10.554981  |\n",
      "|    value_loss           | 1.79e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1489         |\n",
      "|    time_elapsed         | 6147         |\n",
      "|    total_timesteps      | 1524736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.674649e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.958       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.02e+04     |\n",
      "|    n_updates            | 40110        |\n",
      "|    policy_gradient_loss | -0.000302    |\n",
      "|    reward               | -50.973778   |\n",
      "|    value_loss           | 4.04e+04     |\n",
      "------------------------------------------\n",
      "Episode: 846\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1490          |\n",
      "|    time_elapsed         | 6151          |\n",
      "|    total_timesteps      | 1525760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013176171 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.958        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.32e+05      |\n",
      "|    n_updates            | 40120         |\n",
      "|    policy_gradient_loss | -0.000312     |\n",
      "|    reward               | -7.236144     |\n",
      "|    value_loss           | 2.64e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1491          |\n",
      "|    time_elapsed         | 6155          |\n",
      "|    total_timesteps      | 1526784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0514592e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.957        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.94e+05      |\n",
      "|    n_updates            | 40130         |\n",
      "|    policy_gradient_loss | 6.33e-05      |\n",
      "|    reward               | -59.72759     |\n",
      "|    value_loss           | 3.88e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 847\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 1492         |\n",
      "|    time_elapsed         | 6160         |\n",
      "|    total_timesteps      | 1527808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.220587e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.59e+04     |\n",
      "|    n_updates            | 40140        |\n",
      "|    policy_gradient_loss | -6.47e-05    |\n",
      "|    reward               | -23.823416   |\n",
      "|    value_loss           | 1.52e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1493          |\n",
      "|    time_elapsed         | 6164          |\n",
      "|    total_timesteps      | 1528832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1437456e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.959        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.16e+05      |\n",
      "|    n_updates            | 40150         |\n",
      "|    policy_gradient_loss | -4.19e-05     |\n",
      "|    reward               | -57.266907    |\n",
      "|    value_loss           | 2.31e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 848\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1075136.81\n",
      "total_reward: 75136.81\n",
      "total_cost: 1257515.59\n",
      "total_trades: 1201\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1494          |\n",
      "|    time_elapsed         | 6168          |\n",
      "|    total_timesteps      | 1529856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4030607e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.961        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.81e+04      |\n",
      "|    n_updates            | 40160         |\n",
      "|    policy_gradient_loss | -3.76e-05     |\n",
      "|    reward               | 1.0433602     |\n",
      "|    value_loss           | 1.56e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1495          |\n",
      "|    time_elapsed         | 6172          |\n",
      "|    total_timesteps      | 1530880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9749277e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.963        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.5e+05       |\n",
      "|    n_updates            | 40170         |\n",
      "|    policy_gradient_loss | 4.06e-05      |\n",
      "|    reward               | -58.87641     |\n",
      "|    value_loss           | 1.3e+06       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 248           |\n",
      "|    iterations           | 1496          |\n",
      "|    time_elapsed         | 6176          |\n",
      "|    total_timesteps      | 1531904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6975987e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.963        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.53e+04      |\n",
      "|    n_updates            | 40180         |\n",
      "|    policy_gradient_loss | -4.25e-05     |\n",
      "|    reward               | -89.74389     |\n",
      "|    value_loss           | 1.71e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 849\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1497         |\n",
      "|    time_elapsed         | 6181         |\n",
      "|    total_timesteps      | 1532928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.543953e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.961       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.71e+05     |\n",
      "|    n_updates            | 40190        |\n",
      "|    policy_gradient_loss | -6.8e-05     |\n",
      "|    reward               | -11.969514   |\n",
      "|    value_loss           | 1.14e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1498          |\n",
      "|    time_elapsed         | 6185          |\n",
      "|    total_timesteps      | 1533952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9359286e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.96         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.08e+05      |\n",
      "|    n_updates            | 40200         |\n",
      "|    policy_gradient_loss | -1.91e-06     |\n",
      "|    reward               | -65.78437     |\n",
      "|    value_loss           | 1.62e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 850\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1499          |\n",
      "|    time_elapsed         | 6189          |\n",
      "|    total_timesteps      | 1534976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5673147e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.96         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.35e+05      |\n",
      "|    n_updates            | 40210         |\n",
      "|    policy_gradient_loss | -4.86e-05     |\n",
      "|    reward               | 23.706198     |\n",
      "|    value_loss           | 4.7e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1500         |\n",
      "|    time_elapsed         | 6194         |\n",
      "|    total_timesteps      | 1536000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.488385e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.959       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.19e+05     |\n",
      "|    n_updates            | 40220        |\n",
      "|    policy_gradient_loss | 2.1e-05      |\n",
      "|    reward               | -53.738758   |\n",
      "|    value_loss           | 1.24e+06     |\n",
      "------------------------------------------\n",
      "Episode: 851\n",
      "Episode: 852\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699784.03\n",
      "total_reward: -300215.97\n",
      "total_cost: 267956.87\n",
      "total_trades: 301\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1501          |\n",
      "|    time_elapsed         | 6198          |\n",
      "|    total_timesteps      | 1537024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8933322e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.959        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.13e+04      |\n",
      "|    n_updates            | 40230         |\n",
      "|    policy_gradient_loss | -8.85e-05     |\n",
      "|    reward               | -30.193008    |\n",
      "|    value_loss           | 1.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1502          |\n",
      "|    time_elapsed         | 6203          |\n",
      "|    total_timesteps      | 1538048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9095681e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.959        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.33e+04      |\n",
      "|    n_updates            | 40240         |\n",
      "|    policy_gradient_loss | 4.78e-05      |\n",
      "|    reward               | -19.613272    |\n",
      "|    value_loss           | 1.07e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1503          |\n",
      "|    time_elapsed         | 6207          |\n",
      "|    total_timesteps      | 1539072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022301677 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.961        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.71e+04      |\n",
      "|    n_updates            | 40250         |\n",
      "|    policy_gradient_loss | -0.00042      |\n",
      "|    reward               | -30.134417    |\n",
      "|    value_loss           | 3.43e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 853\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1504          |\n",
      "|    time_elapsed         | 6211          |\n",
      "|    total_timesteps      | 1540096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021824392 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.965        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.21e+05      |\n",
      "|    n_updates            | 40260         |\n",
      "|    policy_gradient_loss | -0.000165     |\n",
      "|    reward               | -38.89468     |\n",
      "|    value_loss           | 2.43e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 854\n",
      "Episode: 855\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1505         |\n",
      "|    time_elapsed         | 6216         |\n",
      "|    total_timesteps      | 1541120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.310035e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44e+05     |\n",
      "|    n_updates            | 40270        |\n",
      "|    policy_gradient_loss | 9.63e-05     |\n",
      "|    reward               | -28.664623   |\n",
      "|    value_loss           | 2.89e+05     |\n",
      "------------------------------------------\n",
      "Episode: 856\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699183.68\n",
      "total_reward: -300816.32\n",
      "total_cost: 222760.39\n",
      "total_trades: 247\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1506         |\n",
      "|    time_elapsed         | 6220         |\n",
      "|    total_timesteps      | 1542144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007809836 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.966       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.77e+04     |\n",
      "|    n_updates            | 40280        |\n",
      "|    policy_gradient_loss | -0.000392    |\n",
      "|    reward               | -37.045265   |\n",
      "|    value_loss           | 9.55e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1507          |\n",
      "|    time_elapsed         | 6224          |\n",
      "|    total_timesteps      | 1543168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090141466 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.957        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.82e+04      |\n",
      "|    n_updates            | 40290         |\n",
      "|    policy_gradient_loss | -0.000711     |\n",
      "|    reward               | -101.15036    |\n",
      "|    value_loss           | 3.66e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 857\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1508          |\n",
      "|    time_elapsed         | 6229          |\n",
      "|    total_timesteps      | 1544192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017873687 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.957        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.61e+05      |\n",
      "|    n_updates            | 40300         |\n",
      "|    policy_gradient_loss | 0.00023       |\n",
      "|    reward               | -16.616428    |\n",
      "|    value_loss           | 1.12e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1509          |\n",
      "|    time_elapsed         | 6233          |\n",
      "|    total_timesteps      | 1545216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9936415e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.958        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.05e+04      |\n",
      "|    n_updates            | 40310         |\n",
      "|    policy_gradient_loss | -1.31e-05     |\n",
      "|    reward               | -52.412792    |\n",
      "|    value_loss           | 8.11e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 858\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1510         |\n",
      "|    time_elapsed         | 6237         |\n",
      "|    total_timesteps      | 1546240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.592825e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.89e+04     |\n",
      "|    n_updates            | 40320        |\n",
      "|    policy_gradient_loss | -1.56e-05    |\n",
      "|    reward               | -31.324554   |\n",
      "|    value_loss           | 1.98e+05     |\n",
      "------------------------------------------\n",
      "Episode: 859\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1511          |\n",
      "|    time_elapsed         | 6241          |\n",
      "|    total_timesteps      | 1547264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7176145e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.959        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.37e+05      |\n",
      "|    n_updates            | 40330         |\n",
      "|    policy_gradient_loss | -1.04e-05     |\n",
      "|    reward               | -48.374454    |\n",
      "|    value_loss           | 4.74e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 860\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696913.03\n",
      "total_reward: -303086.97\n",
      "total_cost: 525976.00\n",
      "total_trades: 571\n",
      "=================================\n",
      "Episode: 861\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1512         |\n",
      "|    time_elapsed         | 6247         |\n",
      "|    total_timesteps      | 1548288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.007737e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.958       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.44e+04     |\n",
      "|    n_updates            | 40340        |\n",
      "|    policy_gradient_loss | -0.000184    |\n",
      "|    reward               | -0.5906454   |\n",
      "|    value_loss           | 1.29e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1513          |\n",
      "|    time_elapsed         | 6252          |\n",
      "|    total_timesteps      | 1549312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9846556e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.27e+05      |\n",
      "|    n_updates            | 40350         |\n",
      "|    policy_gradient_loss | -0.000294     |\n",
      "|    reward               | -47.51083     |\n",
      "|    value_loss           | 4.54e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1514         |\n",
      "|    time_elapsed         | 6256         |\n",
      "|    total_timesteps      | 1550336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.903036e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.2e+04      |\n",
      "|    n_updates            | 40360        |\n",
      "|    policy_gradient_loss | -4.39e-05    |\n",
      "|    reward               | -101.54368   |\n",
      "|    value_loss           | 1.44e+05     |\n",
      "------------------------------------------\n",
      "Episode: 862\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1515          |\n",
      "|    time_elapsed         | 6261          |\n",
      "|    total_timesteps      | 1551360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.5175776e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.95e+05      |\n",
      "|    n_updates            | 40370         |\n",
      "|    policy_gradient_loss | 5.46e-05      |\n",
      "|    reward               | -12.541338    |\n",
      "|    value_loss           | 1.19e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1516          |\n",
      "|    time_elapsed         | 6266          |\n",
      "|    total_timesteps      | 1552384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4510006e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.954        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 40380         |\n",
      "|    policy_gradient_loss | -1.1e-05      |\n",
      "|    reward               | -65.236885    |\n",
      "|    value_loss           | 2.47e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 863\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1517          |\n",
      "|    time_elapsed         | 6272          |\n",
      "|    total_timesteps      | 1553408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1295604e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.953        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.15e+05      |\n",
      "|    n_updates            | 40390         |\n",
      "|    policy_gradient_loss | -8.18e-05     |\n",
      "|    reward               | 41.773064     |\n",
      "|    value_loss           | 2.31e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1518          |\n",
      "|    time_elapsed         | 6277          |\n",
      "|    total_timesteps      | 1554432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3924894e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.951        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.66e+05      |\n",
      "|    n_updates            | 40400         |\n",
      "|    policy_gradient_loss | -2.53e-05     |\n",
      "|    reward               | 200.81862     |\n",
      "|    value_loss           | 7.32e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 6281        |\n",
      "|    total_timesteps      | 1555456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.45485e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.949      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.82e+06    |\n",
      "|    n_updates            | 40410       |\n",
      "|    policy_gradient_loss | -3.52e-05   |\n",
      "|    reward               | 236.18694   |\n",
      "|    value_loss           | 3.63e+06    |\n",
      "-----------------------------------------\n",
      "Episode: 864\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6135940.34\n",
      "total_reward: 5135940.34\n",
      "total_cost: 3004482.44\n",
      "total_trades: 1021\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1520          |\n",
      "|    time_elapsed         | 6285          |\n",
      "|    total_timesteps      | 1556480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.3621126e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.21e+06      |\n",
      "|    n_updates            | 40420         |\n",
      "|    policy_gradient_loss | -2.55e-05     |\n",
      "|    reward               | -31.388058    |\n",
      "|    value_loss           | 1.44e+07      |\n",
      "-------------------------------------------\n",
      "Episode: 865\n",
      "Episode: 866\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1521          |\n",
      "|    time_elapsed         | 6290          |\n",
      "|    total_timesteps      | 1557504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4138717e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.948        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.99e+06      |\n",
      "|    n_updates            | 40430         |\n",
      "|    policy_gradient_loss | -5.97e-06     |\n",
      "|    reward               | -11.330938    |\n",
      "|    value_loss           | 1.4e+07       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1522          |\n",
      "|    time_elapsed         | 6295          |\n",
      "|    total_timesteps      | 1558528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4488254e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.949        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.46e+04      |\n",
      "|    n_updates            | 40440         |\n",
      "|    policy_gradient_loss | -0.000116     |\n",
      "|    reward               | -65.08676     |\n",
      "|    value_loss           | 8.91e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 867\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1523         |\n",
      "|    time_elapsed         | 6299         |\n",
      "|    total_timesteps      | 1559552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.870324e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.955       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.6e+04      |\n",
      "|    n_updates            | 40450        |\n",
      "|    policy_gradient_loss | -0.000249    |\n",
      "|    reward               | 1.7495748    |\n",
      "|    value_loss           | 1.92e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1524          |\n",
      "|    time_elapsed         | 6303          |\n",
      "|    total_timesteps      | 1560576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055337185 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.965        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.49e+04      |\n",
      "|    n_updates            | 40460         |\n",
      "|    policy_gradient_loss | -0.000625     |\n",
      "|    reward               | -70.44004     |\n",
      "|    value_loss           | 1.9e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 868\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 771712.91\n",
      "total_reward: -228287.09\n",
      "total_cost: 1106284.34\n",
      "total_trades: 1032\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1525          |\n",
      "|    time_elapsed         | 6307          |\n",
      "|    total_timesteps      | 1561600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048780156 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.985        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.67e+05      |\n",
      "|    n_updates            | 40470         |\n",
      "|    policy_gradient_loss | 2.03e-05      |\n",
      "|    reward               | -8.25888      |\n",
      "|    value_loss           | 3.33e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1526         |\n",
      "|    time_elapsed         | 6312         |\n",
      "|    total_timesteps      | 1562624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.597099e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.995       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.35e+05     |\n",
      "|    n_updates            | 40480        |\n",
      "|    policy_gradient_loss | 7.52e-05     |\n",
      "|    reward               | -59.08961    |\n",
      "|    value_loss           | 1.87e+06     |\n",
      "------------------------------------------\n",
      "Episode: 869\n",
      "Episode: 870\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1527          |\n",
      "|    time_elapsed         | 6316          |\n",
      "|    total_timesteps      | 1563648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0998687e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.998        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.35e+05      |\n",
      "|    n_updates            | 40490         |\n",
      "|    policy_gradient_loss | -1.7e-05      |\n",
      "|    reward               | -12.03441     |\n",
      "|    value_loss           | 2.7e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 871\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1528          |\n",
      "|    time_elapsed         | 6320          |\n",
      "|    total_timesteps      | 1564672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9577945e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.96e+05      |\n",
      "|    n_updates            | 40500         |\n",
      "|    policy_gradient_loss | -6.78e-05     |\n",
      "|    reward               | -39.424816    |\n",
      "|    value_loss           | 7.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 872\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694858.85\n",
      "total_reward: -305141.15\n",
      "total_cost: 399636.87\n",
      "total_trades: 451\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1529         |\n",
      "|    time_elapsed         | 6325         |\n",
      "|    total_timesteps      | 1565696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.734184e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.68e+04     |\n",
      "|    n_updates            | 40510        |\n",
      "|    policy_gradient_loss | -3.27e-05    |\n",
      "|    reward               | 51.775574    |\n",
      "|    value_loss           | 7.36e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1530         |\n",
      "|    time_elapsed         | 6329         |\n",
      "|    total_timesteps      | 1566720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.417473e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.00511      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.5e+05      |\n",
      "|    n_updates            | 40520        |\n",
      "|    policy_gradient_loss | 4.22e-05     |\n",
      "|    reward               | 131.80885    |\n",
      "|    value_loss           | 1.5e+06      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1531          |\n",
      "|    time_elapsed         | 6332          |\n",
      "|    total_timesteps      | 1567744       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0547685e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.0214       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.31e+06      |\n",
      "|    n_updates            | 40530         |\n",
      "|    policy_gradient_loss | 5.4e-06       |\n",
      "|    reward               | 283.80325     |\n",
      "|    value_loss           | 6.7e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 873\n",
      "Episode: 874\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1532         |\n",
      "|    time_elapsed         | 6337         |\n",
      "|    total_timesteps      | 1568768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.132744e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.0549       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.58e+06     |\n",
      "|    n_updates            | 40540        |\n",
      "|    policy_gradient_loss | -5.69e-07    |\n",
      "|    reward               | -23.906656   |\n",
      "|    value_loss           | 1.52e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1533          |\n",
      "|    time_elapsed         | 6341          |\n",
      "|    total_timesteps      | 1569792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4551915e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0.343         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.54e+06      |\n",
      "|    n_updates            | 40550         |\n",
      "|    policy_gradient_loss | -1.72e-06     |\n",
      "|    reward               | -46.70053     |\n",
      "|    value_loss           | 7.09e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1534         |\n",
      "|    time_elapsed         | 6345         |\n",
      "|    total_timesteps      | 1570816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.732779e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.8e+04      |\n",
      "|    n_updates            | 40560        |\n",
      "|    policy_gradient_loss | -6.75e-05    |\n",
      "|    reward               | -108.03644   |\n",
      "|    value_loss           | 7.64e+04     |\n",
      "------------------------------------------\n",
      "Episode: 875\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1535          |\n",
      "|    time_elapsed         | 6349          |\n",
      "|    total_timesteps      | 1571840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2365112e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.12e+05      |\n",
      "|    n_updates            | 40570         |\n",
      "|    policy_gradient_loss | -2.36e-05     |\n",
      "|    reward               | -46.614315    |\n",
      "|    value_loss           | 8.28e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 876\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698079.08\n",
      "total_reward: -301920.92\n",
      "total_cost: 556438.51\n",
      "total_trades: 581\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1536         |\n",
      "|    time_elapsed         | 6353         |\n",
      "|    total_timesteps      | 1572864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.045136e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.21e+04     |\n",
      "|    n_updates            | 40580        |\n",
      "|    policy_gradient_loss | -9.87e-05    |\n",
      "|    reward               | -33.02642    |\n",
      "|    value_loss           | 1.25e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1537          |\n",
      "|    time_elapsed         | 6358          |\n",
      "|    total_timesteps      | 1573888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2596698e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.83e+04      |\n",
      "|    n_updates            | 40590         |\n",
      "|    policy_gradient_loss | -0.000199     |\n",
      "|    reward               | -72.61063     |\n",
      "|    value_loss           | 1.77e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 877\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1538          |\n",
      "|    time_elapsed         | 6362          |\n",
      "|    total_timesteps      | 1574912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3118453e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.36e+05      |\n",
      "|    n_updates            | 40600         |\n",
      "|    policy_gradient_loss | 5.11e-05      |\n",
      "|    reward               | -43.620323    |\n",
      "|    value_loss           | 2.72e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1539          |\n",
      "|    time_elapsed         | 6366          |\n",
      "|    total_timesteps      | 1575936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6244263e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.2e+05       |\n",
      "|    n_updates            | 40610         |\n",
      "|    policy_gradient_loss | -0.000226     |\n",
      "|    reward               | -45.817577    |\n",
      "|    value_loss           | 4.4e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1540         |\n",
      "|    time_elapsed         | 6370         |\n",
      "|    total_timesteps      | 1576960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.484756e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.07e+05     |\n",
      "|    n_updates            | 40620        |\n",
      "|    policy_gradient_loss | 9.33e-05     |\n",
      "|    reward               | -36.848095   |\n",
      "|    value_loss           | 4.14e+05     |\n",
      "------------------------------------------\n",
      "Episode: 878\n",
      "Episode: 879\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1541         |\n",
      "|    time_elapsed         | 6375         |\n",
      "|    total_timesteps      | 1577984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.752089e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.69e+05     |\n",
      "|    n_updates            | 40630        |\n",
      "|    policy_gradient_loss | 4.17e-07     |\n",
      "|    reward               | -47.053303   |\n",
      "|    value_loss           | 3.39e+05     |\n",
      "------------------------------------------\n",
      "Episode: 880\n",
      "Current company: ['WMT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 688210.00\n",
      "total_reward: -311790.00\n",
      "total_cost: 337992.71\n",
      "total_trades: 405\n",
      "=================================\n",
      "Episode: 881\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1542          |\n",
      "|    time_elapsed         | 6379          |\n",
      "|    total_timesteps      | 1579008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5850833e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.36e+04      |\n",
      "|    n_updates            | 40640         |\n",
      "|    policy_gradient_loss | -4.09e-05     |\n",
      "|    reward               | -2.4353802    |\n",
      "|    value_loss           | 8.73e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1543          |\n",
      "|    time_elapsed         | 6383          |\n",
      "|    total_timesteps      | 1580032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7174945e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.08e+05      |\n",
      "|    n_updates            | 40650         |\n",
      "|    policy_gradient_loss | -0.000181     |\n",
      "|    reward               | -23.466406    |\n",
      "|    value_loss           | 2.15e+05      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 1544       |\n",
      "|    time_elapsed         | 6387       |\n",
      "|    total_timesteps      | 1581056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00085326 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.32e+04   |\n",
      "|    n_updates            | 40660      |\n",
      "|    policy_gradient_loss | -0.00111   |\n",
      "|    reward               | -35.89123  |\n",
      "|    value_loss           | 2.65e+04   |\n",
      "----------------------------------------\n",
      "Episode: 882\n",
      "Episode: 883\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1545          |\n",
      "|    time_elapsed         | 6392          |\n",
      "|    total_timesteps      | 1582080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087028637 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.99e+04      |\n",
      "|    n_updates            | 40670         |\n",
      "|    policy_gradient_loss | -0.000563     |\n",
      "|    reward               | -17.871984    |\n",
      "|    value_loss           | 2e+05         |\n",
      "-------------------------------------------\n",
      "Episode: 884\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693201.45\n",
      "total_reward: -306798.55\n",
      "total_cost: 150410.05\n",
      "total_trades: 169\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1546         |\n",
      "|    time_elapsed         | 6396         |\n",
      "|    total_timesteps      | 1583104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.314964e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.13e+05     |\n",
      "|    n_updates            | 40680        |\n",
      "|    policy_gradient_loss | 0.000258     |\n",
      "|    reward               | -40.290806   |\n",
      "|    value_loss           | 2.27e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1547          |\n",
      "|    time_elapsed         | 6400          |\n",
      "|    total_timesteps      | 1584128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2239903e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.12e+04      |\n",
      "|    n_updates            | 40690         |\n",
      "|    policy_gradient_loss | -0.000198     |\n",
      "|    reward               | -78.32646     |\n",
      "|    value_loss           | 6.25e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 885\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1548          |\n",
      "|    time_elapsed         | 6405          |\n",
      "|    total_timesteps      | 1585152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4928573e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.33e+05      |\n",
      "|    n_updates            | 40700         |\n",
      "|    policy_gradient_loss | 0.000166      |\n",
      "|    reward               | -23.588774    |\n",
      "|    value_loss           | 8.67e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1549          |\n",
      "|    time_elapsed         | 6409          |\n",
      "|    total_timesteps      | 1586176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0605436e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.01e+05      |\n",
      "|    n_updates            | 40710         |\n",
      "|    policy_gradient_loss | 2.38e-05      |\n",
      "|    reward               | -45.936867    |\n",
      "|    value_loss           | 1.2e+06       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1550          |\n",
      "|    time_elapsed         | 6413          |\n",
      "|    total_timesteps      | 1587200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7825084e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.34e+04      |\n",
      "|    n_updates            | 40720         |\n",
      "|    policy_gradient_loss | -4.13e-05     |\n",
      "|    reward               | -96.42968     |\n",
      "|    value_loss           | 1.47e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 886\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1551        |\n",
      "|    time_elapsed         | 6417        |\n",
      "|    total_timesteps      | 1588224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 1.76084e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.96e+05    |\n",
      "|    n_updates            | 40730       |\n",
      "|    policy_gradient_loss | 1.85e-05    |\n",
      "|    reward               | 9.098011    |\n",
      "|    value_loss           | 9.93e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1552         |\n",
      "|    time_elapsed         | 6421         |\n",
      "|    total_timesteps      | 1589248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.569833e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.87e+05     |\n",
      "|    n_updates            | 40740        |\n",
      "|    policy_gradient_loss | -0.000147    |\n",
      "|    reward               | -2.349243    |\n",
      "|    value_loss           | 3.75e+05     |\n",
      "------------------------------------------\n",
      "Episode: 887\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1553          |\n",
      "|    time_elapsed         | 6426          |\n",
      "|    total_timesteps      | 1590272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7576672e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.88e+04      |\n",
      "|    n_updates            | 40750         |\n",
      "|    policy_gradient_loss | -1.1e-05      |\n",
      "|    reward               | -2.0954816    |\n",
      "|    value_loss           | 7.76e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1554          |\n",
      "|    time_elapsed         | 6430          |\n",
      "|    total_timesteps      | 1591296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6592304e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.41e+05      |\n",
      "|    n_updates            | 40760         |\n",
      "|    policy_gradient_loss | -0.000216     |\n",
      "|    reward               | -18.659065    |\n",
      "|    value_loss           | 2.83e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1555          |\n",
      "|    time_elapsed         | 6434          |\n",
      "|    total_timesteps      | 1592320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018642016 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.73e+04      |\n",
      "|    n_updates            | 40770         |\n",
      "|    policy_gradient_loss | -0.000554     |\n",
      "|    reward               | -87.35714     |\n",
      "|    value_loss           | 3.47e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 888\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 969026.11\n",
      "total_reward: -30973.89\n",
      "total_cost: 1129254.41\n",
      "total_trades: 1096\n",
      "=================================\n",
      "Episode: 889\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1556          |\n",
      "|    time_elapsed         | 6438          |\n",
      "|    total_timesteps      | 1593344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012227573 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.44e+05      |\n",
      "|    n_updates            | 40780         |\n",
      "|    policy_gradient_loss | 0.000176      |\n",
      "|    reward               | -3.4841337    |\n",
      "|    value_loss           | 6.88e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 890\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1557          |\n",
      "|    time_elapsed         | 6443          |\n",
      "|    total_timesteps      | 1594368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8676662e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.91e+05      |\n",
      "|    n_updates            | 40790         |\n",
      "|    policy_gradient_loss | 0.000101      |\n",
      "|    reward               | -5.8468027    |\n",
      "|    value_loss           | 9.83e+05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1558        |\n",
      "|    time_elapsed         | 6447        |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004324084 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7e+04     |\n",
      "|    n_updates            | 40800       |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | -51.88222   |\n",
      "|    value_loss           | 3.4e+04     |\n",
      "-----------------------------------------\n",
      "Episode: 891\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1559         |\n",
      "|    time_elapsed         | 6451         |\n",
      "|    total_timesteps      | 1596416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019360475 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.977       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.05e+05     |\n",
      "|    n_updates            | 40810        |\n",
      "|    policy_gradient_loss | 0.00107      |\n",
      "|    reward               | 8.238676     |\n",
      "|    value_loss           | 2.1e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1560          |\n",
      "|    time_elapsed         | 6456          |\n",
      "|    total_timesteps      | 1597440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013653393 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.995        |\n",
      "|    explained_variance   | 0.724         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.49e+05      |\n",
      "|    n_updates            | 40820         |\n",
      "|    policy_gradient_loss | -8.2e-05      |\n",
      "|    reward               | -16.266146    |\n",
      "|    value_loss           | 1.3e+06       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1561         |\n",
      "|    time_elapsed         | 6460         |\n",
      "|    total_timesteps      | 1598464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.130185e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.996       |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.1e+05      |\n",
      "|    n_updates            | 40830        |\n",
      "|    policy_gradient_loss | -0.000211    |\n",
      "|    reward               | -69.43446    |\n",
      "|    value_loss           | 2.21e+05     |\n",
      "------------------------------------------\n",
      "Episode: 892\n",
      "Current company: ['AAPL']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2471257.74\n",
      "total_reward: 1471257.74\n",
      "total_cost: 1185219.57\n",
      "total_trades: 951\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1562          |\n",
      "|    time_elapsed         | 6464          |\n",
      "|    total_timesteps      | 1599488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2120989e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.967        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.78e+05      |\n",
      "|    n_updates            | 40840         |\n",
      "|    policy_gradient_loss | 5.32e-05      |\n",
      "|    reward               | -7.2958283    |\n",
      "|    value_loss           | 5.56e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1563          |\n",
      "|    time_elapsed         | 6468          |\n",
      "|    total_timesteps      | 1600512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9178336e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.966        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.01e+05      |\n",
      "|    n_updates            | 40850         |\n",
      "|    policy_gradient_loss | -2.05e-05     |\n",
      "|    reward               | -52.78458     |\n",
      "|    value_loss           | 4.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 893\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1564          |\n",
      "|    time_elapsed         | 6473          |\n",
      "|    total_timesteps      | 1601536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7463843e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.968        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.5e+04       |\n",
      "|    n_updates            | 40860         |\n",
      "|    policy_gradient_loss | -1.07e-05     |\n",
      "|    reward               | -0.19085316   |\n",
      "|    value_loss           | 1.7e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1565          |\n",
      "|    time_elapsed         | 6478          |\n",
      "|    total_timesteps      | 1602560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2250384e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.968        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.39e+05      |\n",
      "|    n_updates            | 40870         |\n",
      "|    policy_gradient_loss | -5.57e-06     |\n",
      "|    reward               | -22.964695    |\n",
      "|    value_loss           | 1.48e+06      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 247            |\n",
      "|    iterations           | 1566           |\n",
      "|    time_elapsed         | 6482           |\n",
      "|    total_timesteps      | 1603584        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000102093734 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.969         |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 9.82e+03       |\n",
      "|    n_updates            | 40880          |\n",
      "|    policy_gradient_loss | -0.000335      |\n",
      "|    reward               | -88.571365     |\n",
      "|    value_loss           | 1.97e+04       |\n",
      "--------------------------------------------\n",
      "Episode: 894\n",
      "Episode: 895\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1567         |\n",
      "|    time_elapsed         | 6487         |\n",
      "|    total_timesteps      | 1604608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001159776 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.15e+05     |\n",
      "|    n_updates            | 40890        |\n",
      "|    policy_gradient_loss | -5.53e-05    |\n",
      "|    reward               | -10.358174   |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1568         |\n",
      "|    time_elapsed         | 6492         |\n",
      "|    total_timesteps      | 1605632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.436664e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.977       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.13e+05     |\n",
      "|    n_updates            | 40900        |\n",
      "|    policy_gradient_loss | 6.82e-05     |\n",
      "|    reward               | 48.38175     |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1569          |\n",
      "|    time_elapsed         | 6497          |\n",
      "|    total_timesteps      | 1606656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2381074e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.82e+05      |\n",
      "|    n_updates            | 40910         |\n",
      "|    policy_gradient_loss | 6.76e-06      |\n",
      "|    reward               | 82.31593      |\n",
      "|    value_loss           | 3.64e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 896\n",
      "Current company: ['HD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2620916.79\n",
      "total_reward: 1620916.79\n",
      "total_cost: 1687465.77\n",
      "total_trades: 893\n",
      "=================================\n",
      "Episode: 897\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1570         |\n",
      "|    time_elapsed         | 6502         |\n",
      "|    total_timesteps      | 1607680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.214265e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.978       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03e+06     |\n",
      "|    n_updates            | 40920        |\n",
      "|    policy_gradient_loss | -1.49e-06    |\n",
      "|    reward               | -17.515839   |\n",
      "|    value_loss           | 2.05e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1571          |\n",
      "|    time_elapsed         | 6507          |\n",
      "|    total_timesteps      | 1608704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.3236955e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.97e+05      |\n",
      "|    n_updates            | 40930         |\n",
      "|    policy_gradient_loss | -4.08e-06     |\n",
      "|    reward               | -69.51729     |\n",
      "|    value_loss           | 5.94e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 898\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1572          |\n",
      "|    time_elapsed         | 6511          |\n",
      "|    total_timesteps      | 1609728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1827797e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.91e+05      |\n",
      "|    n_updates            | 40940         |\n",
      "|    policy_gradient_loss | 9.1e-06       |\n",
      "|    reward               | -2.4904656    |\n",
      "|    value_loss           | 3.81e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1573          |\n",
      "|    time_elapsed         | 6516          |\n",
      "|    total_timesteps      | 1610752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3004756e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.97e+05      |\n",
      "|    n_updates            | 40950         |\n",
      "|    policy_gradient_loss | -2.18e-05     |\n",
      "|    reward               | -48.055214    |\n",
      "|    value_loss           | 1.19e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 899\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1574          |\n",
      "|    time_elapsed         | 6521          |\n",
      "|    total_timesteps      | 1611776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7748443e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.979        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.81e+04      |\n",
      "|    n_updates            | 40960         |\n",
      "|    policy_gradient_loss | -0.000238     |\n",
      "|    reward               | 7.859562      |\n",
      "|    value_loss           | 9.63e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1575          |\n",
      "|    time_elapsed         | 6525          |\n",
      "|    total_timesteps      | 1612800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0419167e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.985        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.75e+05      |\n",
      "|    n_updates            | 40970         |\n",
      "|    policy_gradient_loss | 0.000221      |\n",
      "|    reward               | -64.295235    |\n",
      "|    value_loss           | 7.5e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 900\n",
      "Current company: ['IBM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 684639.09\n",
      "total_reward: -315360.91\n",
      "total_cost: 546566.89\n",
      "total_trades: 541\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1576          |\n",
      "|    time_elapsed         | 6530          |\n",
      "|    total_timesteps      | 1613824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016880967 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.99         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.95e+04      |\n",
      "|    n_updates            | 40980         |\n",
      "|    policy_gradient_loss | -0.000731     |\n",
      "|    reward               | -9.712234     |\n",
      "|    value_loss           | 1.79e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1577         |\n",
      "|    time_elapsed         | 6534         |\n",
      "|    total_timesteps      | 1614848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007825154 |\n",
      "|    clip_fraction        | 0.061        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.994       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.25e+04     |\n",
      "|    n_updates            | 40990        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | 25.426804    |\n",
      "|    value_loss           | 6.5e+04      |\n",
      "------------------------------------------\n",
      "Episode: 901\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1578         |\n",
      "|    time_elapsed         | 6539         |\n",
      "|    total_timesteps      | 1615872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037073777 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.45e+04     |\n",
      "|    n_updates            | 41000        |\n",
      "|    policy_gradient_loss | -0.000738    |\n",
      "|    reward               | 29.844667    |\n",
      "|    value_loss           | 4.9e+04      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1579          |\n",
      "|    time_elapsed         | 6543          |\n",
      "|    total_timesteps      | 1616896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061911525 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.53e+05      |\n",
      "|    n_updates            | 41010         |\n",
      "|    policy_gradient_loss | -0.000488     |\n",
      "|    reward               | -11.474626    |\n",
      "|    value_loss           | 1.51e+06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1580        |\n",
      "|    time_elapsed         | 6548        |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.08676e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.74e+04    |\n",
      "|    n_updates            | 41020       |\n",
      "|    policy_gradient_loss | 0.000129    |\n",
      "|    reward               | -28.92969   |\n",
      "|    value_loss           | 3.49e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 902\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1581         |\n",
      "|    time_elapsed         | 6553         |\n",
      "|    total_timesteps      | 1618944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.372144e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.11e+04     |\n",
      "|    n_updates            | 41030        |\n",
      "|    policy_gradient_loss | -8.6e-05     |\n",
      "|    reward               | 24.357225    |\n",
      "|    value_loss           | 4.22e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1582          |\n",
      "|    time_elapsed         | 6557          |\n",
      "|    total_timesteps      | 1619968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5082769e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.92e+04      |\n",
      "|    n_updates            | 41040         |\n",
      "|    policy_gradient_loss | -2.4e-06      |\n",
      "|    reward               | 23.231606     |\n",
      "|    value_loss           | 1.58e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1583          |\n",
      "|    time_elapsed         | 6561          |\n",
      "|    total_timesteps      | 1620992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.3190237e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.93e+05      |\n",
      "|    n_updates            | 41050         |\n",
      "|    policy_gradient_loss | 5.76e-06      |\n",
      "|    reward               | 46.679604     |\n",
      "|    value_loss           | 7.86e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 903\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1584          |\n",
      "|    time_elapsed         | 6566          |\n",
      "|    total_timesteps      | 1622016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7299774e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.09e+05      |\n",
      "|    n_updates            | 41060         |\n",
      "|    policy_gradient_loss | 1.06e-05      |\n",
      "|    reward               | 51.690674     |\n",
      "|    value_loss           | 4.19e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1585          |\n",
      "|    time_elapsed         | 6570          |\n",
      "|    total_timesteps      | 1623040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0541484e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.834         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.83e+05      |\n",
      "|    n_updates            | 41070         |\n",
      "|    policy_gradient_loss | -4.32e-06     |\n",
      "|    reward               | 52.729774     |\n",
      "|    value_loss           | 9.89e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 904\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2538064.33\n",
      "total_reward: 1538064.33\n",
      "total_cost: 1513194.17\n",
      "total_trades: 847\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1586         |\n",
      "|    time_elapsed         | 6574         |\n",
      "|    total_timesteps      | 1624064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.731149e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.022        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.01e+05     |\n",
      "|    n_updates            | 41080        |\n",
      "|    policy_gradient_loss | -8.74e-06    |\n",
      "|    reward               | -11.503478   |\n",
      "|    value_loss           | 4.34e+05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 246            |\n",
      "|    iterations           | 1587           |\n",
      "|    time_elapsed         | 6579           |\n",
      "|    total_timesteps      | 1625088        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.00641046e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.07          |\n",
      "|    explained_variance   | 0.728          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 6.55e+05       |\n",
      "|    n_updates            | 41090          |\n",
      "|    policy_gradient_loss | -8.96e-06      |\n",
      "|    reward               | -69.723976     |\n",
      "|    value_loss           | 1.33e+06       |\n",
      "--------------------------------------------\n",
      "Episode: 905\n",
      "Episode: 906\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1588          |\n",
      "|    time_elapsed         | 6584          |\n",
      "|    total_timesteps      | 1626112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3224933e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.87e+05      |\n",
      "|    n_updates            | 41100         |\n",
      "|    policy_gradient_loss | -5.48e-06     |\n",
      "|    reward               | -26.527712    |\n",
      "|    value_loss           | 3.75e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1589          |\n",
      "|    time_elapsed         | 6588          |\n",
      "|    total_timesteps      | 1627136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3722823e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.55e+04      |\n",
      "|    n_updates            | 41110         |\n",
      "|    policy_gradient_loss | -4.96e-05     |\n",
      "|    reward               | 15.426653     |\n",
      "|    value_loss           | 9.09e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 907\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1590         |\n",
      "|    time_elapsed         | 6592         |\n",
      "|    total_timesteps      | 1628160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.292496e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.62e+04     |\n",
      "|    n_updates            | 41120        |\n",
      "|    policy_gradient_loss | -0.00019     |\n",
      "|    reward               | 0.87747663   |\n",
      "|    value_loss           | 7.25e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1591          |\n",
      "|    time_elapsed         | 6597          |\n",
      "|    total_timesteps      | 1629184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2360446e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.73e+06      |\n",
      "|    n_updates            | 41130         |\n",
      "|    policy_gradient_loss | -0.000335     |\n",
      "|    reward               | 84.04562      |\n",
      "|    value_loss           | 3.46e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1592          |\n",
      "|    time_elapsed         | 6601          |\n",
      "|    total_timesteps      | 1630208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2496486e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.96e+05      |\n",
      "|    n_updates            | 41140         |\n",
      "|    policy_gradient_loss | -0.000133     |\n",
      "|    reward               | 188.6537      |\n",
      "|    value_loss           | 9.92e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 908\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2777329.52\n",
      "total_reward: 1777329.52\n",
      "total_cost: 2288715.01\n",
      "total_trades: 1020\n",
      "=================================\n",
      "Episode: 909\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1593          |\n",
      "|    time_elapsed         | 6605          |\n",
      "|    total_timesteps      | 1631232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2612512e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.24e+06      |\n",
      "|    n_updates            | 41150         |\n",
      "|    policy_gradient_loss | 2.58e-05      |\n",
      "|    reward               | -2.6485455    |\n",
      "|    value_loss           | 6.48e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1594          |\n",
      "|    time_elapsed         | 6609          |\n",
      "|    total_timesteps      | 1632256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4938414e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.76e+06      |\n",
      "|    n_updates            | 41160         |\n",
      "|    policy_gradient_loss | -4.56e-05     |\n",
      "|    reward               | -32.42987     |\n",
      "|    value_loss           | 3.52e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 910\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1595         |\n",
      "|    time_elapsed         | 6614         |\n",
      "|    total_timesteps      | 1633280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.899983e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.6e+04      |\n",
      "|    n_updates            | 41170        |\n",
      "|    policy_gradient_loss | -0.000444    |\n",
      "|    reward               | -19.001846   |\n",
      "|    value_loss           | 5.21e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1596          |\n",
      "|    time_elapsed         | 6618          |\n",
      "|    total_timesteps      | 1634304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9713202e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.43e+04      |\n",
      "|    n_updates            | 41180         |\n",
      "|    policy_gradient_loss | 4.65e-05      |\n",
      "|    reward               | -74.18233     |\n",
      "|    value_loss           | 1.29e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 911\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1597          |\n",
      "|    time_elapsed         | 6623          |\n",
      "|    total_timesteps      | 1635328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1656742e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.47e+05      |\n",
      "|    n_updates            | 41190         |\n",
      "|    policy_gradient_loss | 4.17e-05      |\n",
      "|    reward               | -28.709385    |\n",
      "|    value_loss           | 4.95e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 912\n",
      "Current company: ['JPM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 693908.20\n",
      "total_reward: -306091.80\n",
      "total_cost: 575506.85\n",
      "total_trades: 587\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1598         |\n",
      "|    time_elapsed         | 6627         |\n",
      "|    total_timesteps      | 1636352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.731149e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.87e+05     |\n",
      "|    n_updates            | 41200        |\n",
      "|    policy_gradient_loss | 5.4e-06      |\n",
      "|    reward               | -8.915165    |\n",
      "|    value_loss           | 5.74e+05     |\n",
      "------------------------------------------\n",
      "Episode: 913\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 246            |\n",
      "|    iterations           | 1599           |\n",
      "|    time_elapsed         | 6631           |\n",
      "|    total_timesteps      | 1637376        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.02154445e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.03          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.42e+05       |\n",
      "|    n_updates            | 41210          |\n",
      "|    policy_gradient_loss | 4.95e-06       |\n",
      "|    reward               | -11.313258     |\n",
      "|    value_loss           | 2.83e+05       |\n",
      "--------------------------------------------\n",
      "Episode: 914\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1600         |\n",
      "|    time_elapsed         | 6635         |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.746602e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.33e+04     |\n",
      "|    n_updates            | 41220        |\n",
      "|    policy_gradient_loss | -0.000191    |\n",
      "|    reward               | -4.981846    |\n",
      "|    value_loss           | 4.68e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1601          |\n",
      "|    time_elapsed         | 6639          |\n",
      "|    total_timesteps      | 1639424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9202318e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.91e+04      |\n",
      "|    n_updates            | 41230         |\n",
      "|    policy_gradient_loss | 7.62e-05      |\n",
      "|    reward               | -59.55577     |\n",
      "|    value_loss           | 1.58e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 915\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1602          |\n",
      "|    time_elapsed         | 6644          |\n",
      "|    total_timesteps      | 1640448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1101132e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.25e+04      |\n",
      "|    n_updates            | 41240         |\n",
      "|    policy_gradient_loss | -6.3e-05      |\n",
      "|    reward               | -11.44293     |\n",
      "|    value_loss           | 1.85e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1603         |\n",
      "|    time_elapsed         | 6648         |\n",
      "|    total_timesteps      | 1641472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.602829e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.72e+05     |\n",
      "|    n_updates            | 41250        |\n",
      "|    policy_gradient_loss | 6.9e-05      |\n",
      "|    reward               | -26.550455   |\n",
      "|    value_loss           | 7.46e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1604          |\n",
      "|    time_elapsed         | 6652          |\n",
      "|    total_timesteps      | 1642496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1820015e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.94e+03      |\n",
      "|    n_updates            | 41260         |\n",
      "|    policy_gradient_loss | -4.37e-05     |\n",
      "|    reward               | -41.464767    |\n",
      "|    value_loss           | 1.2e+04       |\n",
      "-------------------------------------------\n",
      "Episode: 916\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1115552.09\n",
      "total_reward: 115552.09\n",
      "total_cost: 1175731.24\n",
      "total_trades: 1049\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1605          |\n",
      "|    time_elapsed         | 6656          |\n",
      "|    total_timesteps      | 1643520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7923433e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+05      |\n",
      "|    n_updates            | 41270         |\n",
      "|    policy_gradient_loss | -0.000246     |\n",
      "|    reward               | 23.937828     |\n",
      "|    value_loss           | 2.79e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1606          |\n",
      "|    time_elapsed         | 6660          |\n",
      "|    total_timesteps      | 1644544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7692219e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.96e+05      |\n",
      "|    n_updates            | 41280         |\n",
      "|    policy_gradient_loss | -2.73e-05     |\n",
      "|    reward               | 52.25667      |\n",
      "|    value_loss           | 3.92e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1607          |\n",
      "|    time_elapsed         | 6664          |\n",
      "|    total_timesteps      | 1645568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4216514e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.12e+05      |\n",
      "|    n_updates            | 41290         |\n",
      "|    policy_gradient_loss | -5.48e-05     |\n",
      "|    reward               | 86.44151      |\n",
      "|    value_loss           | 4.23e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 917\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1608          |\n",
      "|    time_elapsed         | 6669          |\n",
      "|    total_timesteps      | 1646592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2514141e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.73e+06      |\n",
      "|    n_updates            | 41300         |\n",
      "|    policy_gradient_loss | -2.29e-05     |\n",
      "|    reward               | 6.6099443     |\n",
      "|    value_loss           | 3.47e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1609          |\n",
      "|    time_elapsed         | 6673          |\n",
      "|    total_timesteps      | 1647616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5687345e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+05      |\n",
      "|    n_updates            | 41310         |\n",
      "|    policy_gradient_loss | -7.62e-07     |\n",
      "|    reward               | -47.01516     |\n",
      "|    value_loss           | 4.9e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 918\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1610          |\n",
      "|    time_elapsed         | 6677          |\n",
      "|    total_timesteps      | 1648640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047689385 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.22e+04      |\n",
      "|    n_updates            | 41320         |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    reward               | -24.327036    |\n",
      "|    value_loss           | 1.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 919\n",
      "Episode: 920\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695302.72\n",
      "total_reward: -304697.28\n",
      "total_cost: 128676.72\n",
      "total_trades: 153\n",
      "=================================\n",
      "Episode: 921\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1611          |\n",
      "|    time_elapsed         | 6682          |\n",
      "|    total_timesteps      | 1649664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049621885 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.82e+05      |\n",
      "|    n_updates            | 41330         |\n",
      "|    policy_gradient_loss | 0.000164      |\n",
      "|    reward               | -25.557903    |\n",
      "|    value_loss           | 7.64e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 922\n",
      "Episode: 923\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1612         |\n",
      "|    time_elapsed         | 6686         |\n",
      "|    total_timesteps      | 1650688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005926469 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.23e+04     |\n",
      "|    n_updates            | 41340        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | -6.79838     |\n",
      "|    value_loss           | 4.46e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1613         |\n",
      "|    time_elapsed         | 6690         |\n",
      "|    total_timesteps      | 1651712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006514401 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.83e+04     |\n",
      "|    n_updates            | 41350        |\n",
      "|    policy_gradient_loss | -0.000713    |\n",
      "|    reward               | -3.5177357   |\n",
      "|    value_loss           | 7.66e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1614          |\n",
      "|    time_elapsed         | 6694          |\n",
      "|    total_timesteps      | 1652736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022529683 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.5e+04       |\n",
      "|    n_updates            | 41360         |\n",
      "|    policy_gradient_loss | -0.000345     |\n",
      "|    reward               | 49.642605     |\n",
      "|    value_loss           | 5e+04         |\n",
      "-------------------------------------------\n",
      "Episode: 924\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2447566.98\n",
      "total_reward: 1447566.98\n",
      "total_cost: 1635306.50\n",
      "total_trades: 992\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1615          |\n",
      "|    time_elapsed         | 6698          |\n",
      "|    total_timesteps      | 1653760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4432818e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.999        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.9e+05       |\n",
      "|    n_updates            | 41370         |\n",
      "|    policy_gradient_loss | 7.5e-05       |\n",
      "|    reward               | -6.5425115    |\n",
      "|    value_loss           | 5.79e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1616          |\n",
      "|    time_elapsed         | 6703          |\n",
      "|    total_timesteps      | 1654784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7237997e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.997        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.47e+05      |\n",
      "|    n_updates            | 41380         |\n",
      "|    policy_gradient_loss | -4.25e-05     |\n",
      "|    reward               | -50.878933    |\n",
      "|    value_loss           | 4.95e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1617         |\n",
      "|    time_elapsed         | 6707         |\n",
      "|    total_timesteps      | 1655808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.134412e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.995       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.25e+04     |\n",
      "|    n_updates            | 41390        |\n",
      "|    policy_gradient_loss | -8.51e-05    |\n",
      "|    reward               | -72.887985   |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n",
      "Episode: 925\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1618          |\n",
      "|    time_elapsed         | 6711          |\n",
      "|    total_timesteps      | 1656832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8129587e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.993        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.07e+05      |\n",
      "|    n_updates            | 41400         |\n",
      "|    policy_gradient_loss | 9.88e-06      |\n",
      "|    reward               | -15.7754965   |\n",
      "|    value_loss           | 6.14e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 926\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1619         |\n",
      "|    time_elapsed         | 6715         |\n",
      "|    total_timesteps      | 1657856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.090648e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.994       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.17e+05     |\n",
      "|    n_updates            | 41410        |\n",
      "|    policy_gradient_loss | -0.000219    |\n",
      "|    reward               | 14.828483    |\n",
      "|    value_loss           | 2.35e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 6719         |\n",
      "|    total_timesteps      | 1658880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.251083e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.74e+04     |\n",
      "|    n_updates            | 41420        |\n",
      "|    policy_gradient_loss | -0.000283    |\n",
      "|    reward               | -50.43669    |\n",
      "|    value_loss           | 1.95e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1621          |\n",
      "|    time_elapsed         | 6723          |\n",
      "|    total_timesteps      | 1659904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3665157e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.2e+05       |\n",
      "|    n_updates            | 41430         |\n",
      "|    policy_gradient_loss | -3.08e-05     |\n",
      "|    reward               | -92.30449     |\n",
      "|    value_loss           | 2.39e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 927\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1622          |\n",
      "|    time_elapsed         | 6727          |\n",
      "|    total_timesteps      | 1660928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4906857e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.56e+05      |\n",
      "|    n_updates            | 41440         |\n",
      "|    policy_gradient_loss | -7.66e-05     |\n",
      "|    reward               | 191.30655     |\n",
      "|    value_loss           | 9.12e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1623         |\n",
      "|    time_elapsed         | 6731         |\n",
      "|    total_timesteps      | 1661952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.210436e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.55e+06     |\n",
      "|    n_updates            | 41450        |\n",
      "|    policy_gradient_loss | 7.47e-07     |\n",
      "|    reward               | 257.0817     |\n",
      "|    value_loss           | 3.12e+06     |\n",
      "------------------------------------------\n",
      "Episode: 928\n",
      "Current company: ['CRM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4704350.56\n",
      "total_reward: 3704350.56\n",
      "total_cost: 2765424.95\n",
      "total_trades: 855\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1624          |\n",
      "|    time_elapsed         | 6735          |\n",
      "|    total_timesteps      | 1662976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6298145e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.175        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.13e+06      |\n",
      "|    n_updates            | 41460         |\n",
      "|    policy_gradient_loss | -3.84e-06     |\n",
      "|    reward               | 6.006538      |\n",
      "|    value_loss           | 1.24e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1625          |\n",
      "|    time_elapsed         | 6739          |\n",
      "|    total_timesteps      | 1664000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0267984e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.353         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.33e+07      |\n",
      "|    n_updates            | 41470         |\n",
      "|    policy_gradient_loss | -2.72e-06     |\n",
      "|    reward               | 8.891526      |\n",
      "|    value_loss           | 2.67e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1626         |\n",
      "|    time_elapsed         | 6743         |\n",
      "|    total_timesteps      | 1665024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026328573 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.45e+04     |\n",
      "|    n_updates            | 41480        |\n",
      "|    policy_gradient_loss | -0.000921    |\n",
      "|    reward               | 3.024544     |\n",
      "|    value_loss           | 2.89e+04     |\n",
      "------------------------------------------\n",
      "Episode: 929\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1627          |\n",
      "|    time_elapsed         | 6748          |\n",
      "|    total_timesteps      | 1666048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7337676e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.986        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.65e+04      |\n",
      "|    n_updates            | 41490         |\n",
      "|    policy_gradient_loss | 2.69e-05      |\n",
      "|    reward               | -17.292282    |\n",
      "|    value_loss           | 3.29e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1628          |\n",
      "|    time_elapsed         | 6752          |\n",
      "|    total_timesteps      | 1667072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4673063e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.984        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 41500         |\n",
      "|    policy_gradient_loss | 3.59e-05      |\n",
      "|    reward               | -64.39828     |\n",
      "|    value_loss           | 2.46e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 930\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1629         |\n",
      "|    time_elapsed         | 6756         |\n",
      "|    total_timesteps      | 1668096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.511195e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.982       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.5e+05      |\n",
      "|    n_updates            | 41510        |\n",
      "|    policy_gradient_loss | 1.54e-05     |\n",
      "|    reward               | 23.913       |\n",
      "|    value_loss           | 3e+05        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1630         |\n",
      "|    time_elapsed         | 6760         |\n",
      "|    total_timesteps      | 1669120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.449882e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.981       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.18e+05     |\n",
      "|    n_updates            | 41520        |\n",
      "|    policy_gradient_loss | -7.43e-05    |\n",
      "|    reward               | 24.862776    |\n",
      "|    value_loss           | 4.35e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1631          |\n",
      "|    time_elapsed         | 6764          |\n",
      "|    total_timesteps      | 1670144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4173158e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.16e+05      |\n",
      "|    n_updates            | 41530         |\n",
      "|    policy_gradient_loss | -8.47e-05     |\n",
      "|    reward               | 18.02634      |\n",
      "|    value_loss           | 8.31e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 931\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1632          |\n",
      "|    time_elapsed         | 6768          |\n",
      "|    total_timesteps      | 1671168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3814147e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.977        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.07e+04      |\n",
      "|    n_updates            | 41540         |\n",
      "|    policy_gradient_loss | -4.8e-05      |\n",
      "|    reward               | -43.890335    |\n",
      "|    value_loss           | 1.81e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 932\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695333.03\n",
      "total_reward: -304666.97\n",
      "total_cost: 586419.92\n",
      "total_trades: 603\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1633          |\n",
      "|    time_elapsed         | 6772          |\n",
      "|    total_timesteps      | 1672192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7333153e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.978        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.12e+04      |\n",
      "|    n_updates            | 41550         |\n",
      "|    policy_gradient_loss | -1.73e-06     |\n",
      "|    reward               | -21.23491     |\n",
      "|    value_loss           | 8.24e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1634          |\n",
      "|    time_elapsed         | 6776          |\n",
      "|    total_timesteps      | 1673216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2395845e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.977        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.59e+05      |\n",
      "|    n_updates            | 41560         |\n",
      "|    policy_gradient_loss | 4.82e-05      |\n",
      "|    reward               | -58.380154    |\n",
      "|    value_loss           | 7.18e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 933\n",
      "Episode: 934\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1635          |\n",
      "|    time_elapsed         | 6780          |\n",
      "|    total_timesteps      | 1674240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0505547e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.76e+05      |\n",
      "|    n_updates            | 41570         |\n",
      "|    policy_gradient_loss | -5.62e-05     |\n",
      "|    reward               | -37.051888    |\n",
      "|    value_loss           | 3.53e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1636          |\n",
      "|    time_elapsed         | 6784          |\n",
      "|    total_timesteps      | 1675264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0699885e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.86e+05      |\n",
      "|    n_updates            | 41580         |\n",
      "|    policy_gradient_loss | -2.77e-05     |\n",
      "|    reward               | -85.725464    |\n",
      "|    value_loss           | 3.73e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 935\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 6788         |\n",
      "|    total_timesteps      | 1676288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.897542e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.977       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.37e+05     |\n",
      "|    n_updates            | 41590        |\n",
      "|    policy_gradient_loss | -6.8e-05     |\n",
      "|    reward               | -10.040677   |\n",
      "|    value_loss           | 2.74e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 6792        |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007581435 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04e+04    |\n",
      "|    n_updates            | 41600       |\n",
      "|    policy_gradient_loss | -0.000594   |\n",
      "|    reward               | -28.146976  |\n",
      "|    value_loss           | 2.07e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 936\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2721656.38\n",
      "total_reward: 1721656.38\n",
      "total_cost: 1329174.80\n",
      "total_trades: 928\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1639         |\n",
      "|    time_elapsed         | 6797         |\n",
      "|    total_timesteps      | 1678336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003861619 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6e+04        |\n",
      "|    n_updates            | 41610        |\n",
      "|    policy_gradient_loss | -2.05e-05    |\n",
      "|    reward               | -23.964653   |\n",
      "|    value_loss           | 1.21e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1640         |\n",
      "|    time_elapsed         | 6801         |\n",
      "|    total_timesteps      | 1679360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.749301e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.25e+05     |\n",
      "|    n_updates            | 41620        |\n",
      "|    policy_gradient_loss | 1.37e-05     |\n",
      "|    reward               | -76.36615    |\n",
      "|    value_loss           | 2.51e+05     |\n",
      "------------------------------------------\n",
      "Episode: 937\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1641          |\n",
      "|    time_elapsed         | 6805          |\n",
      "|    total_timesteps      | 1680384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7198264e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75e+05      |\n",
      "|    n_updates            | 41630         |\n",
      "|    policy_gradient_loss | -2.85e-05     |\n",
      "|    reward               | 13.584591     |\n",
      "|    value_loss           | 3.5e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1642         |\n",
      "|    time_elapsed         | 6809         |\n",
      "|    total_timesteps      | 1681408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.749287e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.27e+05     |\n",
      "|    n_updates            | 41640        |\n",
      "|    policy_gradient_loss | -6.72e-05    |\n",
      "|    reward               | -54.579155   |\n",
      "|    value_loss           | 6.55e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1643          |\n",
      "|    time_elapsed         | 6813          |\n",
      "|    total_timesteps      | 1682432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4692245e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.73e+04      |\n",
      "|    n_updates            | 41650         |\n",
      "|    policy_gradient_loss | -0.000266     |\n",
      "|    reward               | -95.590675    |\n",
      "|    value_loss           | 9.46e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 938\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1644          |\n",
      "|    time_elapsed         | 6817          |\n",
      "|    total_timesteps      | 1683456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011227414 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.1e+05       |\n",
      "|    n_updates            | 41660         |\n",
      "|    policy_gradient_loss | -0.000135     |\n",
      "|    reward               | -55.504482    |\n",
      "|    value_loss           | 8.2e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 939\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1645          |\n",
      "|    time_elapsed         | 6821          |\n",
      "|    total_timesteps      | 1684480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1072727e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.05e+04      |\n",
      "|    n_updates            | 41670         |\n",
      "|    policy_gradient_loss | 2.39e-05      |\n",
      "|    reward               | -10.246969    |\n",
      "|    value_loss           | 1.41e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1646         |\n",
      "|    time_elapsed         | 6825         |\n",
      "|    total_timesteps      | 1685504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.051494e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81e+05     |\n",
      "|    n_updates            | 41680        |\n",
      "|    policy_gradient_loss | -0.000239    |\n",
      "|    reward               | -60.104538   |\n",
      "|    value_loss           | 3.62e+05     |\n",
      "------------------------------------------\n",
      "Episode: 940\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 689766.70\n",
      "total_reward: -310233.30\n",
      "total_cost: 887071.30\n",
      "total_trades: 871\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1647          |\n",
      "|    time_elapsed         | 6829          |\n",
      "|    total_timesteps      | 1686528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3533339e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.19e+05      |\n",
      "|    n_updates            | 41690         |\n",
      "|    policy_gradient_loss | 3.53e-05      |\n",
      "|    reward               | -8.731396     |\n",
      "|    value_loss           | 2.37e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1648         |\n",
      "|    time_elapsed         | 6833         |\n",
      "|    total_timesteps      | 1687552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.191883e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.26e+05     |\n",
      "|    n_updates            | 41700        |\n",
      "|    policy_gradient_loss | -2.61e-05    |\n",
      "|    reward               | -39.77333    |\n",
      "|    value_loss           | 1.25e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1649         |\n",
      "|    time_elapsed         | 6837         |\n",
      "|    total_timesteps      | 1688576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.011672e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.13e+04     |\n",
      "|    n_updates            | 41710        |\n",
      "|    policy_gradient_loss | -4.23e-05    |\n",
      "|    reward               | -60.036148   |\n",
      "|    value_loss           | 8.33e+04     |\n",
      "------------------------------------------\n",
      "Episode: 941\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1650         |\n",
      "|    time_elapsed         | 6841         |\n",
      "|    total_timesteps      | 1689600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.352144e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.63e+05     |\n",
      "|    n_updates            | 41720        |\n",
      "|    policy_gradient_loss | 5.43e-05     |\n",
      "|    reward               | -4.5688376   |\n",
      "|    value_loss           | 7.28e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1651          |\n",
      "|    time_elapsed         | 6845          |\n",
      "|    total_timesteps      | 1690624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1299853e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.57e+05      |\n",
      "|    n_updates            | 41730         |\n",
      "|    policy_gradient_loss | -3.08e-05     |\n",
      "|    reward               | -10.132591    |\n",
      "|    value_loss           | 9.16e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1652          |\n",
      "|    time_elapsed         | 6849          |\n",
      "|    total_timesteps      | 1691648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5849163e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.65e+04      |\n",
      "|    n_updates            | 41740         |\n",
      "|    policy_gradient_loss | -8.26e-05     |\n",
      "|    reward               | -22.273846    |\n",
      "|    value_loss           | 7.37e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 942\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1653          |\n",
      "|    time_elapsed         | 6853          |\n",
      "|    total_timesteps      | 1692672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026943302 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.83e+04      |\n",
      "|    n_updates            | 41750         |\n",
      "|    policy_gradient_loss | -0.000383     |\n",
      "|    reward               | -41.52574     |\n",
      "|    value_loss           | 3.65e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 943\n",
      "Episode: 944\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 695514.61\n",
      "total_reward: -304485.39\n",
      "total_cost: 151113.78\n",
      "total_trades: 171\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1654          |\n",
      "|    time_elapsed         | 6857          |\n",
      "|    total_timesteps      | 1693696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032175635 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.92e+04      |\n",
      "|    n_updates            | 41760         |\n",
      "|    policy_gradient_loss | -6.4e-05      |\n",
      "|    reward               | -7.3460197    |\n",
      "|    value_loss           | 1.78e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1655         |\n",
      "|    time_elapsed         | 6861         |\n",
      "|    total_timesteps      | 1694720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003848757 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.28e+04     |\n",
      "|    n_updates            | 41770        |\n",
      "|    policy_gradient_loss | -0.000667    |\n",
      "|    reward               | 95.85567     |\n",
      "|    value_loss           | 1.06e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1656          |\n",
      "|    time_elapsed         | 6865          |\n",
      "|    total_timesteps      | 1695744       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026247377 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.46e+06      |\n",
      "|    n_updates            | 41780         |\n",
      "|    policy_gradient_loss | 0.000803      |\n",
      "|    reward               | 107.00199     |\n",
      "|    value_loss           | 2.91e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 945\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1657          |\n",
      "|    time_elapsed         | 6869          |\n",
      "|    total_timesteps      | 1696768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4292385e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.46e+06      |\n",
      "|    n_updates            | 41790         |\n",
      "|    policy_gradient_loss | 0.000184      |\n",
      "|    reward               | -31.878977    |\n",
      "|    value_loss           | 4.92e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1658          |\n",
      "|    time_elapsed         | 6873          |\n",
      "|    total_timesteps      | 1697792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1408854e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.42e+05      |\n",
      "|    n_updates            | 41800         |\n",
      "|    policy_gradient_loss | -7.92e-06     |\n",
      "|    reward               | -51.29194     |\n",
      "|    value_loss           | 2.84e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 946\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1659         |\n",
      "|    time_elapsed         | 6877         |\n",
      "|    total_timesteps      | 1698816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.569977e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.07e+05     |\n",
      "|    n_updates            | 41810        |\n",
      "|    policy_gradient_loss | 3.04e-05     |\n",
      "|    reward               | 29.638052    |\n",
      "|    value_loss           | 2.13e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1660          |\n",
      "|    time_elapsed         | 6881          |\n",
      "|    total_timesteps      | 1699840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5743963e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.7e+05       |\n",
      "|    n_updates            | 41820         |\n",
      "|    policy_gradient_loss | -0.000343     |\n",
      "|    reward               | -43.05158     |\n",
      "|    value_loss           | 7.4e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1661          |\n",
      "|    time_elapsed         | 6885          |\n",
      "|    total_timesteps      | 1700864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8298935e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.3e+05       |\n",
      "|    n_updates            | 41830         |\n",
      "|    policy_gradient_loss | 0.000136      |\n",
      "|    reward               | -78.22855     |\n",
      "|    value_loss           | 2.6e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 947\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 247            |\n",
      "|    iterations           | 1662           |\n",
      "|    time_elapsed         | 6889           |\n",
      "|    total_timesteps      | 1701888        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.33671565e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -1.06          |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 2.91e+05       |\n",
      "|    n_updates            | 41840          |\n",
      "|    policy_gradient_loss | -8.7e-05       |\n",
      "|    reward               | -7.8625765     |\n",
      "|    value_loss           | 5.82e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1663          |\n",
      "|    time_elapsed         | 6893          |\n",
      "|    total_timesteps      | 1702912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4711404e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.36e+05      |\n",
      "|    n_updates            | 41850         |\n",
      "|    policy_gradient_loss | -5.72e-05     |\n",
      "|    reward               | -55.348       |\n",
      "|    value_loss           | 4.73e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 948\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1044592.08\n",
      "total_reward: 44592.08\n",
      "total_cost: 1051737.44\n",
      "total_trades: 997\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1664          |\n",
      "|    time_elapsed         | 6897          |\n",
      "|    total_timesteps      | 1703936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8685649e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.57e+04      |\n",
      "|    n_updates            | 41860         |\n",
      "|    policy_gradient_loss | -2.4e-05      |\n",
      "|    reward               | 1.0941334     |\n",
      "|    value_loss           | 7.14e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1665         |\n",
      "|    time_elapsed         | 6901         |\n",
      "|    total_timesteps      | 1704960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.090842e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.65e+05     |\n",
      "|    n_updates            | 41870        |\n",
      "|    policy_gradient_loss | 8.28e-05     |\n",
      "|    reward               | -31.382942   |\n",
      "|    value_loss           | 1.13e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1666         |\n",
      "|    time_elapsed         | 6905         |\n",
      "|    total_timesteps      | 1705984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008229063 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.97e+04     |\n",
      "|    n_updates            | 41880        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | -73.79721    |\n",
      "|    value_loss           | 3.95e+04     |\n",
      "------------------------------------------\n",
      "Episode: 949\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1667          |\n",
      "|    time_elapsed         | 6909          |\n",
      "|    total_timesteps      | 1707008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081560784 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.6e+05       |\n",
      "|    n_updates            | 41890         |\n",
      "|    policy_gradient_loss | 0.000846      |\n",
      "|    reward               | -13.149956    |\n",
      "|    value_loss           | 7.2e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 950\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1668         |\n",
      "|    time_elapsed         | 6914         |\n",
      "|    total_timesteps      | 1708032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.703163e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.7e+05      |\n",
      "|    n_updates            | 41900        |\n",
      "|    policy_gradient_loss | 3.42e-05     |\n",
      "|    reward               | 3.4369972    |\n",
      "|    value_loss           | 7.39e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1669          |\n",
      "|    time_elapsed         | 6918          |\n",
      "|    total_timesteps      | 1709056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1851022e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28e+05      |\n",
      "|    n_updates            | 41910         |\n",
      "|    policy_gradient_loss | -3.06e-05     |\n",
      "|    reward               | -41.62431     |\n",
      "|    value_loss           | 2.56e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1670         |\n",
      "|    time_elapsed         | 6922         |\n",
      "|    total_timesteps      | 1710080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.147499e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.44e+04     |\n",
      "|    n_updates            | 41920        |\n",
      "|    policy_gradient_loss | -0.000257    |\n",
      "|    reward               | -93.159935   |\n",
      "|    value_loss           | 6.91e+04     |\n",
      "------------------------------------------\n",
      "Episode: 951\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1671          |\n",
      "|    time_elapsed         | 6927          |\n",
      "|    total_timesteps      | 1711104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5654695e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.1e+05       |\n",
      "|    n_updates            | 41930         |\n",
      "|    policy_gradient_loss | 0.000235      |\n",
      "|    reward               | 10.525896     |\n",
      "|    value_loss           | 6.22e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1672          |\n",
      "|    time_elapsed         | 6931          |\n",
      "|    total_timesteps      | 1712128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4642795e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.2e+05       |\n",
      "|    n_updates            | 41940         |\n",
      "|    policy_gradient_loss | -1.48e-06     |\n",
      "|    reward               | -44.97244     |\n",
      "|    value_loss           | 6.41e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 952\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1212091.61\n",
      "total_reward: 212091.61\n",
      "total_cost: 1026878.52\n",
      "total_trades: 918\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1673          |\n",
      "|    time_elapsed         | 6935          |\n",
      "|    total_timesteps      | 1713152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9100996e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.42e+04      |\n",
      "|    n_updates            | 41950         |\n",
      "|    policy_gradient_loss | -2e-05        |\n",
      "|    reward               | -11.758826    |\n",
      "|    value_loss           | 8.84e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1674          |\n",
      "|    time_elapsed         | 6939          |\n",
      "|    total_timesteps      | 1714176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9417377e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.99e+04      |\n",
      "|    n_updates            | 41960         |\n",
      "|    policy_gradient_loss | -0.000186     |\n",
      "|    reward               | -55.92544     |\n",
      "|    value_loss           | 1.6e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 953\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1675          |\n",
      "|    time_elapsed         | 6943          |\n",
      "|    total_timesteps      | 1715200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9383908e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.32e+04      |\n",
      "|    n_updates            | 41970         |\n",
      "|    policy_gradient_loss | 6.8e-05       |\n",
      "|    reward               | -17.232454    |\n",
      "|    value_loss           | 1.26e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1676         |\n",
      "|    time_elapsed         | 6947         |\n",
      "|    total_timesteps      | 1716224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.191056e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.79e+04     |\n",
      "|    n_updates            | 41980        |\n",
      "|    policy_gradient_loss | -0.000156    |\n",
      "|    reward               | -54.15381    |\n",
      "|    value_loss           | 9.59e+04     |\n",
      "------------------------------------------\n",
      "Episode: 954\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1677          |\n",
      "|    time_elapsed         | 6951          |\n",
      "|    total_timesteps      | 1717248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2434025e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.36e+05      |\n",
      "|    n_updates            | 41990         |\n",
      "|    policy_gradient_loss | 0.00014       |\n",
      "|    reward               | -7.008166     |\n",
      "|    value_loss           | 4.72e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 955\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1678          |\n",
      "|    time_elapsed         | 6955          |\n",
      "|    total_timesteps      | 1718272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2435283e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.33e+05      |\n",
      "|    n_updates            | 42000         |\n",
      "|    policy_gradient_loss | -5.29e-05     |\n",
      "|    reward               | -22.341417    |\n",
      "|    value_loss           | 4.69e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1679         |\n",
      "|    time_elapsed         | 6960         |\n",
      "|    total_timesteps      | 1719296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.380863e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.11e+04     |\n",
      "|    n_updates            | 42010        |\n",
      "|    policy_gradient_loss | -6.26e-05    |\n",
      "|    reward               | -58.637802   |\n",
      "|    value_loss           | 1.03e+05     |\n",
      "------------------------------------------\n",
      "Episode: 956\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 688247.78\n",
      "total_reward: -311752.22\n",
      "total_cost: 758862.80\n",
      "total_trades: 825\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1680         |\n",
      "|    time_elapsed         | 6963         |\n",
      "|    total_timesteps      | 1720320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.918198e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12e+05     |\n",
      "|    n_updates            | 42020        |\n",
      "|    policy_gradient_loss | 4.58e-05     |\n",
      "|    reward               | -0.01        |\n",
      "|    value_loss           | 2.26e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 6967        |\n",
      "|    total_timesteps      | 1721344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.43861e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21e+05    |\n",
      "|    n_updates            | 42030       |\n",
      "|    policy_gradient_loss | -4.83e-05   |\n",
      "|    reward               | -12.343567  |\n",
      "|    value_loss           | 1.04e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1682          |\n",
      "|    time_elapsed         | 6971          |\n",
      "|    total_timesteps      | 1722368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1398067e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.94e+04      |\n",
      "|    n_updates            | 42040         |\n",
      "|    policy_gradient_loss | -0.000145     |\n",
      "|    reward               | -37.84701     |\n",
      "|    value_loss           | 5.87e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 957\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1683          |\n",
      "|    time_elapsed         | 6976          |\n",
      "|    total_timesteps      | 1723392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0458421e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.9e+04       |\n",
      "|    n_updates            | 42050         |\n",
      "|    policy_gradient_loss | 2.76e-05      |\n",
      "|    reward               | -2.4702368    |\n",
      "|    value_loss           | 7.81e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1684          |\n",
      "|    time_elapsed         | 6980          |\n",
      "|    total_timesteps      | 1724416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1714444e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.69e+04      |\n",
      "|    n_updates            | 42060         |\n",
      "|    policy_gradient_loss | 3.52e-05      |\n",
      "|    reward               | -37.323627    |\n",
      "|    value_loss           | 1.14e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1685         |\n",
      "|    time_elapsed         | 6983         |\n",
      "|    total_timesteps      | 1725440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.189486e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.43e+04     |\n",
      "|    n_updates            | 42070        |\n",
      "|    policy_gradient_loss | -9.3e-05     |\n",
      "|    reward               | -51.107403   |\n",
      "|    value_loss           | 2.86e+04     |\n",
      "------------------------------------------\n",
      "Episode: 958\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1686         |\n",
      "|    time_elapsed         | 6988         |\n",
      "|    total_timesteps      | 1726464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.894635e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.3e+05      |\n",
      "|    n_updates            | 42080        |\n",
      "|    policy_gradient_loss | -1.36e-05    |\n",
      "|    reward               | -22.614199   |\n",
      "|    value_loss           | 2.6e+05      |\n",
      "------------------------------------------\n",
      "Episode: 959\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1687         |\n",
      "|    time_elapsed         | 6992         |\n",
      "|    total_timesteps      | 1727488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.848473e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.71e+04     |\n",
      "|    n_updates            | 42090        |\n",
      "|    policy_gradient_loss | 3.68e-05     |\n",
      "|    reward               | -7.57962     |\n",
      "|    value_loss           | 1.75e+05     |\n",
      "------------------------------------------\n",
      "Episode: 960\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1239896.05\n",
      "total_reward: 239896.05\n",
      "total_cost: 109545.07\n",
      "total_trades: 110\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1688         |\n",
      "|    time_elapsed         | 6996         |\n",
      "|    total_timesteps      | 1728512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.442424e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.73e+05     |\n",
      "|    n_updates            | 42100        |\n",
      "|    policy_gradient_loss | 7.82e-06     |\n",
      "|    reward               | -55.156094   |\n",
      "|    value_loss           | 3.47e+05     |\n",
      "------------------------------------------\n",
      "Episode: 961\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 7000         |\n",
      "|    total_timesteps      | 1729536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.254312e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.85e+04     |\n",
      "|    n_updates            | 42110        |\n",
      "|    policy_gradient_loss | -8.73e-05    |\n",
      "|    reward               | -22.483555   |\n",
      "|    value_loss           | 1.98e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1690          |\n",
      "|    time_elapsed         | 7004          |\n",
      "|    total_timesteps      | 1730560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2578752e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.47e+05      |\n",
      "|    n_updates            | 42120         |\n",
      "|    policy_gradient_loss | -7.27e-05     |\n",
      "|    reward               | -67.747765    |\n",
      "|    value_loss           | 2.93e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 962\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1691          |\n",
      "|    time_elapsed         | 7009          |\n",
      "|    total_timesteps      | 1731584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7200364e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.11e+04      |\n",
      "|    n_updates            | 42130         |\n",
      "|    policy_gradient_loss | 3.61e-05      |\n",
      "|    reward               | 1.66363       |\n",
      "|    value_loss           | 1.62e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1692         |\n",
      "|    time_elapsed         | 7013         |\n",
      "|    total_timesteps      | 1732608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.033477e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.39e+05     |\n",
      "|    n_updates            | 42140        |\n",
      "|    policy_gradient_loss | 2.88e-06     |\n",
      "|    reward               | -48.21785    |\n",
      "|    value_loss           | 8.79e+05     |\n",
      "------------------------------------------\n",
      "Episode: 963\n",
      "Episode: 964\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1236105.43\n",
      "total_reward: 236105.43\n",
      "total_cost: 104850.71\n",
      "total_trades: 106\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1693         |\n",
      "|    time_elapsed         | 7017         |\n",
      "|    total_timesteps      | 1733632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.536976e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.4e+04      |\n",
      "|    n_updates            | 42150        |\n",
      "|    policy_gradient_loss | -8.02e-05    |\n",
      "|    reward               | -12.302897   |\n",
      "|    value_loss           | 1.48e+05     |\n",
      "------------------------------------------\n",
      "Episode: 965\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1694         |\n",
      "|    time_elapsed         | 7021         |\n",
      "|    total_timesteps      | 1734656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.002607e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.16e+05     |\n",
      "|    n_updates            | 42160        |\n",
      "|    policy_gradient_loss | -1.96e-05    |\n",
      "|    reward               | -17.495855   |\n",
      "|    value_loss           | 2.32e+05     |\n",
      "------------------------------------------\n",
      "Episode: 966\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1695          |\n",
      "|    time_elapsed         | 7025          |\n",
      "|    total_timesteps      | 1735680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014087022 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.66e+04      |\n",
      "|    n_updates            | 42170         |\n",
      "|    policy_gradient_loss | -0.000532     |\n",
      "|    reward               | -2.8652647    |\n",
      "|    value_loss           | 9.32e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1696          |\n",
      "|    time_elapsed         | 7030          |\n",
      "|    total_timesteps      | 1736704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011386373 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+05      |\n",
      "|    n_updates            | 42180         |\n",
      "|    policy_gradient_loss | -6.3e-05      |\n",
      "|    reward               | -2.044196     |\n",
      "|    value_loss           | 2.12e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1697          |\n",
      "|    time_elapsed         | 7034          |\n",
      "|    total_timesteps      | 1737728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7784182e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.15e+05      |\n",
      "|    n_updates            | 42190         |\n",
      "|    policy_gradient_loss | -0.000244     |\n",
      "|    reward               | -52.95118     |\n",
      "|    value_loss           | 2.29e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 967\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1698          |\n",
      "|    time_elapsed         | 7038          |\n",
      "|    total_timesteps      | 1738752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9959362e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.03e+05      |\n",
      "|    n_updates            | 42200         |\n",
      "|    policy_gradient_loss | -0.000378     |\n",
      "|    reward               | -22.963913    |\n",
      "|    value_loss           | 4.06e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1699          |\n",
      "|    time_elapsed         | 7042          |\n",
      "|    total_timesteps      | 1739776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3327513e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.79e+05      |\n",
      "|    n_updates            | 42210         |\n",
      "|    policy_gradient_loss | -0.000117     |\n",
      "|    reward               | -43.39072     |\n",
      "|    value_loss           | 3.58e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1700          |\n",
      "|    time_elapsed         | 7046          |\n",
      "|    total_timesteps      | 1740800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7871825e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.05e+04      |\n",
      "|    n_updates            | 42220         |\n",
      "|    policy_gradient_loss | -0.000141     |\n",
      "|    reward               | -74.867004    |\n",
      "|    value_loss           | 1.01e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 968\n",
      "Current company: ['TRV']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1046021.90\n",
      "total_reward: 46021.90\n",
      "total_cost: 992405.64\n",
      "total_trades: 976\n",
      "=================================\n",
      "Episode: 969\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1701          |\n",
      "|    time_elapsed         | 7051          |\n",
      "|    total_timesteps      | 1741824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2442295e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.49e+05      |\n",
      "|    n_updates            | 42230         |\n",
      "|    policy_gradient_loss | 4.51e-05      |\n",
      "|    reward               | 47.944923     |\n",
      "|    value_loss           | 8.98e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1702         |\n",
      "|    time_elapsed         | 7055         |\n",
      "|    total_timesteps      | 1742848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.578941e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.14e+05     |\n",
      "|    n_updates            | 42240        |\n",
      "|    policy_gradient_loss | -5.68e-06    |\n",
      "|    reward               | 69.29199     |\n",
      "|    value_loss           | 2.29e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 7059        |\n",
      "|    total_timesteps      | 1743872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.33148e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.89e+05    |\n",
      "|    n_updates            | 42250       |\n",
      "|    policy_gradient_loss | -9.18e-05   |\n",
      "|    reward               | 284.70917   |\n",
      "|    value_loss           | 1.18e+06    |\n",
      "-----------------------------------------\n",
      "Episode: 970\n",
      "Episode: 971\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1704          |\n",
      "|    time_elapsed         | 7063          |\n",
      "|    total_timesteps      | 1744896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7235288e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.17e+06      |\n",
      "|    n_updates            | 42260         |\n",
      "|    policy_gradient_loss | 7.38e-05      |\n",
      "|    reward               | -15.683158    |\n",
      "|    value_loss           | 1.03e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1705          |\n",
      "|    time_elapsed         | 7067          |\n",
      "|    total_timesteps      | 1745920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6170393e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.15e+06      |\n",
      "|    n_updates            | 42270         |\n",
      "|    policy_gradient_loss | -1.84e-06     |\n",
      "|    reward               | -43.011044    |\n",
      "|    value_loss           | 4.31e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1706          |\n",
      "|    time_elapsed         | 7071          |\n",
      "|    total_timesteps      | 1746944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9797008e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.13e+04      |\n",
      "|    n_updates            | 42280         |\n",
      "|    policy_gradient_loss | -1.68e-05     |\n",
      "|    reward               | -86.31203     |\n",
      "|    value_loss           | 1.83e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 972\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 874143.96\n",
      "total_reward: -125856.04\n",
      "total_cost: 951379.39\n",
      "total_trades: 993\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1707         |\n",
      "|    time_elapsed         | 7075         |\n",
      "|    total_timesteps      | 1747968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.438567e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.69e+05     |\n",
      "|    n_updates            | 42290        |\n",
      "|    policy_gradient_loss | -4.09e-05    |\n",
      "|    reward               | -55.494957   |\n",
      "|    value_loss           | 5.39e+05     |\n",
      "------------------------------------------\n",
      "Episode: 973\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1708          |\n",
      "|    time_elapsed         | 7080          |\n",
      "|    total_timesteps      | 1748992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8525905e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.07e+05      |\n",
      "|    n_updates            | 42300         |\n",
      "|    policy_gradient_loss | -3.03e-05     |\n",
      "|    reward               | 17.942322     |\n",
      "|    value_loss           | 2.13e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1709          |\n",
      "|    time_elapsed         | 7084          |\n",
      "|    total_timesteps      | 1750016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7567072e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.01e+04      |\n",
      "|    n_updates            | 42310         |\n",
      "|    policy_gradient_loss | 1.29e-05      |\n",
      "|    reward               | -34.954254    |\n",
      "|    value_loss           | 1e+05         |\n",
      "-------------------------------------------\n",
      "Episode: 974\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1710          |\n",
      "|    time_elapsed         | 7088          |\n",
      "|    total_timesteps      | 1751040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030834018 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.76e+04      |\n",
      "|    n_updates            | 42320         |\n",
      "|    policy_gradient_loss | -0.000654     |\n",
      "|    reward               | -14.015913    |\n",
      "|    value_loss           | 5.52e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1711         |\n",
      "|    time_elapsed         | 7092         |\n",
      "|    total_timesteps      | 1752064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011307457 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.54e+04     |\n",
      "|    n_updates            | 42330        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | -58.011196   |\n",
      "|    value_loss           | 5.08e+04     |\n",
      "------------------------------------------\n",
      "Episode: 975\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1712         |\n",
      "|    time_elapsed         | 7096         |\n",
      "|    total_timesteps      | 1753088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005441437 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.32e+05     |\n",
      "|    n_updates            | 42340        |\n",
      "|    policy_gradient_loss | 0.000198     |\n",
      "|    reward               | -30.485462   |\n",
      "|    value_loss           | 2.64e+05     |\n",
      "------------------------------------------\n",
      "Episode: 976\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 690234.17\n",
      "total_reward: -309765.83\n",
      "total_cost: 98281.82\n",
      "total_trades: 121\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1713          |\n",
      "|    time_elapsed         | 7101          |\n",
      "|    total_timesteps      | 1754112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2654046e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.67e+05      |\n",
      "|    n_updates            | 42350         |\n",
      "|    policy_gradient_loss | -0.000135     |\n",
      "|    reward               | 15.037023     |\n",
      "|    value_loss           | 7.33e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1714         |\n",
      "|    time_elapsed         | 7105         |\n",
      "|    total_timesteps      | 1755136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.354094e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.48e+04     |\n",
      "|    n_updates            | 42360        |\n",
      "|    policy_gradient_loss | -0.000193    |\n",
      "|    reward               | -27.62822    |\n",
      "|    value_loss           | 8.95e+04     |\n",
      "------------------------------------------\n",
      "Episode: 977\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1715          |\n",
      "|    time_elapsed         | 7109          |\n",
      "|    total_timesteps      | 1756160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9842777e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.67e+04      |\n",
      "|    n_updates            | 42370         |\n",
      "|    policy_gradient_loss | -6.43e-05     |\n",
      "|    reward               | 35.90974      |\n",
      "|    value_loss           | 5.34e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1716          |\n",
      "|    time_elapsed         | 7113          |\n",
      "|    total_timesteps      | 1757184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0856463e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.92          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.12e+04      |\n",
      "|    n_updates            | 42380         |\n",
      "|    policy_gradient_loss | 2.17e-05      |\n",
      "|    reward               | 85.509895     |\n",
      "|    value_loss           | 1.63e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1717          |\n",
      "|    time_elapsed         | 7117          |\n",
      "|    total_timesteps      | 1758208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7810456e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0.284         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+06      |\n",
      "|    n_updates            | 42390         |\n",
      "|    policy_gradient_loss | 7.19e-06      |\n",
      "|    reward               | 132.084       |\n",
      "|    value_loss           | 2.8e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 978\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1718          |\n",
      "|    time_elapsed         | 7121          |\n",
      "|    total_timesteps      | 1759232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5576675e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.76e+06      |\n",
      "|    n_updates            | 42400         |\n",
      "|    policy_gradient_loss | -8.66e-06     |\n",
      "|    reward               | -31.733492    |\n",
      "|    value_loss           | 3.53e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 979\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1719         |\n",
      "|    time_elapsed         | 7126         |\n",
      "|    total_timesteps      | 1760256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.612375e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.91e+06     |\n",
      "|    n_updates            | 42410        |\n",
      "|    policy_gradient_loss | -1.34e-05    |\n",
      "|    reward               | -36.1554     |\n",
      "|    value_loss           | 3.82e+06     |\n",
      "------------------------------------------\n",
      "Episode: 980\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698593.26\n",
      "total_reward: -301406.74\n",
      "total_cost: 251929.01\n",
      "total_trades: 271\n",
      "=================================\n",
      "Episode: 981\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1720          |\n",
      "|    time_elapsed         | 7130          |\n",
      "|    total_timesteps      | 1761280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5801786e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.19e+04      |\n",
      "|    n_updates            | 42420         |\n",
      "|    policy_gradient_loss | -2.25e-05     |\n",
      "|    reward               | -24.049822    |\n",
      "|    value_loss           | 1.84e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1721          |\n",
      "|    time_elapsed         | 7134          |\n",
      "|    total_timesteps      | 1762304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039932405 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.16e+04      |\n",
      "|    n_updates            | 42430         |\n",
      "|    policy_gradient_loss | -0.000426     |\n",
      "|    reward               | -28.734545    |\n",
      "|    value_loss           | 8.33e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1722         |\n",
      "|    time_elapsed         | 7138         |\n",
      "|    total_timesteps      | 1763328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031599533 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.69e+04     |\n",
      "|    n_updates            | 42440        |\n",
      "|    policy_gradient_loss | 0.000455     |\n",
      "|    reward               | -73.357346   |\n",
      "|    value_loss           | 3.39e+04     |\n",
      "------------------------------------------\n",
      "Episode: 982\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 1723        |\n",
      "|    time_elapsed         | 7143        |\n",
      "|    total_timesteps      | 1764352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010980737 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.51e+05    |\n",
      "|    n_updates            | 42450       |\n",
      "|    policy_gradient_loss | 0.00769     |\n",
      "|    reward               | -40.494198  |\n",
      "|    value_loss           | 5.01e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 983\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1724          |\n",
      "|    time_elapsed         | 7147          |\n",
      "|    total_timesteps      | 1765376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095591915 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.06e+04      |\n",
      "|    n_updates            | 42460         |\n",
      "|    policy_gradient_loss | -0.000172     |\n",
      "|    reward               | -4.107169     |\n",
      "|    value_loss           | 1.41e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1725          |\n",
      "|    time_elapsed         | 7151          |\n",
      "|    total_timesteps      | 1766400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.6780306e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.996        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.46e+05      |\n",
      "|    n_updates            | 42470         |\n",
      "|    policy_gradient_loss | 0.000296      |\n",
      "|    reward               | -17.175756    |\n",
      "|    value_loss           | 4.92e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1726          |\n",
      "|    time_elapsed         | 7155          |\n",
      "|    total_timesteps      | 1767424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.1940012e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.994        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.44e+04      |\n",
      "|    n_updates            | 42480         |\n",
      "|    policy_gradient_loss | -3.62e-05     |\n",
      "|    reward               | -10.265141    |\n",
      "|    value_loss           | 6.89e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 984\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2399782.80\n",
      "total_reward: 1399782.80\n",
      "total_cost: 1278244.91\n",
      "total_trades: 943\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1727          |\n",
      "|    time_elapsed         | 7159          |\n",
      "|    total_timesteps      | 1768448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063919177 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+04      |\n",
      "|    n_updates            | 42490         |\n",
      "|    policy_gradient_loss | -0.000842     |\n",
      "|    reward               | -40.070923    |\n",
      "|    value_loss           | 2.87e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 985\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 1728        |\n",
      "|    time_elapsed         | 7163        |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002400918 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.05e+05    |\n",
      "|    n_updates            | 42500       |\n",
      "|    policy_gradient_loss | -0.000251   |\n",
      "|    reward               | -2.4928012  |\n",
      "|    value_loss           | 2.1e+05     |\n",
      "-----------------------------------------\n",
      "Episode: 986\n",
      "Episode: 987\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1729         |\n",
      "|    time_elapsed         | 7167         |\n",
      "|    total_timesteps      | 1770496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019031458 |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.99        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.5e+05      |\n",
      "|    n_updates            | 42510        |\n",
      "|    policy_gradient_loss | -8.49e-05    |\n",
      "|    reward               | -5.6163006   |\n",
      "|    value_loss           | 3e+05        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1730          |\n",
      "|    time_elapsed         | 7171          |\n",
      "|    total_timesteps      | 1771520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023178052 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.998        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.68e+05      |\n",
      "|    n_updates            | 42520         |\n",
      "|    policy_gradient_loss | -0.000586     |\n",
      "|    reward               | -34.08097     |\n",
      "|    value_loss           | 3.36e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1731          |\n",
      "|    time_elapsed         | 7175          |\n",
      "|    total_timesteps      | 1772544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1426643e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1            |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.06e+04      |\n",
      "|    n_updates            | 42530         |\n",
      "|    policy_gradient_loss | -0.000189     |\n",
      "|    reward               | -92.99724     |\n",
      "|    value_loss           | 4.2e+04       |\n",
      "-------------------------------------------\n",
      "Episode: 988\n",
      "Current company: ['KO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 877129.16\n",
      "total_reward: -122870.84\n",
      "total_cost: 877266.96\n",
      "total_trades: 867\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1732         |\n",
      "|    time_elapsed         | 7179         |\n",
      "|    total_timesteps      | 1773568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.378305e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.79e+05     |\n",
      "|    n_updates            | 42540        |\n",
      "|    policy_gradient_loss | -3.84e-06    |\n",
      "|    reward               | 53.019485    |\n",
      "|    value_loss           | 9.59e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1733         |\n",
      "|    time_elapsed         | 7183         |\n",
      "|    total_timesteps      | 1774592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.781061e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.00723      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.76e+05     |\n",
      "|    n_updates            | 42550        |\n",
      "|    policy_gradient_loss | -4.26e-05    |\n",
      "|    reward               | 123.94151    |\n",
      "|    value_loss           | 1.35e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1734          |\n",
      "|    time_elapsed         | 7187          |\n",
      "|    total_timesteps      | 1775616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3300527e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.62          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.05e+06      |\n",
      "|    n_updates            | 42560         |\n",
      "|    policy_gradient_loss | -3.04e-06     |\n",
      "|    reward               | 121.36384     |\n",
      "|    value_loss           | 2.14e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 989\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1735          |\n",
      "|    time_elapsed         | 7191          |\n",
      "|    total_timesteps      | 1776640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2258762e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | -0.0923       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+06      |\n",
      "|    n_updates            | 42570         |\n",
      "|    policy_gradient_loss | -7.19e-06     |\n",
      "|    reward               | -16.722397    |\n",
      "|    value_loss           | 3.29e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1736          |\n",
      "|    time_elapsed         | 7195          |\n",
      "|    total_timesteps      | 1777664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8498547e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0.74          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.85e+05      |\n",
      "|    n_updates            | 42580         |\n",
      "|    policy_gradient_loss | -3.31e-05     |\n",
      "|    reward               | -74.6276      |\n",
      "|    value_loss           | 1.18e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 990\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1737         |\n",
      "|    time_elapsed         | 7199         |\n",
      "|    total_timesteps      | 1778688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.140187e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.31e+05     |\n",
      "|    n_updates            | 42590        |\n",
      "|    policy_gradient_loss | -5.43e-05    |\n",
      "|    reward               | 26.111958    |\n",
      "|    value_loss           | 4.62e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1738          |\n",
      "|    time_elapsed         | 7203          |\n",
      "|    total_timesteps      | 1779712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1830201e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0.0736        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.94e+05      |\n",
      "|    n_updates            | 42600         |\n",
      "|    policy_gradient_loss | 1.45e-05      |\n",
      "|    reward               | 209.76862     |\n",
      "|    value_loss           | 1.4e+06       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1739         |\n",
      "|    time_elapsed         | 7207         |\n",
      "|    total_timesteps      | 1780736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.338814e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.11e+06     |\n",
      "|    n_updates            | 42610        |\n",
      "|    policy_gradient_loss | 7.63e-07     |\n",
      "|    reward               | 135.46391    |\n",
      "|    value_loss           | 6.25e+06     |\n",
      "------------------------------------------\n",
      "Episode: 991\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1740          |\n",
      "|    time_elapsed         | 7211          |\n",
      "|    total_timesteps      | 1781760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6298145e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 0.0323        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.69e+06      |\n",
      "|    n_updates            | 42620         |\n",
      "|    policy_gradient_loss | -6.08e-08     |\n",
      "|    reward               | -2.5078926    |\n",
      "|    value_loss           | 5.4e+06       |\n",
      "-------------------------------------------\n",
      "Episode: 992\n",
      "Current company: ['CVX']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699891.82\n",
      "total_reward: -300108.18\n",
      "total_cost: 378874.28\n",
      "total_trades: 407\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1741          |\n",
      "|    time_elapsed         | 7215          |\n",
      "|    total_timesteps      | 1782784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4680048e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0.705         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.6e+06       |\n",
      "|    n_updates            | 42630         |\n",
      "|    policy_gradient_loss | -3.92e-06     |\n",
      "|    reward               | -7.5265546    |\n",
      "|    value_loss           | 3.24e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 7219         |\n",
      "|    total_timesteps      | 1783808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.015572e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44e+05     |\n",
      "|    n_updates            | 42640        |\n",
      "|    policy_gradient_loss | -6.7e-05     |\n",
      "|    reward               | -63.52692    |\n",
      "|    value_loss           | 2.89e+05     |\n",
      "------------------------------------------\n",
      "Episode: 993\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1743          |\n",
      "|    time_elapsed         | 7223          |\n",
      "|    total_timesteps      | 1784832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2315868e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.83e+04      |\n",
      "|    n_updates            | 42650         |\n",
      "|    policy_gradient_loss | -7.77e-05     |\n",
      "|    reward               | -31.643942    |\n",
      "|    value_loss           | 1.78e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 994\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1744          |\n",
      "|    time_elapsed         | 7227          |\n",
      "|    total_timesteps      | 1785856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2881024e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.68e+04      |\n",
      "|    n_updates            | 42660         |\n",
      "|    policy_gradient_loss | -0.000136     |\n",
      "|    reward               | -6.817903     |\n",
      "|    value_loss           | 1.76e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 7231         |\n",
      "|    total_timesteps      | 1786880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.016428e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84e+05     |\n",
      "|    n_updates            | 42670        |\n",
      "|    policy_gradient_loss | -2.47e-05    |\n",
      "|    reward               | -65.18841    |\n",
      "|    value_loss           | 3.69e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1746          |\n",
      "|    time_elapsed         | 7235          |\n",
      "|    total_timesteps      | 1787904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9729563e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.64e+04      |\n",
      "|    n_updates            | 42680         |\n",
      "|    policy_gradient_loss | -1.51e-05     |\n",
      "|    reward               | -70.28637     |\n",
      "|    value_loss           | 1.33e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 995\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 7240         |\n",
      "|    total_timesteps      | 1788928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.272938e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.37e+05     |\n",
      "|    n_updates            | 42690        |\n",
      "|    policy_gradient_loss | -2.77e-05    |\n",
      "|    reward               | -32.98851    |\n",
      "|    value_loss           | 1.27e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1748          |\n",
      "|    time_elapsed         | 7244          |\n",
      "|    total_timesteps      | 1789952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9397197e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.55e+05      |\n",
      "|    n_updates            | 42700         |\n",
      "|    policy_gradient_loss | -2.38e-05     |\n",
      "|    reward               | -69.47722     |\n",
      "|    value_loss           | 3.11e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 996\n",
      "Current company: ['JNJ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 969853.67\n",
      "total_reward: -30146.33\n",
      "total_cost: 765036.25\n",
      "total_trades: 820\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1749         |\n",
      "|    time_elapsed         | 7247         |\n",
      "|    total_timesteps      | 1790976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.458745e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.8e+05      |\n",
      "|    n_updates            | 42710        |\n",
      "|    policy_gradient_loss | -8.71e-06    |\n",
      "|    reward               | -7.058382    |\n",
      "|    value_loss           | 5.61e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 7251        |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.68806e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13e+05    |\n",
      "|    n_updates            | 42720       |\n",
      "|    policy_gradient_loss | 1.16e-05    |\n",
      "|    reward               | -32.981594  |\n",
      "|    value_loss           | 1.43e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1751          |\n",
      "|    time_elapsed         | 7255          |\n",
      "|    total_timesteps      | 1793024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3694163e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.17e+04      |\n",
      "|    n_updates            | 42730         |\n",
      "|    policy_gradient_loss | -0.000165     |\n",
      "|    reward               | -60.037685    |\n",
      "|    value_loss           | 2.38e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 997\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1752          |\n",
      "|    time_elapsed         | 7259          |\n",
      "|    total_timesteps      | 1794048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8229977e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.66e+05      |\n",
      "|    n_updates            | 42740         |\n",
      "|    policy_gradient_loss | 2.87e-05      |\n",
      "|    reward               | -11.90778     |\n",
      "|    value_loss           | 3.34e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 998\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1753          |\n",
      "|    time_elapsed         | 7263          |\n",
      "|    total_timesteps      | 1795072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1571683e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.1e+05       |\n",
      "|    n_updates            | 42750         |\n",
      "|    policy_gradient_loss | 2.93e-05      |\n",
      "|    reward               | -6.544949     |\n",
      "|    value_loss           | 2.2e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 999\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1754         |\n",
      "|    time_elapsed         | 7268         |\n",
      "|    total_timesteps      | 1796096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.276494e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.93e+04     |\n",
      "|    n_updates            | 42760        |\n",
      "|    policy_gradient_loss | -1.46e-05    |\n",
      "|    reward               | -13.556496   |\n",
      "|    value_loss           | 1.39e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1755          |\n",
      "|    time_elapsed         | 7271          |\n",
      "|    total_timesteps      | 1797120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5506825e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.86e+04      |\n",
      "|    n_updates            | 42770         |\n",
      "|    policy_gradient_loss | -4.27e-05     |\n",
      "|    reward               | 8.654483      |\n",
      "|    value_loss           | 1.77e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1756          |\n",
      "|    time_elapsed         | 7275          |\n",
      "|    total_timesteps      | 1798144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010701793 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.02         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.54e+04      |\n",
      "|    n_updates            | 42780         |\n",
      "|    policy_gradient_loss | -0.000219     |\n",
      "|    reward               | -52.8487      |\n",
      "|    value_loss           | 9.08e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1000\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1190652.35\n",
      "total_reward: 190652.35\n",
      "total_cost: 1160637.86\n",
      "total_trades: 884\n",
      "=================================\n",
      "Episode: 1001\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1757         |\n",
      "|    time_elapsed         | 7280         |\n",
      "|    total_timesteps      | 1799168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.003786e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.92e+04     |\n",
      "|    n_updates            | 42790        |\n",
      "|    policy_gradient_loss | -8.18e-05    |\n",
      "|    reward               | -13.309092   |\n",
      "|    value_loss           | 9.85e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1758          |\n",
      "|    time_elapsed         | 7284          |\n",
      "|    total_timesteps      | 1800192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012478483 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.13e+05      |\n",
      "|    n_updates            | 42800         |\n",
      "|    policy_gradient_loss | -7.33e-05     |\n",
      "|    reward               | 14.795153     |\n",
      "|    value_loss           | 2.26e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1759          |\n",
      "|    time_elapsed         | 7288          |\n",
      "|    total_timesteps      | 1801216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022130646 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.03         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.69e+04      |\n",
      "|    n_updates            | 42810         |\n",
      "|    policy_gradient_loss | -0.000289     |\n",
      "|    reward               | -81.969124    |\n",
      "|    value_loss           | 5.38e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1002\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1760         |\n",
      "|    time_elapsed         | 7292         |\n",
      "|    total_timesteps      | 1802240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.814656e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.98e+04     |\n",
      "|    n_updates            | 42820        |\n",
      "|    policy_gradient_loss | 0.000178     |\n",
      "|    reward               | -24.351473   |\n",
      "|    value_loss           | 1.8e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1761         |\n",
      "|    time_elapsed         | 7296         |\n",
      "|    total_timesteps      | 1803264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.940355e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.56e+05     |\n",
      "|    n_updates            | 42830        |\n",
      "|    policy_gradient_loss | -1.28e-05    |\n",
      "|    reward               | -33.786404   |\n",
      "|    value_loss           | 3.13e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 7300        |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.87443e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.77e+04    |\n",
      "|    n_updates            | 42840       |\n",
      "|    policy_gradient_loss | -0.000224   |\n",
      "|    reward               | -73.22385   |\n",
      "|    value_loss           | 5.55e+04    |\n",
      "-----------------------------------------\n",
      "Episode: 1003\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1763         |\n",
      "|    time_elapsed         | 7305         |\n",
      "|    total_timesteps      | 1805312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.108182e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.36e+05     |\n",
      "|    n_updates            | 42850        |\n",
      "|    policy_gradient_loss | 0.000203     |\n",
      "|    reward               | 13.431365    |\n",
      "|    value_loss           | 8.73e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1764          |\n",
      "|    time_elapsed         | 7309          |\n",
      "|    total_timesteps      | 1806336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6582275e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.47e+04      |\n",
      "|    n_updates            | 42860         |\n",
      "|    policy_gradient_loss | -0.000233     |\n",
      "|    reward               | 74.01238      |\n",
      "|    value_loss           | 1.69e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1004\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2209831.28\n",
      "total_reward: 1209831.28\n",
      "total_cost: 1673837.30\n",
      "total_trades: 939\n",
      "=================================\n",
      "Episode: 1005\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1765          |\n",
      "|    time_elapsed         | 7313          |\n",
      "|    total_timesteps      | 1807360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2293534e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.15e+05      |\n",
      "|    n_updates            | 42870         |\n",
      "|    policy_gradient_loss | 0.00013       |\n",
      "|    reward               | -5.507011     |\n",
      "|    value_loss           | 4.3e+05       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1766          |\n",
      "|    time_elapsed         | 7317          |\n",
      "|    total_timesteps      | 1808384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5081757e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.2e+06       |\n",
      "|    n_updates            | 42880         |\n",
      "|    policy_gradient_loss | -8.04e-05     |\n",
      "|    reward               | -12.423358    |\n",
      "|    value_loss           | 2.39e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1767          |\n",
      "|    time_elapsed         | 7321          |\n",
      "|    total_timesteps      | 1809408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4577527e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.12e+04      |\n",
      "|    n_updates            | 42890         |\n",
      "|    policy_gradient_loss | -1.27e-05     |\n",
      "|    reward               | -52.98855     |\n",
      "|    value_loss           | 1.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1006\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1768          |\n",
      "|    time_elapsed         | 7325          |\n",
      "|    total_timesteps      | 1810432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7016428e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.55e+04      |\n",
      "|    n_updates            | 42900         |\n",
      "|    policy_gradient_loss | -9.5e-06      |\n",
      "|    reward               | -16.706615    |\n",
      "|    value_loss           | 1.71e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1769          |\n",
      "|    time_elapsed         | 7329          |\n",
      "|    total_timesteps      | 1811456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6111957e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.06e+05      |\n",
      "|    n_updates            | 42910         |\n",
      "|    policy_gradient_loss | 1.54e-05      |\n",
      "|    reward               | -73.05923     |\n",
      "|    value_loss           | 4.11e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1770          |\n",
      "|    time_elapsed         | 7333          |\n",
      "|    total_timesteps      | 1812480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0879012e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.67e+05      |\n",
      "|    n_updates            | 42920         |\n",
      "|    policy_gradient_loss | -1.11e-05     |\n",
      "|    reward               | -87.976555    |\n",
      "|    value_loss           | 3.34e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1007\n",
      "Episode: 1008\n",
      "Current company: ['INTC']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698032.81\n",
      "total_reward: -301967.19\n",
      "total_cost: 232062.43\n",
      "total_trades: 263\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1771          |\n",
      "|    time_elapsed         | 7338          |\n",
      "|    total_timesteps      | 1813504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0291343e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.18e+05      |\n",
      "|    n_updates            | 42930         |\n",
      "|    policy_gradient_loss | -4.38e-06     |\n",
      "|    reward               | 5.7241626     |\n",
      "|    value_loss           | 1.04e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1772         |\n",
      "|    time_elapsed         | 7342         |\n",
      "|    total_timesteps      | 1814528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.794487e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.14e+05     |\n",
      "|    n_updates            | 42940        |\n",
      "|    policy_gradient_loss | -9.48e-05    |\n",
      "|    reward               | 46.207375    |\n",
      "|    value_loss           | 4.29e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1773         |\n",
      "|    time_elapsed         | 7346         |\n",
      "|    total_timesteps      | 1815552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.712682e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.78e+05     |\n",
      "|    n_updates            | 42950        |\n",
      "|    policy_gradient_loss | 9.12e-06     |\n",
      "|    reward               | -8.179605    |\n",
      "|    value_loss           | 7.57e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1009\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1774          |\n",
      "|    time_elapsed         | 7350          |\n",
      "|    total_timesteps      | 1816576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5442569e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.45e+05      |\n",
      "|    n_updates            | 42960         |\n",
      "|    policy_gradient_loss | -3.44e-05     |\n",
      "|    reward               | -27.641792    |\n",
      "|    value_loss           | 2.9e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1010\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1775        |\n",
      "|    time_elapsed         | 7354        |\n",
      "|    total_timesteps      | 1817600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.23152e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.12e+04    |\n",
      "|    n_updates            | 42970       |\n",
      "|    policy_gradient_loss | -0.000188   |\n",
      "|    reward               | 0.79248625  |\n",
      "|    value_loss           | 6.24e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1776          |\n",
      "|    time_elapsed         | 7358          |\n",
      "|    total_timesteps      | 1818624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011076353 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.71e+05      |\n",
      "|    n_updates            | 42980         |\n",
      "|    policy_gradient_loss | 9.45e-05      |\n",
      "|    reward               | -13.70569     |\n",
      "|    value_loss           | 3.41e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1777         |\n",
      "|    time_elapsed         | 7362         |\n",
      "|    total_timesteps      | 1819648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032383623 |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.16e+03     |\n",
      "|    n_updates            | 42990        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | -65.152756   |\n",
      "|    value_loss           | 4.32e+03     |\n",
      "------------------------------------------\n",
      "Episode: 1011\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1778         |\n",
      "|    time_elapsed         | 7366         |\n",
      "|    total_timesteps      | 1820672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046235514 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.11e+05     |\n",
      "|    n_updates            | 43000        |\n",
      "|    policy_gradient_loss | 0.00439      |\n",
      "|    reward               | -10.910033   |\n",
      "|    value_loss           | 2.23e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1779          |\n",
      "|    time_elapsed         | 7370          |\n",
      "|    total_timesteps      | 1821696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046936615 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.69e+05      |\n",
      "|    n_updates            | 43010         |\n",
      "|    policy_gradient_loss | 0.000215      |\n",
      "|    reward               | -70.6224      |\n",
      "|    value_loss           | 7.39e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1012\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 683410.40\n",
      "total_reward: -316589.60\n",
      "total_cost: 447389.44\n",
      "total_trades: 489\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1780          |\n",
      "|    time_elapsed         | 7375          |\n",
      "|    total_timesteps      | 1822720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3599866e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.25e+05      |\n",
      "|    n_updates            | 43020         |\n",
      "|    policy_gradient_loss | 0.000172      |\n",
      "|    reward               | -39.391052    |\n",
      "|    value_loss           | 2.5e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1781         |\n",
      "|    time_elapsed         | 7378         |\n",
      "|    total_timesteps      | 1823744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.611929e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.42e+04     |\n",
      "|    n_updates            | 43030        |\n",
      "|    policy_gradient_loss | -0.000246    |\n",
      "|    reward               | -90.473465   |\n",
      "|    value_loss           | 1.29e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1013\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1782          |\n",
      "|    time_elapsed         | 7383          |\n",
      "|    total_timesteps      | 1824768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8413022e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.23e+05      |\n",
      "|    n_updates            | 43040         |\n",
      "|    policy_gradient_loss | -0.000244     |\n",
      "|    reward               | -10.881855    |\n",
      "|    value_loss           | 1.05e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1783         |\n",
      "|    time_elapsed         | 7387         |\n",
      "|    total_timesteps      | 1825792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.580462e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.98e+05     |\n",
      "|    n_updates            | 43050        |\n",
      "|    policy_gradient_loss | 6.3e-05      |\n",
      "|    reward               | -39.489006   |\n",
      "|    value_loss           | 1.6e+06      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1784         |\n",
      "|    time_elapsed         | 7391         |\n",
      "|    total_timesteps      | 1826816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.758069e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.46e+04     |\n",
      "|    n_updates            | 43060        |\n",
      "|    policy_gradient_loss | -5.42e-05    |\n",
      "|    reward               | -47.79011    |\n",
      "|    value_loss           | 8.93e+04     |\n",
      "------------------------------------------\n",
      "Episode: 1014\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1785         |\n",
      "|    time_elapsed         | 7395         |\n",
      "|    total_timesteps      | 1827840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.483134e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.6e+05      |\n",
      "|    n_updates            | 43070        |\n",
      "|    policy_gradient_loss | -4.85e-05    |\n",
      "|    reward               | 8.253218     |\n",
      "|    value_loss           | 3.23e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1786          |\n",
      "|    time_elapsed         | 7399          |\n",
      "|    total_timesteps      | 1828864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9484025e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8e+04         |\n",
      "|    n_updates            | 43080         |\n",
      "|    policy_gradient_loss | -8.83e-05     |\n",
      "|    reward               | -11.560171    |\n",
      "|    value_loss           | 1.6e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1015\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1787          |\n",
      "|    time_elapsed         | 7403          |\n",
      "|    total_timesteps      | 1829888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8491504e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.58e+05      |\n",
      "|    n_updates            | 43090         |\n",
      "|    policy_gradient_loss | -9.1e-05      |\n",
      "|    reward               | 3.094663      |\n",
      "|    value_loss           | 5.16e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1788          |\n",
      "|    time_elapsed         | 7407          |\n",
      "|    total_timesteps      | 1830912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021571107 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.06         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.41e+04      |\n",
      "|    n_updates            | 43100         |\n",
      "|    policy_gradient_loss | -0.000484     |\n",
      "|    reward               | -17.113754    |\n",
      "|    value_loss           | 6.83e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1789         |\n",
      "|    time_elapsed         | 7411         |\n",
      "|    total_timesteps      | 1831936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053872257 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.44e+03     |\n",
      "|    n_updates            | 43110        |\n",
      "|    policy_gradient_loss | -0.000132    |\n",
      "|    reward               | 65.12513     |\n",
      "|    value_loss           | 1.89e+04     |\n",
      "------------------------------------------\n",
      "Episode: 1016\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2265893.16\n",
      "total_reward: 1265893.16\n",
      "total_cost: 1334321.23\n",
      "total_trades: 915\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 1790        |\n",
      "|    time_elapsed         | 7415        |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012007963 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.2e+04     |\n",
      "|    n_updates            | 43120       |\n",
      "|    policy_gradient_loss | 0.00898     |\n",
      "|    reward               | -25.580994  |\n",
      "|    value_loss           | 1.64e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1791          |\n",
      "|    time_elapsed         | 7419          |\n",
      "|    total_timesteps      | 1833984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077415357 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.6e+05       |\n",
      "|    n_updates            | 43130         |\n",
      "|    policy_gradient_loss | 0.000781      |\n",
      "|    reward               | -51.7966      |\n",
      "|    value_loss           | 5.19e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1017\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1792         |\n",
      "|    time_elapsed         | 7423         |\n",
      "|    total_timesteps      | 1835008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.304634e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12e+05     |\n",
      "|    n_updates            | 43140        |\n",
      "|    policy_gradient_loss | -0.000185    |\n",
      "|    reward               | -7.454545    |\n",
      "|    value_loss           | 2.24e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1793          |\n",
      "|    time_elapsed         | 7427          |\n",
      "|    total_timesteps      | 1836032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6376434e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.08         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.81e+05      |\n",
      "|    n_updates            | 43150         |\n",
      "|    policy_gradient_loss | -7.27e-05     |\n",
      "|    reward               | -27.579353    |\n",
      "|    value_loss           | 5.62e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1794         |\n",
      "|    time_elapsed         | 7431         |\n",
      "|    total_timesteps      | 1837056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022769254 |\n",
      "|    clip_fraction        | 0.0609       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.65e+03     |\n",
      "|    n_updates            | 43160        |\n",
      "|    policy_gradient_loss | 0.000203     |\n",
      "|    reward               | -70.76114    |\n",
      "|    value_loss           | 9.31e+03     |\n",
      "------------------------------------------\n",
      "Episode: 1018\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 1795       |\n",
      "|    time_elapsed         | 7436       |\n",
      "|    total_timesteps      | 1838080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06581497 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.86e+05   |\n",
      "|    n_updates            | 43170      |\n",
      "|    policy_gradient_loss | 0.0292     |\n",
      "|    reward               | -40.37808  |\n",
      "|    value_loss           | 5.73e+05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1796         |\n",
      "|    time_elapsed         | 7440         |\n",
      "|    total_timesteps      | 1839104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042954227 |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.954       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.49e+05     |\n",
      "|    n_updates            | 43180        |\n",
      "|    policy_gradient_loss | 0.00463      |\n",
      "|    reward               | -82.22501    |\n",
      "|    value_loss           | 8.98e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1019\n",
      "Episode: 1020\n",
      "Current company: ['WBA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697256.70\n",
      "total_reward: -302743.30\n",
      "total_cost: 210529.24\n",
      "total_trades: 243\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1797         |\n",
      "|    time_elapsed         | 7445         |\n",
      "|    total_timesteps      | 1840128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004563483 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.925       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.62e+05     |\n",
      "|    n_updates            | 43190        |\n",
      "|    policy_gradient_loss | -0.000505    |\n",
      "|    reward               | 6.0929556    |\n",
      "|    value_loss           | 5.24e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 7449         |\n",
      "|    total_timesteps      | 1841152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.742727e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.915       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.92e+04     |\n",
      "|    n_updates            | 43200        |\n",
      "|    policy_gradient_loss | -9.66e-05    |\n",
      "|    reward               | -41.694733   |\n",
      "|    value_loss           | 7.84e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1799         |\n",
      "|    time_elapsed         | 7454         |\n",
      "|    total_timesteps      | 1842176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.823211e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.911       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.2e+04      |\n",
      "|    n_updates            | 43210        |\n",
      "|    policy_gradient_loss | 9.03e-05     |\n",
      "|    reward               | -79.27408    |\n",
      "|    value_loss           | 1.04e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1021\n",
      "Episode: 1022\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1800         |\n",
      "|    time_elapsed         | 7458         |\n",
      "|    total_timesteps      | 1843200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.319583e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.911       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.05e+05     |\n",
      "|    n_updates            | 43220        |\n",
      "|    policy_gradient_loss | 9.23e-06     |\n",
      "|    reward               | -24.797318   |\n",
      "|    value_loss           | 4.11e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1801          |\n",
      "|    time_elapsed         | 7463          |\n",
      "|    total_timesteps      | 1844224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013739604 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.98e+04      |\n",
      "|    n_updates            | 43230         |\n",
      "|    policy_gradient_loss | -0.000348     |\n",
      "|    reward               | -23.910027    |\n",
      "|    value_loss           | 7.96e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1802          |\n",
      "|    time_elapsed         | 7467          |\n",
      "|    total_timesteps      | 1845248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015080883 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.18e+04      |\n",
      "|    n_updates            | 43240         |\n",
      "|    policy_gradient_loss | 0.00012       |\n",
      "|    reward               | -70.056816    |\n",
      "|    value_loss           | 1.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1023\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 1803         |\n",
      "|    time_elapsed         | 7472         |\n",
      "|    total_timesteps      | 1846272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.716701e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.911       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.28e+05     |\n",
      "|    n_updates            | 43250        |\n",
      "|    policy_gradient_loss | -5.98e-06    |\n",
      "|    reward               | -27.652222   |\n",
      "|    value_loss           | 2.57e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1804          |\n",
      "|    time_elapsed         | 7476          |\n",
      "|    total_timesteps      | 1847296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1823216e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.15e+04      |\n",
      "|    n_updates            | 43260         |\n",
      "|    policy_gradient_loss | -1.51e-06     |\n",
      "|    reward               | -71.87001     |\n",
      "|    value_loss           | 1.24e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1024\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 795850.35\n",
      "total_reward: -204149.65\n",
      "total_cost: 1184169.26\n",
      "total_trades: 1220\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1805          |\n",
      "|    time_elapsed         | 7480          |\n",
      "|    total_timesteps      | 1848320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7468424e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.86e+05      |\n",
      "|    n_updates            | 43270         |\n",
      "|    policy_gradient_loss | -2.5e-05      |\n",
      "|    reward               | 9.525054      |\n",
      "|    value_loss           | 5.74e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1806          |\n",
      "|    time_elapsed         | 7485          |\n",
      "|    total_timesteps      | 1849344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6868656e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.87e+05      |\n",
      "|    n_updates            | 43280         |\n",
      "|    policy_gradient_loss | -1.12e-06     |\n",
      "|    reward               | -30.030016    |\n",
      "|    value_loss           | 1.58e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1807          |\n",
      "|    time_elapsed         | 7489          |\n",
      "|    total_timesteps      | 1850368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6403223e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.89e+04      |\n",
      "|    n_updates            | 43290         |\n",
      "|    policy_gradient_loss | -2.2e-06      |\n",
      "|    reward               | -65.90595     |\n",
      "|    value_loss           | 1.18e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1025\n",
      "Episode: 1026\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1808          |\n",
      "|    time_elapsed         | 7494          |\n",
      "|    total_timesteps      | 1851392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3806933e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.85e+05      |\n",
      "|    n_updates            | 43300         |\n",
      "|    policy_gradient_loss | 5.53e-06      |\n",
      "|    reward               | 7.537635      |\n",
      "|    value_loss           | 3.71e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1809          |\n",
      "|    time_elapsed         | 7498          |\n",
      "|    total_timesteps      | 1852416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5262125e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.61e+05      |\n",
      "|    n_updates            | 43310         |\n",
      "|    policy_gradient_loss | -1.07e-06     |\n",
      "|    reward               | -24.32942     |\n",
      "|    value_loss           | 5.23e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1810          |\n",
      "|    time_elapsed         | 7502          |\n",
      "|    total_timesteps      | 1853440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6144123e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.03e+03      |\n",
      "|    n_updates            | 43320         |\n",
      "|    policy_gradient_loss | -2.32e-05     |\n",
      "|    reward               | -45.249294    |\n",
      "|    value_loss           | 1.81e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1027\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1811          |\n",
      "|    time_elapsed         | 7507          |\n",
      "|    total_timesteps      | 1854464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1106555e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.23e+04      |\n",
      "|    n_updates            | 43330         |\n",
      "|    policy_gradient_loss | -6.01e-05     |\n",
      "|    reward               | -23.377302    |\n",
      "|    value_loss           | 1.05e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1812          |\n",
      "|    time_elapsed         | 7511          |\n",
      "|    total_timesteps      | 1855488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0042644e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.32e+05      |\n",
      "|    n_updates            | 43340         |\n",
      "|    policy_gradient_loss | 3.26e-06      |\n",
      "|    reward               | -63.250603    |\n",
      "|    value_loss           | 2.64e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1028\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 644486.79\n",
      "total_reward: -355513.21\n",
      "total_cost: 970369.89\n",
      "total_trades: 1103\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 247           |\n",
      "|    iterations           | 1813          |\n",
      "|    time_elapsed         | 7516          |\n",
      "|    total_timesteps      | 1856512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1402957e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.72e+05      |\n",
      "|    n_updates            | 43350         |\n",
      "|    policy_gradient_loss | -8.22e-06     |\n",
      "|    reward               | 0.7097619     |\n",
      "|    value_loss           | 3.45e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1814          |\n",
      "|    time_elapsed         | 7520          |\n",
      "|    total_timesteps      | 1857536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2945384e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.45e+05      |\n",
      "|    n_updates            | 43360         |\n",
      "|    policy_gradient_loss | -4.79e-05     |\n",
      "|    reward               | -36.230488    |\n",
      "|    value_loss           | 1.09e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 1029\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1815          |\n",
      "|    time_elapsed         | 7525          |\n",
      "|    total_timesteps      | 1858560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5614863e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.2e+04       |\n",
      "|    n_updates            | 43370         |\n",
      "|    policy_gradient_loss | -4.28e-05     |\n",
      "|    reward               | -35.474564    |\n",
      "|    value_loss           | 1.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1030\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1816          |\n",
      "|    time_elapsed         | 7529          |\n",
      "|    total_timesteps      | 1859584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7400674e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.03e+04      |\n",
      "|    n_updates            | 43380         |\n",
      "|    policy_gradient_loss | -1.99e-05     |\n",
      "|    reward               | -25.266438    |\n",
      "|    value_loss           | 1.61e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1031\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1817          |\n",
      "|    time_elapsed         | 7535          |\n",
      "|    total_timesteps      | 1860608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5634806e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01e+05      |\n",
      "|    n_updates            | 43390         |\n",
      "|    policy_gradient_loss | 3.56e-06      |\n",
      "|    reward               | -1.2400608    |\n",
      "|    value_loss           | 2.03e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1818         |\n",
      "|    time_elapsed         | 7539         |\n",
      "|    total_timesteps      | 1861632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.021552e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.5e+05      |\n",
      "|    n_updates            | 43400        |\n",
      "|    policy_gradient_loss | -6.9e-06     |\n",
      "|    reward               | -37.64822    |\n",
      "|    value_loss           | 3e+05        |\n",
      "------------------------------------------\n",
      "Episode: 1032\n",
      "Current company: ['AXP']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 698424.02\n",
      "total_reward: -301575.98\n",
      "total_cost: 596460.21\n",
      "total_trades: 673\n",
      "=================================\n",
      "Episode: 1033\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1819          |\n",
      "|    time_elapsed         | 7544          |\n",
      "|    total_timesteps      | 1862656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4540426e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9e+04         |\n",
      "|    n_updates            | 43410         |\n",
      "|    policy_gradient_loss | -8.47e-06     |\n",
      "|    reward               | -32.407738    |\n",
      "|    value_loss           | 1.8e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1034\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1820          |\n",
      "|    time_elapsed         | 7548          |\n",
      "|    total_timesteps      | 1863680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7130515e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+05      |\n",
      "|    n_updates            | 43420         |\n",
      "|    policy_gradient_loss | -4.1e-05      |\n",
      "|    reward               | -43.323418    |\n",
      "|    value_loss           | 2.98e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1821         |\n",
      "|    time_elapsed         | 7552         |\n",
      "|    total_timesteps      | 1864704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.249043e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.05e+05     |\n",
      "|    n_updates            | 43430        |\n",
      "|    policy_gradient_loss | -3.59e-05    |\n",
      "|    reward               | -64.70876    |\n",
      "|    value_loss           | 2.1e+05      |\n",
      "------------------------------------------\n",
      "Episode: 1035\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1822         |\n",
      "|    time_elapsed         | 7557         |\n",
      "|    total_timesteps      | 1865728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.912762e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.33e+05     |\n",
      "|    n_updates            | 43440        |\n",
      "|    policy_gradient_loss | 1.65e-05     |\n",
      "|    reward               | 4.9124074    |\n",
      "|    value_loss           | 6.67e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1823          |\n",
      "|    time_elapsed         | 7561          |\n",
      "|    total_timesteps      | 1866752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5553163e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.26e+05      |\n",
      "|    n_updates            | 43450         |\n",
      "|    policy_gradient_loss | 5.04e-06      |\n",
      "|    reward               | 67.676765     |\n",
      "|    value_loss           | 8.53e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1824          |\n",
      "|    time_elapsed         | 7566          |\n",
      "|    total_timesteps      | 1867776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4982804e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.59e+05      |\n",
      "|    n_updates            | 43460         |\n",
      "|    policy_gradient_loss | 9.71e-07      |\n",
      "|    reward               | 87.58319      |\n",
      "|    value_loss           | 9.18e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1036\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1993520.98\n",
      "total_reward: 993520.98\n",
      "total_cost: 2355083.73\n",
      "total_trades: 1265\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1825          |\n",
      "|    time_elapsed         | 7570          |\n",
      "|    total_timesteps      | 1868800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6600901e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.26e+06      |\n",
      "|    n_updates            | 43470         |\n",
      "|    policy_gradient_loss | 1.62e-07      |\n",
      "|    reward               | -32.507446    |\n",
      "|    value_loss           | 2.52e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 1037\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1826          |\n",
      "|    time_elapsed         | 7575          |\n",
      "|    total_timesteps      | 1869824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5553163e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.12e+05      |\n",
      "|    n_updates            | 43480         |\n",
      "|    policy_gradient_loss | -2.59e-06     |\n",
      "|    reward               | -0.9714919    |\n",
      "|    value_loss           | 1.23e+06      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 246            |\n",
      "|    iterations           | 1827           |\n",
      "|    time_elapsed         | 7579           |\n",
      "|    total_timesteps      | 1870848        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.18860044e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.913         |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.39e+05       |\n",
      "|    n_updates            | 43490          |\n",
      "|    policy_gradient_loss | -4.74e-06      |\n",
      "|    reward               | -5.645257      |\n",
      "|    value_loss           | 2.78e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1828          |\n",
      "|    time_elapsed         | 7583          |\n",
      "|    total_timesteps      | 1871872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9988663e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.09e+05      |\n",
      "|    n_updates            | 43500         |\n",
      "|    policy_gradient_loss | 3.22e-06      |\n",
      "|    reward               | -66.20763     |\n",
      "|    value_loss           | 4.18e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1038\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1829          |\n",
      "|    time_elapsed         | 7588          |\n",
      "|    total_timesteps      | 1872896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5401823e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.62e+05      |\n",
      "|    n_updates            | 43510         |\n",
      "|    policy_gradient_loss | -1.27e-05     |\n",
      "|    reward               | 43.90554      |\n",
      "|    value_loss           | 7.23e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1830         |\n",
      "|    time_elapsed         | 7592         |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.778887e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.922       |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.3e+05      |\n",
      "|    n_updates            | 43520        |\n",
      "|    policy_gradient_loss | -3.65e-06    |\n",
      "|    reward               | 17.012625    |\n",
      "|    value_loss           | 1.06e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1831         |\n",
      "|    time_elapsed         | 7595         |\n",
      "|    total_timesteps      | 1874944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.400522e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.125       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.74e+05     |\n",
      "|    n_updates            | 43530        |\n",
      "|    policy_gradient_loss | -4.79e-05    |\n",
      "|    reward               | 154.67337    |\n",
      "|    value_loss           | 3.58e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1039\n",
      "Episode: 1040\n",
      "Current company: ['NKE']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699995.52\n",
      "total_reward: -300004.48\n",
      "total_cost: 137101.92\n",
      "total_trades: 155\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1832         |\n",
      "|    time_elapsed         | 7600         |\n",
      "|    total_timesteps      | 1875968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.881869e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.0935      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.95e+05     |\n",
      "|    n_updates            | 43540        |\n",
      "|    policy_gradient_loss | -5.87e-06    |\n",
      "|    reward               | 6.944804     |\n",
      "|    value_loss           | 1.21e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1833          |\n",
      "|    time_elapsed         | 7604          |\n",
      "|    total_timesteps      | 1876992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4784746e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0.623         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.86e+05      |\n",
      "|    n_updates            | 43550         |\n",
      "|    policy_gradient_loss | -7.68e-06     |\n",
      "|    reward               | -15.180179    |\n",
      "|    value_loss           | 1.58e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 1041\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 246       |\n",
      "|    iterations           | 1834      |\n",
      "|    time_elapsed         | 7609      |\n",
      "|    total_timesteps      | 1878016   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.913    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 8.65e+04  |\n",
      "|    n_updates            | 43560     |\n",
      "|    policy_gradient_loss | -1.24e-06 |\n",
      "|    reward               | -7.108661 |\n",
      "|    value_loss           | 2.12e+05  |\n",
      "---------------------------------------\n",
      "Episode: 1042\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 1835       |\n",
      "|    time_elapsed         | 7613       |\n",
      "|    total_timesteps      | 1879040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.913     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.89e+05   |\n",
      "|    n_updates            | 43570      |\n",
      "|    policy_gradient_loss | 3.82e-07   |\n",
      "|    reward               | -32.170795 |\n",
      "|    value_loss           | 3.91e+05   |\n",
      "----------------------------------------\n",
      "Episode: 1043\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 1836       |\n",
      "|    time_elapsed         | 7618       |\n",
      "|    total_timesteps      | 1880064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.913     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.64e+04   |\n",
      "|    n_updates            | 43580      |\n",
      "|    policy_gradient_loss | 4.79e-08   |\n",
      "|    reward               | -15.457085 |\n",
      "|    value_loss           | 5.5e+04    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1837         |\n",
      "|    time_elapsed         | 7622         |\n",
      "|    total_timesteps      | 1881088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.373739e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.01e+05     |\n",
      "|    n_updates            | 43590        |\n",
      "|    policy_gradient_loss | -3.53e-06    |\n",
      "|    reward               | -58.479614   |\n",
      "|    value_loss           | 2.03e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1044\n",
      "Current company: ['VZ']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696042.86\n",
      "total_reward: -303957.14\n",
      "total_cost: 863540.96\n",
      "total_trades: 881\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 246            |\n",
      "|    iterations           | 1838           |\n",
      "|    time_elapsed         | 7627           |\n",
      "|    total_timesteps      | 1882112        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.10594556e-07 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.913         |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 8.87e+04       |\n",
      "|    n_updates            | 43600          |\n",
      "|    policy_gradient_loss | 1.1e-06        |\n",
      "|    reward               | -4.6013913     |\n",
      "|    value_loss           | 1.78e+05       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1839          |\n",
      "|    time_elapsed         | 7631          |\n",
      "|    total_timesteps      | 1883136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0372757e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75e+05      |\n",
      "|    n_updates            | 43610         |\n",
      "|    policy_gradient_loss | -1.82e-05     |\n",
      "|    reward               | -85.15303     |\n",
      "|    value_loss           | 3.5e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1045\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1840          |\n",
      "|    time_elapsed         | 7636          |\n",
      "|    total_timesteps      | 1884160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9895379e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.35e+05      |\n",
      "|    n_updates            | 43620         |\n",
      "|    policy_gradient_loss | 7.87e-06      |\n",
      "|    reward               | -42.56381     |\n",
      "|    value_loss           | 5.17e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1841         |\n",
      "|    time_elapsed         | 7640         |\n",
      "|    total_timesteps      | 1885184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.213063e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.912       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.75e+04     |\n",
      "|    n_updates            | 43630        |\n",
      "|    policy_gradient_loss | -3.75e-07    |\n",
      "|    reward               | -76.98777    |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1046\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 246       |\n",
      "|    iterations           | 1842      |\n",
      "|    time_elapsed         | 7645      |\n",
      "|    total_timesteps      | 1886208   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.912    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3.92e+05  |\n",
      "|    n_updates            | 43640     |\n",
      "|    policy_gradient_loss | 6.14e-07  |\n",
      "|    reward               | -5.571068 |\n",
      "|    value_loss           | 8.02e+05  |\n",
      "---------------------------------------\n",
      "Episode: 1047\n",
      "Episode: 1048\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 668991.28\n",
      "total_reward: -331008.72\n",
      "total_cost: 58996.86\n",
      "total_trades: 57\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1843          |\n",
      "|    time_elapsed         | 7649          |\n",
      "|    total_timesteps      | 1887232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3748726e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.38e+05      |\n",
      "|    n_updates            | 43650         |\n",
      "|    policy_gradient_loss | -2.25e-06     |\n",
      "|    reward               | -5.721866     |\n",
      "|    value_loss           | 8.88e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1049\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1844          |\n",
      "|    time_elapsed         | 7654          |\n",
      "|    total_timesteps      | 1888256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0512837e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.02e+04      |\n",
      "|    n_updates            | 43660         |\n",
      "|    policy_gradient_loss | -2.94e-05     |\n",
      "|    reward               | -20.50305     |\n",
      "|    value_loss           | 1.62e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1050\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1845         |\n",
      "|    time_elapsed         | 7658         |\n",
      "|    total_timesteps      | 1889280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.264282e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.52e+04     |\n",
      "|    n_updates            | 43670        |\n",
      "|    policy_gradient_loss | -6.23e-05    |\n",
      "|    reward               | 0.42058092   |\n",
      "|    value_loss           | 3.04e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1846          |\n",
      "|    time_elapsed         | 7663          |\n",
      "|    total_timesteps      | 1890304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9251015e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.44e+05      |\n",
      "|    n_updates            | 43680         |\n",
      "|    policy_gradient_loss | -0.000239     |\n",
      "|    reward               | -34.892704    |\n",
      "|    value_loss           | 2.89e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1847          |\n",
      "|    time_elapsed         | 7667          |\n",
      "|    total_timesteps      | 1891328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084645173 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.91         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.44e+04      |\n",
      "|    n_updates            | 43690         |\n",
      "|    policy_gradient_loss | -0.000793     |\n",
      "|    reward               | -88.846214    |\n",
      "|    value_loss           | 4.88e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1051\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1848          |\n",
      "|    time_elapsed         | 7671          |\n",
      "|    total_timesteps      | 1892352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078743626 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.9          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.93e+05      |\n",
      "|    n_updates            | 43700         |\n",
      "|    policy_gradient_loss | 0.00183       |\n",
      "|    reward               | -47.663696    |\n",
      "|    value_loss           | 9.87e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1849         |\n",
      "|    time_elapsed         | 7676         |\n",
      "|    total_timesteps      | 1893376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.526794e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.93e+05     |\n",
      "|    n_updates            | 43710        |\n",
      "|    policy_gradient_loss | 7.4e-05      |\n",
      "|    reward               | -38.95491    |\n",
      "|    value_loss           | 7.87e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1052\n",
      "Current company: ['BA']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 582859.25\n",
      "total_reward: -417140.75\n",
      "total_cost: 1275002.85\n",
      "total_trades: 1101\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1850          |\n",
      "|    time_elapsed         | 7680          |\n",
      "|    total_timesteps      | 1894400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1870579e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.892        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.02e+05      |\n",
      "|    n_updates            | 43720         |\n",
      "|    policy_gradient_loss | -6.64e-05     |\n",
      "|    reward               | -2.0974338    |\n",
      "|    value_loss           | 2.04e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1851          |\n",
      "|    time_elapsed         | 7684          |\n",
      "|    total_timesteps      | 1895424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9380823e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.06e+05      |\n",
      "|    n_updates            | 43730         |\n",
      "|    policy_gradient_loss | -1.59e-06     |\n",
      "|    reward               | -32.14062     |\n",
      "|    value_loss           | 2.21e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1852          |\n",
      "|    time_elapsed         | 7688          |\n",
      "|    total_timesteps      | 1896448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9325324e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.89         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.25e+04      |\n",
      "|    n_updates            | 43740         |\n",
      "|    policy_gradient_loss | 5.86e-06      |\n",
      "|    reward               | -46.53412     |\n",
      "|    value_loss           | 6.83e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1053\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1853          |\n",
      "|    time_elapsed         | 7693          |\n",
      "|    total_timesteps      | 1897472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0494917e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.49e+05      |\n",
      "|    n_updates            | 43750         |\n",
      "|    policy_gradient_loss | -1.26e-05     |\n",
      "|    reward               | -37.681015    |\n",
      "|    value_loss           | 3e+05         |\n",
      "-------------------------------------------\n",
      "Episode: 1054\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1854          |\n",
      "|    time_elapsed         | 7697          |\n",
      "|    total_timesteps      | 1898496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0966323e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.11e+05      |\n",
      "|    n_updates            | 43760         |\n",
      "|    policy_gradient_loss | 1.15e-05      |\n",
      "|    reward               | -4.9128237    |\n",
      "|    value_loss           | 4.26e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1855          |\n",
      "|    time_elapsed         | 7701          |\n",
      "|    total_timesteps      | 1899520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2800017e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.89         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.45e+04      |\n",
      "|    n_updates            | 43770         |\n",
      "|    policy_gradient_loss | -7.62e-05     |\n",
      "|    reward               | -28.412785    |\n",
      "|    value_loss           | 1.3e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1055\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1856          |\n",
      "|    time_elapsed         | 7706          |\n",
      "|    total_timesteps      | 1900544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2270327e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.889        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.16e+04      |\n",
      "|    n_updates            | 43780         |\n",
      "|    policy_gradient_loss | 6.01e-05      |\n",
      "|    reward               | -4.53585      |\n",
      "|    value_loss           | 6.39e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1857          |\n",
      "|    time_elapsed         | 7710          |\n",
      "|    total_timesteps      | 1901568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1471136e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.89         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.46e+05      |\n",
      "|    n_updates            | 43790         |\n",
      "|    policy_gradient_loss | 2.45e-05      |\n",
      "|    reward               | -17.322716    |\n",
      "|    value_loss           | 2.93e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1858          |\n",
      "|    time_elapsed         | 7715          |\n",
      "|    total_timesteps      | 1902592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5659392e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.78e+03      |\n",
      "|    n_updates            | 43800         |\n",
      "|    policy_gradient_loss | -0.000145     |\n",
      "|    reward               | -8.048637     |\n",
      "|    value_loss           | 9.58e+03      |\n",
      "-------------------------------------------\n",
      "Episode: 1056\n",
      "Current company: ['MSFT']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1790946.95\n",
      "total_reward: 790946.95\n",
      "total_cost: 1538635.36\n",
      "total_trades: 1221\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1859          |\n",
      "|    time_elapsed         | 7719          |\n",
      "|    total_timesteps      | 1903616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2256205e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.94e+04      |\n",
      "|    n_updates            | 43810         |\n",
      "|    policy_gradient_loss | 0.000185      |\n",
      "|    reward               | -26.775734    |\n",
      "|    value_loss           | 9.88e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1860          |\n",
      "|    time_elapsed         | 7723          |\n",
      "|    total_timesteps      | 1904640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0594403e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.34e+04      |\n",
      "|    n_updates            | 43820         |\n",
      "|    policy_gradient_loss | -2.06e-05     |\n",
      "|    reward               | -90.79099     |\n",
      "|    value_loss           | 4.69e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1057\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1861         |\n",
      "|    time_elapsed         | 7728         |\n",
      "|    total_timesteps      | 1905664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.528579e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.92e+05     |\n",
      "|    n_updates            | 43830        |\n",
      "|    policy_gradient_loss | -1.92e-05    |\n",
      "|    reward               | 1.0612624    |\n",
      "|    value_loss           | 7.83e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1862         |\n",
      "|    time_elapsed         | 7732         |\n",
      "|    total_timesteps      | 1906688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.258495e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.982       |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.58e+05     |\n",
      "|    n_updates            | 43840        |\n",
      "|    policy_gradient_loss | 1.23e-05     |\n",
      "|    reward               | -29.019186   |\n",
      "|    value_loss           | 5.42e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1058\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1863          |\n",
      "|    time_elapsed         | 7736          |\n",
      "|    total_timesteps      | 1907712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3823737e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.896        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.33e+04      |\n",
      "|    n_updates            | 43850         |\n",
      "|    policy_gradient_loss | -1.37e-05     |\n",
      "|    reward               | -26.00996     |\n",
      "|    value_loss           | 8.65e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 1864        |\n",
      "|    time_elapsed         | 7741        |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.89223e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.76e+04    |\n",
      "|    n_updates            | 43860       |\n",
      "|    policy_gradient_loss | -4.23e-05   |\n",
      "|    reward               | -44.336918  |\n",
      "|    value_loss           | 1.35e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1865          |\n",
      "|    time_elapsed         | 7746          |\n",
      "|    total_timesteps      | 1909760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7042926e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.68e+04      |\n",
      "|    n_updates            | 43870         |\n",
      "|    policy_gradient_loss | -6.5e-05      |\n",
      "|    reward               | 76.52762      |\n",
      "|    value_loss           | 7.38e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1059\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1866          |\n",
      "|    time_elapsed         | 7750          |\n",
      "|    total_timesteps      | 1910784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0199299e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.1e+04       |\n",
      "|    n_updates            | 43880         |\n",
      "|    policy_gradient_loss | -0.000178     |\n",
      "|    reward               | -34.765823    |\n",
      "|    value_loss           | 1.82e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1060\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697123.66\n",
      "total_reward: -302876.34\n",
      "total_cost: 704533.64\n",
      "total_trades: 733\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1867          |\n",
      "|    time_elapsed         | 7755          |\n",
      "|    total_timesteps      | 1911808       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6118865e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.24e+05      |\n",
      "|    n_updates            | 43890         |\n",
      "|    policy_gradient_loss | 7.97e-06      |\n",
      "|    reward               | -8.399521     |\n",
      "|    value_loss           | 2.47e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1868         |\n",
      "|    time_elapsed         | 7759         |\n",
      "|    total_timesteps      | 1912832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.856855e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.89        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.67e+05     |\n",
      "|    n_updates            | 43900        |\n",
      "|    policy_gradient_loss | 1.04e-05     |\n",
      "|    reward               | -57.191734   |\n",
      "|    value_loss           | 3.34e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1061\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1869          |\n",
      "|    time_elapsed         | 7763          |\n",
      "|    total_timesteps      | 1913856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2515887e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.89         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.51e+04      |\n",
      "|    n_updates            | 43910         |\n",
      "|    policy_gradient_loss | -5.08e-05     |\n",
      "|    reward               | -2.2075775    |\n",
      "|    value_loss           | 1.3e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1062\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1870         |\n",
      "|    time_elapsed         | 7768         |\n",
      "|    total_timesteps      | 1914880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.982859e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.79e+05     |\n",
      "|    n_updates            | 43920        |\n",
      "|    policy_gradient_loss | -8.22e-05    |\n",
      "|    reward               | -5.281842    |\n",
      "|    value_loss           | 1.36e+06     |\n",
      "------------------------------------------\n",
      "Episode: 1063\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1871          |\n",
      "|    time_elapsed         | 7772          |\n",
      "|    total_timesteps      | 1915904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2641692e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.889        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.28e+04      |\n",
      "|    n_updates            | 43930         |\n",
      "|    policy_gradient_loss | -5.4e-05      |\n",
      "|    reward               | -22.580284    |\n",
      "|    value_loss           | 4.57e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1872         |\n",
      "|    time_elapsed         | 7777         |\n",
      "|    total_timesteps      | 1916928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.014388e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.891       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.27e+04     |\n",
      "|    n_updates            | 43940        |\n",
      "|    policy_gradient_loss | -2.15e-05    |\n",
      "|    reward               | -54.264828   |\n",
      "|    value_loss           | 2.53e+04     |\n",
      "------------------------------------------\n",
      "Episode: 1064\n",
      "Current company: ['MCD']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 865691.05\n",
      "total_reward: -134308.95\n",
      "total_cost: 1266158.66\n",
      "total_trades: 1210\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1873         |\n",
      "|    time_elapsed         | 7781         |\n",
      "|    total_timesteps      | 1917952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.747498e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.893       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.99e+05     |\n",
      "|    n_updates            | 43950        |\n",
      "|    policy_gradient_loss | 9.46e-07     |\n",
      "|    reward               | -17.848886   |\n",
      "|    value_loss           | 3.98e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1065\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1874          |\n",
      "|    time_elapsed         | 7786          |\n",
      "|    total_timesteps      | 1918976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0617534e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.38e+05      |\n",
      "|    n_updates            | 43960         |\n",
      "|    policy_gradient_loss | 1.82e-05      |\n",
      "|    reward               | -44.947136    |\n",
      "|    value_loss           | 1.08e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1875          |\n",
      "|    time_elapsed         | 7790          |\n",
      "|    total_timesteps      | 1920000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4823897e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.894        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.13e+04      |\n",
      "|    n_updates            | 43970         |\n",
      "|    policy_gradient_loss | -3.74e-05     |\n",
      "|    reward               | -94.004555    |\n",
      "|    value_loss           | 8.33e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1066\n",
      "Episode: 1067\n",
      "Episode: 1068\n",
      "Current company: ['HON']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 686026.63\n",
      "total_reward: -313973.37\n",
      "total_cost: 161586.60\n",
      "total_trades: 165\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1876          |\n",
      "|    time_elapsed         | 7795          |\n",
      "|    total_timesteps      | 1921024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0116568e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.04e+05      |\n",
      "|    n_updates            | 43980         |\n",
      "|    policy_gradient_loss | 6.1e-06       |\n",
      "|    reward               | -1.0212768    |\n",
      "|    value_loss           | 8.18e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1877          |\n",
      "|    time_elapsed         | 7799          |\n",
      "|    total_timesteps      | 1922048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8417056e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.45e+05      |\n",
      "|    n_updates            | 43990         |\n",
      "|    policy_gradient_loss | 1.36e-06      |\n",
      "|    reward               | -47.568264    |\n",
      "|    value_loss           | 4.93e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1878         |\n",
      "|    time_elapsed         | 7803         |\n",
      "|    total_timesteps      | 1923072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.376844e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.895       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.88e+04     |\n",
      "|    n_updates            | 44000        |\n",
      "|    policy_gradient_loss | -2.76e-05    |\n",
      "|    reward               | -83.291275   |\n",
      "|    value_loss           | 7.79e+04     |\n",
      "------------------------------------------\n",
      "Episode: 1069\n",
      "Episode: 1070\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 7808         |\n",
      "|    total_timesteps      | 1924096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.373759e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.87e+05     |\n",
      "|    n_updates            | 44010        |\n",
      "|    policy_gradient_loss | 3.93e-06     |\n",
      "|    reward               | 25.074923    |\n",
      "|    value_loss           | 9.74e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1880          |\n",
      "|    time_elapsed         | 7812          |\n",
      "|    total_timesteps      | 1925120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8550782e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | 0.0164        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.89e+05      |\n",
      "|    n_updates            | 44020         |\n",
      "|    policy_gradient_loss | -8.87e-06     |\n",
      "|    reward               | 47.02472      |\n",
      "|    value_loss           | 1.18e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1881          |\n",
      "|    time_elapsed         | 7816          |\n",
      "|    total_timesteps      | 1926144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8848223e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.01         |\n",
      "|    explained_variance   | 0.924         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 44030         |\n",
      "|    policy_gradient_loss | -6.61e-05     |\n",
      "|    reward               | 67.18156      |\n",
      "|    value_loss           | 2.48e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1071\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1882          |\n",
      "|    time_elapsed         | 7820          |\n",
      "|    total_timesteps      | 1927168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1897722e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | -0.231        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.03e+04      |\n",
      "|    n_updates            | 44040         |\n",
      "|    policy_gradient_loss | 4.9e-07       |\n",
      "|    reward               | -38.279686    |\n",
      "|    value_loss           | 1.87e+05      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 1883       |\n",
      "|    time_elapsed         | 7824       |\n",
      "|    total_timesteps      | 1928192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 4.2998e-07 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.991     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.46e+05   |\n",
      "|    n_updates            | 44050      |\n",
      "|    policy_gradient_loss | 1.03e-05   |\n",
      "|    reward               | -67.35621  |\n",
      "|    value_loss           | 1.5e+06    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1884         |\n",
      "|    time_elapsed         | 7829         |\n",
      "|    total_timesteps      | 1929216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.146729e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.893       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.56e+05     |\n",
      "|    n_updates            | 44060        |\n",
      "|    policy_gradient_loss | -7.27e-06    |\n",
      "|    reward               | -106.58607   |\n",
      "|    value_loss           | 3.13e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1072\n",
      "Current company: ['MRK']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 930486.53\n",
      "total_reward: -69513.47\n",
      "total_cost: 1140752.75\n",
      "total_trades: 1214\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1885          |\n",
      "|    time_elapsed         | 7833          |\n",
      "|    total_timesteps      | 1930240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0419324e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.7e+05       |\n",
      "|    n_updates            | 44070         |\n",
      "|    policy_gradient_loss | -2.45e-05     |\n",
      "|    reward               | -49.52075     |\n",
      "|    value_loss           | 1.54e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1886          |\n",
      "|    time_elapsed         | 7838          |\n",
      "|    total_timesteps      | 1931264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8347207e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.64e+05      |\n",
      "|    n_updates            | 44080         |\n",
      "|    policy_gradient_loss | -7.27e-06     |\n",
      "|    reward               | -78.16364     |\n",
      "|    value_loss           | 7.3e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1073\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1887          |\n",
      "|    time_elapsed         | 7842          |\n",
      "|    total_timesteps      | 1932288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3120007e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.44e+05      |\n",
      "|    n_updates            | 44090         |\n",
      "|    policy_gradient_loss | 4.07e-07      |\n",
      "|    reward               | -29.070677    |\n",
      "|    value_loss           | 4.91e+05      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 246       |\n",
      "|    iterations           | 1888      |\n",
      "|    time_elapsed         | 7846      |\n",
      "|    total_timesteps      | 1933312   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.893    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 5.06e+05  |\n",
      "|    n_updates            | 44100     |\n",
      "|    policy_gradient_loss | -3.02e-07 |\n",
      "|    reward               | -67.18647 |\n",
      "|    value_loss           | 1.01e+06  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1889          |\n",
      "|    time_elapsed         | 7851          |\n",
      "|    total_timesteps      | 1934336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3120083e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.79e+05      |\n",
      "|    n_updates            | 44110         |\n",
      "|    policy_gradient_loss | -5.78e-06     |\n",
      "|    reward               | -63.024498    |\n",
      "|    value_loss           | 3.59e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1074\n",
      "Episode: 1075\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1890          |\n",
      "|    time_elapsed         | 7855          |\n",
      "|    total_timesteps      | 1935360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.5448846e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.25e+05      |\n",
      "|    n_updates            | 44120         |\n",
      "|    policy_gradient_loss | 3.69e-06      |\n",
      "|    reward               | -12.310847    |\n",
      "|    value_loss           | 1.45e+06      |\n",
      "-------------------------------------------\n",
      "Episode: 1076\n",
      "Current company: ['IBM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699587.10\n",
      "total_reward: -300412.90\n",
      "total_cost: 583285.95\n",
      "total_trades: 623\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1891          |\n",
      "|    time_elapsed         | 7860          |\n",
      "|    total_timesteps      | 1936384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5146757e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.895        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3e+04         |\n",
      "|    n_updates            | 44130         |\n",
      "|    policy_gradient_loss | -0.000121     |\n",
      "|    reward               | -11.345057    |\n",
      "|    value_loss           | 6.02e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1892          |\n",
      "|    time_elapsed         | 7864          |\n",
      "|    total_timesteps      | 1937408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0323321e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.898        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.82e+05      |\n",
      "|    n_updates            | 44140         |\n",
      "|    policy_gradient_loss | -1.26e-05     |\n",
      "|    reward               | -71.678444    |\n",
      "|    value_loss           | 3.65e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1077\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1893          |\n",
      "|    time_elapsed         | 7869          |\n",
      "|    total_timesteps      | 1938432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7689537e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.9          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.63e+05      |\n",
      "|    n_updates            | 44150         |\n",
      "|    policy_gradient_loss | -4.83e-05     |\n",
      "|    reward               | 11.943911     |\n",
      "|    value_loss           | 3.27e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1894          |\n",
      "|    time_elapsed         | 7873          |\n",
      "|    total_timesteps      | 1939456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8348295e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.9          |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.31e+05      |\n",
      "|    n_updates            | 44160         |\n",
      "|    policy_gradient_loss | -7.4e-05      |\n",
      "|    reward               | -20.535099    |\n",
      "|    value_loss           | 1.26e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1895         |\n",
      "|    time_elapsed         | 7877         |\n",
      "|    total_timesteps      | 1940480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.339009e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.901       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.15e+05     |\n",
      "|    n_updates            | 44170        |\n",
      "|    policy_gradient_loss | -5.88e-06    |\n",
      "|    reward               | -31.448835   |\n",
      "|    value_loss           | 2.31e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1078\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1896          |\n",
      "|    time_elapsed         | 7882          |\n",
      "|    total_timesteps      | 1941504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8384308e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.901        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.26e+04      |\n",
      "|    n_updates            | 44180         |\n",
      "|    policy_gradient_loss | -3.25e-05     |\n",
      "|    reward               | -23.098188    |\n",
      "|    value_loss           | 6.52e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1079\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1897         |\n",
      "|    time_elapsed         | 7886         |\n",
      "|    total_timesteps      | 1942528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.722418e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.93e+05     |\n",
      "|    n_updates            | 44190        |\n",
      "|    policy_gradient_loss | 3.8e-05      |\n",
      "|    reward               | -14.165655   |\n",
      "|    value_loss           | 3.87e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1898          |\n",
      "|    time_elapsed         | 7891          |\n",
      "|    total_timesteps      | 1943552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7800283e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.9          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.69e+04      |\n",
      "|    n_updates            | 44200         |\n",
      "|    policy_gradient_loss | -1e-05        |\n",
      "|    reward               | -52.150795    |\n",
      "|    value_loss           | 1.14e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1080\n",
      "Current company: ['HON']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 697894.08\n",
      "total_reward: -302105.92\n",
      "total_cost: 1155860.59\n",
      "total_trades: 1113\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1899         |\n",
      "|    time_elapsed         | 7895         |\n",
      "|    total_timesteps      | 1944576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.939487e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.901       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.6e+04      |\n",
      "|    n_updates            | 44210        |\n",
      "|    policy_gradient_loss | 8.73e-06     |\n",
      "|    reward               | -17.998856   |\n",
      "|    value_loss           | 1.12e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1081\n",
      "Episode: 1082\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1900         |\n",
      "|    time_elapsed         | 7900         |\n",
      "|    total_timesteps      | 1945600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.335337e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.901       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.87e+05     |\n",
      "|    n_updates            | 44220        |\n",
      "|    policy_gradient_loss | -3.57e-06    |\n",
      "|    reward               | -27.897255   |\n",
      "|    value_loss           | 1.37e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1901          |\n",
      "|    time_elapsed         | 7904          |\n",
      "|    total_timesteps      | 1946624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011599122 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.9          |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.63e+04      |\n",
      "|    n_updates            | 44230         |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    reward               | -67.35407     |\n",
      "|    value_loss           | 3.26e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1083\n",
      "Episode: 1084\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 689821.12\n",
      "total_reward: -310178.88\n",
      "total_cost: 154729.15\n",
      "total_trades: 181\n",
      "=================================\n",
      "Episode: 1085\n",
      "Episode: 1086\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1902          |\n",
      "|    time_elapsed         | 7909          |\n",
      "|    total_timesteps      | 1947648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012249866 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.897        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.04e+05      |\n",
      "|    n_updates            | 44240         |\n",
      "|    policy_gradient_loss | -0.000544     |\n",
      "|    reward               | -6.13669      |\n",
      "|    value_loss           | 2.11e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1903         |\n",
      "|    time_elapsed         | 7913         |\n",
      "|    total_timesteps      | 1948672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.074408e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.895       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.43e+04     |\n",
      "|    n_updates            | 44250        |\n",
      "|    policy_gradient_loss | -0.000326    |\n",
      "|    reward               | -47.315098   |\n",
      "|    value_loss           | 8.87e+04     |\n",
      "------------------------------------------\n",
      "Episode: 1087\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1904          |\n",
      "|    time_elapsed         | 7917          |\n",
      "|    total_timesteps      | 1949696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6804162e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.892        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.18e+04      |\n",
      "|    n_updates            | 44260         |\n",
      "|    policy_gradient_loss | 2.85e-05      |\n",
      "|    reward               | -19.776154    |\n",
      "|    value_loss           | 1.04e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1088\n",
      "Current company: ['DIS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1324726.83\n",
      "total_reward: 324726.83\n",
      "total_cost: 129187.10\n",
      "total_trades: 131\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1905          |\n",
      "|    time_elapsed         | 7922          |\n",
      "|    total_timesteps      | 1950720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9865187e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.29e+05      |\n",
      "|    n_updates            | 44270         |\n",
      "|    policy_gradient_loss | -8.57e-06     |\n",
      "|    reward               | -49.286118    |\n",
      "|    value_loss           | 8.58e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1906          |\n",
      "|    time_elapsed         | 7926          |\n",
      "|    total_timesteps      | 1951744       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0489173e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.891        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.48e+04      |\n",
      "|    n_updates            | 44280         |\n",
      "|    policy_gradient_loss | -5.38e-06     |\n",
      "|    reward               | -90.62994     |\n",
      "|    value_loss           | 1.9e+05       |\n",
      "-------------------------------------------\n",
      "Episode: 1089\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1907         |\n",
      "|    time_elapsed         | 7931         |\n",
      "|    total_timesteps      | 1952768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.514624e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.891       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.88e+05     |\n",
      "|    n_updates            | 44290        |\n",
      "|    policy_gradient_loss | 6.92e-06     |\n",
      "|    reward               | -6.30184     |\n",
      "|    value_loss           | 5.76e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1090\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1908         |\n",
      "|    time_elapsed         | 7936         |\n",
      "|    total_timesteps      | 1953792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.826005e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.892       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.55e+05     |\n",
      "|    n_updates            | 44300        |\n",
      "|    policy_gradient_loss | -2.52e-05    |\n",
      "|    reward               | -6.860653    |\n",
      "|    value_loss           | 1.31e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1909          |\n",
      "|    time_elapsed         | 7941          |\n",
      "|    total_timesteps      | 1954816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2701064e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.892        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39e+05      |\n",
      "|    n_updates            | 44310         |\n",
      "|    policy_gradient_loss | 3.85e-07      |\n",
      "|    reward               | 0.57115644    |\n",
      "|    value_loss           | 2.79e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1910          |\n",
      "|    time_elapsed         | 7946          |\n",
      "|    total_timesteps      | 1955840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2658071e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.893        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.48e+03      |\n",
      "|    n_updates            | 44320         |\n",
      "|    policy_gradient_loss | -5.84e-05     |\n",
      "|    reward               | -55.0015      |\n",
      "|    value_loss           | 8.95e+03      |\n",
      "-------------------------------------------\n",
      "Episode: 1091\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1911         |\n",
      "|    time_elapsed         | 7951         |\n",
      "|    total_timesteps      | 1956864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.645708e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.04e+05     |\n",
      "|    n_updates            | 44330        |\n",
      "|    policy_gradient_loss | 3.08e-05     |\n",
      "|    reward               | -21.602715   |\n",
      "|    value_loss           | 2.09e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1092\n",
      "Current company: ['AMGN']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 690694.55\n",
      "total_reward: -309305.45\n",
      "total_cost: 563301.59\n",
      "total_trades: 621\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1912          |\n",
      "|    time_elapsed         | 7956          |\n",
      "|    total_timesteps      | 1957888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8365681e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.898        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.62e+05      |\n",
      "|    n_updates            | 44340         |\n",
      "|    policy_gradient_loss | -3.22e-05     |\n",
      "|    reward               | -1.563127     |\n",
      "|    value_loss           | 3.25e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1913          |\n",
      "|    time_elapsed         | 7961          |\n",
      "|    total_timesteps      | 1958912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6012928e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.899        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.61e+05      |\n",
      "|    n_updates            | 44350         |\n",
      "|    policy_gradient_loss | -1.34e-05     |\n",
      "|    reward               | -7.835264     |\n",
      "|    value_loss           | 3.22e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1914          |\n",
      "|    time_elapsed         | 7965          |\n",
      "|    total_timesteps      | 1959936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7691287e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.9          |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.53e+04      |\n",
      "|    n_updates            | 44360         |\n",
      "|    policy_gradient_loss | -0.000203     |\n",
      "|    reward               | -71.69428     |\n",
      "|    value_loss           | 5.05e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1093\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1915         |\n",
      "|    time_elapsed         | 7969         |\n",
      "|    total_timesteps      | 1960960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.527206e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.902       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.67e+05     |\n",
      "|    n_updates            | 44370        |\n",
      "|    policy_gradient_loss | 1.51e-06     |\n",
      "|    reward               | -6.1519485   |\n",
      "|    value_loss           | 3.35e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1916          |\n",
      "|    time_elapsed         | 7973          |\n",
      "|    total_timesteps      | 1961984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5855767e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.903        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.98e+05      |\n",
      "|    n_updates            | 44380         |\n",
      "|    policy_gradient_loss | 4.96e-05      |\n",
      "|    reward               | -0.13343641   |\n",
      "|    value_loss           | 9.97e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 1917         |\n",
      "|    time_elapsed         | 7978         |\n",
      "|    total_timesteps      | 1963008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.167699e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.903       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.4e+04      |\n",
      "|    n_updates            | 44390        |\n",
      "|    policy_gradient_loss | -8.25e-06    |\n",
      "|    reward               | 5.375681     |\n",
      "|    value_loss           | 8.8e+04      |\n",
      "------------------------------------------\n",
      "Episode: 1094\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1918          |\n",
      "|    time_elapsed         | 7982          |\n",
      "|    total_timesteps      | 1964032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6237914e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.903        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.64e+04      |\n",
      "|    n_updates            | 44400         |\n",
      "|    policy_gradient_loss | -7.95e-05     |\n",
      "|    reward               | -37.515213    |\n",
      "|    value_loss           | 7.29e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1095\n",
      "Episode: 1096\n",
      "Current company: ['CSCO']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 696561.65\n",
      "total_reward: -303438.35\n",
      "total_cost: 53402.84\n",
      "total_trades: 65\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1919          |\n",
      "|    time_elapsed         | 7987          |\n",
      "|    total_timesteps      | 1965056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7745416e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.905        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.46e+05      |\n",
      "|    n_updates            | 44410         |\n",
      "|    policy_gradient_loss | 5.14e-05      |\n",
      "|    reward               | -13.870189    |\n",
      "|    value_loss           | 6.92e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1920          |\n",
      "|    time_elapsed         | 7991          |\n",
      "|    total_timesteps      | 1966080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7311187e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.905        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.76e+05      |\n",
      "|    n_updates            | 44420         |\n",
      "|    policy_gradient_loss | -3.53e-06     |\n",
      "|    reward               | -62.581112    |\n",
      "|    value_loss           | 3.51e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1097\n",
      "Episode: 1098\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 1921          |\n",
      "|    time_elapsed         | 7996          |\n",
      "|    total_timesteps      | 1967104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8475264e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.906        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.42e+05      |\n",
      "|    n_updates            | 44430         |\n",
      "|    policy_gradient_loss | -7.24e-06     |\n",
      "|    reward               | -41.80593     |\n",
      "|    value_loss           | 2.85e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1099\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1922          |\n",
      "|    time_elapsed         | 8000          |\n",
      "|    total_timesteps      | 1968128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1617667e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.906        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.1e+05       |\n",
      "|    n_updates            | 44440         |\n",
      "|    policy_gradient_loss | -8.51e-06     |\n",
      "|    reward               | -37.626892    |\n",
      "|    value_loss           | 2.21e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1923         |\n",
      "|    time_elapsed         | 8004         |\n",
      "|    total_timesteps      | 1969152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.250116e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.907       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.44e+04     |\n",
      "|    n_updates            | 44450        |\n",
      "|    policy_gradient_loss | -0.000184    |\n",
      "|    reward               | -69.73947    |\n",
      "|    value_loss           | 6.89e+04     |\n",
      "------------------------------------------\n",
      "Episode: 1100\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699823.43\n",
      "total_reward: -300176.57\n",
      "total_cost: 982241.91\n",
      "total_trades: 1000\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1924         |\n",
      "|    time_elapsed         | 8009         |\n",
      "|    total_timesteps      | 1970176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.575175e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.908       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.91e+05     |\n",
      "|    n_updates            | 44460        |\n",
      "|    policy_gradient_loss | 7.37e-05     |\n",
      "|    reward               | -35.642223   |\n",
      "|    value_loss           | 5.82e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1101\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 1925        |\n",
      "|    time_elapsed         | 8013        |\n",
      "|    total_timesteps      | 1971200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.43079e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.909      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.53e+05    |\n",
      "|    n_updates            | 44470       |\n",
      "|    policy_gradient_loss | 1.86e-05    |\n",
      "|    reward               | -34.18996   |\n",
      "|    value_loss           | 7.06e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 1102\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1926          |\n",
      "|    time_elapsed         | 8019          |\n",
      "|    total_timesteps      | 1972224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1037337e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.909        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.29e+05      |\n",
      "|    n_updates            | 44480         |\n",
      "|    policy_gradient_loss | -3.92e-05     |\n",
      "|    reward               | 14.637373     |\n",
      "|    value_loss           | 2.58e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1927         |\n",
      "|    time_elapsed         | 8023         |\n",
      "|    total_timesteps      | 1973248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.499607e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.909       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.03e+05     |\n",
      "|    n_updates            | 44490        |\n",
      "|    policy_gradient_loss | -8.32e-05    |\n",
      "|    reward               | -27.39177    |\n",
      "|    value_loss           | 4.06e+05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 245            |\n",
      "|    iterations           | 1928           |\n",
      "|    time_elapsed         | 8028           |\n",
      "|    total_timesteps      | 1974272        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.31238485e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | -0.911         |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 1.76e+05       |\n",
      "|    n_updates            | 44500          |\n",
      "|    policy_gradient_loss | 3.44e-05       |\n",
      "|    reward               | -78.92052      |\n",
      "|    value_loss           | 3.53e+05       |\n",
      "--------------------------------------------\n",
      "Episode: 1103\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1929          |\n",
      "|    time_elapsed         | 8032          |\n",
      "|    total_timesteps      | 1975296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9031577e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.912        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.23e+05      |\n",
      "|    n_updates            | 44510         |\n",
      "|    policy_gradient_loss | -1.34e-05     |\n",
      "|    reward               | -32.07401     |\n",
      "|    value_loss           | 4.47e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1930          |\n",
      "|    time_elapsed         | 8036          |\n",
      "|    total_timesteps      | 1976320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7097372e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.17e+04      |\n",
      "|    n_updates            | 44520         |\n",
      "|    policy_gradient_loss | -0.000198     |\n",
      "|    reward               | -63.73557     |\n",
      "|    value_loss           | 1.03e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1104\n",
      "Current company: ['UNH']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1380702.72\n",
      "total_reward: 380702.72\n",
      "total_cost: 1327493.37\n",
      "total_trades: 1254\n",
      "=================================\n",
      "Episode: 1105\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1931          |\n",
      "|    time_elapsed         | 8041          |\n",
      "|    total_timesteps      | 1977344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2757852e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.908        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.83e+05      |\n",
      "|    n_updates            | 44530         |\n",
      "|    policy_gradient_loss | -0.000209     |\n",
      "|    reward               | -18.720263    |\n",
      "|    value_loss           | 3.66e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1932         |\n",
      "|    time_elapsed         | 8045         |\n",
      "|    total_timesteps      | 1978368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.324976e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.906       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.3e+05      |\n",
      "|    n_updates            | 44540        |\n",
      "|    policy_gradient_loss | 2e-06        |\n",
      "|    reward               | -58.622234   |\n",
      "|    value_loss           | 6.61e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1933         |\n",
      "|    time_elapsed         | 8049         |\n",
      "|    total_timesteps      | 1979392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.487826e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.905       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.09e+05     |\n",
      "|    n_updates            | 44550        |\n",
      "|    policy_gradient_loss | 1.01e-05     |\n",
      "|    reward               | -114.812004  |\n",
      "|    value_loss           | 2.23e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1106\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1934          |\n",
      "|    time_elapsed         | 8054          |\n",
      "|    total_timesteps      | 1980416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2572931e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.905        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.43e+05      |\n",
      "|    n_updates            | 44560         |\n",
      "|    policy_gradient_loss | -1.18e-05     |\n",
      "|    reward               | -17.080496    |\n",
      "|    value_loss           | 1.09e+06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 1935        |\n",
      "|    time_elapsed         | 8058        |\n",
      "|    total_timesteps      | 1981440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.33765e-07 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.905      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.68e+04    |\n",
      "|    n_updates            | 44570       |\n",
      "|    policy_gradient_loss | -1.18e-05   |\n",
      "|    reward               | -40.41374   |\n",
      "|    value_loss           | 1.75e+05    |\n",
      "-----------------------------------------\n",
      "Episode: 1107\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1936          |\n",
      "|    time_elapsed         | 8063          |\n",
      "|    total_timesteps      | 1982464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4823544e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.906        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.06e+04      |\n",
      "|    n_updates            | 44580         |\n",
      "|    policy_gradient_loss | -4.48e-05     |\n",
      "|    reward               | -9.588599     |\n",
      "|    value_loss           | 6.14e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1937          |\n",
      "|    time_elapsed         | 8067          |\n",
      "|    total_timesteps      | 1983488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5886416e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.907        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.7e+05       |\n",
      "|    n_updates            | 44590         |\n",
      "|    policy_gradient_loss | 6.67e-06      |\n",
      "|    reward               | -31.03667     |\n",
      "|    value_loss           | 7.4e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1938         |\n",
      "|    time_elapsed         | 8071         |\n",
      "|    total_timesteps      | 1984512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.651746e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.909       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.5e+04      |\n",
      "|    n_updates            | 44600        |\n",
      "|    policy_gradient_loss | -5.48e-05    |\n",
      "|    reward               | -100.34407   |\n",
      "|    value_loss           | 3.02e+04     |\n",
      "------------------------------------------\n",
      "Episode: 1108\n",
      "Current company: ['MMM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 677323.62\n",
      "total_reward: -322676.38\n",
      "total_cost: 1104885.44\n",
      "total_trades: 1087\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1939          |\n",
      "|    time_elapsed         | 8076          |\n",
      "|    total_timesteps      | 1985536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9118687e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.91         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.78e+05      |\n",
      "|    n_updates            | 44610         |\n",
      "|    policy_gradient_loss | -8.14e-05     |\n",
      "|    reward               | -36.376034    |\n",
      "|    value_loss           | 7.57e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1940          |\n",
      "|    time_elapsed         | 8080          |\n",
      "|    total_timesteps      | 1986560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5691697e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.911        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.21e+05      |\n",
      "|    n_updates            | 44620         |\n",
      "|    policy_gradient_loss | -1.61e-05     |\n",
      "|    reward               | 47.83628      |\n",
      "|    value_loss           | 6.42e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1109\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1941          |\n",
      "|    time_elapsed         | 8084          |\n",
      "|    total_timesteps      | 1987584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5988283e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.913        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.17e+04      |\n",
      "|    n_updates            | 44630         |\n",
      "|    policy_gradient_loss | -0.000139     |\n",
      "|    reward               | -2.5718842    |\n",
      "|    value_loss           | 1.43e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1942          |\n",
      "|    time_elapsed         | 8088          |\n",
      "|    total_timesteps      | 1988608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2225507e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.916        |\n",
      "|    explained_variance   | 0.0805        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.52e+05      |\n",
      "|    n_updates            | 44640         |\n",
      "|    policy_gradient_loss | -6.44e-05     |\n",
      "|    reward               | -22.579296    |\n",
      "|    value_loss           | 9.05e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1943          |\n",
      "|    time_elapsed         | 8092          |\n",
      "|    total_timesteps      | 1989632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4065375e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.993        |\n",
      "|    explained_variance   | 0.924         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.61e+04      |\n",
      "|    n_updates            | 44650         |\n",
      "|    policy_gradient_loss | 1.75e-05      |\n",
      "|    reward               | -58.42901     |\n",
      "|    value_loss           | 7.39e+04      |\n",
      "-------------------------------------------\n",
      "Episode: 1110\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1944          |\n",
      "|    time_elapsed         | 8097          |\n",
      "|    total_timesteps      | 1990656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1526281e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.917        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.63e+05      |\n",
      "|    n_updates            | 44660         |\n",
      "|    policy_gradient_loss | -3.4e-05      |\n",
      "|    reward               | 16.272099     |\n",
      "|    value_loss           | 3.27e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1945         |\n",
      "|    time_elapsed         | 8101         |\n",
      "|    total_timesteps      | 1991680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.545211e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.916       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.87e+05     |\n",
      "|    n_updates            | 44670        |\n",
      "|    policy_gradient_loss | -6.18e-05    |\n",
      "|    reward               | -57.64781    |\n",
      "|    value_loss           | 5.75e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1946          |\n",
      "|    time_elapsed         | 8105          |\n",
      "|    total_timesteps      | 1992704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2844837e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.915        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.42e+04      |\n",
      "|    n_updates            | 44680         |\n",
      "|    policy_gradient_loss | -2.19e-05     |\n",
      "|    reward               | -99.161606    |\n",
      "|    value_loss           | 1.69e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1111\n",
      "Episode: 1112\n",
      "Current company: ['JPM']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694957.19\n",
      "total_reward: -305042.81\n",
      "total_cost: 55874.03\n",
      "total_trades: 61\n",
      "=================================\n",
      "Episode: 1113\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1947          |\n",
      "|    time_elapsed         | 8111          |\n",
      "|    total_timesteps      | 1993728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2613829e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.915        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.63e+05      |\n",
      "|    n_updates            | 44690         |\n",
      "|    policy_gradient_loss | 1.64e-05      |\n",
      "|    reward               | -22.581161    |\n",
      "|    value_loss           | 1.33e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1948         |\n",
      "|    time_elapsed         | 8115         |\n",
      "|    total_timesteps      | 1994752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.823079e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.16e+05     |\n",
      "|    n_updates            | 44700        |\n",
      "|    policy_gradient_loss | -8.83e-05    |\n",
      "|    reward               | -60.458393   |\n",
      "|    value_loss           | 6.32e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1949          |\n",
      "|    time_elapsed         | 8119          |\n",
      "|    total_timesteps      | 1995776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2238237e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.914        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.26e+05      |\n",
      "|    n_updates            | 44710         |\n",
      "|    policy_gradient_loss | 3.18e-05      |\n",
      "|    reward               | -87.9676      |\n",
      "|    value_loss           | 2.53e+05      |\n",
      "-------------------------------------------\n",
      "Episode: 1114\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1950         |\n",
      "|    time_elapsed         | 8123         |\n",
      "|    total_timesteps      | 1996800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.452886e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.68e+05     |\n",
      "|    n_updates            | 44720        |\n",
      "|    policy_gradient_loss | 1.44e-07     |\n",
      "|    reward               | -37.957104   |\n",
      "|    value_loss           | 1.14e+06     |\n",
      "------------------------------------------\n",
      "Episode: 1115\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1951         |\n",
      "|    time_elapsed         | 8128         |\n",
      "|    total_timesteps      | 1997824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.660128e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.69e+05     |\n",
      "|    n_updates            | 44730        |\n",
      "|    policy_gradient_loss | -2.86e-05    |\n",
      "|    reward               | -7.603168    |\n",
      "|    value_loss           | 3.39e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1116\n",
      "Current company: ['GS']\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694280.39\n",
      "total_reward: -305719.61\n",
      "total_cost: 157210.99\n",
      "total_trades: 171\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 1952         |\n",
      "|    time_elapsed         | 8133         |\n",
      "|    total_timesteps      | 1998848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.806804e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.915       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03e+05     |\n",
      "|    n_updates            | 44740        |\n",
      "|    policy_gradient_loss | 2.77e-06     |\n",
      "|    reward               | -52.999775   |\n",
      "|    value_loss           | 8.06e+05     |\n",
      "------------------------------------------\n",
      "Episode: 1117\n",
      "Episode: 1118\n",
      "Episode: 1119\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1953          |\n",
      "|    time_elapsed         | 8137          |\n",
      "|    total_timesteps      | 1999872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5533373e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.915        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.09e+04      |\n",
      "|    n_updates            | 44750         |\n",
      "|    policy_gradient_loss | -3.31e-05     |\n",
      "|    reward               | 2.435416      |\n",
      "|    value_loss           | 1.22e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 245           |\n",
      "|    iterations           | 1954          |\n",
      "|    time_elapsed         | 8142          |\n",
      "|    total_timesteps      | 2000896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4835678e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.915        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.47e+04      |\n",
      "|    n_updates            | 44760         |\n",
      "|    policy_gradient_loss | -6.28e-05     |\n",
      "|    reward               | -5.9965158    |\n",
      "|    value_loss           | 6.97e+04      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  trained_model\n",
    "except NameError:\n",
    "    trained_ppo = PPO(\"MlpPolicy\", env_train,n_steps=1024,ent_coef=0.01,learning_rate=0.00025,batch_size=2048,clip_range=0.1,\n",
    "                      policy_kwargs=policy_kwargs,tensorboard_log=TENSORBOARD_LOG_DIR + \"/test_ppo\",verbose=1)\n",
    "    trained_ppo.learn(total_timesteps=total_training_step,tb_log_name='ppo',callback=TensorboardCallback())\n",
    "else:\n",
    "    trained_model.env = env_train\n",
    "    trained_ppo = trained_model.learn(total_timesteps=total_training_step,tb_log_name='ppo',callback=TensorboardCallback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_ddpg = DRLAgent(env = env_train)\n",
    "# DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": episode_length, \"learning_rate\": 0.001}\n",
    "# model_ddpg = agent_ddpg.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS,tensorboard_log=TENSORBOARD_LOG_DIR + \"/test_ddpg_tensorboard/\")\n",
    "\n",
    "# # set up logger\n",
    "# tmp_path = TENSORBOARD_LOG_DIR + '/ddpg'\n",
    "# new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "# # Set new logger\n",
    "# model_sac.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the training log just show up when total_timesteps higher than 15.000\n",
    "# trained_ddpg = agent_ddpg.train_model(model=model_ddpg,\n",
    "#                              tb_log_name='ddpg',\n",
    "#                              total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "# # The noise objects for DDPG\n",
    "# n_actions = env_train.action_space.shape[-1]\n",
    "# action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# # Train the agent\n",
    "# trained_ddpg = DDPG(\"MlpPolicy\", env_train, action_noise=action_noise, verbose=1)\n",
    "# trained_ddpg.learn(total_timesteps=total_timesteps, log_interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_length = len(e_train_gym.df) + 1\n",
    "# episode_amount = 4\n",
    "# total_training_step = episode_length*episode_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 2048, 'buffer_size': 58204, 'learning_rate': 0.0003, 'learning_starts': 58204, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# agent_sac = DRLAgent(env = env_train)\n",
    "# SAC_PARAMS = {\n",
    "#     \"batch_size\": 2048,\n",
    "#     \"buffer_size\": episode_length,\n",
    "#     \"learning_rate\": 0.0003,\n",
    "#     \"learning_starts\": episode_length,\n",
    "#     \"ent_coef\": \"auto_0.1\",\n",
    "# }\n",
    "\n",
    "# model_sac = agent_sac.get_model(\"sac\",model_kwargs = SAC_PARAMS,tensorboard_log=TENSORBOARD_LOG_DIR + \"/test_sac/\")\n",
    "\n",
    "# # # set up logger\n",
    "# # tmp_path = TENSORBOARD_LOG_DIR + '/test_sac/sac_12'\n",
    "# # new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "# # # Set new logger\n",
    "# # model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# trained_sac = agent_sac.train_model(model=model_sac, \n",
    "#                              tb_log_name='sac',\n",
    "#                              total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_td3 = DRLAgent(env = env_train)\n",
    "# TD3_PARAMS = {\"batch_size\": 100, \n",
    "#               \"buffer_size\": 1000000, \n",
    "#               \"learning_rate\": 0.001}\n",
    "\n",
    "# model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_td3 = agent.train_model(model=model_td3, \n",
    "#                              tb_log_name='td3',\n",
    "#                              total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_a2c = DRLAgent(env = env_train)\n",
    "\n",
    "# A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "# model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_a2c = agent.train_model(model=model_a2c, \n",
    "#                                 tb_log_name='a2c',\n",
    "#                                 total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at the begining. We use the PPO model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2018-12 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = trade_data.reset_index(drop=True)\n",
    "\n",
    "# trade_data = data_split(processed_full, TEST_START_DATE, TEST_END_DATE)\n",
    "e_trade_gym = StockTradingEnv(df = trade_data, **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRL_prediction function allow testing the model using trading_data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRL_prediction(model, environment, deterministic=False):\n",
    "        \"\"\"make a prediction and get results\"\"\"\n",
    "        # test_env, test_obs = environment.get_sb_env()\n",
    "        # account_memory = None  # This help avoid unnecessary list creation\n",
    "        # actions_memory = None  # optimize memory consumption\n",
    "\n",
    "        test_obs = environment.reset()[0]\n",
    "        # max_steps = len(environment.df.index.unique()) - 1\n",
    "\n",
    "        for i in range(0,len(environment.df)):\n",
    "            action = model.predict(np.asarray(test_obs), deterministic=deterministic)\n",
    "            test_obs,reward,terminal,truncated,info = environment.step(action)\n",
    "            # test_obs, rewards, dones, info = test_env.step(action)\n",
    "\n",
    "            # if (i == max_steps - 1):  # more descriptive condition for early termination to clarify the logic\n",
    "            #     account_memory = environment.env_method(method_name=\"save_asset_memory\")\n",
    "            #     actions_memory = environment.env_method(method_name=\"save_action_memory\")\n",
    "\n",
    "            if terminal:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        return pd.DataFrame(e_trade_gym.asset_memory, columns=['account_value']), pd.DataFrame(e_trade_gym.actions_memory,columns=['actions','none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRL_prediction(model=trained_ppo, environment = e_trade_gym)\n",
    "\n",
    "# df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "#     model=trained_ddpg, \n",
    "#     environment = e_trade_gym)\n",
    "\n",
    "# df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "\n",
    "# df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "#     model=trained_a2c, \n",
    "#     environment = e_trade_gym) if if_using_a2c else [None, None]\n",
    "\n",
    "# df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "#     model=trained_td3, \n",
    "#     environment = e_trade_gym) if if_using_td3 else [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_ppo.shape\n",
    "# df_account_value_ddpg.shape\n",
    "# df_account_value_sac.shape\n",
    "# df_account_value_td3.shape\n",
    "# df_account_value_a2c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo['date'] = trade_data.date\n",
    "# df_account_value_ddpg['date'] = trade_data.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1.127245e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1.129035e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1.128967e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1.126539e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1.126491e+06</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      account_value       date\n",
       "1135   1.127245e+06 2024-02-29\n",
       "1136   1.129035e+06 2024-02-29\n",
       "1137   1.128967e+06 2024-02-29\n",
       "1138   1.126539e+06 2024-02-29\n",
       "1139   1.126491e+06 2024-02-29"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_ppo.tail()\n",
    "# df_account_value_ddpg.tail()\n",
    "# df_account_value_sac.tail()\n",
    "# df_account_value_td3.tail()\n",
    "# df_account_value_a2c.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_actions_ppo.actions.unique()\n",
    "# df_actions_ddpg.head()\n",
    "# df_actions_sac.head()\n",
    "# df_actions_td3.head()\n",
    "# df_actions_a2c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actions</th>\n",
       "      <th>none</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.9013582]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1.0]</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actions  none       date\n",
       "0         [1.0]  None 2021-01-31\n",
       "1        [-1.0]  None 2021-01-31\n",
       "2        [-1.0]  None 2021-01-31\n",
       "3  [-0.9013582]  None 2021-01-31\n",
       "4        [-1.0]  None 2021-01-31"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_ppo['date'] = trade_data.date\n",
    "df_actions_ppo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>9.990001e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>9.174570e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>9.603747e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>9.505173e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>1.049017e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  account_value\n",
       "0 2021-01-31   9.990001e+05\n",
       "1 2021-02-28   9.174570e+05\n",
       "2 2021-03-31   9.603747e+05\n",
       "3 2021-04-30   9.505173e+05\n",
       "4 2021-05-31   1.049017e+06"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value = pd.DataFrame(df_account_value_ppo.date.unique())\n",
    "df_account_value.columns = ['date']\n",
    "df_account_value['account_value'] = df_account_value.apply(lambda x: \\\n",
    "                                    df_account_value_ppo[df_account_value_ppo.date == x.date].iloc[-1].account_value, axis=1)\n",
    "df_account_value.head()\n",
    "\n",
    "# df_account_value = pd.DataFrame(df_account_value_ddpg.date.unique())\n",
    "# df_account_value.columns = ['date']\n",
    "# df_account_value['account_value'] = df_account_value.apply(lambda x: \\\n",
    "#                                     df_account_value_ddpg[df_account_value_ddpg.date == x.date].iloc[-1].account_value, axis=1)\n",
    "# df_account_value.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a missmatch between the quarterly computation of df_account_value and the daily frequency of the comparison datasets. We need to transform the df_account_value to a daily basis.\n",
    "To fill up the missing data, th **ffill** function effectively imputes values, providing the continous picture of account value trends until the next recorded change. However, for the entries preceding the first recorded change, we will use the **initial_amount**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>9.990001e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>9.174570e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>9.603747e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>9.505173e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>1.049017e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>1.048674e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>1.126485e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1.127625e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>1.126538e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>1.214924e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>1.162212e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>1.231293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>1.214851e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>1.203596e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>1.239295e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1.302839e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>1.326611e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>1.262456e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>1.271055e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>1.279077e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>1.271961e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>1.450595e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>1.608961e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>1.428349e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>1.350539e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1.270791e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>1.280473e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>1.288394e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>1.205204e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>1.253580e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>1.254508e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>1.227742e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>1.188535e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>1.201624e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1.300744e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1.324027e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>1.129046e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>1.126491e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>1.126491e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  account_value\n",
       "0  2021-01-31   9.990001e+05\n",
       "1  2021-02-28   9.174570e+05\n",
       "2  2021-03-31   9.603747e+05\n",
       "3  2021-04-30   9.505173e+05\n",
       "4  2021-05-31   1.049017e+06\n",
       "5  2021-06-30   1.048674e+06\n",
       "6  2021-07-31   1.126485e+06\n",
       "7  2021-08-31   1.127625e+06\n",
       "8  2021-09-30   1.126538e+06\n",
       "9  2021-10-31   1.214924e+06\n",
       "10 2021-11-30   1.162212e+06\n",
       "11 2021-12-31   1.231293e+06\n",
       "12 2022-01-31   1.214851e+06\n",
       "13 2022-02-28   1.203596e+06\n",
       "14 2022-03-31   1.239295e+06\n",
       "15 2022-04-30   1.302839e+06\n",
       "16 2022-05-31   1.326611e+06\n",
       "17 2022-06-30   1.262456e+06\n",
       "18 2022-07-31   1.271055e+06\n",
       "19 2022-08-31   1.279077e+06\n",
       "20 2022-09-30   1.271961e+06\n",
       "21 2022-10-31   1.450595e+06\n",
       "22 2022-11-30   1.608961e+06\n",
       "23 2022-12-31   1.428349e+06\n",
       "24 2023-01-31   1.350539e+06\n",
       "25 2023-02-28   1.270791e+06\n",
       "26 2023-03-31   1.280473e+06\n",
       "27 2023-04-30   1.288394e+06\n",
       "28 2023-05-31   1.205204e+06\n",
       "29 2023-06-30   1.253580e+06\n",
       "30 2023-07-31   1.254508e+06\n",
       "31 2023-08-31   1.227742e+06\n",
       "32 2023-09-30   1.188535e+06\n",
       "33 2023-10-31   1.201624e+06\n",
       "34 2023-11-30   1.300744e+06\n",
       "35 2023-12-31   1.324027e+06\n",
       "36 2024-01-31   1.129046e+06\n",
       "37 2024-02-29   1.126491e+06\n",
       "38 2024-03-31   1.126491e+06"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_account_value = pd.DataFrame(df.date.unique())\n",
    "daily_account_value.columns = ['date']\n",
    "daily_account_value['date'] = pd.to_datetime(daily_account_value.date)\n",
    "daily_account_value = daily_account_value.merge(df_account_value,how='left')\n",
    "daily_account_value.ffill(inplace=True)\n",
    "daily_account_value.fillna(env_kwargs[\"initial_amount\"],inplace=True)\n",
    "daily_account_value = daily_account_value[daily_account_value.date >= TEST_START_DATE]\n",
    "daily_account_value.reset_index(inplace=True,drop=True)\n",
    "daily_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9mKF7GGtj1g",
    "outputId": "99c5e5f8-2e3f-49c3-e5a6-4e66ed92e40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "\n",
      " ppo:\n",
      "Annual return          0.026679\n",
      "Cumulative returns     0.126491\n",
      "Annual volatility      0.157634\n",
      "Sharpe ratio           0.245803\n",
      "Calmar ratio           0.083626\n",
      "Stability              0.339569\n",
      "Max drawdown          -0.319024\n",
      "Omega ratio            1.195159\n",
      "Sortino ratio          0.373782\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.280696\n",
      "Daily value at risk   -0.019706\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "# now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "print(\"\\n ppo:\")\n",
    "perf_stats_all_ppo = backtest_stats(account_value=df_account_value_ppo)\n",
    "perf_stats_all_ppo = pd.DataFrame(perf_stats_all_ppo)\n",
    "# perf_stats_all_ppo.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_ppo_\"+now+'.csv')\n",
    "\n",
    "# print(\"\\n ddpg:\")\n",
    "# perf_stats_all_ddpg = backtest_stats(account_value=df_account_value_ddpg)\n",
    "# perf_stats_all_ddpg = pd.DataFrame(perf_stats_all_ddpg)\n",
    "# perf_stats_all_ddpg.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_ddpg_\"+now+'.csv')\n",
    "\n",
    "# print(\"\\n sac:\")\n",
    "# perf_stats_all_sac = backtest_stats(account_value=df_account_value_sac)\n",
    "# perf_stats_all_sac = pd.DataFrame(perf_stats_all_sac)\n",
    "#   perf_stats_all_sac.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_sac_\"+now+'.csv')\n",
    "\n",
    "#   print(\"\\n atd3:\")\n",
    "#   perf_stats_all_td3 = backtest_stats(account_value=df_account_value_td3)\n",
    "#   perf_stats_all_td3 = pd.DataFrame(perf_stats_all_td3)\n",
    "#   perf_stats_all_td3.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_td3_\"+now+'.csv')\n",
    "\n",
    "#   print(\"\\n a2c:\")\n",
    "#   perf_stats_all_a2c = backtest_stats(account_value=df_account_value_a2c)\n",
    "#   perf_stats_all_a2c = pd.DataFrame(perf_stats_all_a2c)\n",
    "#   perf_stats_all_a2c.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_a2c_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oyosyW7_tj1g",
    "outputId": "0e54f2d5-6057-4a14-c94a-5f2af26ad171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Annual return          0.089358\n",
      "Cumulative returns     0.316223\n",
      "Annual volatility      0.146547\n",
      "Sharpe ratio           0.658110\n",
      "Calmar ratio           0.407268\n",
      "Stability              0.108092\n",
      "Max drawdown          -0.219408\n",
      "Omega ratio            1.118655\n",
      "Sortino ratio          0.940026\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.003905\n",
      "Daily value at risk   -0.018081\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = TEST_START_DATE,\n",
    "        end = TEST_END_DATE)\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTest with DJIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2021-01-31</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2024-03-31</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>1</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>117.294%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>12.762%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>93.886%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-29.986%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-11.341%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.99</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.16</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.84</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.34</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.25</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x7200 with 13 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "\n",
    "backtest_plot(daily_account_value, \n",
    "            baseline_ticker = '^DJI', \n",
    "            baseline_start = TEST_START_DATE,\n",
    "            baseline_end = TEST_END_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Buy&Hold Strategy\n",
    "pass in df_account_value, this information is stored in env class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTest with Buy&Hold Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(DOW_30_TICKER)\n",
    "test_portfolio = DOW_30_TICKER\n",
    "modify_fields = ['open','high','low','close']\n",
    "used_columns = ['date','close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock_test_ = get_baseline(\n",
    "#         ticker='AXP', \n",
    "#         start = TEST_START_DATE,\n",
    "#         end = TEST_END_DATE)\n",
    "# df_stock_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for field in modify_fields:\n",
    "#     df_stock_test_[field] = df_stock_test_[field]/df_stock_test_.iloc[0][field]/len(test_portfolio)\n",
    "# df_stock_test_ = df_stock_test_[used_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "oBQx4bVQFi-a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Shape of DataFrame:  (809, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (809, 8)\n",
      "Annual return           0.415405\n",
      "Cumulative returns      0.055238\n",
      "Annual volatility       0.142013\n",
      "Sharpe ratio            2.581803\n",
      "Calmar ratio           10.349362\n",
      "Stability               0.407411\n",
      "Max drawdown           -0.040138\n",
      "Omega ratio             1.575704\n",
      "Sortino ratio           3.763793\n",
      "Skew                         NaN\n",
      "Kurtosis                     NaN\n",
      "Tail ratio              0.848874\n",
      "Daily value at risk    -0.016437\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "shape = daily_account_value.shape\n",
    "df_hold_ = pd.DataFrame(0,index=range(shape[0]), columns=range(shape[1]))\n",
    "df_hold_.columns = used_columns\n",
    "df_hold_['date'] = daily_account_value.date\n",
    "\n",
    "for stock in test_portfolio:\n",
    "    df_stock_ = get_baseline(\n",
    "        ticker=stock, \n",
    "        start = TEST_START_DATE,\n",
    "        end = TEST_END_DATE)\n",
    "    # for field in modify_fields:\n",
    "    if len(df_stock_) < len(df_hold_):\n",
    "        final_row = df_stock_.iloc[-1]\n",
    "        new_rows = pd.DataFrame([final_row] * (len(df_hold_) - len(df_stock_)))\n",
    "        df_stock_ = pd.concat([df_stock_, new_rows], ignore_index=True)\n",
    "        \n",
    "        for i in range(0,len(df_stock_) < len(df_hold_)):\n",
    "            df_stock_.iloc[en(df_stock_)] = df_stock_.iloc[len(df_stock_-1)]\n",
    "    df_stock_['close'] = df_stock_['close']/df_stock_.iloc[0]['close']/len(test_portfolio)\n",
    "    df_hold_['close'] = df_hold_.close + df_stock_.close\n",
    "\n",
    "stats = backtest_stats(df_hold_, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model' calculation encompass the entire timeframe, including non-working days. To address this, we need to determine the most appropriate method to fill up the weekend plots, for example backfilling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hold_.date = pd.to_datetime(df_hold_['date'])\n",
    "# df_hold_ = pd.merge(df_account_value_ppo['date'],df_hold_,how='left')\n",
    "# df_hold_.bfill(inplace=True)\n",
    "# df_hold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_hold:                      hold\n",
      "date                    \n",
      "2021-01-31  1.000000e+06\n",
      "2021-02-28  1.006314e+06\n",
      "2021-03-31  1.021052e+06\n",
      "2021-04-30  1.029017e+06\n",
      "2021-05-31  1.030249e+06\n",
      "2021-06-30  1.029785e+06\n",
      "2021-07-31  1.033666e+06\n",
      "2021-08-31  1.035076e+06\n",
      "2021-09-30  1.035051e+06\n",
      "2021-10-31  1.026937e+06\n",
      "2021-11-30  1.030746e+06\n",
      "2021-12-31  1.039045e+06\n",
      "2022-01-31  1.038597e+06\n",
      "2022-02-28  1.029507e+06\n",
      "2022-03-31  1.028421e+06\n",
      "2022-04-30  1.027227e+06\n",
      "2022-05-31  1.009060e+06\n",
      "2022-06-30  1.018215e+06\n",
      "2022-07-31  9.973398e+05\n",
      "2022-08-31  1.004524e+06\n",
      "2022-09-30  1.018989e+06\n",
      "2022-10-31  1.020445e+06\n",
      "2022-11-30  1.033378e+06\n",
      "2022-12-31  1.038320e+06\n",
      "2023-01-31  1.046430e+06\n",
      "2023-02-28  1.044933e+06\n",
      "2023-03-31  1.047083e+06\n",
      "2023-04-30  1.047593e+06\n",
      "2023-05-31  1.049621e+06\n",
      "2023-06-30  1.051232e+06\n",
      "2023-07-31  1.054914e+06\n",
      "2023-08-31  1.050851e+06\n",
      "2023-09-30  1.052054e+06\n",
      "2023-10-31  1.054023e+06\n",
      "2023-11-30  1.055057e+06\n",
      "2023-12-31  1.069562e+06\n",
      "2024-01-31  1.051501e+06\n",
      "2024-02-29  1.034710e+06\n",
      "2024-03-31  1.055238e+06\n"
     ]
    }
   ],
   "source": [
    "df_hold = pd.DataFrame()\n",
    "df_hold['date'] = daily_account_value['date']\n",
    "df_hold['hold'] = df_hold_['close'] / df_hold_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "# print(\"df_hold: \", df_hold)\n",
    "# df_dji.to_csv(\"df_dji.csv\")\n",
    "df_hold = df_hold.set_index(df_hold.columns[0])\n",
    "print(\"df_hold: \", df_hold)\n",
    "# df_hold.to_csv(\"df_dji+.csv\")\n",
    "\n",
    "# df_account_value.to_csv('df_account_value.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to Buy&Hold===========\n",
      "result:                     stock          hold\n",
      "date                                  \n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "2021-01-31  1.000000e+06  1.000000e+06\n",
      "...                  ...           ...\n",
      "2024-02-29  1.380588e+06  1.034710e+06\n",
      "2024-02-29  1.380471e+06  1.034710e+06\n",
      "2024-02-29  1.380471e+06  1.034710e+06\n",
      "2024-02-29  1.380471e+06  1.034710e+06\n",
      "2024-02-29  1.380407e+06  1.034710e+06\n",
      "\n",
      "[1140 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to Buy&Hold===========\")\n",
    "df_result = pd.DataFrame({'date': df_account_value_ppo['date'], 'stock': df_account_value_ppo['account_value']})\n",
    "df_result = df_result.set_index('date')\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result = pd.merge(df_result, df_hold, left_index=True, right_index=True)\n",
    "print(\"result: \", result)\n",
    "# result.to_csv(\"result.csv\")\n",
    "result.columns = ['model', 'buy_and_hold']\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "# 8. Save and load model #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.1'></a>\n",
    "## 8.1 Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/FinRL-Tutorials-master/6-Binhlai_Testing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./trained_models/main_dow30_randomTic_discrete_256neu_ppo_5m_steps'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"./\"+TRAINED_MODEL_DIR+\"/main_dow30_randomTic_discrete_256neu_ppo_5m_steps\"\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 Save model as ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.onnx\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.policies import BasePolicy\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxableSB3Policy(th.nn.Module):\n",
    "    def __init__(self, policy: BasePolicy):\n",
    "        super().__init__()\n",
    "        self.policy = policy\n",
    "\n",
    "    def forward(self, observation: th.Tensor) -> Tuple[th.Tensor, th.Tensor, th.Tensor]:\n",
    "        # NOTE: Preprocessing is included, but postprocessing\n",
    "        # (clipping/inscaling actions) is not,\n",
    "        # If needed, you also need to transpose the images so that they are channel first\n",
    "        # use deterministic=False if you want to export the stochastic policy\n",
    "        # policy() returns `actions, values, log_prob` for PPO\n",
    "        return self.policy(observation, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_policy = OnnxableSB3Policy(trained_ppo.policy)\n",
    "observation_size = trained_ppo.observation_space.shape\n",
    "dummy_input = th.randn(1, *observation_size)\n",
    "\n",
    "th.onnx.export(\n",
    "    onnx_policy,\n",
    "    dummy_input,\n",
    "    \"sac_model_1200k_sac9.onnx\",\n",
    "    opset_version=17,\n",
    "    input_names=[\"input\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.2'></a>\n",
    "## 8.2 Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.2.1'></a>\n",
    "### 8.2.1 Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/GameProjects/DataScience/DeepReinforcementLearning/FinRL-Tutorials-master/6-Binhlai_Testing\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./trained_models/main_dow30_randomTic_discrete_256neu_ppo_3m_steps'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"./\"+TRAINED_MODEL_DIR+\"/main_dow30_randomTic_discrete_256neu_ppo_3m_steps\"\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = PPO.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continous training based on the previous model at [**Part5. Train DRL Agents**](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Establish the training environment using StockTradingEnv() class\n",
    "# agent = DRLAgent(env = env_train)\n",
    "# trained_model.env = env_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trained_ppo = agent.train_model(model=trained_model, \n",
    "#                              tb_log_name='ppo',\n",
    "#                              total_timesteps=total_training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = StockTradingEnv(df = trade_data, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_step = 1000\n",
    "test_result = []\n",
    "test_env.reset()\n",
    "for i in range(0,test_step):\n",
    "    observation = [test_env.state]\n",
    "    observation = np.array(observation).astype(np.float32)\n",
    "    actions, values, log_prob = ort_sess.run(None, {\"input\": observation})\n",
    "    result = test_env.step(actions)\n",
    "    test_result.append(result[1])\n",
    "    if result[2] == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 Load ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = \"all_in_one_ppo.onnx\"\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# # Check that the predictions are the same\n",
    "# with th.no_grad():\n",
    "#     print(model.policy(th.as_tensor(observation), deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = np.zeros((1, state_space)).astype(np.float32)\n",
    "ort_sess = ort.InferenceSession(onnx_path)\n",
    "actions, values, log_prob = ort_sess.run(None, {\"input\": observation})\n",
    "print(actions, values, log_prob)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
