{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e91c12-71bd-4b60-860f-8f8a2927fdb3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa4886b-62de-465b-a445-301d7a87dc7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiffusionPipeline, ControlNetModel\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatting_postprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m postprocess\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import copy\n",
    "import numpy\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from diffusers import DiffusionPipeline, ControlNetModel\n",
    "from matting_postprocess import postprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcba702-a3c6-4820-a057-24a5e09ecbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(single_res, input_image, ratio=0.95):\n",
    "    # Rescale and recenter\n",
    "    image_arr = numpy.array(input_image)\n",
    "    ret, mask = cv2.threshold(numpy.array(input_image.split()[-1]), 0, 255, cv2.THRESH_BINARY)\n",
    "    x, y, w, h = cv2.boundingRect(mask)\n",
    "    max_size = max(w, h)\n",
    "    side_len = int(max_size / ratio)\n",
    "    padded_image = numpy.zeros((side_len, side_len, 4), dtype=numpy.uint8)\n",
    "    center = side_len//2\n",
    "    padded_image[center-h//2:center-h//2+h, center-w//2:center-w//2+w] = image_arr[y:y+h, x:x+w]\n",
    "    rgba = Image.fromarray(padded_image).resize((single_res, single_res), Image.LANCZOS)\n",
    "    return rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8bf72-ca5a-4f17-8ac6-a80afc3df5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pipeline\n",
    "pipeline: DiffusionPipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"sudo-ai/zero123plus-v1.2\", custom_pipeline=\"sudo-ai/zero123plus-pipeline\",\n",
    "    torch_dtype=torch.float16, local_files_only=True\n",
    ")\n",
    "normal_pipeline = copy.copy(pipeline)\n",
    "normal_pipeline.add_controlnet(ControlNetModel.from_pretrained(\n",
    "    \"sudo-ai/controlnet-zp12-normal-gen-v1\", torch_dtype=torch.float16, local_files_only=True\n",
    "), conditioning_scale=1.0)\n",
    "pipeline.to(\"cuda:0\", torch.float16)\n",
    "normal_pipeline.to(\"cuda:0\", torch.float16)\n",
    "# Run the pipeline\n",
    "cond = Image.open(requests.get(\"https://d.skis.ltd/nrp/sample-data/10_cond.png\", stream=True).raw)\n",
    "# Optional: rescale input image if it occupies only a small region in input\n",
    "# cond = rescale(512, cond)\n",
    "# Generate 6 images\n",
    "genimg = pipeline(\n",
    "    cond,\n",
    "    prompt='', guidance_scale=4, num_inference_steps=75, width=640, height=960\n",
    ").images[0]\n",
    "# Generate normal image\n",
    "# We observe that a higher CFG scale (4) is more robust\n",
    "# but with CFG = 1 it is faster and is usually good enough for normal image\n",
    "# You can adjust to your needs\n",
    "normalimg = normal_pipeline(\n",
    "    cond, depth_image=genimg,\n",
    "    prompt='', guidance_scale=4, num_inference_steps=75, width=640, height=960\n",
    ").images[0]\n",
    "genimg, normalimg = postprocess(genimg, normalimg)\n",
    "genimg.save(\"colors.png\")\n",
    "normalimg.save(\"normals.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
